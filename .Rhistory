mtext(c("Head", "Tail"), side=3, adj=c(0.05, 0.95), line=-1)
legend("top", paste("Group", 1:pamcl$nc), col=colz, lty=1, bty="n", lwd=3, horiz=TRUE)
}
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, ", nsitesmf, " sites and both sexes combined.",
"  Fish are lined up by their noses.", h=3, w=6.5)
fig.grpdif <- function(title) {
plot(1:dim(med2)[1], med2$mdif, ylim=c(-1, 1)*max(amdif), las=1,
xlab="Truss  (r#)", ylab="Difference between scaled measures of group 1 and 2", main=title)
abline(h=0)
segments(1:dim(med2)[1], med2$mdif, 1:dim(med2)[1], 0)
}
if(pamcl$nc == 2) {
para("I calculated the median of each of the scaled measurements for each group.",
"  Then I looked at the difference between those medians to see which truss measurements",
" were the most different between the groups (Figure ", jvamiscenv$figcount, ").")
# median measures per group
med <- t(apply(subscmf, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesmf, "Sites, Both Sexes"))
figu("Difference in truss measurements between the cluster groups, ", nsitesmf, " sites and both sexes combined.", 
h=4, w=4)
}
para("I also looked at how the clustering would have proceeded if we had started with a single cluster of fish at each site.",
"  For this, I used agglomerative hierarchical clustering with the centroid method and the squared Euclidean distances (Figure ",
jvamiscenv$figcount, ".)")
cent <- apply(subscmf, 2, tapply, submf$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(submf$LS))
fig.dendro <- function() {
par(mar=c(4, 1, 0, 10))
plot(as.dendrogram(hc1), horiz=TRUE, xlab="Height", ylab="")
}
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, ", nsitesmf, " sites and both sexes combined.", h=8.5, w=4.4)
ks <- 1:nsitesm
pamcl <- pamk(data=subscm, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("The recommended number of clusters for males was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig <- function() fig.nclusters(title=paste(nsitesm, "Sites, Males"))
figu("Recommended number of clusters based on the optimum average silhouette width, males at ", nsitesm, " sites.", h=4, w=4)
both <- tab.prop(group, subm)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, males at ", nsitesm, " sites.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "lightblue", "darkblue")
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, males at ", nsitesm, " sites.", h=4, w=4)
medall <- apply(subm[, ltrussvars]/subm$TL, 2, median, na.rm=TRUE)
fcall <- fishpts(medall)[[2]]
medun <- t(apply(subm[, ltrussvars]/subm$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, males at ", nsitesm, " sites.",
"  Fish are lined up by their noses.", h=3, w=6.5)
if(pamcl$nc == 2) {
# median measures per group
med <- t(apply(subscm, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesm, "Sites, Males"))
figu("Difference in truss measurements between the cluster groups, males at ", nsitesm, " sites.", h=4, w=4)
}
cent <- apply(subscm, 2, tapply, subm$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(subm$LS))
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, males at ", nsitesm, " sites.", h=8.5, w=4.4)
males <- list(ks=ks, pamcl=pamcl, group=group, both=both, g=g, colz=colz, fc=fc, fcall=fcall, xyr=xyr, hc1=hc1)
ks <- 1:nsitesf
pamcl <- pamk(data=subscf, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("The recommended number of clusters for females was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig <- function() fig.nclusters(title=paste(nsitesf, "Sites, Females"))
figu("Recommended number of clusters based on the optimum average silhouette width, females at ", nsitesf, " sites.", h=4, w=4)
both <- tab.prop(group, subf)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, females at ", nsitesf, " sites.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "brown", "orange")
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, females at ", nsitesf, " sites.", h=4, w=4)
medall <- apply(subf[, ltrussvars]/subf$TL, 2, median, na.rm=TRUE)
fcall <- fishpts(medall)[[2]]
medun <- t(apply(subf[, ltrussvars]/subf$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, females at ", nsitesf, " sites.",
"  Fish are lined up by their noses.", h=3, w=6.5)
if(pamcl$nc == 2) {
# median measures per group
med <- t(apply(subscf, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesf, "Sites, Females"))
figu("Difference in residual (log transformed, size corrected, and scaled) truss measurements between the cluster groups,",
" females at ", nsitesf, " sites.", h=4, w=4)
}
cent <- apply(subscf, 2, tapply, subf$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(subf$LS))
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, females at ", nsitesf, " sites.", h=8.5, w=4.4)
females <- list(ks=ks, pamcl=pamcl, group=group, both=both, g=g, colz=colz, fc=fc, fcall=fcall, xyr=xyr, hc1=hc1)
medun.ms <- t(apply(subm[, ltrussvars]/subm$TL, 2, tapply, subm$LS, median, na.rm=TRUE))
medun.fs <- t(apply(subf[, ltrussvars]/subf$TL, 2, tapply, subf$LS, median, na.rm=TRUE))
medun.mu <- t(apply(subm[, ltrussvars], 2, tapply, subm$LS, median, na.rm=TRUE))
medun.fu <- t(apply(subf[, ltrussvars], 2, tapply, subf$LS, median, na.rm=TRUE))
fc.ms <- lapply(data.frame(medun.ms), function(x) fishpts(x)[[2]])
fc.fs <- lapply(data.frame(medun.fs), function(x) fishpts(x)[[2]])
fc.mu <- lapply(data.frame(medun.mu), function(x) fishpts(x)[[2]])
fc.fu <- lapply(data.frame(medun.fu), function(x) fishpts(x)[[2]])
# fc.ms <- lapply(data.frame(medun.ms), function(x) buildfish(x))
# fc.fs <- lapply(data.frame(medun.fs), function(x) buildfish(x))
# fc.mu <- lapply(data.frame(medun.mu), function(x) buildfish(x))
# fc.fu <- lapply(data.frame(medun.fu), function(x) buildfish(x))
xyr.s <- apply(rbind(do.call(rbind, fc.ms), do.call(rbind, fc.fs)), 2, range)
xyr.u <- apply(rbind(do.call(rbind, fc.mu), do.call(rbind, fc.fu)), 2, range)
suls <- dimnames(medun.ms)[[2]]
picksites <- c("H - ST. MARY", "O - CHAUMONT", "S - DEVILS I", "S - GRAND PO")
fig <- function() {
par(mfrow=c(4, 2), mar=c(0, 0, 1, 0), oma=c(0, 0, 2, 0))
for(i in match(picksites, suls)) {
eqscplot(1, 1, type="n", xlim=xyr.s[, 1], ylim=xyr.s[, 2], axes=FALSE, xlab="", ylab="")
lines(fc.ms[[i]][fishpord, ], col="blue", type="o")
lines(fc.fs[[i]][fishpord, ], col="red", type="o")
mtext(paste("     ", suls[i]), side=3, adj=0, line=-2)
eqscplot(1, 1, type="n", xlim=xyr.u[, 1], ylim=xyr.u[, 2], axes=FALSE, xlab="", ylab="")
lines(fc.mu[[i]][fishpord, ], col="blue", type="o")
lines(fc.fu[[i]][fishpord, ], col="red", type="o")
}
mtext(c("Scaled", "Unscaled"), side=3, adj=c(0.2, 0.8), outer=TRUE)
legend("top", c("Male", "Female"), col=c("blue", "red"), lty=1, bty="n")
}
figu("Comparison of median fish shapes of males and females at four selected sites,",
" using both scaled (by total length, left diagrams) and unscaled (right diagrams) truss measurements.",
"  Fish are lined up by their noses.", newpage="port")
####################
heading("Presentation figures", 2)
rm(ks, pamcl, group, both, g, colz, fc, xyr, hc1)
# use a single order of sites based on seriation of male and female cluster group proportions
gmf <- cbind(males$g[order(rownames(males$g)), ], females$g[order(rownames(females$g)), ])
ord <- seriate(gmf, method="PCA")
gmfo <- gmf[get_order(ord, 1), ]
gm <- gmfo[, 1:dim(males$g)[2]]
gf <- gmfo[, dim(males$g)[2]+(1:dim(females$g)[2])]
rm(gmf, ord, gmfo)
fig <- function() {
par(mfrow=c(1, 2))
attach(males)
g <- gm
fig.bargrp()
detach(males)
attach(females)
g <- gf
fig.bargrp()
detach(females)
}
figu("Proportion of male (left) and female (right) fish assigned to cluster groups in each lake and site.", h=3.5, w=6.5)
fig.gfish2 <- function() {
par(mar=c(0, 0, 1, 0))
for(i in 1:length(fc)) {
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
lines(fcall[fishpord, ], lty=2)
points(fcall[fishpord, ], pch=21, bg="white", col="black")
co <- fc[[i]]
lines(co[fishpord, ], col=colz[i], type="o", lwd=2, pch=16)
if(i==1) mtext(c("Head", "Tail"), side=3, adj=c(0.05, 0.95), line=-1)
}
}
fig <- function() {
nfish <- max(dim(gm)[2], dim(gf)[2])
par(mfcol=c(nfish, 2))
attach(males)
fig.gfish2()
detach(males)
attach(females)
par(mfg=c(1, 2))
fig.gfish2()
detach(females)
}
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group.",
"  Dashed lines represent the median male (left) and female (right) fish.",
"  Fish are lined up by their noses.", h=3.5, w=6.5)
endrtf()
rm(med, med2, med3, amdif, cent, hc1, pamcl, g, medun, fc, xyr)
if(FALSE) {
# print the points for one fish to overlay on photo
co <- fishpts(dat[dat$ID==500, ltrussvars])[[2]]
# co <- buildfish(dat[dat$ID==500, ltrussvars])
xyr <- apply(co, 2, range)
windows()
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
points(co[fishpord, ], col="red", pch=16)
}
ls()
# C:\JVA\Consult\Yule\CiscoMorpho\CiscoMorpho v6.r
# bring in functions
source("C:/JVA/Consult/Yule/CiscoMorpho/CiscoMorphFunctions.r")
library(fpc)
library(rpart)
library(rpart.plot)
library(seriation)
library(plyr)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/Cisco size-corrected residuals FINAL.xls")
dat1 <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
dat1$LS <- paste(substring(dat1$LAKE, 1, 1), dat1$SITE, sep=" - ")
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/FISH MORPHOMETRICS with total lengths RAW Truss measurements.xlsx")
datraw <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/Re-measured photos for Jean.xlsx")
remeas <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
dat2 <- cbind(dat1, datraw[match(dat1$ID, datraw$ID.), paste0("L", 1:31)])
ltrussvars <- paste0("L", 1:31)
rtrussvars <- paste0("r", 1:31)
# replace truss lengths for 21 fish photos that were remeasured
dat2[match(remeas$ID., dat2$ID), ltrussvars] <- remeas[, ltrussvars]
# more Lake Huron (Manitoulin Island) and Lake Erie data (22 Jan 2015 e-mail, https://mail.google.com/mail/u/0/#inbox/14b12f1714db6fe0)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/2014 Huron and Erie Cisco morphometric measurements.xlsx")
more <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
more$OBS <- 1:dim(more)[1]
# missing AGE
fromnames <- c("Fish.ID", "TL..mm.")
tonames <-  c("ID",  "TL")
names(more) <- recode(names(more), fromnames, tonames)
names(more) <- casefold(names(more), upper=TRUE)
more$SITE[more$SITE=="Manitoulin Island"] <- "MANITOULIN"
more$LS <- ifelse(more$LAKE=="Erie", "E - ALL", paste(substring(more$LAKE, 1, 1), more$SITE, sep=" - "))
more$SEX <- as.numeric(more$SEX)
dat3 <- rbind.fill(dat2, more)
####################
doc <- startrtf(file=paste(Sys.Date(), "Cisco Morpho"), dir="C:/JVA/Consult/Yule/CiscoMorpho")
heading("Exploring Dan's Cisco Morphometrics Data")
heading("Jean V. Adams - 27 January 2015", 2)
para("There was one row in the cisco morphometrics data with missing truss measurements (Table ", jvamiscenv$tabcount, ").",
"  This row was eliminated from further analysis.")
tab <- dat3[is.na(dat3$L1), c("OBS", "ID", "SEX", "AGE", "LAKE", "SITE", "LS", "TL", ltrussvars[1:5])]
tabl("Records with missing truss measurements.", row.names=FALSE)
dat4 <- dat3[!is.na(dat3$L1), ]
para("There were a few rows in the cisco morphometrics data with duplicate IDs.",
"  Most of the measurements were pretty close, but a few were a bit further off (Table ", jvamiscenv$tabcount, ").",
"  Dan checked into these, and could only find photos for OBSs 563 and 675,",
" so all of the other observations were removed prior to analysis.")
a <- dat4[dat4$ID %in% dat4$ID[duplicated(dat4$ID)], ]
b <- a[c(1, 3, 5, 7, 9), rtrussvars] - a[c(2, 4, 6, 8, 10), rtrussvars]
#plot(sort(abs(unlist(b))))
tab <- a[, c(1:7, 7+c(9, 16, 28, 29))]
tab[, 8:11] <- format(round(tab[, 8:11], 2))
tabl("Records with duplicate IDs.  Truss measurements are given for those measures that were off by more than 0.3.", row.names=FALSE)
dat4 <- dat4[!(dat4$OBS %in% tab$OBS[!(tab$OBS %in% c(563, 675))]), ]
para("Prior to analysis, the size component was removed from the morphometric measures.",
"  Truss measurements (in mm) were natural log transformed, and the first principal component",
" (based on the covariance matrix) of these measures was used as general measure of size (Figure ", jvamiscenv$figcount, ").")
# log transform the lengths
ldat <- log(dat4[, ltrussvars])
# use the first principal component as size
size <- princomp(ldat, cor=FALSE, scores=TRUE)$scores[, 1]
fig <- function() {
par(mar=c(4, 4, 1, 1))
plot(dat4$TL, size, xlab="Total length of fish  (mm)", ylab="General measure of size  (PC1)", las=1)
}
figu("Relation between fish total length and derived general measure of fish size based on the first",
" principal component score of the log transformed truss measurements.", h=4, w=4)
# regress size (x) on each of the log transformed lengths (y) to get a residual
rdat <- sapply(ldat, function(y) lm(y ~ size)$resid)
dimnames(rdat)[[2]] <- rtrussvars
dat <- cbind(dat4[, c("OBS", "ID", "SEX", "AGE", "LAKE", "SITE", "LS", "TL", ltrussvars)], size, rdat)
# write.csv(dat, "C:/JVA/Consult/Yule/CiscoMorpho/Cisco morpho with Jean residuals.csv", row.names=FALSE)
rm(wb, dat1, datraw, dat3, dat4, a, b, ldat, size, rdat)
para("There were also ", sum(is.na(dat$SEX)), " records where sex was missing (Table ", jvamiscenv$tabcount, ").")
a <- table(dat$LS[is.na(dat$SEX)])
tab <- data.frame(LakeSite=names(a), Nrecords=as.numeric(a))
tabl("Number of records, by lake and site, with nothing entered for sex.", row.names=FALSE)
para("And ", sum(!is.na(dat$SEX) & !(dat$SEX %in% 1:2)), " records where sex was not equal to 1 or 2 (Table ", jvamiscenv$tabcount, ").")
tab <- dat[!is.na(dat$SEX) & !(dat$SEX %in% 1:2), c(1:6, 8:10)]
tab[, 7:9] <- round(tab[, 7:9], 2)
tabl("Records with sex not equal to 1 or 2.", row.names=FALSE)
para("For analyses conducted for individual sexes, I used only those records with sex equal to 1 (males) or 2 (females) .",
"  In all cases (both sexes, just males, and just females),",
" I scaled the data (subtracting the mean and dividing by the standard deviation),",
" so that all of the truss measurements would have the same mean and variance.",
"  This ensures that each truss measure will be given the same amount of weight in a cluster analysis.")
# subset the data
submf.all <- dat[!duplicated(dat$ID), ]
para("I looked at the length distribution and sex composition at all sites (Figures ", jvamiscenv$figcount, " and ", jvamiscenv$figcount+1, ").",
"  Only those fish greater than or equal to 300 mm were used in the tables, figures, and analyses that follow Figure ", jvamiscenv$figcount, ".")
susl <- sort(unique(dat$LS))
tlmed <- tapply(submf.all$TL, submf.all$LS, median)
ord <- order(tlmed)
fig <- function() {
par(mfrow=c(length(susl), 1), mar=c(0, 0, 0, 0), oma=c(4, 1, 1, 0))
for(i in ord) {
sel <- submf.all$LS == susl[i]
hist(submf.all$TL[sel], breaks=seq(200, 550, 10), axes=FALSE, col="gray", xlab="", ylab="", main="")
mtext(susl[i], side=3, line=-1, adj=0.05, cex=0.7)
abline(v=seq(200, 550, 50))
abline(v=tlmed[i], col="cyan", lwd=2)
}
axis(1, outer=TRUE, lwd=0, lwd.ticks=1)
mtext("Total length  (mm)", side=1, outer=TRUE, line=2.5)
mtext("Frequency", side=2, outer=TRUE, line=-0.5)
}
figu("Length frequency distribution of all fish by lake and site, sites ordered by median length (vertical cyan lines).", newpage="port")
# further subset the data, only fish >= 300 mm
submf <- submf.all[submf.all$TL >= 300, ]
subm <- dat[!duplicated(dat$ID) & !is.na(dat$SEX) & dat$SEX==1, ]
subf <- dat[!duplicated(dat$ID) & !is.na(dat$SEX) & dat$SEX==2, ]
# rescale the data
subscmf <- scale(submf[, rtrussvars])
subscm <- scale(subm[, rtrussvars])
subscf <- scale(subf[, rtrussvars])
if(FALSE) {
# error check truss measurements
submftruss <- data.frame(t(submf[, ltrussvars]))
names(submftruss) <- submf$ID
fc1 <- lapply(submftruss, buildfish)
fc2 <- lapply(submftruss, buildfish, upfirst=FALSE)
fc1[sapply(fc1, function(x) any(is.na(x)))]
fc2[sapply(fc2, function(x) any(is.na(x)))]
buildfish(submf[submf$ID==106439, ltrussvars])
buildfish(submf[submf$ID==106439, ltrussvars], upfirst=FALSE)
sort(signif(submf[submf$ID==106439, ltrussvars], 3))
# error in ID 106439, L5=54.9, L10=182, L11=122 ... L10 too big??
# this error seems to be fixed with the remeasuring
t1 <- t(sapply(fc1, fc2truss))
t2 <- t(sapply(fc2, fc2truss))
r1 <- submf[, ltrussvars] - t1[, ltrussvars]
r2 <- submf[, ltrussvars] - t2[, ltrussvars]
mse1 <- sqrt(apply(r1^2, 1, sum))
mse2 <- sqrt(apply(r2^2, 1, sum))
mse <- pmax(mse1, mse2, na.rm=TRUE)
sel <- mse > 20
round(r1[sel, ])
round(r2[sel, ])
t1[sel, ]
t2[sel, ]
submf[sel, ]
#####################################################################################
# remeas[remeas$ID. %in% submf$ID[sel], ]
count <- 0
for(i in 1:30) {
for(j in (i+1):31) {
if(count %% 9 == 0) {
windows()
par(mfrow=c(3, 3), mar=c(4, 4, 1, 1), cex=0.5)
}
count <- count + 1
plotblank(submf[, ltrussvars[i]], submf[, ltrussvars[j]], xlab=ltrussvars[i], ylab=ltrussvars[j])
text(submf[, ltrussvars[i]], submf[, ltrussvars[j]], seq(submf$ID))
}}
# these are rows selected as outliers from the plots
a <- c(586, 146, 117, 66, 255, 164, 215, 14, 374, 74, 97, 226, 239, 39, 571, 193, 738, 305, 219, 75)
mse[a]
b <- sort(unique(c(seq(sel)[sel], a)))
btruss <- data.frame(t(submf[b, ltrussvars]/submf$TL))
names(btruss) <- submf$ID[b]
fc <- lapply(btruss, function(x) fishpts(x)[[2]])
fc1 <- lapply(btruss, function(x) buildfish(x))
fc2 <- lapply(btruss, function(x) buildfish(x, upfirst=FALSE))
fishpord <- c(1:4, 6, 8, 10, 12, 14, 13, 11, 9, 7, 5, 1)
fishpord2 <- c(1:14, 1)
xyr <- apply(do.call(rbind, fc), 2, range)
windows(h=9, w=6.5)
par(mar=c(0, 0, 1, 0), mfrow=c(9, 3))
for(i in 1:length(fc)) {
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="", main=submf$ID[b][i])
lines(fc[[i]][fishpord, ], type="o")
lines(fc1[[i]][fishpord2, ], type="o", col="red")
lines(fc2[[i]][fishpord2, ], type="o", col="blue")
}
allison <- c(106414, 106439, 106509, 106517, 106518, 106540, 106220, 106250, 106262, 106268, 106297, 87077,
87081, 87089, 87126, 87143, 8105018, 28, 102661, 102003, 102945)
btruss <- data.frame(t(submf[submf$ID %in% allison, ltrussvars]/submf$TL))
names(btruss) <- submf$ID[submf$ID %in% allison]
fc <- lapply(btruss, function(x) fishpts(x)[[2]])
fc1 <- lapply(btruss, function(x) buildfish(x))
fc2 <- lapply(btruss, function(x) buildfish(x, upfirst=FALSE))
xyr <- apply(do.call(rbind, fc), 2, range)
windows(h=9, w=6.5)
par(mar=c(0, 0, 1, 0), mfrow=c(7, 3))
for(i in 1:length(fc)) {
if(i==6) frame()
j <- match(allison[-6][i], names(btruss))
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="", main=allison[-6][i])
lines(fc[[j]][fishpord, ], type="o")
lines(fc1[[j]][fishpord2, ], type="o", col="red")
lines(fc2[[j]][fishpord2, ], type="o", col="blue")
}
}
subb <- rbind(subm, subf)
pmale <- tapply(subb$SEX==1, subb$LS, mean)
ord <- order(pmale)
fig <- function() {
par(mar=c(4, 11, 1, 1), xaxs="i")
barplot(rbind(pmale[ord], 1-pmale[ord]), horiz=TRUE, las=1, xlim=c(0, 1), col=c("blue", "red"), xlab="Proportion males", ylab="")
box()
abline(v=seq(0.2, 0.8, 0.2))
}
figu("Sex composition by lake and site, sites ordered by the proportion of males (blue).", h=4, w=4)
nsitesmf <- length(unique(submf$LS))
nsitesm <- length(unique(subm$LS))
nsitesf <- length(unique(subf$LS))
ks <- 1:nsitesmf
pamcl <- pamk(data=subscmf, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("I used the PAM (partitioning around medioids) method for clustering.",
"  I let the number of clusters range from 1 to the number of sites represented: ", 
nsitesmf, " sites for both sexes combined, ", nsitesm, " for males, and ", nsitesf, " for females.",
"  The recommended number of clusters for data from both sexes combined",
" based on the optimum average silhouette width was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig.nclusters <- function(title) {
plot(ks[-1], pamcl$crit[-1], las=1, type="b", 
xlab="No. of clusters", ylab="Average silhouette width", main=title)
abline(v=pamcl$nc, lty=2)
sel <- ks==pamcl$nc
points(ks[sel], pamcl$crit[sel], pch=16, cex=1.5)
}
fig <- function() fig.nclusters(title=paste(nsitesmf, "Sites, Both Sexes"))
figu("Recommended number of clusters based on the optimum average silhouette width, ", nsitesmf, " sites and both sexes combined.", h=4, w=4)
# look at the proportion of fish in each lake/site assigned to each cluster group
tab.prop <- function(grp, df) {
tot <- tapply(!is.na(grp), list(df$LS, grp), sum)
tot[is.na(tot)] <- 0
prop <- tot/apply(tot, 1, sum)
ord <- seriate(prop, method="PCA")
g <- prop[get_order(ord, 1), get_order(ord, 2)]
dimnames(g)[[2]] <- paste0("G", dimnames(g)[[2]])
list(g=g, gord=get_order(ord, 2))
}
both <- tab.prop(group, submf)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, ", nsitesmf, " sites and both sexes combined.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "lightgreen", "darkgreen")
fig.bargrp <- function() {
par(mar=c(4, 8, 1, 1),  xaxs="i")
barplot(t(g)[, dim(g)[1]:1], horiz=TRUE, las=1, xlim=c(0, 1), col=colz[both$gord], xlab="Proportion of fish", ylab="")
box()
}
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, ", nsitesmf, " sites and both sexes combined.", h=4, w=4)
rm(tlmed, ord, subb, pmale, g)
para("I divided the truss measurements by the fish total length and calculated the median of these values for each cluster group.",
"  Then I built a representative fish diagram of each cluster group based on these values (Figure ", jvamiscenv$figcount, ").")
fishpord <- c(1:4, 6, 8, 10, 12, 14, 13, 11, 9, 7, 5, 1)
#fishpord <- c(1:14, 1)
medun <- t(apply(submf[, ltrussvars]/submf$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig.gfish <- function() {
par(mar=c(0, 0, 1, 0))
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
for(i in 1:length(fc)) {
co <- fc[[i]]
lines(co[fishpord, ], col=colz[i], type="o")
}
mtext(c("Head", "Tail"), side=3, adj=c(0.05, 0.95), line=-1)
legend("top", paste("Group", 1:pamcl$nc), col=colz, lty=1, bty="n", lwd=3, horiz=TRUE)
}
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, ", nsitesmf, " sites and both sexes combined.",
"  Fish are lined up by their noses.", h=3, w=6.5)
fig.grpdif <- function(title) {
plot(1:dim(med2)[1], med2$mdif, ylim=c(-1, 1)*max(amdif), las=1,
xlab="Truss  (r#)", ylab="Difference between scaled measures of group 1 and 2", main=title)
abline(h=0)
segments(1:dim(med2)[1], med2$mdif, 1:dim(med2)[1], 0)
}
if(pamcl$nc == 2) {
para("I calculated the median of each of the scaled measurements for each group.",
"  Then I looked at the difference between those medians to see which truss measurements",
" were the most different between the groups (Figure ", jvamiscenv$figcount, ").")
# median measures per group
med <- t(apply(subscmf, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesmf, "Sites, Both Sexes"))
figu("Difference in truss measurements between the cluster groups, ", nsitesmf, " sites and both sexes combined.", 
h=4, w=4)
}
para("I also looked at how the clustering would have proceeded if we had started with a single cluster of fish at each site.",
"  For this, I used agglomerative hierarchical clustering with the centroid method and the squared Euclidean distances (Figure ",
jvamiscenv$figcount, ".)")
cent <- apply(subscmf, 2, tapply, submf$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(submf$LS))
fig.dendro <- function() {
par(mar=c(4, 1, 0, 10))
plot(as.dendrogram(hc1), horiz=TRUE, xlab="Height", ylab="")
}
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, ", nsitesmf, " sites and both sexes combined.", h=8.5, w=4.4)
ks <- 1:nsitesm
pamcl <- pamk(data=subscm, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("The recommended number of clusters for males was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig <- function() fig.nclusters(title=paste(nsitesm, "Sites, Males"))
figu("Recommended number of clusters based on the optimum average silhouette width, males at ", nsitesm, " sites.", h=4, w=4)
both <- tab.prop(group, subm)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, males at ", nsitesm, " sites.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "lightblue", "darkblue")
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, males at ", nsitesm, " sites.", h=4, w=4)
medall <- apply(subm[, ltrussvars]/subm$TL, 2, median, na.rm=TRUE)
fcall <- fishpts(medall)[[2]]
medun <- t(apply(subm[, ltrussvars]/subm$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, males at ", nsitesm, " sites.",
"  Fish are lined up by their noses.", h=3, w=6.5)
if(pamcl$nc == 2) {
# median measures per group
med <- t(apply(subscm, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesm, "Sites, Males"))
figu("Difference in truss measurements between the cluster groups, males at ", nsitesm, " sites.", h=4, w=4)
}
cent <- apply(subscm, 2, tapply, subm$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(subm$LS))
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, males at ", nsitesm, " sites.", h=8.5, w=4.4)
males <- list(ks=ks, pamcl=pamcl, group=group, both=both, g=g, colz=colz, fc=fc, fcall=fcall, xyr=xyr, hc1=hc1)
ks <- 1:nsitesf
pamcl <- pamk(data=subscf, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("The recommended number of clusters for females was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig <- function() fig.nclusters(title=paste(nsitesf, "Sites, Females"))
figu("Recommended number of clusters based on the optimum average silhouette width, females at ", nsitesf, " sites.", h=4, w=4)
both <- tab.prop(group, subf)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, females at ", nsitesf, " sites.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "brown", "orange")
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, females at ", nsitesf, " sites.", h=4, w=4)
medall <- apply(subf[, ltrussvars]/subf$TL, 2, median, na.rm=TRUE)
fcall <- fishpts(medall)[[2]]
medun <- t(apply(subf[, ltrussvars]/subf$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, females at ", nsitesf, " sites.",
"  Fish are lined up by their noses.", h=3, w=6.5)
if(pamcl$nc == 2) {
# median measures per group
med <- t(apply(subscf, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesf, "Sites, Females"))
figu("Difference in residual (log transformed, size corrected, and scaled) truss measurements between the cluster groups,",
" females at ", nsitesf, " sites.", h=4, w=4)
}
cent <- apply(subscf, 2, tapply, subf$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(subf$LS))
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, females at ", nsitesf, " sites.", h=8.5, w=4.4)
females <- list(ks=ks, pamcl=pamcl, group=group, both=both, g=g, colz=colz, fc=fc, fcall=fcall, xyr=xyr, hc1=hc1)
medun.ms <- t(apply(subm[, ltrussvars]/subm$TL, 2, tapply, subm$LS, median, na.rm=TRUE))
medun.fs <- t(apply(subf[, ltrussvars]/subf$TL, 2, tapply, subf$LS, median, na.rm=TRUE))
medun.mu <- t(apply(subm[, ltrussvars], 2, tapply, subm$LS, median, na.rm=TRUE))
medun.fu <- t(apply(subf[, ltrussvars], 2, tapply, subf$LS, median, na.rm=TRUE))
fc.ms <- lapply(data.frame(medun.ms), function(x) fishpts(x)[[2]])
fc.fs <- lapply(data.frame(medun.fs), function(x) fishpts(x)[[2]])
fc.mu <- lapply(data.frame(medun.mu), function(x) fishpts(x)[[2]])
fc.fu <- lapply(data.frame(medun.fu), function(x) fishpts(x)[[2]])
# fc.ms <- lapply(data.frame(medun.ms), function(x) buildfish(x))
# fc.fs <- lapply(data.frame(medun.fs), function(x) buildfish(x))
# fc.mu <- lapply(data.frame(medun.mu), function(x) buildfish(x))
# fc.fu <- lapply(data.frame(medun.fu), function(x) buildfish(x))
xyr.s <- apply(rbind(do.call(rbind, fc.ms), do.call(rbind, fc.fs)), 2, range)
xyr.u <- apply(rbind(do.call(rbind, fc.mu), do.call(rbind, fc.fu)), 2, range)
suls <- dimnames(medun.ms)[[2]]
picksites <- c("H - ST. MARY", "O - CHAUMONT", "S - DEVILS I", "S - GRAND PO")
fig <- function() {
par(mfrow=c(4, 2), mar=c(0, 0, 1, 0), oma=c(0, 0, 2, 0))
for(i in match(picksites, suls)) {
eqscplot(1, 1, type="n", xlim=xyr.s[, 1], ylim=xyr.s[, 2], axes=FALSE, xlab="", ylab="")
lines(fc.ms[[i]][fishpord, ], col="blue", type="o")
lines(fc.fs[[i]][fishpord, ], col="red", type="o")
mtext(paste("     ", suls[i]), side=3, adj=0, line=-2)
eqscplot(1, 1, type="n", xlim=xyr.u[, 1], ylim=xyr.u[, 2], axes=FALSE, xlab="", ylab="")
lines(fc.mu[[i]][fishpord, ], col="blue", type="o")
lines(fc.fu[[i]][fishpord, ], col="red", type="o")
}
mtext(c("Scaled", "Unscaled"), side=3, adj=c(0.2, 0.8), outer=TRUE)
legend("top", c("Male", "Female"), col=c("blue", "red"), lty=1, bty="n")
}
figu("Comparison of median fish shapes of males and females at four selected sites,",
" using both scaled (by total length, left diagrams) and unscaled (right diagrams) truss measurements.",
"  Fish are lined up by their noses.", newpage="port")
####################
heading("Presentation figures", 2)
rm(ks, pamcl, group, both, g, colz, fc, xyr, hc1)
# use a single order of sites based on seriation of male and female cluster group proportions
gmf <- cbind(males$g[order(rownames(males$g)), ], females$g[order(rownames(females$g)), ])
ord <- seriate(gmf, method="PCA")
gmfo <- gmf[get_order(ord, 1), ]
gm <- gmfo[, 1:dim(males$g)[2]]
gf <- gmfo[, dim(males$g)[2]+(1:dim(females$g)[2])]
rm(gmf, ord, gmfo)
fig <- function() {
par(mfrow=c(1, 2))
attach(males)
g <<- gm
fig.bargrp()
detach(males)
attach(females)
g <<- gf
fig.bargrp()
detach(females)
}
figu("Proportion of male (left) and female (right) fish assigned to cluster groups in each lake and site.", h=3.5, w=6.5)
fig.gfish2 <- function() {
par(mar=c(0, 0, 1, 0))
for(i in 1:length(fc)) {
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
lines(fcall[fishpord, ], lty=2)
points(fcall[fishpord, ], pch=21, bg="white", col="black")
co <- fc[[i]]
lines(co[fishpord, ], col=colz[i], type="o", lwd=2, pch=16)
if(i==1) mtext(c("Head", "Tail"), side=3, adj=c(0.05, 0.95), line=-1)
}
}
fig <- function() {
nfish <- max(dim(gm)[2], dim(gf)[2])
par(mfcol=c(nfish, 2))
attach(males)
fig.gfish2()
detach(males)
attach(females)
par(mfg=c(1, 2))
fig.gfish2()
detach(females)
}
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group.",
"  Dashed lines represent the median male (left) and female (right) fish.",
"  Fish are lined up by their noses.", h=3.5, w=6.5)
endrtf()
rm(med, med2, med3, amdif, cent, medun)
if(FALSE) {
# print the points for one fish to overlay on photo
co <- fishpts(dat[dat$ID==500, ltrussvars])[[2]]
# co <- buildfish(dat[dat$ID==500, ltrussvars])
xyr <- apply(co, 2, range)
windows()
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
points(co[fishpord, ], col="red", pch=16)
}
cleanup()
search()
# C:\JVA\Consult\Yule\CiscoMorpho\CiscoMorpho v6.r
# bring in functions
source("C:/JVA/Consult/Yule/CiscoMorpho/CiscoMorphFunctions.r")
library(fpc)
library(rpart)
library(rpart.plot)
library(seriation)
library(plyr)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/Cisco size-corrected residuals FINAL.xls")
dat1 <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
dat1$LS <- paste(substring(dat1$LAKE, 1, 1), dat1$SITE, sep=" - ")
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/FISH MORPHOMETRICS with total lengths RAW Truss measurements.xlsx")
datraw <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/Re-measured photos for Jean.xlsx")
remeas <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
dat2 <- cbind(dat1, datraw[match(dat1$ID, datraw$ID.), paste0("L", 1:31)])
ltrussvars <- paste0("L", 1:31)
rtrussvars <- paste0("r", 1:31)
# replace truss lengths for 21 fish photos that were remeasured
dat2[match(remeas$ID., dat2$ID), ltrussvars] <- remeas[, ltrussvars]
# more Lake Huron (Manitoulin Island) and Lake Erie data (22 Jan 2015 e-mail, https://mail.google.com/mail/u/0/#inbox/14b12f1714db6fe0)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/2014 Huron and Erie Cisco morphometric measurements.xlsx")
more <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
more$OBS <- 1:dim(more)[1]
# missing AGE
fromnames <- c("Fish.ID", "TL..mm.")
tonames <-  c("ID",  "TL")
names(more) <- recode(names(more), fromnames, tonames)
names(more) <- casefold(names(more), upper=TRUE)
more$SITE[more$SITE=="Manitoulin Island"] <- "MANITOULIN"
more$LS <- ifelse(more$LAKE=="Erie", "E - ALL", paste(substring(more$LAKE, 1, 1), more$SITE, sep=" - "))
more$SEX <- as.numeric(more$SEX)
dat3 <- rbind.fill(dat2, more)
####################
doc <- startrtf(file=paste(Sys.Date(), "Cisco Morpho"), dir="C:/JVA/Consult/Yule/CiscoMorpho")
heading("Exploring Dan's Cisco Morphometrics Data")
heading("Jean V. Adams - 27 January 2015", 2)
para("There was one row in the cisco morphometrics data with missing truss measurements (Table ", jvamiscenv$tabcount, ").",
"  This row was eliminated from further analysis.")
tab <- dat3[is.na(dat3$L1), c("OBS", "ID", "SEX", "AGE", "LAKE", "SITE", "LS", "TL", ltrussvars[1:5])]
tabl("Records with missing truss measurements.", row.names=FALSE)
dat4 <- dat3[!is.na(dat3$L1), ]
para("There were a few rows in the cisco morphometrics data with duplicate IDs.",
"  Most of the measurements were pretty close, but a few were a bit further off (Table ", jvamiscenv$tabcount, ").",
"  Dan checked into these, and could only find photos for OBSs 563 and 675,",
" so all of the other observations were removed prior to analysis.")
a <- dat4[dat4$ID %in% dat4$ID[duplicated(dat4$ID)], ]
b <- a[c(1, 3, 5, 7, 9), rtrussvars] - a[c(2, 4, 6, 8, 10), rtrussvars]
#plot(sort(abs(unlist(b))))
tab <- a[, c(1:7, 7+c(9, 16, 28, 29))]
tab[, 8:11] <- format(round(tab[, 8:11], 2))
tabl("Records with duplicate IDs.  Truss measurements are given for those measures that were off by more than 0.3.", row.names=FALSE)
dat4 <- dat4[!(dat4$OBS %in% tab$OBS[!(tab$OBS %in% c(563, 675))]), ]
para("Prior to analysis, the size component was removed from the morphometric measures.",
"  Truss measurements (in mm) were natural log transformed, and the first principal component",
" (based on the covariance matrix) of these measures was used as general measure of size (Figure ", jvamiscenv$figcount, ").")
# log transform the lengths
ldat <- log(dat4[, ltrussvars])
# use the first principal component as size
size <- princomp(ldat, cor=FALSE, scores=TRUE)$scores[, 1]
fig <- function() {
par(mar=c(4, 4, 1, 1))
plot(dat4$TL, size, xlab="Total length of fish  (mm)", ylab="General measure of size  (PC1)", las=1)
}
figu("Relation between fish total length and derived general measure of fish size based on the first",
" principal component score of the log transformed truss measurements.", h=4, w=4)
# regress size (x) on each of the log transformed lengths (y) to get a residual
rdat <- sapply(ldat, function(y) lm(y ~ size)$resid)
dimnames(rdat)[[2]] <- rtrussvars
dat <- cbind(dat4[, c("OBS", "ID", "SEX", "AGE", "LAKE", "SITE", "LS", "TL", ltrussvars)], size, rdat)
# write.csv(dat, "C:/JVA/Consult/Yule/CiscoMorpho/Cisco morpho with Jean residuals.csv", row.names=FALSE)
rm(wb, dat1, datraw, dat3, dat4, a, b, ldat, size, rdat)
para("There were also ", sum(is.na(dat$SEX)), " records where sex was missing (Table ", jvamiscenv$tabcount, ").")
a <- table(dat$LS[is.na(dat$SEX)])
tab <- data.frame(LakeSite=names(a), Nrecords=as.numeric(a))
tabl("Number of records, by lake and site, with nothing entered for sex.", row.names=FALSE)
para("And ", sum(!is.na(dat$SEX) & !(dat$SEX %in% 1:2)), " records where sex was not equal to 1 or 2 (Table ", jvamiscenv$tabcount, ").")
tab <- dat[!is.na(dat$SEX) & !(dat$SEX %in% 1:2), c(1:6, 8:10)]
tab[, 7:9] <- round(tab[, 7:9], 2)
tabl("Records with sex not equal to 1 or 2.", row.names=FALSE)
para("For analyses conducted for individual sexes, I used only those records with sex equal to 1 (males) or 2 (females) .",
"  In all cases (both sexes, just males, and just females),",
" I scaled the data (subtracting the mean and dividing by the standard deviation),",
" so that all of the truss measurements would have the same mean and variance.",
"  This ensures that each truss measure will be given the same amount of weight in a cluster analysis.")
# subset the data
submf.all <- dat[!duplicated(dat$ID), ]
para("I looked at the length distribution and sex composition at all sites (Figures ", jvamiscenv$figcount, " and ", jvamiscenv$figcount+1, ").",
"  Only those fish greater than or equal to 300 mm were used in the tables, figures, and analyses that follow Figure ", jvamiscenv$figcount, ".")
susl <- sort(unique(dat$LS))
tlmed <- tapply(submf.all$TL, submf.all$LS, median)
ord <- order(tlmed)
fig <- function() {
par(mfrow=c(length(susl), 1), mar=c(0, 0, 0, 0), oma=c(4, 1, 1, 0))
for(i in ord) {
sel <- submf.all$LS == susl[i]
hist(submf.all$TL[sel], breaks=seq(200, 550, 10), axes=FALSE, col="gray", xlab="", ylab="", main="")
mtext(susl[i], side=3, line=-1, adj=0.05, cex=0.7)
abline(v=seq(200, 550, 50))
abline(v=tlmed[i], col="cyan", lwd=2)
}
axis(1, outer=TRUE, lwd=0, lwd.ticks=1)
mtext("Total length  (mm)", side=1, outer=TRUE, line=2.5)
mtext("Frequency", side=2, outer=TRUE, line=-0.5)
}
figu("Length frequency distribution of all fish by lake and site, sites ordered by median length (vertical cyan lines).", newpage="port")
# further subset the data, only fish >= 300 mm
submf <- submf.all[submf.all$TL >= 300, ]
subm <- dat[!duplicated(dat$ID) & !is.na(dat$SEX) & dat$SEX==1, ]
subf <- dat[!duplicated(dat$ID) & !is.na(dat$SEX) & dat$SEX==2, ]
# rescale the data
subscmf <- scale(submf[, rtrussvars])
subscm <- scale(subm[, rtrussvars])
subscf <- scale(subf[, rtrussvars])
if(FALSE) {
# error check truss measurements
submftruss <- data.frame(t(submf[, ltrussvars]))
names(submftruss) <- submf$ID
fc1 <- lapply(submftruss, buildfish)
fc2 <- lapply(submftruss, buildfish, upfirst=FALSE)
fc1[sapply(fc1, function(x) any(is.na(x)))]
fc2[sapply(fc2, function(x) any(is.na(x)))]
buildfish(submf[submf$ID==106439, ltrussvars])
buildfish(submf[submf$ID==106439, ltrussvars], upfirst=FALSE)
sort(signif(submf[submf$ID==106439, ltrussvars], 3))
# error in ID 106439, L5=54.9, L10=182, L11=122 ... L10 too big??
# this error seems to be fixed with the remeasuring
t1 <- t(sapply(fc1, fc2truss))
t2 <- t(sapply(fc2, fc2truss))
r1 <- submf[, ltrussvars] - t1[, ltrussvars]
r2 <- submf[, ltrussvars] - t2[, ltrussvars]
mse1 <- sqrt(apply(r1^2, 1, sum))
mse2 <- sqrt(apply(r2^2, 1, sum))
mse <- pmax(mse1, mse2, na.rm=TRUE)
sel <- mse > 20
round(r1[sel, ])
round(r2[sel, ])
t1[sel, ]
t2[sel, ]
submf[sel, ]
#####################################################################################
# remeas[remeas$ID. %in% submf$ID[sel], ]
count <- 0
for(i in 1:30) {
for(j in (i+1):31) {
if(count %% 9 == 0) {
windows()
par(mfrow=c(3, 3), mar=c(4, 4, 1, 1), cex=0.5)
}
count <- count + 1
plotblank(submf[, ltrussvars[i]], submf[, ltrussvars[j]], xlab=ltrussvars[i], ylab=ltrussvars[j])
text(submf[, ltrussvars[i]], submf[, ltrussvars[j]], seq(submf$ID))
}}
# these are rows selected as outliers from the plots
a <- c(586, 146, 117, 66, 255, 164, 215, 14, 374, 74, 97, 226, 239, 39, 571, 193, 738, 305, 219, 75)
mse[a]
b <- sort(unique(c(seq(sel)[sel], a)))
btruss <- data.frame(t(submf[b, ltrussvars]/submf$TL))
names(btruss) <- submf$ID[b]
fc <- lapply(btruss, function(x) fishpts(x)[[2]])
fc1 <- lapply(btruss, function(x) buildfish(x))
fc2 <- lapply(btruss, function(x) buildfish(x, upfirst=FALSE))
fishpord <- c(1:4, 6, 8, 10, 12, 14, 13, 11, 9, 7, 5, 1)
fishpord2 <- c(1:14, 1)
xyr <- apply(do.call(rbind, fc), 2, range)
windows(h=9, w=6.5)
par(mar=c(0, 0, 1, 0), mfrow=c(9, 3))
for(i in 1:length(fc)) {
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="", main=submf$ID[b][i])
lines(fc[[i]][fishpord, ], type="o")
lines(fc1[[i]][fishpord2, ], type="o", col="red")
lines(fc2[[i]][fishpord2, ], type="o", col="blue")
}
allison <- c(106414, 106439, 106509, 106517, 106518, 106540, 106220, 106250, 106262, 106268, 106297, 87077,
87081, 87089, 87126, 87143, 8105018, 28, 102661, 102003, 102945)
btruss <- data.frame(t(submf[submf$ID %in% allison, ltrussvars]/submf$TL))
names(btruss) <- submf$ID[submf$ID %in% allison]
fc <- lapply(btruss, function(x) fishpts(x)[[2]])
fc1 <- lapply(btruss, function(x) buildfish(x))
fc2 <- lapply(btruss, function(x) buildfish(x, upfirst=FALSE))
xyr <- apply(do.call(rbind, fc), 2, range)
windows(h=9, w=6.5)
par(mar=c(0, 0, 1, 0), mfrow=c(7, 3))
for(i in 1:length(fc)) {
if(i==6) frame()
j <- match(allison[-6][i], names(btruss))
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="", main=allison[-6][i])
lines(fc[[j]][fishpord, ], type="o")
lines(fc1[[j]][fishpord2, ], type="o", col="red")
lines(fc2[[j]][fishpord2, ], type="o", col="blue")
}
}
subb <- rbind(subm, subf)
pmale <- tapply(subb$SEX==1, subb$LS, mean)
ord <- order(pmale)
fig <- function() {
par(mar=c(4, 11, 1, 1), xaxs="i")
barplot(rbind(pmale[ord], 1-pmale[ord]), horiz=TRUE, las=1, xlim=c(0, 1), col=c("blue", "red"), xlab="Proportion males", ylab="")
box()
abline(v=seq(0.2, 0.8, 0.2))
}
figu("Sex composition by lake and site, sites ordered by the proportion of males (blue).", h=4, w=4)
nsitesmf <- length(unique(submf$LS))
nsitesm <- length(unique(subm$LS))
nsitesf <- length(unique(subf$LS))
ks <- 1:nsitesmf
pamcl <- pamk(data=subscmf, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("I used the PAM (partitioning around medioids) method for clustering.",
"  I let the number of clusters range from 1 to the number of sites represented: ", 
nsitesmf, " sites for both sexes combined, ", nsitesm, " for males, and ", nsitesf, " for females.",
"  The recommended number of clusters for data from both sexes combined",
" based on the optimum average silhouette width was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig.nclusters <- function(title) {
plot(ks[-1], pamcl$crit[-1], las=1, type="b", 
xlab="No. of clusters", ylab="Average silhouette width", main=title)
abline(v=pamcl$nc, lty=2)
sel <- ks==pamcl$nc
points(ks[sel], pamcl$crit[sel], pch=16, cex=1.5)
}
fig <- function() fig.nclusters(title=paste(nsitesmf, "Sites, Both Sexes"))
figu("Recommended number of clusters based on the optimum average silhouette width, ", nsitesmf, " sites and both sexes combined.", h=4, w=4)
# look at the proportion of fish in each lake/site assigned to each cluster group
tab.prop <- function(grp, df) {
tot <- tapply(!is.na(grp), list(df$LS, grp), sum)
tot[is.na(tot)] <- 0
prop <- tot/apply(tot, 1, sum)
ord <- seriate(prop, method="PCA")
g <- prop[get_order(ord, 1), get_order(ord, 2)]
dimnames(g)[[2]] <- paste0("G", dimnames(g)[[2]])
list(g=g, gord=get_order(ord, 2))
}
both <- tab.prop(group, submf)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, ", nsitesmf, " sites and both sexes combined.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "lightgreen", "darkgreen")
fig.bargrp <- function() {
par(mar=c(4, 8, 1, 1),  xaxs="i")
barplot(t(g)[, dim(g)[1]:1], horiz=TRUE, las=1, xlim=c(0, 1), col=colz[both$gord], xlab="Proportion of fish", ylab="")
box()
}
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, ", nsitesmf, " sites and both sexes combined.", h=4, w=4)
rm(tlmed, ord, subb, pmale, g)
para("I divided the truss measurements by the fish total length and calculated the median of these values for each cluster group.",
"  Then I built a representative fish diagram of each cluster group based on these values (Figure ", jvamiscenv$figcount, ").")
fishpord <- c(1:4, 6, 8, 10, 12, 14, 13, 11, 9, 7, 5, 1)
#fishpord <- c(1:14, 1)
medun <- t(apply(submf[, ltrussvars]/submf$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig.gfish <- function() {
par(mar=c(0, 0, 1, 0))
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
for(i in 1:length(fc)) {
co <- fc[[i]]
lines(co[fishpord, ], col=colz[i], type="o")
}
mtext(c("Head", "Tail"), side=3, adj=c(0.05, 0.95), line=-1)
legend("top", paste("Group", 1:pamcl$nc), col=colz, lty=1, bty="n", lwd=3, horiz=TRUE)
}
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, ", nsitesmf, " sites and both sexes combined.",
"  Fish are lined up by their noses.", h=3, w=6.5)
fig.grpdif <- function(title) {
plot(1:dim(med2)[1], med2$mdif, ylim=c(-1, 1)*max(amdif), las=1,
xlab="Truss  (r#)", ylab="Difference between scaled measures of group 1 and 2", main=title)
abline(h=0)
segments(1:dim(med2)[1], med2$mdif, 1:dim(med2)[1], 0)
}
if(pamcl$nc == 2) {
para("I calculated the median of each of the scaled measurements for each group.",
"  Then I looked at the difference between those medians to see which truss measurements",
" were the most different between the groups (Figure ", jvamiscenv$figcount, ").")
# median measures per group
med <- t(apply(subscmf, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesmf, "Sites, Both Sexes"))
figu("Difference in truss measurements between the cluster groups, ", nsitesmf, " sites and both sexes combined.", 
h=4, w=4)
}
para("I also looked at how the clustering would have proceeded if we had started with a single cluster of fish at each site.",
"  For this, I used agglomerative hierarchical clustering with the centroid method and the squared Euclidean distances (Figure ",
jvamiscenv$figcount, ".)")
cent <- apply(subscmf, 2, tapply, submf$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(submf$LS))
fig.dendro <- function() {
par(mar=c(4, 1, 0, 10))
plot(as.dendrogram(hc1), horiz=TRUE, xlab="Height", ylab="")
}
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, ", nsitesmf, " sites and both sexes combined.", h=8.5, w=4.4)
ks <- 1:nsitesm
pamcl <- pamk(data=subscm, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("The recommended number of clusters for males was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig <- function() fig.nclusters(title=paste(nsitesm, "Sites, Males"))
figu("Recommended number of clusters based on the optimum average silhouette width, males at ", nsitesm, " sites.", h=4, w=4)
both <- tab.prop(group, subm)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, males at ", nsitesm, " sites.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "lightblue", "darkblue")
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, males at ", nsitesm, " sites.", h=4, w=4)
medall <- apply(subm[, ltrussvars]/subm$TL, 2, median, na.rm=TRUE)
fcall <- fishpts(medall)[[2]]
medun <- t(apply(subm[, ltrussvars]/subm$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, males at ", nsitesm, " sites.",
"  Fish are lined up by their noses.", h=3, w=6.5)
if(pamcl$nc == 2) {
# median measures per group
med <- t(apply(subscm, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesm, "Sites, Males"))
figu("Difference in truss measurements between the cluster groups, males at ", nsitesm, " sites.", h=4, w=4)
}
cent <- apply(subscm, 2, tapply, subm$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(subm$LS))
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, males at ", nsitesm, " sites.", h=8.5, w=4.4)
males <- list(ks=ks, pamcl=pamcl, group=group, both=both, g=g, colz=colz, fc=fc, fcall=fcall, xyr=xyr, hc1=hc1)
ks <- 1:nsitesf
pamcl <- pamk(data=subscf, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("The recommended number of clusters for females was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig <- function() fig.nclusters(title=paste(nsitesf, "Sites, Females"))
figu("Recommended number of clusters based on the optimum average silhouette width, females at ", nsitesf, " sites.", h=4, w=4)
both <- tab.prop(group, subf)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, females at ", nsitesf, " sites.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "brown", "orange")
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, females at ", nsitesf, " sites.", h=4, w=4)
medall <- apply(subf[, ltrussvars]/subf$TL, 2, median, na.rm=TRUE)
fcall <- fishpts(medall)[[2]]
medun <- t(apply(subf[, ltrussvars]/subf$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, females at ", nsitesf, " sites.",
"  Fish are lined up by their noses.", h=3, w=6.5)
if(pamcl$nc == 2) {
# median measures per group
med <- t(apply(subscf, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesf, "Sites, Females"))
figu("Difference in residual (log transformed, size corrected, and scaled) truss measurements between the cluster groups,",
" females at ", nsitesf, " sites.", h=4, w=4)
}
cent <- apply(subscf, 2, tapply, subf$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(subf$LS))
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, females at ", nsitesf, " sites.", h=8.5, w=4.4)
females <- list(ks=ks, pamcl=pamcl, group=group, both=both, g=g, colz=colz, fc=fc, fcall=fcall, xyr=xyr, hc1=hc1)
medun.ms <- t(apply(subm[, ltrussvars]/subm$TL, 2, tapply, subm$LS, median, na.rm=TRUE))
medun.fs <- t(apply(subf[, ltrussvars]/subf$TL, 2, tapply, subf$LS, median, na.rm=TRUE))
medun.mu <- t(apply(subm[, ltrussvars], 2, tapply, subm$LS, median, na.rm=TRUE))
medun.fu <- t(apply(subf[, ltrussvars], 2, tapply, subf$LS, median, na.rm=TRUE))
fc.ms <- lapply(data.frame(medun.ms), function(x) fishpts(x)[[2]])
fc.fs <- lapply(data.frame(medun.fs), function(x) fishpts(x)[[2]])
fc.mu <- lapply(data.frame(medun.mu), function(x) fishpts(x)[[2]])
fc.fu <- lapply(data.frame(medun.fu), function(x) fishpts(x)[[2]])
# fc.ms <- lapply(data.frame(medun.ms), function(x) buildfish(x))
# fc.fs <- lapply(data.frame(medun.fs), function(x) buildfish(x))
# fc.mu <- lapply(data.frame(medun.mu), function(x) buildfish(x))
# fc.fu <- lapply(data.frame(medun.fu), function(x) buildfish(x))
xyr.s <- apply(rbind(do.call(rbind, fc.ms), do.call(rbind, fc.fs)), 2, range)
xyr.u <- apply(rbind(do.call(rbind, fc.mu), do.call(rbind, fc.fu)), 2, range)
suls <- dimnames(medun.ms)[[2]]
picksites <- c("H - ST. MARY", "O - CHAUMONT", "S - DEVILS I", "S - GRAND PO")
fig <- function() {
par(mfrow=c(4, 2), mar=c(0, 0, 1, 0), oma=c(0, 0, 2, 0))
for(i in match(picksites, suls)) {
eqscplot(1, 1, type="n", xlim=xyr.s[, 1], ylim=xyr.s[, 2], axes=FALSE, xlab="", ylab="")
lines(fc.ms[[i]][fishpord, ], col="blue", type="o")
lines(fc.fs[[i]][fishpord, ], col="red", type="o")
mtext(paste("     ", suls[i]), side=3, adj=0, line=-2)
eqscplot(1, 1, type="n", xlim=xyr.u[, 1], ylim=xyr.u[, 2], axes=FALSE, xlab="", ylab="")
lines(fc.mu[[i]][fishpord, ], col="blue", type="o")
lines(fc.fu[[i]][fishpord, ], col="red", type="o")
}
mtext(c("Scaled", "Unscaled"), side=3, adj=c(0.2, 0.8), outer=TRUE)
legend("top", c("Male", "Female"), col=c("blue", "red"), lty=1, bty="n")
}
figu("Comparison of median fish shapes of males and females at four selected sites,",
" using both scaled (by total length, left diagrams) and unscaled (right diagrams) truss measurements.",
"  Fish are lined up by their noses.", newpage="port")
####################
heading("Presentation figures", 2)
rm(ks, pamcl, group, both, g, colz, fc, fcall, xyr, hc1)
# use a single order of sites based on seriation of male and female cluster group proportions
gmf <- cbind(males$g[order(rownames(males$g)), ], females$g[order(rownames(females$g)), ])
ord <- seriate(gmf, method="PCA")
gmfo <- gmf[get_order(ord, 1), ]
gm <- gmfo[, 1:dim(males$g)[2]]
gf <- gmfo[, dim(males$g)[2]+(1:dim(females$g)[2])]
rm(gmf, ord, gmfo)
fig <- function() {
par(mfrow=c(1, 2))
attach(males)
g <<- gm
fig.bargrp()
detach(males)
attach(females)
g <<- gf
fig.bargrp()
detach(females)
}
figu("Proportion of male (left) and female (right) fish assigned to cluster groups in each lake and site.", h=3.5, w=6.5)
fig.gfish2 <- function() {
par(mar=c(0, 0, 1, 0))
for(i in 1:length(fc)) {
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
lines(fcall[fishpord, ], lty=2)
points(fcall[fishpord, ], pch=21, bg="white", col="black")
co <- fc[[i]]
lines(co[fishpord, ], col=colz[i], type="o", lwd=2, pch=16)
if(i==1) mtext(c("Head", "Tail"), side=3, adj=c(0.05, 0.95), line=-1)
}
}
fig <- function() {
nfish <- max(dim(gm)[2], dim(gf)[2])
par(mfcol=c(nfish, 2))
attach(males)
fig.gfish2()
detach(males)
attach(females)
par(mfg=c(1, 2))
fig.gfish2()
detach(females)
}
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group.",
"  Dashed lines represent the median male (left) and female (right) fish.",
"  Fish are lined up by their noses.", h=3.5, w=6.5)
endrtf()
rm(med, med2, med3, amdif, cent, medun)
if(FALSE) {
# print the points for one fish to overlay on photo
co <- fishpts(dat[dat$ID==500, ltrussvars])[[2]]
# co <- buildfish(dat[dat$ID==500, ltrussvars])
xyr <- apply(co, 2, range)
windows()
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
points(co[fishpord, ], col="red", pch=16)
}
cleanup()
q()
# C:\JVA\Consult\Yule\CiscoMorpho\CiscoMorpho v6.r
# bring in functions
source("C:/JVA/Consult/Yule/CiscoMorpho/CiscoMorphFunctions.r")
library(fpc)
library(rpart)
library(rpart.plot)
library(seriation)
library(plyr)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/Cisco size-corrected residuals FINAL.xls")
dat1 <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
dat1$LS <- paste(substring(dat1$LAKE, 1, 1), dat1$SITE, sep=" - ")
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/FISH MORPHOMETRICS with total lengths RAW Truss measurements.xlsx")
datraw <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/Re-measured photos for Jean.xlsx")
remeas <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
dat2 <- cbind(dat1, datraw[match(dat1$ID, datraw$ID.), paste0("L", 1:31)])
ltrussvars <- paste0("L", 1:31)
rtrussvars <- paste0("r", 1:31)
# replace truss lengths for 21 fish photos that were remeasured
dat2[match(remeas$ID., dat2$ID), ltrussvars] <- remeas[, ltrussvars]
# more Lake Huron (Manitoulin Island) and Lake Erie data (22 Jan 2015 e-mail, https://mail.google.com/mail/u/0/#inbox/14b12f1714db6fe0)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/2014 Huron and Erie Cisco morphometric measurements.xlsx")
more <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
more$OBS <- 1:dim(more)[1]
# missing AGE
fromnames <- c("Fish.ID", "TL..mm.")
tonames <-  c("ID",  "TL")
names(more) <- recode(names(more), fromnames, tonames)
names(more) <- casefold(names(more), upper=TRUE)
more$SITE[more$SITE=="Manitoulin Island"] <- "MANITOULIN"
more$LS <- ifelse(more$LAKE=="Erie", "E - ALL", paste(substring(more$LAKE, 1, 1), more$SITE, sep=" - "))
more$SEX <- as.numeric(more$SEX)
dat3 <- rbind.fill(dat2, more)
####################
doc <- startrtf(file=paste(Sys.Date(), "Cisco Morpho"), dir="C:/JVA/Consult/Yule/CiscoMorpho")
heading("Exploring Dan's Cisco Morphometrics Data")
heading("Jean V. Adams - 27 January 2015", 2)
para("There was one row in the cisco morphometrics data with missing truss measurements (Table ", jvamiscenv$tabcount, ").",
"  This row was eliminated from further analysis.")
tab <- dat3[is.na(dat3$L1), c("OBS", "ID", "SEX", "AGE", "LAKE", "SITE", "LS", "TL", ltrussvars[1:5])]
tabl("Records with missing truss measurements.", row.names=FALSE)
dat4 <- dat3[!is.na(dat3$L1), ]
para("There were a few rows in the cisco morphometrics data with duplicate IDs.",
"  Most of the measurements were pretty close, but a few were a bit further off (Table ", jvamiscenv$tabcount, ").",
"  Dan checked into these, and could only find photos for OBSs 563 and 675,",
" so all of the other observations were removed prior to analysis.")
a <- dat4[dat4$ID %in% dat4$ID[duplicated(dat4$ID)], ]
b <- a[c(1, 3, 5, 7, 9), rtrussvars] - a[c(2, 4, 6, 8, 10), rtrussvars]
#plot(sort(abs(unlist(b))))
tab <- a[, c(1:7, 7+c(9, 16, 28, 29))]
tab[, 8:11] <- format(round(tab[, 8:11], 2))
tabl("Records with duplicate IDs.  Truss measurements are given for those measures that were off by more than 0.3.", row.names=FALSE)
dat4 <- dat4[!(dat4$OBS %in% tab$OBS[!(tab$OBS %in% c(563, 675))]), ]
para("Prior to analysis, the size component was removed from the morphometric measures.",
"  Truss measurements (in mm) were natural log transformed, and the first principal component",
" (based on the covariance matrix) of these measures was used as general measure of size (Figure ", jvamiscenv$figcount, ").")
# log transform the lengths
ldat <- log(dat4[, ltrussvars])
# use the first principal component as size
size <- princomp(ldat, cor=FALSE, scores=TRUE)$scores[, 1]
fig <- function() {
par(mar=c(4, 4, 1, 1))
plot(dat4$TL, size, xlab="Total length of fish  (mm)", ylab="General measure of size  (PC1)", las=1)
}
figu("Relation between fish total length and derived general measure of fish size based on the first",
" principal component score of the log transformed truss measurements.", h=4, w=4)
# regress size (x) on each of the log transformed lengths (y) to get a residual
rdat <- sapply(ldat, function(y) lm(y ~ size)$resid)
dimnames(rdat)[[2]] <- rtrussvars
dat <- cbind(dat4[, c("OBS", "ID", "SEX", "AGE", "LAKE", "SITE", "LS", "TL", ltrussvars)], size, rdat)
# write.csv(dat, "C:/JVA/Consult/Yule/CiscoMorpho/Cisco morpho with Jean residuals.csv", row.names=FALSE)
rm(wb, dat1, datraw, dat3, dat4, a, b, ldat, size, rdat)
para("There were also ", sum(is.na(dat$SEX)), " records where sex was missing (Table ", jvamiscenv$tabcount, ").")
a <- table(dat$LS[is.na(dat$SEX)])
tab <- data.frame(LakeSite=names(a), Nrecords=as.numeric(a))
tabl("Number of records, by lake and site, with nothing entered for sex.", row.names=FALSE)
para("And ", sum(!is.na(dat$SEX) & !(dat$SEX %in% 1:2)), " records where sex was not equal to 1 or 2 (Table ", jvamiscenv$tabcount, ").")
tab <- dat[!is.na(dat$SEX) & !(dat$SEX %in% 1:2), c(1:6, 8:10)]
tab[, 7:9] <- round(tab[, 7:9], 2)
tabl("Records with sex not equal to 1 or 2.", row.names=FALSE)
para("For analyses conducted for individual sexes, I used only those records with sex equal to 1 (males) or 2 (females) .",
"  In all cases (both sexes, just males, and just females),",
" I scaled the data (subtracting the mean and dividing by the standard deviation),",
" so that all of the truss measurements would have the same mean and variance.",
"  This ensures that each truss measure will be given the same amount of weight in a cluster analysis.")
# subset the data
submf.all <- dat[!duplicated(dat$ID), ]
para("I looked at the length distribution and sex composition at all sites (Figures ", jvamiscenv$figcount, " and ", jvamiscenv$figcount+1, ").",
"  Only those fish greater than or equal to 300 mm were used in the tables, figures, and analyses that follow Figure ", jvamiscenv$figcount, ".")
susl <- sort(unique(dat$LS))
tlmed <- tapply(submf.all$TL, submf.all$LS, median)
ord <- order(tlmed)
fig <- function() {
par(mfrow=c(length(susl), 1), mar=c(0, 0, 0, 0), oma=c(4, 1, 1, 0))
for(i in ord) {
sel <- submf.all$LS == susl[i]
hist(submf.all$TL[sel], breaks=seq(200, 550, 10), axes=FALSE, col="gray", xlab="", ylab="", main="")
mtext(susl[i], side=3, line=-1, adj=0.05, cex=0.7)
abline(v=seq(200, 550, 50))
abline(v=tlmed[i], col="cyan", lwd=2)
}
axis(1, outer=TRUE, lwd=0, lwd.ticks=1)
mtext("Total length  (mm)", side=1, outer=TRUE, line=2.5)
mtext("Frequency", side=2, outer=TRUE, line=-0.5)
}
figu("Length frequency distribution of all fish by lake and site, sites ordered by median length (vertical cyan lines).", newpage="port")
# further subset the data, only fish >= 300 mm
submf <- submf.all[submf.all$TL >= 300, ]
subm <- dat[!duplicated(dat$ID) & !is.na(dat$SEX) & dat$SEX==1, ]
subf <- dat[!duplicated(dat$ID) & !is.na(dat$SEX) & dat$SEX==2, ]
# rescale the data
subscmf <- scale(submf[, rtrussvars])
subscm <- scale(subm[, rtrussvars])
subscf <- scale(subf[, rtrussvars])
if(FALSE) {
# error check truss measurements
submftruss <- data.frame(t(submf[, ltrussvars]))
names(submftruss) <- submf$ID
fc1 <- lapply(submftruss, buildfish)
fc2 <- lapply(submftruss, buildfish, upfirst=FALSE)
fc1[sapply(fc1, function(x) any(is.na(x)))]
fc2[sapply(fc2, function(x) any(is.na(x)))]
buildfish(submf[submf$ID==106439, ltrussvars])
buildfish(submf[submf$ID==106439, ltrussvars], upfirst=FALSE)
sort(signif(submf[submf$ID==106439, ltrussvars], 3))
# error in ID 106439, L5=54.9, L10=182, L11=122 ... L10 too big??
# this error seems to be fixed with the remeasuring
t1 <- t(sapply(fc1, fc2truss))
t2 <- t(sapply(fc2, fc2truss))
r1 <- submf[, ltrussvars] - t1[, ltrussvars]
r2 <- submf[, ltrussvars] - t2[, ltrussvars]
mse1 <- sqrt(apply(r1^2, 1, sum))
mse2 <- sqrt(apply(r2^2, 1, sum))
mse <- pmax(mse1, mse2, na.rm=TRUE)
sel <- mse > 20
round(r1[sel, ])
round(r2[sel, ])
t1[sel, ]
t2[sel, ]
submf[sel, ]
#####################################################################################
# remeas[remeas$ID. %in% submf$ID[sel], ]
count <- 0
for(i in 1:30) {
for(j in (i+1):31) {
if(count %% 9 == 0) {
windows()
par(mfrow=c(3, 3), mar=c(4, 4, 1, 1), cex=0.5)
}
count <- count + 1
plotblank(submf[, ltrussvars[i]], submf[, ltrussvars[j]], xlab=ltrussvars[i], ylab=ltrussvars[j])
text(submf[, ltrussvars[i]], submf[, ltrussvars[j]], seq(submf$ID))
}}
# these are rows selected as outliers from the plots
a <- c(586, 146, 117, 66, 255, 164, 215, 14, 374, 74, 97, 226, 239, 39, 571, 193, 738, 305, 219, 75)
mse[a]
b <- sort(unique(c(seq(sel)[sel], a)))
btruss <- data.frame(t(submf[b, ltrussvars]/submf$TL))
names(btruss) <- submf$ID[b]
fc <- lapply(btruss, function(x) fishpts(x)[[2]])
fc1 <- lapply(btruss, function(x) buildfish(x))
fc2 <- lapply(btruss, function(x) buildfish(x, upfirst=FALSE))
fishpord <- c(1:4, 6, 8, 10, 12, 14, 13, 11, 9, 7, 5, 1)
fishpord2 <- c(1:14, 1)
xyr <- apply(do.call(rbind, fc), 2, range)
windows(h=9, w=6.5)
par(mar=c(0, 0, 1, 0), mfrow=c(9, 3))
for(i in 1:length(fc)) {
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="", main=submf$ID[b][i])
lines(fc[[i]][fishpord, ], type="o")
lines(fc1[[i]][fishpord2, ], type="o", col="red")
lines(fc2[[i]][fishpord2, ], type="o", col="blue")
}
allison <- c(106414, 106439, 106509, 106517, 106518, 106540, 106220, 106250, 106262, 106268, 106297, 87077,
87081, 87089, 87126, 87143, 8105018, 28, 102661, 102003, 102945)
btruss <- data.frame(t(submf[submf$ID %in% allison, ltrussvars]/submf$TL))
names(btruss) <- submf$ID[submf$ID %in% allison]
fc <- lapply(btruss, function(x) fishpts(x)[[2]])
fc1 <- lapply(btruss, function(x) buildfish(x))
fc2 <- lapply(btruss, function(x) buildfish(x, upfirst=FALSE))
xyr <- apply(do.call(rbind, fc), 2, range)
windows(h=9, w=6.5)
par(mar=c(0, 0, 1, 0), mfrow=c(7, 3))
for(i in 1:length(fc)) {
if(i==6) frame()
j <- match(allison[-6][i], names(btruss))
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="", main=allison[-6][i])
lines(fc[[j]][fishpord, ], type="o")
lines(fc1[[j]][fishpord2, ], type="o", col="red")
lines(fc2[[j]][fishpord2, ], type="o", col="blue")
}
}
subb <- rbind(subm, subf)
pmale <- tapply(subb$SEX==1, subb$LS, mean)
ord <- order(pmale)
fig <- function() {
par(mar=c(4, 11, 1, 1), xaxs="i")
barplot(rbind(pmale[ord], 1-pmale[ord]), horiz=TRUE, las=1, xlim=c(0, 1), col=c("blue", "red"), xlab="Proportion males", ylab="")
box()
abline(v=seq(0.2, 0.8, 0.2))
}
figu("Sex composition by lake and site, sites ordered by the proportion of males (blue).", h=4, w=4)
nsitesmf <- length(unique(submf$LS))
nsitesm <- length(unique(subm$LS))
nsitesf <- length(unique(subf$LS))
ks <- 1:nsitesmf
pamcl <- pamk(data=subscmf, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("I used the PAM (partitioning around medioids) method for clustering.",
"  I let the number of clusters range from 1 to the number of sites represented: ", 
nsitesmf, " sites for both sexes combined, ", nsitesm, " for males, and ", nsitesf, " for females.",
"  The recommended number of clusters for data from both sexes combined",
" based on the optimum average silhouette width was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig.nclusters <- function(title) {
plot(ks[-1], pamcl$crit[-1], las=1, type="b", 
xlab="No. of clusters", ylab="Average silhouette width", main=title)
abline(v=pamcl$nc, lty=2)
sel <- ks==pamcl$nc
points(ks[sel], pamcl$crit[sel], pch=16, cex=1.5)
}
fig <- function() fig.nclusters(title=paste(nsitesmf, "Sites, Both Sexes"))
figu("Recommended number of clusters based on the optimum average silhouette width, ", nsitesmf, " sites and both sexes combined.", h=4, w=4)
# look at the proportion of fish in each lake/site assigned to each cluster group
tab.prop <- function(grp, df) {
tot <- tapply(!is.na(grp), list(df$LS, grp), sum)
tot[is.na(tot)] <- 0
prop <- tot/apply(tot, 1, sum)
ord <- seriate(prop, method="PCA")
g <- prop[get_order(ord, 1), get_order(ord, 2)]
dimnames(g)[[2]] <- paste0("G", dimnames(g)[[2]])
list(g=g, gord=get_order(ord, 2))
}
both <- tab.prop(group, submf)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, ", nsitesmf, " sites and both sexes combined.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "lightgreen", "darkgreen")
fig.bargrp <- function() {
par(mar=c(4, 8, 1, 1),  xaxs="i")
barplot(t(g)[, dim(g)[1]:1], horiz=TRUE, las=1, xlim=c(0, 1), col=colz[both$gord], xlab="Proportion of fish", ylab="")
box()
}
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, ", nsitesmf, " sites and both sexes combined.", h=4, w=4)
rm(tlmed, ord, subb, pmale, g)
para("I divided the truss measurements by the fish total length and calculated the median of these values for each cluster group.",
"  Then I built a representative fish diagram of each cluster group based on these values (Figure ", jvamiscenv$figcount, ").")
fishpord <- c(1:4, 6, 8, 10, 12, 14, 13, 11, 9, 7, 5, 1)
#fishpord <- c(1:14, 1)
medun <- t(apply(submf[, ltrussvars]/submf$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig.gfish <- function() {
par(mar=c(0, 0, 1, 0))
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
for(i in 1:length(fc)) {
co <- fc[[i]]
lines(co[fishpord, ], col=colz[i], type="o")
}
mtext(c("Head", "Tail"), side=3, adj=c(0.05, 0.95), line=-1)
legend("top", paste("Group", 1:pamcl$nc), col=colz, lty=1, bty="n", lwd=3, horiz=TRUE)
}
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, ", nsitesmf, " sites and both sexes combined.",
"  Fish are lined up by their noses.", h=3, w=6.5)
fig.grpdif <- function(title) {
plot(1:dim(med2)[1], med2$mdif, ylim=c(-1, 1)*max(amdif), las=1,
xlab="Truss  (r#)", ylab="Difference between scaled measures of group 1 and 2", main=title)
abline(h=0)
segments(1:dim(med2)[1], med2$mdif, 1:dim(med2)[1], 0)
}
if(pamcl$nc == 2) {
para("I calculated the median of each of the scaled measurements for each group.",
"  Then I looked at the difference between those medians to see which truss measurements",
" were the most different between the groups (Figure ", jvamiscenv$figcount, ").")
# median measures per group
med <- t(apply(subscmf, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesmf, "Sites, Both Sexes"))
figu("Difference in truss measurements between the cluster groups, ", nsitesmf, " sites and both sexes combined.", 
h=4, w=4)
}
para("I also looked at how the clustering would have proceeded if we had started with a single cluster of fish at each site.",
"  For this, I used agglomerative hierarchical clustering with the centroid method and the squared Euclidean distances (Figure ",
jvamiscenv$figcount, ".)")
cent <- apply(subscmf, 2, tapply, submf$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(submf$LS))
fig.dendro <- function() {
par(mar=c(4, 1, 0, 10))
plot(as.dendrogram(hc1), horiz=TRUE, xlab="Height", ylab="")
}
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, ", nsitesmf, " sites and both sexes combined.", h=8.5, w=4.4)
ks <- 1:nsitesm
pamcl <- pamk(data=subscm, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("The recommended number of clusters for males was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
group
length(group)
dim(subscm)
head(subscm)
head(subm)
dim(subm)
head(subm, 2)
# C:\JVA\Consult\Yule\CiscoMorpho\CiscoMorpho v6.r
# bring in functions
source("C:/JVA/Consult/Yule/CiscoMorpho/CiscoMorphFunctions.r")
library(fpc)
library(rpart)
library(rpart.plot)
library(seriation)
library(plyr)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/Cisco size-corrected residuals FINAL.xls")
dat1 <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
dat1$LS <- paste(substring(dat1$LAKE, 1, 1), dat1$SITE, sep=" - ")
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/FISH MORPHOMETRICS with total lengths RAW Truss measurements.xlsx")
datraw <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/Re-measured photos for Jean.xlsx")
remeas <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
dat2 <- cbind(dat1, datraw[match(dat1$ID, datraw$ID.), paste0("L", 1:31)])
ltrussvars <- paste0("L", 1:31)
rtrussvars <- paste0("r", 1:31)
# replace truss lengths for 21 fish photos that were remeasured
dat2[match(remeas$ID., dat2$ID), ltrussvars] <- remeas[, ltrussvars]
# more Lake Huron (Manitoulin Island) and Lake Erie data (22 Jan 2015 e-mail, https://mail.google.com/mail/u/0/#inbox/14b12f1714db6fe0)
wb <- loadWorkbook("C:/JVA/Consult/Yule/CiscoMorpho/2014 Huron and Erie Cisco morphometric measurements.xlsx")
more <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
more$OBS <- 1:dim(more)[1]
# missing AGE
fromnames <- c("Fish.ID", "TL..mm.")
tonames <-  c("ID",  "TL")
names(more) <- recode(names(more), fromnames, tonames)
names(more) <- casefold(names(more), upper=TRUE)
more$SITE[more$SITE=="Manitoulin Island"] <- "MANITOULIN"
more$LS <- ifelse(more$LAKE=="Erie", "E - ALL", paste(substring(more$LAKE, 1, 1), more$SITE, sep=" - "))
more$SEX <- as.numeric(more$SEX)
dat3 <- rbind.fill(dat2, more)
####################
doc <- startrtf(file=paste(Sys.Date(), "Cisco Morpho"), dir="C:/JVA/Consult/Yule/CiscoMorpho")
heading("Exploring Dan's Cisco Morphometrics Data")
heading("Jean V. Adams - 27 January 2015", 2)
para("There was one row in the cisco morphometrics data with missing truss measurements (Table ", jvamiscenv$tabcount, ").",
"  This row was eliminated from further analysis.")
tab <- dat3[is.na(dat3$L1), c("OBS", "ID", "SEX", "AGE", "LAKE", "SITE", "LS", "TL", ltrussvars[1:5])]
tabl("Records with missing truss measurements.", row.names=FALSE)
dat4 <- dat3[!is.na(dat3$L1), ]
para("There were a few rows in the cisco morphometrics data with duplicate IDs.",
"  Most of the measurements were pretty close, but a few were a bit further off (Table ", jvamiscenv$tabcount, ").",
"  Dan checked into these, and could only find photos for OBSs 563 and 675,",
" so all of the other observations were removed prior to analysis.")
a <- dat4[dat4$ID %in% dat4$ID[duplicated(dat4$ID)], ]
b <- a[c(1, 3, 5, 7, 9), rtrussvars] - a[c(2, 4, 6, 8, 10), rtrussvars]
#plot(sort(abs(unlist(b))))
tab <- a[, c(1:7, 7+c(9, 16, 28, 29))]
tab[, 8:11] <- format(round(tab[, 8:11], 2))
tabl("Records with duplicate IDs.  Truss measurements are given for those measures that were off by more than 0.3.", row.names=FALSE)
dat4 <- dat4[!(dat4$OBS %in% tab$OBS[!(tab$OBS %in% c(563, 675))]), ]
para("Prior to analysis, the size component was removed from the morphometric measures.",
"  Truss measurements (in mm) were natural log transformed, and the first principal component",
" (based on the covariance matrix) of these measures was used as general measure of size (Figure ", jvamiscenv$figcount, ").")
# log transform the lengths
ldat <- log(dat4[, ltrussvars])
# use the first principal component as size
size <- princomp(ldat, cor=FALSE, scores=TRUE)$scores[, 1]
fig <- function() {
par(mar=c(4, 4, 1, 1))
plot(dat4$TL, size, xlab="Total length of fish  (mm)", ylab="General measure of size  (PC1)", las=1)
}
figu("Relation between fish total length and derived general measure of fish size based on the first",
" principal component score of the log transformed truss measurements.", h=4, w=4)
# regress size (x) on each of the log transformed lengths (y) to get a residual
rdat <- sapply(ldat, function(y) lm(y ~ size)$resid)
dimnames(rdat)[[2]] <- rtrussvars
dat <- cbind(dat4[, c("OBS", "ID", "SEX", "AGE", "LAKE", "SITE", "LS", "TL", ltrussvars)], size, rdat)
# write.csv(dat, "C:/JVA/Consult/Yule/CiscoMorpho/Cisco morpho with Jean residuals.csv", row.names=FALSE)
rm(wb, dat1, datraw, dat3, dat4, a, b, ldat, size, rdat)
para("There were also ", sum(is.na(dat$SEX)), " records where sex was missing (Table ", jvamiscenv$tabcount, ").")
a <- table(dat$LS[is.na(dat$SEX)])
tab <- data.frame(LakeSite=names(a), Nrecords=as.numeric(a))
tabl("Number of records, by lake and site, with nothing entered for sex.", row.names=FALSE)
para("And ", sum(!is.na(dat$SEX) & !(dat$SEX %in% 1:2)), " records where sex was not equal to 1 or 2 (Table ", jvamiscenv$tabcount, ").")
tab <- dat[!is.na(dat$SEX) & !(dat$SEX %in% 1:2), c(1:6, 8:10)]
tab[, 7:9] <- round(tab[, 7:9], 2)
tabl("Records with sex not equal to 1 or 2.", row.names=FALSE)
para("For analyses conducted for individual sexes, I used only those records with sex equal to 1 (males) or 2 (females) .",
"  In all cases (both sexes, just males, and just females),",
" I scaled the data (subtracting the mean and dividing by the standard deviation),",
" so that all of the truss measurements would have the same mean and variance.",
"  This ensures that each truss measure will be given the same amount of weight in a cluster analysis.")
# subset the data
submf.all <- dat[!duplicated(dat$ID), ]
para("I looked at the length distribution and sex composition at all sites (Figures ", jvamiscenv$figcount, " and ", jvamiscenv$figcount+1, ").",
"  Only those fish greater than or equal to 300 mm were used in the tables, figures, and analyses that follow Figure ", jvamiscenv$figcount, ".")
susl <- sort(unique(dat$LS))
tlmed <- tapply(submf.all$TL, submf.all$LS, median)
ord <- order(tlmed)
fig <- function() {
par(mfrow=c(length(susl), 1), mar=c(0, 0, 0, 0), oma=c(4, 1, 1, 0))
for(i in ord) {
sel <- submf.all$LS == susl[i]
hist(submf.all$TL[sel], breaks=seq(200, 550, 10), axes=FALSE, col="gray", xlab="", ylab="", main="")
mtext(susl[i], side=3, line=-1, adj=0.05, cex=0.7)
abline(v=seq(200, 550, 50))
abline(v=tlmed[i], col="cyan", lwd=2)
}
axis(1, outer=TRUE, lwd=0, lwd.ticks=1)
mtext("Total length  (mm)", side=1, outer=TRUE, line=2.5)
mtext("Frequency", side=2, outer=TRUE, line=-0.5)
}
figu("Length frequency distribution of all fish by lake and site, sites ordered by median length (vertical cyan lines).", newpage="port")
# further subset the data, only fish >= 300 mm
submf <- submf.all[submf.all$TL >= 300, ]
subm <- dat[!duplicated(dat$ID) & !is.na(dat$SEX) & dat$SEX==1, ]
subf <- dat[!duplicated(dat$ID) & !is.na(dat$SEX) & dat$SEX==2, ]
# rescale the data
subscmf <- scale(submf[, rtrussvars])
subscm <- scale(subm[, rtrussvars])
subscf <- scale(subf[, rtrussvars])
if(FALSE) {
# error check truss measurements
submftruss <- data.frame(t(submf[, ltrussvars]))
names(submftruss) <- submf$ID
fc1 <- lapply(submftruss, buildfish)
fc2 <- lapply(submftruss, buildfish, upfirst=FALSE)
fc1[sapply(fc1, function(x) any(is.na(x)))]
fc2[sapply(fc2, function(x) any(is.na(x)))]
buildfish(submf[submf$ID==106439, ltrussvars])
buildfish(submf[submf$ID==106439, ltrussvars], upfirst=FALSE)
sort(signif(submf[submf$ID==106439, ltrussvars], 3))
# error in ID 106439, L5=54.9, L10=182, L11=122 ... L10 too big??
# this error seems to be fixed with the remeasuring
t1 <- t(sapply(fc1, fc2truss))
t2 <- t(sapply(fc2, fc2truss))
r1 <- submf[, ltrussvars] - t1[, ltrussvars]
r2 <- submf[, ltrussvars] - t2[, ltrussvars]
mse1 <- sqrt(apply(r1^2, 1, sum))
mse2 <- sqrt(apply(r2^2, 1, sum))
mse <- pmax(mse1, mse2, na.rm=TRUE)
sel <- mse > 20
round(r1[sel, ])
round(r2[sel, ])
t1[sel, ]
t2[sel, ]
submf[sel, ]
#####################################################################################
# remeas[remeas$ID. %in% submf$ID[sel], ]
count <- 0
for(i in 1:30) {
for(j in (i+1):31) {
if(count %% 9 == 0) {
windows()
par(mfrow=c(3, 3), mar=c(4, 4, 1, 1), cex=0.5)
}
count <- count + 1
plotblank(submf[, ltrussvars[i]], submf[, ltrussvars[j]], xlab=ltrussvars[i], ylab=ltrussvars[j])
text(submf[, ltrussvars[i]], submf[, ltrussvars[j]], seq(submf$ID))
}}
# these are rows selected as outliers from the plots
a <- c(586, 146, 117, 66, 255, 164, 215, 14, 374, 74, 97, 226, 239, 39, 571, 193, 738, 305, 219, 75)
mse[a]
b <- sort(unique(c(seq(sel)[sel], a)))
btruss <- data.frame(t(submf[b, ltrussvars]/submf$TL))
names(btruss) <- submf$ID[b]
fc <- lapply(btruss, function(x) fishpts(x)[[2]])
fc1 <- lapply(btruss, function(x) buildfish(x))
fc2 <- lapply(btruss, function(x) buildfish(x, upfirst=FALSE))
fishpord <- c(1:4, 6, 8, 10, 12, 14, 13, 11, 9, 7, 5, 1)
fishpord2 <- c(1:14, 1)
xyr <- apply(do.call(rbind, fc), 2, range)
windows(h=9, w=6.5)
par(mar=c(0, 0, 1, 0), mfrow=c(9, 3))
for(i in 1:length(fc)) {
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="", main=submf$ID[b][i])
lines(fc[[i]][fishpord, ], type="o")
lines(fc1[[i]][fishpord2, ], type="o", col="red")
lines(fc2[[i]][fishpord2, ], type="o", col="blue")
}
allison <- c(106414, 106439, 106509, 106517, 106518, 106540, 106220, 106250, 106262, 106268, 106297, 87077,
87081, 87089, 87126, 87143, 8105018, 28, 102661, 102003, 102945)
btruss <- data.frame(t(submf[submf$ID %in% allison, ltrussvars]/submf$TL))
names(btruss) <- submf$ID[submf$ID %in% allison]
fc <- lapply(btruss, function(x) fishpts(x)[[2]])
fc1 <- lapply(btruss, function(x) buildfish(x))
fc2 <- lapply(btruss, function(x) buildfish(x, upfirst=FALSE))
xyr <- apply(do.call(rbind, fc), 2, range)
windows(h=9, w=6.5)
par(mar=c(0, 0, 1, 0), mfrow=c(7, 3))
for(i in 1:length(fc)) {
if(i==6) frame()
j <- match(allison[-6][i], names(btruss))
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="", main=allison[-6][i])
lines(fc[[j]][fishpord, ], type="o")
lines(fc1[[j]][fishpord2, ], type="o", col="red")
lines(fc2[[j]][fishpord2, ], type="o", col="blue")
}
}
subb <- rbind(subm, subf)
pmale <- tapply(subb$SEX==1, subb$LS, mean)
ord <- order(pmale)
fig <- function() {
par(mar=c(4, 11, 1, 1), xaxs="i")
barplot(rbind(pmale[ord], 1-pmale[ord]), horiz=TRUE, las=1, xlim=c(0, 1), col=c("blue", "red"), xlab="Proportion males", ylab="")
box()
abline(v=seq(0.2, 0.8, 0.2))
}
figu("Sex composition by lake and site, sites ordered by the proportion of males (blue).", h=4, w=4)
nsitesmf <- length(unique(submf$LS))
nsitesm <- length(unique(subm$LS))
nsitesf <- length(unique(subf$LS))
ks <- 1:nsitesmf
pamcl <- pamk(data=subscmf, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("I used the PAM (partitioning around medioids) method for clustering.",
"  I let the number of clusters range from 1 to the number of sites represented: ", 
nsitesmf, " sites for both sexes combined, ", nsitesm, " for males, and ", nsitesf, " for females.",
"  The recommended number of clusters for data from both sexes combined",
" based on the optimum average silhouette width was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig.nclusters <- function(title) {
plot(ks[-1], pamcl$crit[-1], las=1, type="b", 
xlab="No. of clusters", ylab="Average silhouette width", main=title)
abline(v=pamcl$nc, lty=2)
sel <- ks==pamcl$nc
points(ks[sel], pamcl$crit[sel], pch=16, cex=1.5)
}
fig <- function() fig.nclusters(title=paste(nsitesmf, "Sites, Both Sexes"))
figu("Recommended number of clusters based on the optimum average silhouette width, ", nsitesmf, " sites and both sexes combined.", h=4, w=4)
# look at the proportion of fish in each lake/site assigned to each cluster group
tab.prop <- function(grp, df) {
tot <- tapply(!is.na(grp), list(df$LS, grp), sum)
tot[is.na(tot)] <- 0
prop <- tot/apply(tot, 1, sum)
ord <- seriate(prop, method="PCA")
g <- prop[get_order(ord, 1), get_order(ord, 2)]
dimnames(g)[[2]] <- paste0("G", dimnames(g)[[2]])
list(g=g, gord=get_order(ord, 2))
}
both <- tab.prop(group, submf)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, ", nsitesmf, " sites and both sexes combined.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "lightgreen", "darkgreen")
fig.bargrp <- function() {
par(mar=c(4, 8, 1, 1),  xaxs="i")
barplot(t(g)[, dim(g)[1]:1], horiz=TRUE, las=1, xlim=c(0, 1), col=colz[both$gord], xlab="Proportion of fish", ylab="")
box()
}
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, ", nsitesmf, " sites and both sexes combined.", h=4, w=4)
rm(tlmed, ord, subb, pmale, g)
para("I divided the truss measurements by the fish total length and calculated the median of these values for each cluster group.",
"  Then I built a representative fish diagram of each cluster group based on these values (Figure ", jvamiscenv$figcount, ").")
fishpord <- c(1:4, 6, 8, 10, 12, 14, 13, 11, 9, 7, 5, 1)
#fishpord <- c(1:14, 1)
medun <- t(apply(submf[, ltrussvars]/submf$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig.gfish <- function() {
par(mar=c(0, 0, 1, 0))
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
for(i in 1:length(fc)) {
co <- fc[[i]]
lines(co[fishpord, ], col=colz[i], type="o")
}
mtext(c("Head", "Tail"), side=3, adj=c(0.05, 0.95), line=-1)
legend("top", paste("Group", 1:pamcl$nc), col=colz, lty=1, bty="n", lwd=3, horiz=TRUE)
}
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, ", nsitesmf, " sites and both sexes combined.",
"  Fish are lined up by their noses.", h=3, w=6.5)
fig.grpdif <- function(title) {
plot(1:dim(med2)[1], med2$mdif, ylim=c(-1, 1)*max(amdif), las=1,
xlab="Truss  (r#)", ylab="Difference between scaled measures of group 1 and 2", main=title)
abline(h=0)
segments(1:dim(med2)[1], med2$mdif, 1:dim(med2)[1], 0)
}
if(pamcl$nc == 2) {
para("I calculated the median of each of the scaled measurements for each group.",
"  Then I looked at the difference between those medians to see which truss measurements",
" were the most different between the groups (Figure ", jvamiscenv$figcount, ").")
# median measures per group
med <- t(apply(subscmf, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesmf, "Sites, Both Sexes"))
figu("Difference in truss measurements between the cluster groups, ", nsitesmf, " sites and both sexes combined.", 
h=4, w=4)
}
para("I also looked at how the clustering would have proceeded if we had started with a single cluster of fish at each site.",
"  For this, I used agglomerative hierarchical clustering with the centroid method and the squared Euclidean distances (Figure ",
jvamiscenv$figcount, ".)")
cent <- apply(subscmf, 2, tapply, submf$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(submf$LS))
fig.dendro <- function() {
par(mar=c(4, 1, 0, 10))
plot(as.dendrogram(hc1), horiz=TRUE, xlab="Height", ylab="")
}
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, ", nsitesmf, " sites and both sexes combined.", h=8.5, w=4.4)
ks <- 1:nsitesm
pamcl <- pamk(data=subscm, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("The recommended number of clusters for males was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig <- function() fig.nclusters(title=paste(nsitesm, "Sites, Males"))
figu("Recommended number of clusters based on the optimum average silhouette width, males at ", nsitesm, " sites.", h=4, w=4)
both <- tab.prop(group, subm)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, males at ", nsitesm, " sites.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "lightblue", "darkblue")
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, males at ", nsitesm, " sites.", h=4, w=4)
medall <- apply(subm[, ltrussvars]/subm$TL, 2, median, na.rm=TRUE)
fcall <- fishpts(medall)[[2]]
medun <- t(apply(subm[, ltrussvars]/subm$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, males at ", nsitesm, " sites.",
"  Fish are lined up by their noses.", h=3, w=6.5)
if(pamcl$nc == 2) {
# median measures per group
med <- t(apply(subscm, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesm, "Sites, Males"))
figu("Difference in truss measurements between the cluster groups, males at ", nsitesm, " sites.", h=4, w=4)
}
cent <- apply(subscm, 2, tapply, subm$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(subm$LS))
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, males at ", nsitesm, " sites.", h=8.5, w=4.4)
write.csv(cbind(group, subm), "C:/JVA/Consult/Yule/CiscoMorpho/Cluster group males.csv", row.names=FALSE)
males <- list(ks=ks, pamcl=pamcl, group=group, both=both, g=g, colz=colz, fc=fc, fcall=fcall, xyr=xyr, hc1=hc1)
ks <- 1:nsitesf
pamcl <- pamk(data=subscf, krange=ks, criterion="asw", usepam=TRUE, scaling=FALSE, diss=FALSE)
group <- pamcl$pamobject$clustering
para("The recommended number of clusters for females was ", pamcl$nc, " (Figure ", jvamiscenv$figcount, ").")
fig <- function() fig.nclusters(title=paste(nsitesf, "Sites, Females"))
figu("Recommended number of clusters based on the optimum average silhouette width, females at ", nsitesf, " sites.", h=4, w=4)
both <- tab.prop(group, subf)
g <- both$g
tab <- data.frame(LakeSite=dimnames(g)[[1]], format(round(g, 4)))
tabl("Proportion of fish assigned to cluster groups in each lake and site, females at ", nsitesf, " sites.", row.names=FALSE)
colz <- colr(1:pamcl$nc, "brown", "orange")
fig <- function() fig.bargrp()
figu("Proportion of fish assigned to cluster groups in each lake and site, females at ", nsitesf, " sites.", h=4, w=4)
medall <- apply(subf[, ltrussvars]/subf$TL, 2, median, na.rm=TRUE)
fcall <- fishpts(medall)[[2]]
medun <- t(apply(subf[, ltrussvars]/subf$TL, 2, tapply, group, median, na.rm=TRUE))
fc <- lapply(data.frame(medun), function(x) fishpts(x)[[2]])
#fc <- lapply(data.frame(medun), function(x) buildfish(x))
xyr <- apply(do.call(rbind, fc), 2, range)
fig <- function() fig.gfish()
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group, females at ", nsitesf, " sites.",
"  Fish are lined up by their noses.", h=3, w=6.5)
if(pamcl$nc == 2) {
# median measures per group
med <- t(apply(subscf, 2, tapply, group, median))
med2 <- data.frame(med, mdif = med[, 1] - med[, 2])
med3 <- med2[order(med2$mdif), ]
amdif <- abs(med2$mdif)
fig <- function() fig.grpdif(title=paste(nsitesf, "Sites, Females"))
figu("Difference in residual (log transformed, size corrected, and scaled) truss measurements between the cluster groups,",
" females at ", nsitesf, " sites.", h=4, w=4)
}
cent <- apply(subscf, 2, tapply, subf$LS, mean)
hc1 <- hclust(dist(cent)^2, method="centroid", members=table(subf$LS))
fig <- function() fig.dendro()
figu("Centroid cluster analysis starting with a single cluster at each site, females at ", nsitesf, " sites.", h=8.5, w=4.4)
write.csv(cbind(group, subf), "C:/JVA/Consult/Yule/CiscoMorpho/Cluster group females.csv", row.names=FALSE)
females <- list(ks=ks, pamcl=pamcl, group=group, both=both, g=g, colz=colz, fc=fc, fcall=fcall, xyr=xyr, hc1=hc1)
medun.ms <- t(apply(subm[, ltrussvars]/subm$TL, 2, tapply, subm$LS, median, na.rm=TRUE))
medun.fs <- t(apply(subf[, ltrussvars]/subf$TL, 2, tapply, subf$LS, median, na.rm=TRUE))
medun.mu <- t(apply(subm[, ltrussvars], 2, tapply, subm$LS, median, na.rm=TRUE))
medun.fu <- t(apply(subf[, ltrussvars], 2, tapply, subf$LS, median, na.rm=TRUE))
fc.ms <- lapply(data.frame(medun.ms), function(x) fishpts(x)[[2]])
fc.fs <- lapply(data.frame(medun.fs), function(x) fishpts(x)[[2]])
fc.mu <- lapply(data.frame(medun.mu), function(x) fishpts(x)[[2]])
fc.fu <- lapply(data.frame(medun.fu), function(x) fishpts(x)[[2]])
# fc.ms <- lapply(data.frame(medun.ms), function(x) buildfish(x))
# fc.fs <- lapply(data.frame(medun.fs), function(x) buildfish(x))
# fc.mu <- lapply(data.frame(medun.mu), function(x) buildfish(x))
# fc.fu <- lapply(data.frame(medun.fu), function(x) buildfish(x))
xyr.s <- apply(rbind(do.call(rbind, fc.ms), do.call(rbind, fc.fs)), 2, range)
xyr.u <- apply(rbind(do.call(rbind, fc.mu), do.call(rbind, fc.fu)), 2, range)
suls <- dimnames(medun.ms)[[2]]
picksites <- c("H - ST. MARY", "O - CHAUMONT", "S - DEVILS I", "S - GRAND PO")
fig <- function() {
par(mfrow=c(4, 2), mar=c(0, 0, 1, 0), oma=c(0, 0, 2, 0))
for(i in match(picksites, suls)) {
eqscplot(1, 1, type="n", xlim=xyr.s[, 1], ylim=xyr.s[, 2], axes=FALSE, xlab="", ylab="")
lines(fc.ms[[i]][fishpord, ], col="blue", type="o")
lines(fc.fs[[i]][fishpord, ], col="red", type="o")
mtext(paste("     ", suls[i]), side=3, adj=0, line=-2)
eqscplot(1, 1, type="n", xlim=xyr.u[, 1], ylim=xyr.u[, 2], axes=FALSE, xlab="", ylab="")
lines(fc.mu[[i]][fishpord, ], col="blue", type="o")
lines(fc.fu[[i]][fishpord, ], col="red", type="o")
}
mtext(c("Scaled", "Unscaled"), side=3, adj=c(0.2, 0.8), outer=TRUE)
legend("top", c("Male", "Female"), col=c("blue", "red"), lty=1, bty="n")
}
figu("Comparison of median fish shapes of males and females at four selected sites,",
" using both scaled (by total length, left diagrams) and unscaled (right diagrams) truss measurements.",
"  Fish are lined up by their noses.", newpage="port")
####################
heading("Presentation figures", 2)
rm(ks, pamcl, group, both, g, colz, fc, fcall, xyr, hc1)
# use a single order of sites based on seriation of male and female cluster group proportions
gmf <- cbind(males$g[order(rownames(males$g)), ], females$g[order(rownames(females$g)), ])
ord <- seriate(gmf, method="PCA")
gmfo <- gmf[get_order(ord, 1), ]
gm <- gmfo[, 1:dim(males$g)[2]]
gf <- gmfo[, dim(males$g)[2]+(1:dim(females$g)[2])]
rm(gmf, ord, gmfo)
fig <- function() {
par(mfrow=c(1, 2))
attach(males)
g <<- gm
fig.bargrp()
detach(males)
attach(females)
g <<- gf
fig.bargrp()
detach(females)
}
figu("Proportion of male (left) and female (right) fish assigned to cluster groups in each lake and site.", h=3.5, w=6.5)
fig.gfish2 <- function() {
par(mar=c(0, 0, 1, 0))
for(i in 1:length(fc)) {
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
lines(fcall[fishpord, ], lty=2)
points(fcall[fishpord, ], pch=21, bg="white", col="black")
co <- fc[[i]]
lines(co[fishpord, ], col=colz[i], type="o", lwd=2, pch=16)
if(i==1) mtext(c("Head", "Tail"), side=3, adj=c(0.05, 0.95), line=-1)
}
}
fig <- function() {
nfish <- max(dim(gm)[2], dim(gf)[2])
par(mfcol=c(nfish, 2))
attach(males)
fig.gfish2()
detach(males)
attach(females)
par(mfg=c(1, 2))
fig.gfish2()
detach(females)
}
figu("Diagram of fish based on median truss measurements (scaled by total length) for each cluster group.",
"  Dashed lines represent the median male (left) and female (right) fish.",
"  Fish are lined up by their noses.", h=3.5, w=6.5)
endrtf()
rm(med, med2, med3, amdif, cent, medun)
if(FALSE) {
# print the points for one fish to overlay on photo
co <- fishpts(dat[dat$ID==500, ltrussvars])[[2]]
# co <- buildfish(dat[dat$ID==500, ltrussvars])
xyr <- apply(co, 2, range)
windows()
eqscplot(1, 1, type="n", xlim=xyr[, 1], ylim=xyr[, 2], axes=FALSE, xlab="", ylab="")
points(co[fishpord, ], col="red", pch=16)
}
tweethead()
cleanup()
q()
tweethead()
q()
tweethead()
q()
P <- array(0, c(2,2,2))
P[,,1] <- matrix(c(1,2,3,4),2,2,byrow=T);
P[,,2] <- matrix(c(5,6,7,8),2,2,byrow=T);
dimnames(P)
dim(P)
dimnames(P) <- list(c("live", "dead"), c("live", "dead"), NULL)
P
q()
?echo
?"<"
??echo
?source
?tweethead
tweethead <- function(tweet=TRUE, username=NULL, website=NULL, credentials=NULL) {
if(is.null(credentials)) {
api_key <- Sys.getenv("twitter_api_key")
api_secret <- Sys.getenv("twitter_api_secret")
access_token <- Sys.getenv("twitter_access_token")
access_token_secret <- Sys.getenv("twitter_access_token_secret")
} else {
api_key <- credentials[1]
api_secret <- credentials[2]
access_token <- credentials[3]
access_token_secret <- credentials[4]
}
# connect to Twitter
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
1
# grab headlines from website
# read in html source code
base.url <- Sys.getenv("website")
base.html <- getURLContent(base.url)[[1]]
# pull off links that say "More"
links <- strsplit(base.html, "ID=")[[1]]
links2 <- sapply(strsplit(links, "</a>"), "[", 1)[-1]
more.codes <- substring(stringin("more", links2), 1, 5)
more.urls <- paste0(base.url, "index.php?ID=", more.codes)
# pull off headline, photo url, photo caption
pull <- function(thisurl) {
thishtml <- getURLContent(thisurl)[[1]]
# headline
headlong <- strsplit(thishtml, "<font size=6><b>")[[1]][2]
head <- strsplit(headlong, "</b>")[[1]][1]
# photo url
photolong <- strsplit(thishtml, "<img src='./Photos/")[[1]]
if(length(photolong)>1) {
photolong <- photolong[2]
photo <- strsplit(photolong, "'><br>")[[1]][1]
photo.url <- paste0(base.url, "Photos/", photo)
} else {
photo.url <- ""
}
# photo caption
caplong <- strsplit(thishtml, "<br><font size=2><b>")[[1]]
if(length(caplong)>1) {
caplong <- caplong[2]
cap <- strsplit(caplong, "</b>")[[1]][1]
} else {
cap <- ""
}
c(article.url=thisurl, headline=head, photo.url=photo.url, photo.caption=cap)
}
# get new tweets ready
m <- do.call(rbind, lapply(more.urls, pull))
currentheads <- apply(m[, 2:1], 1, paste, collapse=". ")
### grab latest tweets
adj <- getUser(Sys.getenv("username"))
oldtweets <- twListToDF(userTimeline(adj, n=15, excludeReplies=TRUE))[, c("text", "favoriteCount", "retweetCount", "created")]
names(oldtweets)[names(oldtweets)=="created"] <- "createdUTC"
### tweet all new tweets that haven't been tweeted before
totweet <- currentheads[!(substring(currentheads, 1, 30) %in% substring(oldtweets$text, 1, 30))]
if(length(totweet) > 0) {
if(tweet) {
lapply(rev(totweet), updateStatus, lat=45.141473, long=-89.152339)
} else {
cat(paste("\n\n***  This is what would be posted if tweet=TRUE.\n\n"))
print(totweet)
cat("\n\n")
}
} else {
cat(paste0("\n\n***  No new headlines since last tweet, ", 
format(max(oldtweets$createdUTC), "%a %b %e %I:%M %p", tz=Sys.timezone()), ".\n\n\n"))
}
out <- list(oldtweets=oldtweets, currentheads=currentheads, totweet=totweet)
1
out
}
tweethead()
library(twitteR)
tweethead()
library(RCurl)
tweethead <- function(tweet=TRUE, username=NULL, website=NULL, credentials=NULL) {
if(is.null(credentials)) {
api_key <- Sys.getenv("twitter_api_key")
api_secret <- Sys.getenv("twitter_api_secret")
access_token <- Sys.getenv("twitter_access_token")
access_token_secret <- Sys.getenv("twitter_access_token_secret")
} else {
api_key <- credentials[1]
api_secret <- credentials[2]
access_token <- credentials[3]
access_token_secret <- credentials[4]
}
# connect to Twitter
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
< echo 1
# grab headlines from website
# read in html source code
base.url <- Sys.getenv("website")
base.html <- getURLContent(base.url)[[1]]
# pull off links that say "More"
links <- strsplit(base.html, "ID=")[[1]]
links2 <- sapply(strsplit(links, "</a>"), "[", 1)[-1]
more.codes <- substring(stringin("more", links2), 1, 5)
more.urls <- paste0(base.url, "index.php?ID=", more.codes)
# pull off headline, photo url, photo caption
pull <- function(thisurl) {
thishtml <- getURLContent(thisurl)[[1]]
# headline
headlong <- strsplit(thishtml, "<font size=6><b>")[[1]][2]
head <- strsplit(headlong, "</b>")[[1]][1]
# photo url
photolong <- strsplit(thishtml, "<img src='./Photos/")[[1]]
if(length(photolong)>1) {
photolong <- photolong[2]
photo <- strsplit(photolong, "'><br>")[[1]][1]
photo.url <- paste0(base.url, "Photos/", photo)
} else {
photo.url <- ""
}
# photo caption
caplong <- strsplit(thishtml, "<br><font size=2><b>")[[1]]
if(length(caplong)>1) {
caplong <- caplong[2]
cap <- strsplit(caplong, "</b>")[[1]][1]
} else {
cap <- ""
}
c(article.url=thisurl, headline=head, photo.url=photo.url, photo.caption=cap)
}
# get new tweets ready
m <- do.call(rbind, lapply(more.urls, pull))
currentheads <- apply(m[, 2:1], 1, paste, collapse=". ")
### grab latest tweets
adj <- getUser(Sys.getenv("username"))
oldtweets <- twListToDF(userTimeline(adj, n=15, excludeReplies=TRUE))[, c("text", "favoriteCount", "retweetCount", "created")]
names(oldtweets)[names(oldtweets)=="created"] <- "createdUTC"
### tweet all new tweets that haven't been tweeted before
totweet <- currentheads[!(substring(currentheads, 1, 30) %in% substring(oldtweets$text, 1, 30))]
if(length(totweet) > 0) {
if(tweet) {
lapply(rev(totweet), updateStatus, lat=45.141473, long=-89.152339)
} else {
cat(paste("\n\n***  This is what would be posted if tweet=TRUE.\n\n"))
print(totweet)
cat("\n\n")
}
} else {
cat(paste0("\n\n***  No new headlines since last tweet, ", 
format(max(oldtweets$createdUTC), "%a %b %e %I:%M %p", tz=Sys.timezone()), ".\n\n\n"))
}
list(oldtweets=oldtweets, currentheads=currentheads, totweet=totweet)
}
cleanup()
source("C:/Users/jvadams/Desktop/new  3.r")
tweethead()
q()
source("C:/Users/jvadams/Desktop/new  3.r")
cleanup()
q()
# C:\JVA\Lamprey\ChemControl\Resistance\Analysis\AnalyzeRaw.r
library(lubridate)
library(LW1949)
source("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/ReadSlaght.r")
dat <- Slaghtdat
rm(Slaghtdat)
sel <- grepl("s", dat$species, ignore.case=TRUE) & grepl("h", dat$water, ignore.case=TRUE)
sub <- dat[sel, ]
attach(sub)
mytable(test.type)
mytable(water)
mytable(location)
mytable(lab)
mytable(acc..no.)
mytable(temp.)
mytable(chemical)
mytable(species)
mytable(total.no..tested)
mytable(Folder)
mytable(File)
mytable(Sheet)
mytable(ill)
mytable(dead)
mytable(cumulative..ill)
mytable(cumulative..dead)
mytable(temp..unit)
mytable(conc..unit)
mytable(aerated.)
mytable(general.comment..regarding.the.whole.test.)
mytable(specific.comment..regarding.just.the.corresponding.line.of.data.)
plot(start.date)
plot(start.time)
plot(end.date)
plot(end.time)
plot(test.no.)
plot(conc.)
plot(check.time)
plot(Row)
plot(ID)
plot(group)
mytable(year(start.date))
head(sub)
head(sub)
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawData.RData")
all.main$Year <- year(all.main$Start_Date)
mi <- match(all.sub$ID, all.main$ID)
all.sub$Year <- all.main$Year[mi]
all.main$fg <- paste(all.main$Folder, all.main$group)
all.sub$fg <- all.main$fg[mi]
rm(mi)
mytable(all.main$Folder)
with(all.main, tapply(ID, Folder, range))
with(all.main, tapply(group, Folder, range))
hb <- all.main[all.main$Folder=="Slaght"]
hb <- all.main[all.main$Folder=="Slaght", ]
dim(hb)
head(hb)
head(sub)
plotdf(hb)
.SavedPlots <- NULL
graphics.off()
hb2 <- with(hb, hb[Water_Name=="Lake Huron", ])
dim(hb2)
plotdf(hb2)
hb2 <- with(hb, hb[Water_Name=="Lake Huron", ])
mytable(hb2$Year)
mytable(hb2$Duration)
length(unique(hb2$group))
mytable(round(hb2$Duration))
hbs <- all.sub[all.sub$ID %in% hb2$ID, ]
head(hbs)
hbs <- all.sub[all.sub$ID %in% hb2$ID & all.sub$Species==2, ]
plotdf(hbs)
.SavedPlots <- NULL
graphics.off()
setdiff(hb2$ID, hbs$ID)
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawData.RData")
all.main$Year <- year(all.main$Start_Date)
mi <- match(all.sub$ID, all.main$ID)
all.sub$Year <- all.main$Year[mi]
all.main$fg <- paste(all.main$Folder, all.main$group)
all.sub$fg <- all.main$fg[mi]
rm(mi)
mytable(all.main$Folder)
with(all.main, tapply(ID, Folder, range))
with(all.main, tapply(group, Folder, range))
hb <- all.main[all.main$Folder=="Slaght", ]
hb2 <- hb[hg$Water_Name=="Lake Huron", ]
mytable(hb2$Year)
mytable(round(hb2$Duration))
length(unique(hb2$group))
hbs <- all.sub[all.sub$ID %in% hb2$ID & all.sub$Species==2, ]
hb2 <- hb2[hb2$ID %in% hbs$ID, ]
mytable(hb2$Year)
mytable(round(hb2$Duration))
length(unique(hb2$group))
cleanup()
tweethead()
q()
tweethead()
q()
library(rpart)
model <- rpart(Product~. , data=trainData, control=rpart.control(minsplit=50, cp=0.002, xval=0))
?rpart
fit <- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis)
fit$cptable
fit <- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis, control=rpart.control(minsplit=50, cp=0.002, xval=0)
)
fit <- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis, control=rpart.control(minsplit=50, cp=0.002, xval=0))
fit$cptable
tweethead()
q()
SysDate()
Sys.Date()
heading
cleanup()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
trttabledf <- function(df, trtcut) {
attach(df)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
detach(df)
info$lrgdens <- info$large/info$survm2/0.08
info$trt <- as.numeric(info$lrgdens>trtcut)
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info$rank <- unlist(aggregate(-info$lrgdens, list(year=info$year), rank)$x)
info <- info[, c("year", "uid", "nplots", "survm2", "catch", "large", "lrgdens", "rank", "trt")]
info
}
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", figcount, ").")
?cheat
ls()
head(ia)
head(ln)
head(op)
head(ia)
head(ln)
head(op)
head(strz)
library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
head(usop)
dim(ia)
dim(op)
look <- merge(ia, op)
dim(look)
look <- merge(ia, op, all.y=TRUE)
dim(look)
head(look)
head(look)
look[is.na(look$infaream2), ]
look[is.na(look$infaream2), ]
descr(look[is.na(look$infaream2), ])
??descr
describe(look[is.na(look$infaream2), ])
plotdf(look[is.na(look$infaream2), ])
.SavedPlots <- NULL
graphics.off()
head(look)
stringin("nip", look$branchn)
stringin("byng", look$branchn)
look[!is.na(look$infaream2) & look$branchn %in% c("Nipigon Bay", "Byng Inlet"), ])
look[!is.na(look$infaream2) & look$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
look[!is.na(look$infaream2) & look$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
head(strz)
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
head(look)
with(look, tapply(infaream2, uid, mean, na.rm=TRUE))
with(look, tapply(infaream2, uid, mean, na.rm=TRUE))/10000
ha <- with(look, tapply(infaream2, uid, mean, na.rm=TRUE))/10000
hist(ha)
plot(sort(ha))
plot(sort(log(ha)))
plot(seq(ha), ha, log="y")
plot(seq(ha), ha, log="y", las=1)
plot(seq(ha), sort(ha), log="y", las=1)
hclust(ha)
hclust(ha[is.na(ha)]))
hclust(ha[!is.na(ha)]))
hclust(ha[!is.na(ha)])
hclust(dist(ha[!is.na(ha)]))
plot(hclust(dist(ha[!is.na(ha)])))
h$class
h <- hclust(dist(ha[!is.na(ha)]))
plot(h)
h$class
names(h)
h
?hclust
g <- cutree(hc, 3)
g <- cutree(h, 3)
tapply(ha, g, range)
ha <- with(look, tapply(infaream2, uid, mean, na.rm=TRUE))/10000
han <- ha[!is.na(ha)]
h <- hclust(dist(han))
plot(h)
h$class
g <- cutree(h, 3)
tapply(han, g, range)
plot(seq(ha), sort(ha), log="y", las=1)
plot(seq(han), sort(han), log="y", las=1)
abline(h=c(10, 20))
cut(han, 3)
?cut
quantile(han, (1:2)/3)
abline(h=quantile(han, (1:2)/3), col="red")
abline(h=c(5, 15), lwd=2)
han
match(names(han), look$uid)
look$branchn[match(names(han), look$uid)]
head(strz)
dput(names(strz))
# do all the surveyed lentic areas have an infested area associated with them?
look <- merge(op, ia, all.x=TRUE)
look2 <- merge(look, strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
head(look2)
head(look2)
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
ha <- with(comb, tapply(infaream2, uid, mean, na.rm=TRUE))/10000
han <- ha[!is.na(ha)]
sizecuts <- round(quantile(han, (1:2)/3))
par(mar=c(4, 4, 1, 1), cex=1.5)
plot(seq(han), sort(han), pch=16, log="y", las=1)
abline(h=sizecuts, lwd=2)
locator()
locator()
ha <- with(comb, tapply(infaream2, uid, mean, na.rm=TRUE))/10000
han <- ha[!is.na(ha)]
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
par(mar=c(4, 4, 1, 1), cex=1.5)
plot(seq(han), sort(han), pch=16, log="y", las=1)
abline(h=sizecuts, lwd=2)
cut(han, c(0, sizecuts, 1000), labels=FALSE)
par(mar=c(4, 4, 1, 1), cex=1.5)
plot(seq(han), sort(han), pch=16, col=sizecat+1, log="y", las=1)
abline(h=sizecuts, lwd=2)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
par(mar=c(4, 4, 1, 1), cex=1.5)
plot(seq(han), sort(han), pch=16, col=sizecat+1, log="y", las=1)
abline(h=sizecuts, lwd=2)
ha <- with(comb, tapply(infaream2, uid, mean, na.rm=TRUE))/10000
han <- ha[!is.na(ha)]
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
par(mar=c(4, 4, 1, 1), cex=1.5)
plot(seq(han), han[ord], pch=16, col=sizecat[ord]+1, log="y", las=1)
abline(h=sizecuts, lwd=2)
par(mar=c(4, 4, 1, 1), cex=1.5)
plot(seq(han), han[ord], pch=16, col=sizecat[ord]+1, log="y", las=1, xlab="Lentic areas, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lwd=2)
axis(2, at=sizecuts)
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han[ord], pch=16, col=sizecat[ord]+1, log="y", xlab="Lentic areas, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lwd=2)
axis(2, at=sizecuts)
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han[ord], pch=16, col=sizecat[ord]+1, log="y", xlab="Lentic areas, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
axis(2, at=sizecuts)
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic areas, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=sizecat[ord]+1)
axis(2, at=sizecuts)
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info$rank <- unlist(aggregate(-info$lrgdens, list(year=info$year), rank)$x)
info <- info[, c("year", "uid", "nplots", "survm2", "catch", "large", "lrgdens", "rank")]
info
base2 <- info[info$nplots >= 6 & info$survm2 >= (6*500), ]
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
fig()
head(comb)
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$infaream2 <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info$rank <- unlist(aggregate(-info$lrgdens, list(year=info$year), rank)$x)
info <- info[, c("year", "uid", "infaream2", "nplots", "survm2", "catch", "large", "lrgdens", "rank")]
info
base2 <- info[info$nplots >= 6 & info$survm2 >= (6*500), ]
fig()
head(base2)
subdex(info, nplots >= 6 & survm2 >= (6*500) & infaream2>0)
subdex
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500) & infaream2>0), ]
head(base2)
fig()
head(base2)
table(base2$year)
head(base3)
base3 <- base2[base2$year > 2009.5, ]
head(base3)
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info$rank <- unlist(aggregate(-info$lrgdens, list(year=info$year), rank)$x)
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens", "rank")]
info
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500) & iaha>0), ]
table(base2$year)
fig()
fig()
base3 <- base2[base2$year > 2009.5, ]
head(base3)
quantile(base3$iaha, (1:2)/3)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic areas, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=sizecat[ord]+1)
axis(2, at=sizecuts)
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcol[sizecat[ord]+1])
axis(2, at=sizecuts)
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info$rank <- unlist(aggregate(-info$lrgdens, list(year=info$year), rank)$x)
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens", "rank")]
info
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500) & iaha>0), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[base2$year > 2009.5, ]
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < 3 ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between 3 and 10 ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > 10 ha will be surveyed with 6 plots.", jvamiscenv$figcount, ").")
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
endrtf()
?cheat
?assign
# C:\JVA\Lamprey\Larvae\Lentic\ReadRankLists.r
wb <- loadWorkbook("c:/temp/junk.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
dat <- 
assign(paste0("dat", trtyearspi]-2000), dat)
}
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
assign(paste0("dat", trtyearspi]-2000), dat)
}
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
assign(paste0("dat", trtyearspi]-2000), dat)
}
i
i <- 1
wb <- loadWorkbook(rfiles[i])
dat <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
assign(paste0("dat", trtyearspi]-2000), dat)
paste0("dat", trtyearspi]-2000)
assign(paste0("dat", trtyears[i]-2000), dat)
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
assign(paste0("dat", trtyears[i]-2000), dat)
}
# C:\JVA\Lamprey\Larvae\Lentic\ReadRankLists.r
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
for(i in seq(trtyears)) {
print(i)
wb <- loadWorkbook(rfiles[i])
dat <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
assign(paste0("dat", trtyears[i]-2000), dat)
}
# C:\JVA\Lamprey\Larvae\Lentic\ReadRankLists.r
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
assign(paste0("dat", trtyears[i]-2000), dat)
print(i)
}
i <- 1
wb <- loadWorkbook(rfiles[i])
dat <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
assign(paste0("dat", trtyears[i]-2000), dat)
i <-2
wb <- loadWorkbook(rfiles[i])
dat <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
assign(paste0("dat", trtyears[i]-2000), dat)
i <- 3
wb <- loadWorkbook(rfiles[i])
dat <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
assign(paste0("dat", trtyears[i]-2000), dat)
i <- 4
wb <- loadWorkbook(rfiles[i])
dat <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
assign(paste0("dat", trtyears[i]-2000), dat)
head(dat11, 2)
head(dat12, 2)
head(dat13, 2)
head(dat14, 2)
head(dat11, 2)
head(dat12, 2)
head(dat13, 2)
head(dat14, 2)
library(dplyr)
rbindfill
?dplyr
library(plyr)
dats <- do.call(rbind.fill, list(dat11, dat12, dat13, dat14))
dim(dats)
with(dats, plot(Rank, Staff.Days.1))
with(dats, plot(Rank, Staff.Days.1), las=1)
dat <- vector("list", length(trtyears))
dat
cleanup()
q()
# C:\JVA\Lamprey\Larvae\Lentic\ReadRankLists.r
library(plyr)
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
dat <- vector("list", length(trtyears))
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat[[i]] <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
dat$FY <- trtyears[i]
}
dats <- do.call(rbind.fill, dat)
with(dats, plot(Rank, Staff.Days.1), las=1)
lapply(dat, class)
library(plyr)
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
dat <- vector("list", length(trtyears))
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat[[i]] <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
dat[[i]]$FY <- trtyears[i]
}
dats <- do.call(rbind.fill, dat)
with(dats, plot(Rank, Staff.Days.1), las=1)
dats <- do.call(rbind.fill, dat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
with(dats, plot(Rank, Staff.Days.1, col=FY-2008), las=1)
with(dats, plot(Rank, Staff.Days.1/1000, col=FY-2008, xlab="Rank", ylab="Cumulative staff days  (thousands)"), las=1)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
head(ia)
with(comb, table(year, branchn, is.na(infaream2)))
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info$rank <- unlist(aggregate(-info$lrgdens, list(year=info$year), rank)$x)
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens", "rank")]
info
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5 & iaha>0, ]
base3 <- base2[subdex(base2, year > 2009.5 & iaha>0), ]
look <- base2[subdex(base2, year > 2009.5), ]
dim(base3)
dim(look)
head(dats)
head(dats)
with(dats, dats[grep("lentic", Chem.Opt), ])
stringin
with(dats, dats[grep("lentic", Chem.Opt, ignore.case=TRUE), ])
head(dats)
with(dats, table(Sample.Year, !is.na(as.numeric(Area..ha.))))
with(dats, table(Sample.Year, grep("lentic", Chem.Opt, ignore.case=TRUE), !is.na(as.numeric(Area..ha.))))
h
head(dats, 2)
head(dats, 2)
head(dats, 2)
dat$Chem.Opt[grep("lent", dats$Chem.Opt)]
dat$Chem.Opt[grep("lent", dats$Chem.Opt, ignore.case=TRUE)]
dat$Chem.Opt[grep("lent", dats$Chem.Opt, ignore.case=TRUE, fixed=TRUE)]
dats$Chem.Opt[grep("lent", dats$Chem.Opt, ignore.case=TRUE, fixed=TRUE)]
dats$Chem.Opt[grep("lent", dats$Chem.Opt, ignore.case=TRUE)]
sort(dats$Chem.Opt[grep("lent", dats$Chem.Opt, ignore.case=TRUE)])
?grep
sel <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
with(dats, table(Sample.Year, sel))
sel <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
with(dats, table(FY, sel))
dats[subdex(dats, Rank<10 & FY==2014), ]
dats[dats$Rank<3, ]
table(is.na(dats$Chem.Opt))
dats <- do.call(rbind.fill, dat)
dats$Chem.Opt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
dats[dats$Rank<3, ]
match("Stream", names(dats))
dats <- dats[, -match("Stream", names(dats))]
dats[dats$Rank<3, ]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
with(dats, plot(Rank, Staff.Days.1/1000, col=FY-2008, xlab="Rank", ylab="Cumulative staff days  (thousands)"), las=1)
sel <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
with(dats, table(FY, sel))
dats$Area.ha <- as.numeric(dats$Area..ha.)
lapply(dats, class)
splitstr(dats$Chem.Opt)
strsplit(dats$Chem.Opt)
strsplit(dats$Chem.Opt, " ")
sapply(strsplit(dats$Chem.Opt, " "), "[", 2)
sort(sapply(strsplit(dats$Chem.Opt, " "), "[", 2))
sapply(strsplit(dats$Chem.Opt, " "), "[", 2)
str <- sapply(strsplit(dats$Chem.Opt, " "), "[", 2)
dats[str > "99]", ]
chemopt <- dats$Chem.Opt
chemopt <- gsub(chemopt, "-", " ")
chemopt <- dats$Chem.Opt
chemopt <- gsub("-", " ", chemopt)
chemopt <- dats$Chem.Opt
chemopt <- gsub("-", " ", chemopt)
str <- sapply(strsplit(chemopt, " "), "[", 2)
dats[str > "99]", ]
staffcostperday <- c(1017)
gbcostperkg <- c(22.66)
daysperha <- c(0.4)
kgperha <- 175
gbcostperha <- daysperha * staffcostperday + gbcostperkg * kgperha
gbcostperha
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
staffcostperday <- c(1002, 1075, 1017, 1017)
gbcostperkg <- c(22.40, 22.66, 22.66, 22.66)
daysperha <- 0.4
kgperha <- 175
gbcostperha <- daysperha * staffcostperday + gbcostperkg * kgperha
staffdaycut <- 6400
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
with(dats, plot(Rank, Staff.Days.1/1000, col=FY-2008, xlab="Rank", ylab="Cumulative staff days  (thousands)"), las=1)
abline(h=staffdaycut/1000, lty=2)
library(plyr)
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
staffcostperday <- c(1002, 1075, 1017, 1017)
gbcostperkg <- c(22.40, 22.66, 22.66, 22.66)
daysperha <- 0.4
kgperha <- 175
gbcostperha <- daysperha * staffcostperday + gbcostperkg * kgperha
staffdaycut <- 6400
dat <- vector("list", length(trtyears))
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat[[i]] <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
dat[[i]]$FY <- trtyears[i]
}
dats <- do.call(rbind.fill, dat)
# combine Chem.Opt and Stream into a single field
dats$Chem.Opt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
dats <- dats[, -match("Stream", names(dats))]
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
dats$areaha <- as.numeric(dats$Area..ha.)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Cost
dats$days <- dats$Staff.Days
chemopt <- dats$Chem.Opt
chemopt <- gsub("-", " ", chemopt)
str <- sapply(strsplit(chemopt, " "), "[", 2)
dats[str > "99]", ]
ls()
head(base3)
base3[subdex(base3, year==2011), ]
sort(str
)
# combine Chem.Opt and Stream into a single field
chemopt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
# then fix chemopts
chemopt <- gsub("-", " ", chemopt)
str <- sapply(strsplit(chemopt, " "), "[", 2)
dats[str > "99]", ]
chemopt[str > "99]"] <- paste("[S 572]", chemopt[str > "99]"])
str <- sapply(strsplit(chemopt, " "), "[", 2)
sort(str)
str <- sapply(strsplit(chemopt, " "), "[", 3)
str
nchar(str)
str <- sapply(strsplit(chemopt, " "), "[", 2)
streamcode <- substring(str, 1, nchar(str)-1)
streamcode
lk <- sapply(strsplit(chemopt, " "), "[", 1)
sort(lk)
table(lk)
dats[lk=="[C", ]
substring(sapply(strsplit(chemopt, " "), "[", 1), 2, 2)
head(base3)
base3$uid
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
dats$areaha <- as.numeric(dats$Area..ha.)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Cost
dats$days <- dats$Staff.Days
# combine Chem.Opt and Stream into a single field
chemopt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
# then fix chemopts
chemopt <- gsub("-", " ", chemopt)
str <- sapply(strsplit(chemopt, " "), "[", 2)
dats[str > "99]", ]
chemopt[str > "99]"] <- paste("[S 572]", chemopt[str > "99]"])
str <- sapply(strsplit(chemopt, " "), "[", 2)
streamcode <- as.numeric(substring(str, 1, nchar(str)-1))
scode <- ifelse(streamcode>10000, streamcode-10000, streamcode)
agent <- ifelse(streamcode>10000, "FWS", "DFO")
lkcode <- recode(substring(sapply(strsplit(chemopt, " "), "[", 1), 2, 2), c("S", "M", "H", "E", "O", "C"), 1:6)
uid <- paste(lkcode, agent, format(scode), sep="-")
uid
ls()
match(base3$uid, uid)
base3[is.na(match(base3$uid, uid)), ]
comb[comb$uid=="2-FWS-143", ]
comb[comb$uid=="2-FWS-143" & comb$year==2011, ]
head(dats)
head(dats)
dats$costperbigkill <- dats$Larvae.100mm
head(dats)
base3[is.na(match(base3$uid, dats$uid[dats$lentic])), ]
dats$uid[dats$lentic]
head(dats)
dats$lentic
dats$uid[dats$lentic]
dats$uid
dat <- vector("list", length(trtyears))
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat[[i]] <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
dat[[i]]$FY <- trtyears[i]
}
dats <- do.call(rbind.fill, dat)
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
dats$areaha <- as.numeric(dats$Area..ha.)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
# combine Chem.Opt and Stream into a single field
dats$Chem.Opt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
dats <- dats[, -match("Stream", names(dats))]
# then convert chemopts to uid's
chemopt <- dats$Chem.Opt
chemopt <- gsub("-", " ", chemopt)
str <- sapply(strsplit(chemopt, " "), "[", 2)
dats[str > "99]", ]
chemopt[str > "99]"] <- paste("[S 572]", chemopt[str > "99]"])
str <- sapply(strsplit(chemopt, " "), "[", 2)
streamcode <- as.numeric(substring(str, 1, nchar(str)-1))
scode <- ifelse(streamcode>10000, streamcode-10000, streamcode)
agent <- ifelse(streamcode>10000, "FWS", "DFO")
lkcode <- recode(substring(sapply(strsplit(chemopt, " "), "[", 1), 2, 2), c("S", "M", "H", "E", "O", "C"), 1:6)
dats$uid <- paste(lkcode, agent, format(scode), sep="-")
base3[is.na(match(base3$uid, dats$uid[dats$lentic])), ]
look <- base3[is.na(match(base3$uid, dats$uid[dats$lentic])), ]
look[order(look$year, look$uid), ]
head(base3)
base3
dim(base3)
split(base3, year)
head(base3)
split(base3, base3$year)
basey <- split(base3, base3$year)
lapply(basey, with, cumsum(iaha))
lapply(basey, with, cumsum(iaha)/sum(iaha))
lapply(basey, with, median(cumsum(iaha)/sum(iaha)))
lapply(basey, with, cumsum(iaha)/sum(iaha)-0.5)
lapply(basey, with, abs(cumsum(iaha)/sum(iaha)-0.5))
lapply(basey, with, which.min(abs(cumsum(iaha)/sum(iaha)-0.5)))
basey <- split(base3, base3$year)
lapply(basey, with, {
cumiaha <- cumsum(iaha)
cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]
)
basey <- split(base3, base3$year)
lapply(basey, with, {
cumiaha <- cumsum(iaha)
cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]
}
)
basey <- split(base3, base3$year)
lapply(basey, with, {
cumiaha <- cumsum(iaha)
ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))])
}
)
basey
aggregate(base3$iaha, list(year=base3$year), cumsum)$x
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
base3
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) 
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3
attach(dats)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=FY-2008, xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=FY-2008)
abline(h=staffdaycut/1000, lty=2)
detach(dats)
attach(dats)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=FY-2008, xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=FY[lentic]-2008)
abline(h=staffdaycut/1000, lty=2)
detach(dats)
head(dats)
attach(dats)
table(lentic, FY)
search()
detach()
# C:\JVA\Lamprey\Larvae\Lentic\ReadRankLists.r
library(plyr)
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
staffcostperday <- c(1002, 1075, 1017, 1017)
gbcostperkg <- c(22.40, 22.66, 22.66, 22.66)
daysperha <- 0.4
kgperha <- 175
gbcostperha <- daysperha * staffcostperday + gbcostperkg * kgperha
staffdaycut <- 6400
dat <- vector("list", length(trtyears))
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat[[i]] <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
dat[[i]]$FY <- trtyears[i]
}
dats <- do.call(rbind.fill, dat)
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
dats$areaha <- as.numeric(dats$Area..ha.)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
# combine Chem.Opt and Stream into a single field
dats$Chem.Opt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
dats <- dats[, -match("Stream", names(dats))]
attach(dats)
table(lentic, FY)
mytable(lentic, FY)
mytable(lentic, areah)
mytable(lentic, FY)
mytable(lentic, areaha)
mytable(FY, lentic)
mytable(round(areaha), lentic)
dats[lentic, ]
dats[lentic, 1:7]
dats[!is.na(areaha), 1:7]
detach(dats)
detach(dats)
# combine Chem.Opt and Stream into a single field
dats$Chem.Opt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
dats <- dats[, -match("Stream", names(dats))]
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
dats$areaha <- as.numeric(dats$Area..ha.)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
attach(dats)
mytable(FY, lentic)
mytable(round(areaha), lentic)
dats[lentic & is.na(areaha), ]
search()
detach()
dats$areaha <- as.numeric(dats$Area..ha.)
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE) & !is.na(dats$areaha)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
attach(dats)
mytable(FY, lentic)
mytable(round(areaha), lentic)
mytable(FY, lentic)
mytable(round(areaha), lentic)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=FY-2008, xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=FY[lentic]-2008)
abline(h=staffdaycut/1000, lty=2)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=FY[lentic]-2008)
abline(h=staffdaycut/1000, lty=2)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
summary(dats)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(Staff.Days.1)], 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(Staff.Days.1)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", sort(unique(FY)), blindcolz[2:5])
FY
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5])
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(Staff.Days.1)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=1)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(Staff.Days.1)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16, title="Treatment Year")
dput(names(dat))
dput(names(dats))
head(dats)
rankdat <- dats[, c("FY", "Rank", "lentic", "LakeID", "Chem.Opt", "areaha", "biglarvkill", "costperbigkill", "days")]
head(rankdat)
format(staffdaycut, big.mark=",")
cleanup()
graphics.off()
search()
detach()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
info
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < 3 ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between 3 and 10 ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > 10 ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four years, survey years 2010-2013 corresponding to treatment years 2011-2014.",
"  For each year, I removed the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(Staff.Days.1)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16, title="Treatment Year")
detach(rankdat)
}
figu("Solid-filled circles represent lentic ChemOpts in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
search()
detach()
cleanup()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
info
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < 3 ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between 3 and 10 ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > 10 ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four years, survey years 2010-2013 corresponding to treatment years 2011-2014.",
"  For each year, I removed the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(cumdays)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], cumdays[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16, title="Treatment Year")
detach(rankdat)
}
figu("Solid-filled circles represent lentic ChemOpts in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
cleanup()
search()
detach()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
info
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < 3 ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between 3 and 10 ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > 10 ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four years, survey years 2010-2013 corresponding to treatment years 2011-2014.",
"  For each year, I removed the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(cumdays)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], cumdays[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16, title="Treatment Year")
detach(rankdat)
}
figu("Solid-filled circles represent lentic ChemOpts in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
endrtf()
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=blindcolz[FY[!lentic]-2009])
points(Rank[lentic],  cumdays[lentic]/1000,  col=blindcolz[FY[lentic]-2009], cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16, title="Treatment Year")
detach(rankdat)
}
windows()
fig()
showmarks()
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=blindcolz[FY[!lentic]-2009])
points(Rank[lentic],  cumdays[lentic]/1000,  col=blindcolz[FY[lentic]-2009], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=2, lwd=2, title="Treatment Year")
detach(rankdat)
}
fig()
blindcolz
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=blindcolz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=blindcolz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=2, lwd=2, title="Treatment Year")
detach(rankdat)
}
fig()
fig <- function() {
colz <- blindcolz[c(2, 3, 7, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, title="Treatment Year")
detach(rankdat)
}
fig()
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, title="Treatment Year")
detach(rankdat)
}
fig()
head(rankdat)
stringin("mary", rankdat$chemopt)
para
library(raster)
?raster
rst <- raster(matrix(1:100, ncol=10), 0, 360, -90, 90, crs="+proj=merc")
rst
raster
args(raster)
raster.matrix
raster:::raster.matrix
showMethods("raster")
showMethods("raster.matrix")
?rotate
rst <- raster(matrix(1:100, ncol=10), 0, 360, -90, 90, crs="+proj=merc")
r2 <- rotate(rst)
rst
r2
cleanup()
q()
tweethead()
q()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
info
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < 3 ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between 3 and 10 ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > 10 ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
endrtf()
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
windows()
fig()
ls()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
info
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, sizecuts, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,"
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 m2 plots depending on the size of the ChemOpt).",
"  In a single simulations a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from the larvae available.",
"  The density of large (> 100 mm) sea lampreys was calculated from these and adjusted for gear efficiency,")
para("large density = large catch / survey area / 0.08.", italic=TRUE)
para("If the large density was greater than ", trtcut, " per m2, then the ChemOpt was selected for treatment.",
"  This approach was then repeated for surveys with less effort, < 6 plots per ChemOpt.",
"  And the whole works was repeated for a total of ", nsim, " simulations.")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 m2 plots depending on the size of the ChemOpt).",
"  In a single simulations a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from the larvae available.",
"  The density of large (> 100 mm) sea lampreys was calculated from these and adjusted for gear efficiency,")
para("large density = large catch / survey area / 0.08.", italic=TRUE)
para("If the large density was greater than ", trtcut, " per m2, then the ChemOpt was selected for treatment.",
"  This approach was then repeated for surveys with less effort, < 6 plots per ChemOpt.",
"  And the whole works was repeated for a total of ", nsim, " simulations.")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 m2 plots depending on the size of the ChemOpt).",
"  In a single simulations a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from the larvae available.",
"  The density of large (> 100 mm) sea lampreys was calculated from these and adjusted for gear efficiency,")
para("large density = large catch / survey area / 0.08.", italic=TRUE)
para("If the large density was greater than ", trtcut, " per m2, then the ChemOpt was selected for treatment.",
"  This approach was then repeated for surveys with less effort, < 6 plots per ChemOpt.",
"  And the whole works was repeated for a total of ", nsim, " simulations.")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
cleanup()
search()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, sizecuts, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 m2 plots depending on the size of the ChemOpt).",
"  In a single simulations a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from the larvae available.",
"  The density of large (> 100 mm) sea lampreys was calculated from these and adjusted for gear efficiency,")
para("large density = large catch / survey area / 0.08.", italic=TRUE)
nsim <- 1000
para("If the large density was greater than ", trtcut, " per m2, then the ChemOpt was selected for treatment.",
"  This approach was then repeated for surveys with less effort, < 6 plots per ChemOpt.",
"  And the whole works was repeated for a total of ", nsim, " simulations.")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
endrtf()
ls()
daysperha <- 0.4
gbcostperha
staffdaycut
daysperha
totcostperha <- gbcostperha
totcostperha
format(totcostperha, big.mark=",", ndec=2)
?format.default
format(totcostperha, big.mark=",", nsmall=2)
paste9)format(totcostperha, big.mark=",", nsmall=2)
paste0("$", format(totcostperha, big.mark=",", nsmall=2))
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", ")
daysperha
ls()
head(base3)
head(rankdat)
# C:\JVA\Lamprey\Larvae\Lentic\ReadRankLists.r
library(plyr)
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
staffcostperday <- c(1002, 1075, 1017, 1017)
gbcostperkg <- c(22.40, 22.66, 22.66, 22.66)
daysperha <- 0.4
kgperha <- 175
totcostperha <- daysperha * staffcostperday + gbcostperkg * kgperha
staffdaycut <- 6400
rm(staffcostperday, gbcostperkg, kgperha)
dat <- vector("list", length(trtyears))
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat[[i]] <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
dat[[i]]$FY <- trtyears[i]
}
dats <- do.call(rbind.fill, dat)
# combine Chem.Opt and Stream into a single field
dats$chemopt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
dats$areaha <- as.numeric(dats$Area..ha.)
dats$lentic <- grepl("lent", dats$chemopt, ignore.case=TRUE) & !is.na(dats$areaha)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
dats$cumdays <- dats$Staff.Days.1
head(dats)
dats[, c("FY", "Rank", "lentic", "chemopt", "cost", "biglarvkill", "costperbigkill", "days", "cumdays")]
dats$areaha <- as.numeric(dats$Area..ha.)
dats$lentic <- grepl("lent", dats$chemopt, ignore.case=TRUE) & !is.na(dats$areaha)
dats$cost <- dats$Cost
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
dats$cumdays <- dats$Staff.Days.1
dats[, c("FY", "Rank", "lentic", "chemopt", "cost", "biglarvkill", "costperbigkill", "days", "cumdays")]
dats[, c("FY", "Rank", "cumdays")]
dats$origcumdays <- dats$Staff.Days.1
rankdat <- dats[, c("FY", "Rank", "lentic", "chemopt", "cost", "biglarvkill", "costperbigkill", "days", "origcumdays")]
head(rankdat)
dim(rankdat)
table(rankdat$lentic)
table(rankdat$lentic, rankdat$origcumdays<6400)
table(rankdat$origcumdays<6400)
mytable(rankdat$lentic, rankdat$origcumdays<6400)
rankdat[is.na(rankdat$origcumdays), ]
rankdat <- dats[dats$biglarvkill>0, c("FY", "Rank", "lentic", "chemopt", "cost", "biglarvkill", "costperbigkill", "days", "origcumdays")]
dim(rankdat)
mytable(rankdat$lentic, rankdat$origcumdays<6400)
rankdat[subdex(rankdat, lentic & origcumdays<6400), ]
rankdat[subdex(rankdat, !lentic & origcumdays<6400), ]
names(rankdat)
dput(names(rankdat))
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "biglarvkill", "costperbigkill", "days")]
ranklentfree
with(ranklentfree, tapply(days, FY, cumsum))
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum)))
staffdaycut
head(rankdat)
rankdat[rankdat$Rank==1, ]
with(rankdat[rankdat$Rank==1, ], origcumdays - days)
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "biglarvkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum)))
cumdays
staffdaycut
susy <- 2010:2013
suty <- susy+1
suty
match(ranklentfree$FY, suty)
susy <- 2010:2013
suty <- susy+1
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "biglarvkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
cumdays
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "biglarvkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
dim(ranklentfree)
ranklentfree
dats$areaha <- as.numeric(dats$Area..ha.)
dats$lentic <- grepl("lent", dats$chemopt, ignore.case=TRUE) & !is.na(dats$areaha)
dats$cost <- dats$Cost
dats$bigkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
dats$origcumdays <- dats$Staff.Days.1
rankdat <- dats[dats$bigkill>0, c("FY", "Rank", "lentic", "chemopt", "cost", "bigkill", "costperbigkill", "days", "origcumdays")]
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "biglarvkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
head(ranklentfree)
ls()
head(base3)
head(op)
head(base3)
# subset survey data meeting criteria
opsub <- op[paste(op$year, op$uid) %in% paste(base3$year, base3$uid), ]
dim(op)
dim(opsub)
nsim <- 10
susy <- 2010:2013
suty <- susy+1
results <- vector("list", length(suty))
names(results) <- suty
seq(along=suty)
y <- 1
df <- opsub[opsub$year==susy[y], ]
idz <- sort(unique(df$uid))
trtp <- array(NA, dim=c(length(idz), length(sunp)), dimnames=list(idz, sunp))
dim(df)
df
head(base3)
match(df$uid, base3$uid[base3$year==suty[y]])
table(df$uid)
with(base3, table(year, uid))
with(base3, table(uid, year))
table(df$uid)
suty[y]
susy
match(df$uid, base3$uid[base3$year==susy[y]])
base3$iaha[match(df$uid, base3$uid[base3$year==susy[y]])]
cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
sizecuts <- c(3, 10)
cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
library(sampling)
?strata
base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])]
base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])
base3$iaha[match(df$uid, base3$uid[base3$year==susy[y]])]
base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])]
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])]
effort <- c(2, 4, 6)
effort[base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])]]
cleanup()
search()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
# subset survey data meeting criteria
opsub <- op[paste(op$year, op$uid) %in% paste(base3$year, base3$uid), ]
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 10
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
date()
results <- vector("list", length(suty))
names(results) <- suty
y <- 1
df <- opsub[opsub$year==susy[y], ]
idz <- sort(unique(df$uid))
reducedeffort <- effort[base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])]]
fulleffort <- rep(6, length(reducedeffort))
trtp <- array(NA, dim=c(length(idz), 2), dimnames=list(idz, c("Full", "Reduced")))
p <- 1
trtm <- array(NA, dim=c(length(idz), nsim), dimnames=list(idz, 1:nsim))
k <- 1
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
# density of big larvae ... compare to trtcut
survm2 <- tapply(df2$baream2, df2$uid, sum)
large <- tapply(df2$newnbig, df2$uid, sum)
lrgdens <- large/survm2/0.08
trtm[, k] <- as.numeric(lrgdens>trtcut)
head(base3)
head(opsub)
names(base3)
dput(names(base3))
args(merge)
?merge
dim(opsub)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat")], all.y=TRUE)
dim(opsub)
head(opsub)
head(rankdat)
head(df)
head(ranklentfree)
### calculations from surveyed data
# infested area
ia <- df$iaha[match(df2$uid, df$uid)]
# cost
cost <- totcostperha*ia
# kill of big larvae
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
bigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/bigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=sort(unique(df2$uid)), cost=cost, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
large
ia
match(df2$uid, df$uid)
match(df$uid, df2$uid)
df$iaha
large
suu <- sort(unique(df2$uid))
# infested area
ia <- df$iaha[match(df$uid, suu)]
ia
match(df$uid, suu)
match(suu, df$uid)
ia <- df$iaha[match(suu, df$uid)]
ia
[match(suu, df$uid)
match(suu, df$uid)
df$iaha
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 10
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
search()
date()
results <- vector("list", length(suty))
names(results) <- suty
df <- opsub[opsub$year==susy[y], ]
idz <- sort(unique(df$uid))
reducedeffort <- effort[df$sizecat]
fulleffort <- rep(6, length(reducedeffort))
trtp <- array(NA, dim=c(length(idz), 2), dimnames=list(idz, c("Full", "Reduced")))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
trtm <- array(NA, dim=c(length(idz), nsim), dimnames=list(idz, 1:nsim))
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
suu <- sort(unique(df2$uid))
# infested area
ia <- df$iaha[match(suu, df$uid)]
# cost
cost <- totcostperha*ia
# kill of big larvae
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
bigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/bigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, bigkill=bigkill, costperbigkill=costperbigkill, days=days)
ia
totcostperha
### calculations from surveyed data
suu <- sort(unique(df2$uid))
# infested area
ia <- df$iaha[match(suu, df$uid)]
# cost
cost <- totcostperha[y]*ia
# kill of big larvae
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
bigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/bigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, bigkill=bigkill, costperbigkill=costperbigkill, days=days)
tempdf
# combine with ranklist data
both <- rbind(ranklentfree[ranklentfree$year == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both
ranklentfree[ranklentfree$year == suty[y], ]
suty
ranklentfree$year
ranklentfree
head(ranklentfree)
both <- rbind(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both
both$cumdays <- cumsum(both$days)
head(both)
head(best3)
head(base3)
library(plyr)
rbind.fill
 sum(both$bigkill[both$cumdays < (staffdaycut + daysabovelist[y])])
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
results
cleanup()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 10
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
idz <- sort(unique(df$uid))
reducedeffort <- effort[df$sizecat]
fulleffort <- rep(6, length(reducedeffort))
trtp <- array(NA, dim=c(length(idz), 2), dimnames=list(idz, c("Full", "Reduced")))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
suu <- sort(unique(df2$uid))
# infested area
ia <- df$iaha[match(suu, df$uid)]
# "real" big kill ... based on all survey data
bigkill <- df$bigkill[match(suu, df$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[both$cumdays < (staffdaycut + daysabovelist[y])])/1000000
}
}
}
rm(y, df, idz, trtp, p, trtm, k, nuid, rowz, df2, L, i, survm2, large, lrgdens, res)
date()
ls()
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
reducedeffort <- effort[df$sizecat]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df$iaha[match(suu, df$uid)]
# "real" big kill ... based on all survey data
bigkill <- df$bigkill[match(suu, df$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[both$cumdays < (staffdaycut + daysabovelist[y])])/1000000
}
}
}
rm(y, df, suu, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
results
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
reducedeffort <- effort[df$sizecat]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[both$cumdays < (staffdaycut + daysabovelist[y])])/1000000
}
}
}
results
rowz
nsim
?strata
head(df)
df$uid
fulleffort
length(fulleffort)
data=swissmunicipalities
data=data[order(data$REG),]
data(swissmunicipalities)
data=swissmunicipalities
data=data[order(data$REG),]
data
dim(data)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
indx <- match(suu, df$uid)
indx
reducedeffort <- effort[df$sizecat[indx]]
reducedeffort
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[both$cumdays < (staffdaycut + daysabovelist[y])])/1000000
}
}
}
results
y <- 1
p <- 1
k <- 1
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
both
both$cumdays < (staffdaycut + daysabovelist[y])
staffdaycut
sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
results
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
results
(both$cumdays + daysabovelist[y]) < staffdaycut
both$cumdays
daysabovelist[y]
staffdaycut
staffdaycut - daysabovelist[y]
dim(both)
dim(tempdf)
dim(ranklentfree)
dim(ranklentfree[ranklentfree$FY == suty[y], ])
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
results
dim(both)
dim(tempdf)
dim(ranklentfree)
dim(ranklentfree[ranklentfree$FY == suty[y], ])
both
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
both
tempdf
a <- ranklentfree[ranklentfree$FY == suty[y], ]
head(a)
rbind.fill(tempdf, head(a))
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
tempdf
ia
large
survm2
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
estbigkill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
tempdf
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
results
both
both[, -2]
daysabovelist[y]
daysabovelist
staffdaycut - daysabovelist
y
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 10
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
results
CI
CI(1:10)
apply(results, 2:3, CI)
col(apply(results, 2:3, CI))
cis <- apply(results, 2:3, CI)
cis[1, , ]
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
rm
cm
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
plot(1, 1, type="n")
points(rm, m, col=cm)
rm
m
plot(1, 1, xlim=range(rm), ylim=range(cis), type="n")
points(rm, m, col=cm)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm), ylim=range(cis), type="n")
points(rm, m, col=cm)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm+cm/10
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm), ylim=range(cis), type="n")
points(xm, m, col=cm)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm+cm/10
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n")
points(xm, m, col=cm)
?cheat
cis
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=cm)
arrows(xm, cis[2, , ], xm, cis[3, , ], col=cm, length=0.1, angle=90, code=3)
cm/10
mean(cm/10)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/10
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=cm)
arrows(xm, cis[2, , ], xm, cis[3, , ], col=cm, length=0.1, angle=90, code=3)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/10
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=cm)
arrows(xm, cis[2, , ], xm, cis[3, , ], col=cm, length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
colx
colz
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/10
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis[2, , ], xm, cis[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/6
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis[2, , ], xm, cis[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/4
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis[2, , ], xm, cis[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
cleanup()
graphics.off()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 100
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/4
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis[2, , ], xm, cis[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
nsim
results
cis
cis0 <- cis - cis[c(1, 1, 1), , ]
cis0
cis0 <- cis - cis[c(1, 1, 1), , ]
m <- cis0[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/4
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis0), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis0[2, , ], xm, cis0[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
cis0 <- 1000*(cis - cis[c(1, 1, 1), , ])
m <- cis0[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/4
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis0), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis0[2, , ], xm, cis0[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
blindcolz
graphics.off()
cleanup()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
para("The results are shown in the following figures.")
fig <- function() {
m <- x[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/4
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(x), type="n", xaxt="n", xlab="Treatment year", ylab=ylabb)
points(xm, m, col=colz[cm])
arrows(xm, x[2, , ], xm, x[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
}
# summary in millions
cis <- apply(results, 2:3, CI)
# summary relative to average, in thousands
cis0 <- 1000*(cis - cis[c(1, 1, 1), , ])
colz <- blindcolz[2:3]
x <- cis
ylabb <- "Millions of larvae killed"
figu("Comparison of ", nsim, " simulations of full survey effort (orange) and reduced survey effort (blue)", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=5, w=5)
x <- cis0
ylabb <- "Thousands of larvae killed  (relative to average)"
figu("Comparison of ", nsim, " simulations of full survey effort (orange) and reduced survey effort (blue)", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=5, w=5)
endrtf()
rm(i, b)
ls()
rm(cis, cis0, colz, x)
ls()
dim(results)
results[, 1, 1]
results[, 1, ]
windows()results[, 1, ]
windows()
boxplot(results[, 1, ])
boxplot(results[, 1, ], log="y")
boxplot(results[, 1, ])
windows()
par(mfrow=c(1, 4))
for(i in 1:4) {
boxplot(results[, i, ])
}
windows()
par(mfrow=c(1, 4), cex=1.5, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=1, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE)
mtext("Millions of larvae killed", side=2, outer=TRUE)
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
fig <- {
par(mfrow=c(1, 4), cex=1.5, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=1, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.5)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.5)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
fig <- function() {
par(mfrow=c(1, 4), cex=1.5, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=1, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.5)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.5)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
fig <- function() {
par(mfrow=c(1, 4), cex=1.5, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=1, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.5)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.5)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
?par
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, col=blindcolz[4], xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, col=blindcolz[4], xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(5, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, col=blindcolz[4], xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
dim(results)
apply(results, 2, function(x) (max(x) + min(x))/2)
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
apply(results, 2, function(x) (max(x) - min(x))/2)
max(apply(results, 2, function(x) (max(x) - min(x))/2))
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
ymid
ymid-yspread
ymid + c(-1, 1)*yspread
ymid[1] + c(-1, 1)*yspread
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(5, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, col=blindcolz[4], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
fig()
windows()
fig()
?boxplot
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(5, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, border=blindcolz[4], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
blindcolz
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(6, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, border=blindcolz[7], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
heading
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
heading(paste0("QUICK SUMMARY:  Reducing the survey effort on small lentic areas (< 10 ha)",
" has little effect on the estimated number of large larvae killed", 2)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha were surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha were surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha were surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calculated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("This was repeated ", format(nsim, big.mark=",") , " times.",
"  Each time, the total number of large larvae killed by the treatment was recorded.",
"  The number of large larvae killed for each stream was simply the number in the real life rank list.",
"  The number of large larvae killed for each lentic area was the best number that we have,",
" the estimate based on all of the available data (at least 6 500 m2 plots)."
"  Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(6, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, border=blindcolz[7], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", format(nsim, big.mark=",") , 
" simulations of full and reduced survey effort in the assessment of lentic ChemOpts with granular Bayluscide.", 
"  Note that the y-axes are scaled so that a difference of 20,000 large larvae looks the same in all years.", h=8.5, w=6.5)
endrtf()
graphics.off()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
heading(paste0("QUICK SUMMARY:  Reducing the survey effort on small lentic areas (< 10 ha)",
" has little effect on the estimated number of large larvae killed"), 2)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha were surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha were surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha were surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calculated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("This was repeated ", format(nsim, big.mark=",") , " times.",
"  Each time, the total number of large larvae killed by the treatment was recorded.",
"  The number of large larvae killed for each stream was simply the number in the real life rank list.",
"  The number of large larvae killed for each lentic area was the best number that we have,",
" the estimate based on all of the available data (at least 6 500 m2 plots)."
"  Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(6, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, border=blindcolz[7], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", format(nsim, big.mark=",") , 
" simulations of full and reduced survey effort in the assessment of lentic ChemOpts with granular Bayluscide.", 
"  Note that the y-axes are scaled so that a difference of 20,000 large larvae looks the same in all years.", h=8.5, w=6.5)
endrtf()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
heading(paste0("QUICK SUMMARY:  Reducing the survey effort on small lentic areas (< 10 ha)",
" has little effect on the estimated number of large larvae killed"), 2)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha were surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha were surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha were surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calculated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("This was repeated ", format(nsim, big.mark=",") , " times.",
"  Each time, the total number of large larvae killed by the treatment was recorded.",
"  The number of large larvae killed for each stream was simply the number in the real life rank list.",
"  The number of large larvae killed for each lentic area was the best number that we have,",
" the estimate based on all of the available data (at least 6 500 m2 plots).",
"  Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(6, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, border=blindcolz[7], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", format(nsim, big.mark=",") , 
" simulations of full and reduced survey effort in the assessment of lentic ChemOpts with granular Bayluscide.", 
"  Note that the y-axes are scaled so that a difference of 20,000 large larvae looks the same in all years.", h=8.5, w=6.5)
endrtf()
q()
tweethead()
q()
options("httr_oauth_cache")
origop <- options("httr_oauth_cache")
origop
class(origop)
length(origop)
options(httr_oauth_cache=origop)
#' Tweet Headlines
#'
#' Tweet the latest headlines from the specified website.
#' @param tweetA logical scalar indicating if tweets should be posted, default TRUE.
#' @param usernameA character scalar, giving the name of the twitter user.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @param websiteA character scalar, giving the name of the website, from which to pull headlines.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @param credentialsA character vector of length four, giving the twitter_api_key, the twitter_api_secret, 
#'the twitter_access_token, and the twitter_access_token_secret.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @return A named vector with the \code{Mean}, lower and upper confidence limits (\code{L} and \code{U}), 
#' and the number of observations \code{N}.
#' @detailsThis function is customized to work on a particular website.  It's not for general use. 
#'To store information in local .Renviron file, use \code{writeLines(c("username=xxx", "website=xxx", 
#'"twitter_api_key=xxx", "twitter_api_secret=xxx", "twitter_access_token=xxx", "twitter_access_token_secret=xxx"), 
#'file.path(getwd(), ".Renviron"))}.
#' @importtwitteR RCurl
#' @export
#' @references
#'
#' Simon Munzert.  19 Jan 2015.
#' Programming a Twitter bot - and the rescue from procrastination.
#' \emph{http://www.r-datacollection.com/blog/Programming-a-Twitter-bot/}
#'
#' Simon Munzert.  21 Dec 2014.
#' How to conduct a tombola with R.
#' \emph{www.r-datacollection.com/blog/How-to-conduct-a-tombola-with-R/}
#' @examples 
#' \dontrun{
#' tweethead(FALSE)
#' tweethead()
#' }
tweethead <- function(tweet=TRUE, username=NULL, website=NULL, credentials=NULL) {
if(is.null(credentials)) {
api_key <- Sys.getenv("twitter_api_key")
api_secret <- Sys.getenv("twitter_api_secret")
access_token <- Sys.getenv("twitter_access_token")
access_token_secret <- Sys.getenv("twitter_access_token_secret")
} else {
api_key <- credentials[1]
api_secret <- credentials[2]
access_token <- credentials[3]
access_token_secret <- credentials[4]
}
# connect to Twitter
origop <- options("httr_oauth_cache")
options(httr_oauth_cache=TRUE)
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
options(httr_oauth_cache=origop)
# grab headlines from website
# read in html source code
base.url <- Sys.getenv("website")
base.html <- getURLContent(base.url)[[1]]
# pull off links that say "More"
links <- strsplit(base.html, "ID=")[[1]]
links2 <- sapply(strsplit(links, "</a>"), "[", 1)[-1]
more.codes <- substring(stringin("more", links2), 1, 5)
more.urls <- paste0(base.url, "index.php?ID=", more.codes)
# pull off headline, photo url, photo caption
pull <- function(thisurl) {
thishtml <- getURLContent(thisurl)[[1]]
# headline
headlong <- strsplit(thishtml, "<font size=6><b>")[[1]][2]
head <- strsplit(headlong, "</b>")[[1]][1]
# photo url
photolong <- strsplit(thishtml, "<img src='./Photos/")[[1]]
if(length(photolong)>1) {
photolong <- photolong[2]
photo <- strsplit(photolong, "'><br>")[[1]][1]
photo.url <- paste0(base.url, "Photos/", photo)
} else {
photo.url <- ""
}
# photo caption
caplong <- strsplit(thishtml, "<br><font size=2><b>")[[1]]
if(length(caplong)>1) {
caplong <- caplong[2]
cap <- strsplit(caplong, "</b>")[[1]][1]
} else {
cap <- ""
}
c(article.url=thisurl, headline=head, photo.url=photo.url, photo.caption=cap)
}
# get new tweets ready
m <- do.call(rbind, lapply(more.urls, pull))
currentheads <- apply(m[, 2:1], 1, paste, collapse=". ")
### grab latest tweets
adj <- getUser(Sys.getenv("username"))
oldtweets <- twListToDF(userTimeline(adj, n=15, excludeReplies=TRUE))[, c("text", "favoriteCount", "retweetCount", "created")]
names(oldtweets)[names(oldtweets)=="created"] <- "createdUTC"
### tweet all new tweets that haven't been tweeted before
totweet <- currentheads[!(substring(currentheads, 1, 30) %in% substring(oldtweets$text, 1, 30))]
if(length(totweet) > 0) {
if(tweet) {
lapply(rev(totweet), updateStatus, lat=45.141473, long=-89.152339)
} else {
cat(paste("\n\n***  This is what would be posted if tweet=TRUE.\n\n"))
print(totweet)
cat("\n\n")
}
} else {
cat(paste0("\n\n***  No new headlines since last tweet, ", 
format(max(oldtweets$createdUTC), "%a %b %e %I:%M %p", tz=Sys.timezone()), ".\n\n\n"))
}
list(oldtweets=oldtweets, currentheads=currentheads, totweet=totweet)
}
tweethead()
library(httr)
library(RCurl)
#' Tweet Headlines
#'
#' Tweet the latest headlines from the specified website.
#' @param tweetA logical scalar indicating if tweets should be posted, default TRUE.
#' @param usernameA character scalar, giving the name of the twitter user.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @param websiteA character scalar, giving the name of the website, from which to pull headlines.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @param credentialsA character vector of length four, giving the twitter_api_key, the twitter_api_secret, 
#'the twitter_access_token, and the twitter_access_token_secret.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @return A named vector with the \code{Mean}, lower and upper confidence limits (\code{L} and \code{U}), 
#' and the number of observations \code{N}.
#' @detailsThis function is customized to work on a particular website.  It's not for general use. 
#'To store information in local .Renviron file, use \code{writeLines(c("username=xxx", "website=xxx", 
#'"twitter_api_key=xxx", "twitter_api_secret=xxx", "twitter_access_token=xxx", "twitter_access_token_secret=xxx"), 
#'file.path(getwd(), ".Renviron"))}.
#' @importtwitteR RCurl
#' @export
#' @references
#'
#' Simon Munzert.  19 Jan 2015.
#' Programming a Twitter bot - and the rescue from procrastination.
#' \emph{http://www.r-datacollection.com/blog/Programming-a-Twitter-bot/}
#'
#' Simon Munzert.  21 Dec 2014.
#' How to conduct a tombola with R.
#' \emph{www.r-datacollection.com/blog/How-to-conduct-a-tombola-with-R/}
#' @examples 
#' \dontrun{
#' tweethead(FALSE)
#' tweethead()
#' }
tweethead <- function(tweet=TRUE, username=NULL, website=NULL, credentials=NULL) {
if(is.null(credentials)) {
api_key <- Sys.getenv("twitter_api_key")
api_secret <- Sys.getenv("twitter_api_secret")
access_token <- Sys.getenv("twitter_access_token")
access_token_secret <- Sys.getenv("twitter_access_token_secret")
} else {
api_key <- credentials[1]
api_secret <- credentials[2]
access_token <- credentials[3]
access_token_secret <- credentials[4]
}
# connect to Twitter
origop <- options("httr_oauth_cache")
options(httr_oauth_cache=TRUE)
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
options(httr_oauth_cache=origop)
# grab headlines from website
# read in html source code
base.url <- Sys.getenv("website")
base.html <- getURLContent(base.url)[[1]]
# pull off links that say "More"
links <- strsplit(base.html, "ID=")[[1]]
links2 <- sapply(strsplit(links, "</a>"), "[", 1)[-1]
more.codes <- substring(stringin("more", links2), 1, 5)
more.urls <- paste0(base.url, "index.php?ID=", more.codes)
# pull off headline, photo url, photo caption
pull <- function(thisurl) {
thishtml <- getURLContent(thisurl)[[1]]
# headline
headlong <- strsplit(thishtml, "<font size=6><b>")[[1]][2]
head <- strsplit(headlong, "</b>")[[1]][1]
# photo url
photolong <- strsplit(thishtml, "<img src='./Photos/")[[1]]
if(length(photolong)>1) {
photolong <- photolong[2]
photo <- strsplit(photolong, "'><br>")[[1]][1]
photo.url <- paste0(base.url, "Photos/", photo)
} else {
photo.url <- ""
}
# photo caption
caplong <- strsplit(thishtml, "<br><font size=2><b>")[[1]]
if(length(caplong)>1) {
caplong <- caplong[2]
cap <- strsplit(caplong, "</b>")[[1]][1]
} else {
cap <- ""
}
c(article.url=thisurl, headline=head, photo.url=photo.url, photo.caption=cap)
}
# get new tweets ready
m <- do.call(rbind, lapply(more.urls, pull))
currentheads <- apply(m[, 2:1], 1, paste, collapse=". ")
### grab latest tweets
adj <- getUser(Sys.getenv("username"))
oldtweets <- twListToDF(userTimeline(adj, n=15, excludeReplies=TRUE))[, c("text", "favoriteCount", "retweetCount", "created")]
names(oldtweets)[names(oldtweets)=="created"] <- "createdUTC"
### tweet all new tweets that haven't been tweeted before
totweet <- currentheads[!(substring(currentheads, 1, 30) %in% substring(oldtweets$text, 1, 30))]
if(length(totweet) > 0) {
if(tweet) {
lapply(rev(totweet), updateStatus, lat=45.141473, long=-89.152339)
} else {
cat(paste("\n\n***  This is what would be posted if tweet=TRUE.\n\n"))
print(totweet)
cat("\n\n")
}
} else {
cat(paste0("\n\n***  No new headlines since last tweet, ", 
format(max(oldtweets$createdUTC), "%a %b %e %I:%M %p", tz=Sys.timezone()), ".\n\n\n"))
}
list(oldtweets=oldtweets, currentheads=currentheads, totweet=totweet)
}
tweethead()
library(twitteR)
search()
tweethead()
?cheat()
cleanup()
q()
pkgup("jvamisc")
q()
