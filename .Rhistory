ylabb <- "Adults"
} else {
fac <- 1000
ylabb <- "Adults  (thousands)"
}
plot(year[selall], combPE[selall]/fac, type="n", las=1, log=llog, xlab="Year", ylab=ylabb, ...)
for(i in seq(lss2)) {
sel2 <- lake==mylake & year > yrcut & ls==lss2[i]
lines(year[sel2], combPE[sel2]/fac, col=colkey$colx[colkey$ls==lss2[i]], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y/fac, col=colkey$colx[colkey$ls==lss2[i]], type="o", pch=16, cex=1.2, lwd=2)
}
}
mapit <- function(mylake, lss, ...) {
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
for(i in seq(lss2)) {
sel <- lake==mylake & year==2014 & ls==lss2[i]
points(long[sel], lat[sel], col=colkey$colx[colkey$ls==lss2[i]], pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colkey$colx[colkey$ls==lss2[i]], ...)
}
}
# all non-model time series
lsbest <- as.numeric(rownames(look2[look2[, "TRUE"]==0, ]))
# all model time series
lsmodel <- as.numeric(rownames(look2[look2[, "FALSE"]==0, ]))
# mixed time series
lsmixed <- as.numeric(rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ]))
# create a color key
yrcut <- 2004.5
sub <- dat[year > yrcut, c("year", "ls", "combPE")]
medPE <- tapply(sub$combPE, sub$ls, median)
df1 <- cbind(medPE, ls=as.numeric(names(medPE)))
df2 <- cbind(ls=c(lsbest, lsmodel, lsmixed), group=rep(c("1best", "2model", "3mixed"), c(length(lsbest), length(lsmodel), length(lsmixed))))
colkey <- merge(df1, df2)
colkey$lake <- floor(colkey$ls)
colkey <- colkey[order(colkey$lake, colkey$group, -colkey$medPE), ]
colkey$lg <- paste(colkey$lake, colkey$group)
colkey$coli <- unlist(tapply(-colkey$medPE, colkey$lg, rank, ties.method="random"))
colkey$colx <- colz[colkey$coli]
head(colkey)
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
dat[lake==3 & year==2008 & combPE > 6000, ]
dat[lake==3 & year>2004.5 & strname=="Garden", ]
plotit(3, lsbest[!(lsbest %in% index.streams[[3]])], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
plotit(3, lsbest[lsbest %in% index.streams[[3]]], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2, font=1, cex=1.2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2, cex=1.5)
# estimate adult index of abundance for each lake using index streams
indices <- lapply(index.streams, index.est, dat, lk)
# combine index data for all lakes in one dataframe
indxall <- do.call(rbind, lapply(indices, "[[", "indxdf"))
# calculate targets 
sptargyrz <- list(1994:1998, 1988:1992, 1989:1993, 1991:1995, 1999:2003)
targyrz <- apply(sapply(sptargyrz, range), 2, paste, collapse="-")
# spawner model
targets.sm <- calctarg(lakenum=lk$lake, adults=lk$PE, year=lk$year, targyears=sptargyrz)
# adult index
targets.ai <- calctarg(lakenum=indxall$lake, adults=indxall$indxkeep, year=indxall$year, targyears=sptargyrz)
# spawner model targets scaled down to adult index
targets.sm.su <- cbind(lake=targets.sm[, 1], (1/sapply(indices, "[[", "scaleup")) * targets.sm[, -1])
# adult index adjusted
targets.ai.adj <- targets.ai
targets.ai.adj[is.na(targets.ai$target), ] <- targets.sm.su[is.na(targets.ai$target), ]
YEAR1 <- 1984
outcex <- 1.2
YEARb <- 2005
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
convfac <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(convfac*c(0, anntotals))/1000
axis(4, at=prt/convfac, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.8, bty="n", border=NA)
}
fig(3)
### spawner model and adult index time series overlaid
fig <- function(mylake, sp=TRUE) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, mylk$hi[x2>=YEARb]/convfac/1000, na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
if(sp) {
arrows(x2, mylk$lo/convfac/1000, x1, mylk$hi/convfac/1000, length=0.05, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
legend("bottom", c("Adult index", "Current method"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18), bty="n")
}
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
if(sp) lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
}
fig(3, FALSE)
fig(3)
graphics.off()
search()
detach()
cleanup()
# C:\JVA\GLFC\CLC\CLCAdultIndex.r
{ # functions
# the following seven plot.table related functions are from the Systematic Investor Toolbox
# load Systematic Investor Toolbox
# require(RCurl)
# sit = getURLContent("https://github.com/systematicinvestor/SIT/raw/master/sit.gz", binary=TRUE, followlocation=TRUE, ssl.verifypeer=FALSE)
# con = gzcon(rawConnection(sit, "rb"))
# source(con)
# close(con)
draw.cell <- function(title, r, c, text.cex = 1, bg.col = 'white', frame.cell = T) {
if(!frame.cell) bcol = bg.col else bcol = 'black'
rect((2*(c - 1) + .5), -(r - .5), (2*c + .5), -(r + .5), col = bg.col, border = bcol)
if( c == 1) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else if( r == 1 ) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else {
text((2*c + .5), -r, title, adj = 1, cex = text.cex)
}
}
plot.table.helper.auto.adjust.cex <- function(temp.table, keep.all.same.cex = FALSE) {
nr = nrow(temp.table)
nc = ncol(temp.table)
all.xrange = diff(par()$usr[1:2]) / nc
xrange = matrix( strwidth(paste('  ', temp.table), units = 'user', cex = 1), nc = nc)
all.yrange = diff(par()$usr[3:4]) / nr
yrange = matrix( 5/3 * strheight(temp.table, units = 'user', cex = 1), nc = nc)
plot.matrix.cex = pmin( round(all.yrange / yrange, 2) , round(all.xrange / xrange, 2) )
header.col.cex = min(plot.matrix.cex[1,-1])
header.row.cex = min(plot.matrix.cex[-1,1])
title.cex = plot.matrix.cex[1, 1]
data.cex = min(plot.matrix.cex[-1, -1])
if ( keep.all.same.cex ) {
plot.matrix.cex[] = min(plot.matrix.cex)
} else {
plot.matrix.cex[1,-1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,-1]= min(c(header.col.cex, header.row.cex, data.cex))
plot.matrix.cex[1,1]= min(c(header.col.cex, header.row.cex, data.cex, title.cex))
plot.matrix.cex[1,-1] = min(c(header.col.cex))
plot.matrix.cex[-1,1] = min(c(header.row.cex))
plot.matrix.cex[-1,-1]= min(c(data.cex))
plot.matrix.cex[1,1]= min(c(title.cex))
}
return(plot.matrix.cex)
}
make.table <- function(nr, nc) {
savepar = par(mar = rep(1, 4))
plot(c(0.5, nc*2 + 0.5), c(-0.5, -(nr + 0.5)), xaxs = 'i', yaxs = 'i',
type = 'n', xlab = '', ylab = '', axes = FALSE)
savepar
}
trim <- function(s) {
s = sub(pattern = '^ +', replacement = '', x = s)
s = sub(pattern = ' +$', replacement = '', x = s)
return(s)
}
plot.table.param <- function(plot.matrix, smain = '', plot.matrix.cex, plot.matrix_bg.col, frame.cell = T, keep.all.same.cex = FALSE) {
n = nrow(plot.matrix)
pages = unique(c(seq(0, n, by = 120), n))
for(p in 1:(length(pages)-1)) {
rindex = (pages[p]+1) : pages[p+1]
temp.table = matrix('', nr = length(rindex)+1, nc = ncol(plot.matrix)+1)
temp.table[-1, -1] = plot.matrix[rindex,]
temp.table[1, -1] = colnames(plot.matrix)
temp.table[-1, 1] = rownames(plot.matrix)[rindex]
temp.table[1, 1] = smain
nr = nrow(temp.table)
nc = ncol(temp.table)
par(mar = c(0, 0, 0, 0), cex = 0.5)
oldpar = make.table(nr, nc)
text.cex = plot.matrix.cex[c(1, 1 + rindex), ]
text.cex = plot.table.helper.auto.adjust.cex(temp.table, keep.all.same.cex)
bg.col = plot.matrix_bg.col[c(1, 1 + rindex), ]
for(r in 1:nr) {
for(c in 1:nc) {
draw.cell( paste('', temp.table[r,c], '', sep=' '), r, c,
text.cex = text.cex[r,c], bg.col = bg.col[r,c], frame.cell = frame.cell)
}}
}
}
plot.table <- function(plot.matrix, smain="", text.cex=1, frame.cell=TRUE, highlight=FALSE, colorbar=FALSE, keep_all.same.cex=FALSE) {
if( is.null(rownames(plot.matrix)) & is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
if( ncol(temp.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[-1, -1, drop = FALSE]
colnames(plot.matrix) = temp.matrix[1, -1]
rownames(plot.matrix) = temp.matrix[-1, 1]
smain = temp.matrix[1, 1]
} else if( is.null(rownames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( ncol(plot.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[, -1, drop = FALSE]
colnames(plot.matrix) = colnames(temp.matrix)[-1]
rownames(plot.matrix) = temp.matrix[,1]
smain = colnames(temp.matrix)[1]
} else if( is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
plot.matrix = temp.matrix[-1, , drop = FALSE]
rownames(plot.matrix) = rownames(temp.matrix)[-1]
colnames(plot.matrix) = temp.matrix[1, ]
smain = rownames(temp.matrix)[1]
}
plot.matrix[which(trim(plot.matrix) == "NA")] = ""
plot.matrix[which(trim(plot.matrix) == "NA%")] = ""
plot.matrix[which(is.na(plot.matrix))] = ""
nr = nrow(plot.matrix) + 1
nc = ncol(plot.matrix) + 1
is_highlight = TRUE
if(is.logical(highlight)) {
is_highlight = highlight
if(highlight) highlight = plot.table.helper.color(plot.matrix)
}
if(!is_highlight) {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[seq(1, nr, 2), ] = "yellow"
plot.matrix_bg.col[1,] = "gray";
plot.table.param( plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
} else {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[1,] = "gray"
plot.matrix_bg.col[2:nr,2:nc] = highlight
plot.table.param(plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
}
}
plot.table.helper.color <- function (temp) {
temp = matrix(as.double(gsub("[%,$]", "", temp)), nrow(temp), ncol(temp))
highlight = as.vector(temp)
cols = rep(NA, length(highlight))
ncols = length(highlight[!is.na(highlight)])
cols[1:ncols] = rev(rainbow(ncols, start=0.5/6, end=3.5/6))
o = sort.list(highlight, na.last = TRUE, decreasing = FALSE)
o1 = sort.list(o, na.last = TRUE, decreasing = FALSE)
highlight = matrix(cols[o1], nrow = nrow(temp))
highlight[is.na(temp)] = NA
return(highlight)
}
ModelEst <- function(fit, df) {
# derive regression estimates from log(y) fit
mse <- rev(as.matrix(summary(fit)[[1]])[, "Mean Sq"])[1]
plpe <- predict(fit, newdata=df, se.fit=T)
m <- plpe$fit
v <- plpe$se.fit^2 + mse
exp(m + v/2)
}
myrange <- function(x) {
if(all(is.na(x))) r <- c(NA, NA) else r <- range(x, na.rm=TRUE)
return(r)
}
jackindex <- function(m) {
# m is a matrix of numbers (stream PEs) with observations (years) as rows and individuals (streams) as columns
if(any(is.na(m))) stop("The input matrix may not have any missing values.")
# calculate the index as the sum of the columns for each row
rowsum <- apply(m, 1, sum)
# calculate the mean of the index
avgind <- mean(rowsum)
# recalculate the index, leaving out one individual at a time
loo <- apply(m, 2, function(column) (rowsum - column))
# rescale the loo index, relative to mean
looscaled <- apply(loo, 2, function(x) x/mean(x))
# convert to original scale
looscaled2 <- looscaled * avgind
# calculate range
ranges <- t(apply(looscaled2, 1, range))
cbind(index=rowsum, lo=ranges[, 1], hi=ranges[, 2])
}
# selstreams <- index.streams[[1]] 
# allstreamdf <- dat
# alllakedf <- lk 
# min.nmr=2 
# show=FALSE
index.est <- function(selstreams, allstreamdf, alllakedf, min.nmr=2, show=FALSE) {
# INDEX OF ADULT SEA LAMPREY ABUNDANCE
### INPUTS
# selstreams = vector of stream ids, e.g., 1.064 (lake + strcode/1000)
# allstreamdf = data frame of mark-recap estimates for all streams, with vars:  year lake ls Emr CVmr
# alllakedf = data frame of lake-wide PEs from Mullett et al. (2003) spawner model with vars:  lake year PE
# min.nmr = minimum number of mark-recapture estimates needed in a year to generate an index, default 2
# show = print out a brief summary of the results, default FALSE
### OUTPUTS
# indfit = simple model used to predict missing mark-recap estimates
# streamdf = original allstreamdf, subsetted by selstreams, with estimates for missing mark-recaps
# indxdf = original alllakedf, subsetted by lake, with annual index, including raw (indxraw), kept based on min.nmr (indxkeep, indxkeep.lo, indxkeep.hi)
# scaleup = conversion factor used to scale up annual index to spawner model PE
streamdf <- allstreamdf[allstreamdf$ls %in% selstreams, ]
# error checks
check1 <- var(streamdf$lake)
if(is.na(check1) | is.null(check1)) stop("Either no streams selected or critical data missing.") else if(check1 > 0) stop("Selected streams should be only from ONE lake.")
if(any(is.na(match(c("year", "lake", "ls", "Emr", "CVmr"), names(allstreamdf))))) stop("allstreamdf must include these variables: year lake ls Emr CVmr.")
if(any(is.na(match(c("year", "lake", "PE"), names(alllakedf))))) stop("alllakedf must include these variables: lake year PE.")
# fill in missing mark-recap data
indfit <- aov(log(Emr) ~ as.factor(ls) + as.factor(year), data=streamdf, weights=1/CVmr^2)
# figure out estimable years (those with at least 1 m-r estimate)
n.mr <- tapply(!is.na(streamdf$Emr), streamdf$year, sum)
eyrs <- as.numeric(names(n.mr)[n.mr > 0.5])
estimable <- streamdf$year %in% eyrs
streamdf$Pmr <- NA
streamdf$Pmr[estimable] <- ModelEst(fit=indfit, df=streamdf[estimable, ])
streamdf$COMBmr <- ifelse(is.na(streamdf$Emr), streamdf$Pmr, streamdf$Emr)
# annual index (sum across streams)
indxdf <- aggregate(COMBmr ~ year + lake, streamdf, sum, na.rm=TRUE, na.action=na.pass)
names(indxdf)[names(indxdf)=="COMBmr"] <- "indxraw"
indxdf$indxraw[indxdf$indxraw==0] <- NA
# only keep lake-wide index for years with at least min.nmr mark-recap estimates
indxdf$n.mr <- n.mr
indxdf$indxkeep <- ifelse(indxdf$n.mr > (min.nmr - 0.5), indxdf$indxraw, NA)
indxdf$indxkeep.lo <- NA
indxdf$indxkeep.hi <- NA
# matrix of stream estimates (rows = years, columns = index streams)
streamests <- with(streamdf, tapply(COMBmr, list(year, ls), mean))
# selection of only those streams with a keepable index
selkeep <- !is.na(indxdf$indxkeep)
jack <- jackindex(streamests[selkeep, ])
indxdf$indxkeep.lo[selkeep] <- jack[, "lo"]
indxdf$indxkeep.hi[selkeep] <- jack[, "hi"]
# scale up the index to the spawner model PE
lk1 <- lk[lk$lake == streamdf$lake[1], ]
indxdf2 <- merge(lk1, indxdf, all=TRUE)
scaleup <- median(indxdf2$PE / indxdf2$indxkeep, na.rm=TRUE)
if(show) {
cat("\nindfit\n")
print(summary(indfit))
cat("\nstreamdf\n")
print(tail(streamdf[, c("lake", "year", "ls", "Emr", "CVmr", "Pmr", "COMBmr")]))
cat("\nscaleup\n")
print(scaleup)
cat("\nindxdf\n")
print(tail(indxdf[, c("lake", "year", "n.mr", "indxraw", "indxkeep", "indxkeep.lo", "indxkeep.hi")]))
}
list(indfit=indfit, streamdf=streamdf, scaleup=scaleup, indxdf=indxdf)
}
calctarg <- function(lakenum, adults, year, targyears, adjust=c(1, 1, 0.25, 1, 1)) {
# lakenum = vector of lake numbers (1-5)
# adults = vector of lakewide adult sea lamprey estimates
# year = vector of years
# targyears = list (length 5) of selected years from which to calculate targets
# lake huron target is 25% of
targets <- data.frame(lake=1:5, target=rep(NA, 5), lo=rep(NA, 5), hi=rep(NA, 5))
for(i in 1:5) {
pick5 <- adults[lakenum==i & is.element(year, targyears[[i]]) & !is.na(adults)]
if(length(pick5) > 0) {
targets$target[i] <- mean(pick5)
n <- length(pick5)
ci <- qnorm(1 - 0.05/2) * sqrt(var(pick5)) / sqrt(n)
targets[i, c("lo", "hi")] <- mean(pick5) + c(-1, 1)*ci# using z dist (known variance)
targets[i, c("target", "lo", "hi")] <- adjust[i]*targets[i, c("target", "lo", "hi")]
} else {
targets[i, c("target", "lo", "hi")] <- c(NA, NA, NA)
}
}
targets
}
}
# bring in lake-wide spawner data
lk <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/LakePEdynamic.csv", as.is=T)
# bring in stream-specific data
dat <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/StreamPEdynamicALLCOLS.csv", as.is=T)
dat$ls <- dat$lscode
attach(dat)
colz <- rep(c(brewer.pal(8, "Dark2"), brewer.pal(8, "Set2")), 4)
### map of trapped and untrapped streams
selm <- year==2014 & est.source=="model"
selo <- year==2014 & est.source!="model"
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selm], lat[selm], col=colz[1], cex=2, lwd=2)
legend("right", c("Trapped", "Untrapped"), pt.cex=c(3, 2), pt.lwd=2, col=colz[2:1], pch=1, bty="n")
### index streams
# 2014-04-09 Jess and Gale agreed that the East Au Gres (38) should be replaced with the Au Sable (36) in Lake Huron
# 2014-04-10 Jess thinks that we should just stick with the East Au Gres (38)
index.streams <- list(
Sup = c(1, 2, 9, 29, 31, 32, 62),
Mic = c(5, 6, 15, 24, 26, 35),
Hur = c(10, 16, 27, 32, 999, 38),
Eri = c(1, 2, 3, 7, 9),
Ont = c(5, 9, 22, 23, 36)
)
index.streams <- lapply(1:5, function(i) i + index.streams[[i]]/1000)
### plots of time series
look <- table(ls, year, est.source=="model")
# just last 10 years
look2 <- apply(look[, 29:38, ], c(1, 3), sum)
look3 <- look2[look2[, 1]>0 & look2[, 2]>0, ]
look3[order(look3[, 1] - look3[, 2]), ]
dat[match(rownames(look3), ls), 1:10]
#dat[match(unlist(index.streams), ls), 1:10]
plotit <- function(mylake, lss, llog="y", yrcut=2004.5, ...) {
selall <- lake==mylake & year > yrcut
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5.5, w=3.3)
par(mar=c(4, 4, 1, 1))
if(llog=="y") {
fac <- 1
ylabb <- "Adults"
} else {
fac <- 1000
ylabb <- "Adults  (thousands)"
}
plot(year[selall], combPE[selall]/fac, type="n", las=1, log=llog, xlab="Year", ylab=ylabb, ...)
for(i in seq(lss2)) {
sel2 <- lake==mylake & year > yrcut & ls==lss2[i]
lines(year[sel2], combPE[sel2]/fac, col=colkey$colx[colkey$ls==lss2[i]], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y/fac, col=colkey$colx[colkey$ls==lss2[i]], type="o", pch=16, cex=1.2, lwd=2)
}
}
mapit <- function(mylake, lss, ...) {
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
for(i in seq(lss2)) {
sel <- lake==mylake & year==2014 & ls==lss2[i]
points(long[sel], lat[sel], col=colkey$colx[colkey$ls==lss2[i]], pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colkey$colx[colkey$ls==lss2[i]], ...)
}
}
# all non-model time series
lsbest <- as.numeric(rownames(look2[look2[, "TRUE"]==0, ]))
# all model time series
lsmodel <- as.numeric(rownames(look2[look2[, "FALSE"]==0, ]))
# mixed time series
lsmixed <- as.numeric(rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ]))
# create a color key
yrcut <- 2004.5
sub <- dat[year > yrcut, c("year", "ls", "combPE")]
medPE <- tapply(sub$combPE, sub$ls, median)
df1 <- cbind(medPE, ls=as.numeric(names(medPE)))
df2 <- cbind(ls=c(lsbest, lsmodel, lsmixed), group=rep(c("1best", "2model", "3mixed"), c(length(lsbest), length(lsmodel), length(lsmixed))))
colkey <- merge(df1, df2)
colkey$lake <- floor(colkey$ls)
colkey <- colkey[order(colkey$lake, colkey$group, -colkey$medPE), ]
colkey$lg <- paste(colkey$lake, colkey$group)
colkey$coli <- unlist(tapply(-colkey$medPE, colkey$lg, rank, ties.method="random"))
colkey$colx <- colz[colkey$coli]
head(colkey)
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
dat[lake==3 & year==2008 & combPE > 6000, ]
dat[lake==3 & year>2004.5 & strname=="Garden", ]
mylake <- 3
plotit(3, lsbest[!(lsbest %in% index.streams[[3]])], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
plotit(3, lsbest[lsbest %in% index.streams[[3]]], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2, font=1, cex=1.2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2, cex=1.5)
# estimate adult index of abundance for each lake using index streams
indices <- lapply(index.streams, index.est, dat, lk)
# combine index data for all lakes in one dataframe
indxall <- do.call(rbind, lapply(indices, "[[", "indxdf"))
# calculate targets 
sptargyrz <- list(1994:1998, 1988:1992, 1989:1993, 1991:1995, 1999:2003)
targyrz <- apply(sapply(sptargyrz, range), 2, paste, collapse="-")
# spawner model
targets.sm <- calctarg(lakenum=lk$lake, adults=lk$PE, year=lk$year, targyears=sptargyrz)
# adult index
targets.ai <- calctarg(lakenum=indxall$lake, adults=indxall$indxkeep, year=indxall$year, targyears=sptargyrz)
# spawner model targets scaled down to adult index
targets.sm.su <- cbind(lake=targets.sm[, 1], (1/sapply(indices, "[[", "scaleup")) * targets.sm[, -1])
# adult index adjusted
targets.ai.adj <- targets.ai
targets.ai.adj[is.na(targets.ai$target), ] <- targets.sm.su[is.na(targets.ai$target), ]
YEAR1 <- 1984
outcex <- 1.2
YEARb <- 2005
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
convfac <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(convfac*c(0, anntotals))/1000
axis(4, at=prt/convfac, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.8, bty="n", border=NA)
}
fig(3)
### spawner model and adult index time series overlaid
fig <- function(mylake, sp=TRUE) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, mylk$hi[x2>=YEARb]/convfac/1000, na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
if(sp) {
arrows(x2, mylk$lo/convfac/1000, x1, mylk$hi/convfac/1000, length=0.05, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
legend("bottom", c("Adult index", "Current method"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18), bty="n")
}
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
if(sp) lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
}
fig(3, FALSE)
fig(3)
cleanup()
q()
cm <- 0:20
dB <- 20*log10(cm) - 67.6
plot(dB, cm)
abline(v=-48)
plot(cm, dB)
plot(cm, dB, las=1)
par("usr")
cm <- 0:20
dB <- 20*log10(cm) - 67.6
dB66 <- 20*log10(6.6) - 67.6
cm48 <- 10^((-48 + 67.6)/20)
windows(h=3, w=4)
par(mar=c(4, 4, 1, 1), xaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, col="blue")
lines(c(cm48, cm48, 0), c(pusr[3], -48, -48), lty=2, col="blue")
points(6.6, db66, col="red")
lines(c(6.6, 6.6, 0), c(pusr[3], db66, db66), lty=2, col="red")
> 
points(6.6, dB66, col="red")
lines(c(6.6, 6.6, 0), c(pusr[3], dB66, dB66), lty=2, col="red")
par(mar=c(4, 4, 1, 1), xaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, col="blue")
lines(c(cm48, cm48, 0), c(pusr[4], -48, -48), lty=2, col="blue")
points(6.6, dB66, col="red")
lines(c(6.6, 6.6, 0), c(pusr[4], dB66, dB66), lty=2, col="red")
> pusr
pusr
par(mar=c(4, 4, 1, 1), xaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, col="blue")
lines(c(cm48, cm48, 0), c(pusr[3], -48, -48), lty=2, col="blue")
points(6.6, dB66, col="red")
lines(c(6.6, 6.6, 0), c(pusr[3], dB66, dB66), lty=2, col="red")
par(mar=c(4, 4, 1, 1), xaxs="i", yaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, col="blue")
lines(c(cm48, cm48, 0), c(pusr[3], -48, -48), lty=2, col="blue")
points(6.6, dB66, col="red")
lines(c(6.6, 6.6, 0), c(pusr[3], dB66, dB66), lty=2, col="red")
par(mar=c(4, 4, 1, 1), xaxs="i", yaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, pch=16, col="blue")
text(cm48, -48, paste0("(", round(cm48, 1), "-48)"), col="blue", pos=4)
lines(c(cm48, cm48, 0), c(pusr[3], -48, -48), lty=2, col="blue")
points(6.6, dB66, pch=16, col="red")
text(6.6, dB66, paste0("(6.6, ", round(dB66, 1), ")"), col="red", pos=4)
lines(c(6.6, 6.6, 0), c(pusr[3], dB66, dB66), lty=2, col="red")
par(mar=c(4, 4, 1, 1), xaxs="i", yaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, pch=16, col="blue")
text(cm48, -48, paste0("(", round(cm48, 1), ", -48.0)"), col="blue", pos=4)
lines(c(cm48, cm48, 0), c(pusr[3], -48, -48), lty=2, col="blue")
points(6.6, dB66, pch=16, col="red")
text(6.6, dB66, paste0("(6.6, ", round(dB66, 1), ")"), col="red", pos=4)
lines(c(6.6, 6.6, 0), c(pusr[3], dB66, dB66), lty=2, col="red")
cleanup()
q()
library(devtools)
?find_rtools
find_rtools()
find_rtools(TRUE)
?capwords
q()
# C:\JVA\Admin\Duties\TallyTally.r
# by default, the data will be summarized for the current fiscal year
FY <- as.numeric(rev(strsplit(date(), " ")[[1]])[1])
start <- paste0(FY-1, "-10-01")
end <- paste0(FY, "-09-30")
#start <- paste0(2014, "-07-01")
#end <- paste0(2014, "-09-30")
wb <- loadWorkbook("C:/JVA/Admin/Duties/NewTally.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=3)
dat$Hours <- as.numeric(dat$Hours)
sub <- dat[substring(dat$Date, 1, 10) >= start & substring(dat$Date, 1, 10) <= end, ]
look <- aggregate(Hours ~ Agency + PersonTask, data=sub, sum)
look2 <- look[order(look$Agency, look$Hours, decreasing=TRUE), c(1, 3, 2)]
look2
write.csv(look2, "C:/JVA/Admin/Duties/latest.csv", row.names=FALSE)
cleanup()
q()
df1<-data.frame(area=c(1,2),group1=c(2,3),group2=c(1,5),group3=c(4,0))
df1
df2<-data.frame(person_id=seq(1:15),area=c(rep(1,7),rep(2,8)),group_num=c(1,1,2,3,3,3,3,1,1,1,2,2,2,2,2))
df2
q()
?cheat
# C:\JVA\Consult\Deines\ExploreChla.r
library(lubridate)
library(rtf)
# read in the data
dat <- read.csv("C:/JVA/Consult/Deines/master_harvest_chl_metadata.csv")
?save
FishSpecies <- dat
save(FishSpecies)
save(FishSpecies, FishSpecies.RData)
save(FishSpecies, "FishSpecies.RData")
save(FishSpecies, file="FishSpecies.RData")
?cheat
q()
install.packages("Deducer",,"http://rforge.net/")
library(Deducer)
q()
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("jvamisc")
setwd("C:/JVA/R/Working Directory")
library(jvamisc)
chi
?chi
## From Agresti(2007) p.39
M <- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))
dimnames(M) <- list(gender = c("M", "F"), party = c("Democrat", "Independent", "Republican"))
chi(M)
ls()
cleanup()
ls()
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 100
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
hist(df$sr2, breaks=brks, col="skyblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="orange", lwd=2)
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 100
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2)
hist(df$sr2, breaks=brks, col="skyblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="orange", lwd=2)
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 100
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="skyblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="orange", lwd=2)
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
graphics.off()
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 1000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="skyblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="orange", lwd=2)
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 1000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="brown", lwd=2)
legend("topleft", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
?hist
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 10000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 10000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization," format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
paste("Randomization," format(nsim, big.mark=","), "simulations")
paste("Randomization,", format(nsim, big.mark=","), "simulations")
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 10000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization:", format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 1000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(3, 3, 3, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="", ylab="", main="Trap catch")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="", ylab="", main="Fish wheel catch")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization:", format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 1000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(3, 3, 3, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="", ylab="", main="Trap catch")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="", ylab="", main="Fish wheel catch")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE, font=2, cex=1.2)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization:", format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 1000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(3, 3, 3, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="", ylab="", main="Trap catch")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="", ylab="", main="Fish wheel catch")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE, font=2, cex=1.3)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization:", format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 10000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(3, 3, 3, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="", ylab="", main="Trap catch")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="", ylab="", main="Fish wheel catch")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE, font=2, cex=1.3)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization:", format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
ctot
ls()
rtot
c1
c2
360-29
22/10000
head(rp)
apply(rp, 2, mean)
cleanup()
q()
?cheat
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
catch <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
temp <- readWorksheet(wb, sheet=getSheets(wb)[3], startRow=1)
warnings()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
catch <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
temp <- readWorksheet(wb, sheet=getSheets(wb)[3], startRow=1)
q()
# install from local folder
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("jvamisc")
setwd("C:/JVA/R/Working Directory")
library(jvamisc)
?capwords
capwords(c("using AIC for model selection"))
capwords(c("using AIC", "for MODEL selection"), strict=FALSE)
attach(cat)
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(capwords(barrier.name[match(sub[j], slbarid)]), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
}
ls()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
cat$week <- marday%/%7 + 1
# ack!  Need zero catches as well !!
table(cat$catch > 0.5)
attach(cat)
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(capwords(barrier.name[match(sub[j], slbarid)]), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
}
cleanup()
search()
detach()
graphics.off()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
cat$week <- marday%/%7 + 1
# ack!  Need zero catches as well !!
table(cat$catch > 0.5)
attach(cat)
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(capwords(barrier.name[match(sub[j], slbarid)]), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
}
cleanup()
search()
q()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
cat$week <- marday%/%7 + 1
# ack!  Need zero catches as well !!
table(cat$catch > 0.5)
cat$week <- cat$marday%/%7 + 1
# ack!  Need zero catches as well !!
table(cat$catch > 0.5)
attach(cat)
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(capwords(barrier.name[match(sub[j], slbarid)]), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
}
capwords(barrier.name[match(sub, slbarid)])
sort(capwords(barrier.name[match(sub, slbarid)]))
length(unique(sort(capwords(barrier.name[match(sub, slbarid)]))))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)]), 1, 10)))
)
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 10)))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 8)))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 6)))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 4)))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 5)))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 6)))
(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 6)))
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
}
wklymyr <- apply(wklycat, 1:2, sum, na.rm=TRUE)
wklymyr
wklymyr <- apply(wklycat, 1:2, sum, na.rm=TRUE)
wklytot <- apply(wklymyr, 2, sum, na.rm=TRUE)
wklymyrp <- sweep(wklymyr, 2, wklytot, "/")
wklymyrp
apply(wklymyrp, 2, sum)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], col="grey", lwd=3)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
cleanup()
q()
ls()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
cat$week <- cat$marday%/%7 + 1
# ack!  Need zero catches as well !!
table(cat$catch > 0.5)
attach(cat)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
tapply(marday, 
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
wklymyr <- apply(wklycat, 1:2, sum, na.rm=TRUE)
wklytot <- apply(wklymyr, 2, sum, na.rm=TRUE)
wklymyrp <- sweep(wklymyr, 2, wklytot, "/")
wklymyrp
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
wklymyr <- apply(wklycat, 1:2, sum, na.rm=TRUE)
wklytot <- apply(wklymyr, 2, sum, na.rm=TRUE)
wklymyrp <- sweep(wklymyr, 2, wklytot, "/")
wklymyrp
wklymyrp
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
dim(wklymyrp)
suw
rows(wklymyrp)
row(wklymyrp)
apply(row(wklymyrp)*wklymyrp, 2, sum)
apply(row(wklymyrp)*wklymyrp, 2, sum)/wklytot
mid <- apply(row(wklymyrp)*wklymyrp, 2, sum)
mid
mid <- apply(row(wklymyrp)*wklymyrp, 2, sum)
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
abline(v=mid[j], lwd=2)
}
suw
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=1:21, lwd=2, col="lightgray")
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col="lightgray")
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col="lightgray")
abline(h=seq(0, 1, 0.2), lwd=2, col="lightgray")
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.2))
abline(h=seq(0, 1, 0.25), lwd=2, col="lightgray")
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.8))
abline(h=seq(0, 1, 0.25), lwd=2, col="lightgray")
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
box()
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1, xaxs="i", yaxs="i")
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1, xaxs="i", yaxs="i")
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), las=1, xaxs="i", yaxs="i")
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, -4), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, -2), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, line=0.5, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
?par
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i", xpd=FALSE)
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
windows()
par("xpd")
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
par(xpd=FALSE)
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
windows(h=5.5, w=9)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
par(xpd=FALSE)
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
par(xpd=FALSE)
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), at=mid[j], side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), at=mid[j], side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
par(xpd=FALSE)
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), at=mid[j], side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
par(xpd=FALSE)
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), at=mid[j], side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
par(xpd=FALSE)
abline(v=mid[j], lwd=2)
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
q()
3pg <- 10
cleanup()
??gaussian
zq
qz
?rnorm
qnorm(0.95, 0, 1)
qnorm(0.975, 0, 1)
qnorm(0.975, 4, 1)
alpha <- 0.05
qnorm(1-alpha/2, 0, 1)
gaus3p <- function(x, y, ...) {
# fit a 3 parameter Gaussian curve
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y), b=sqrt(var(x)), c=x[y==max(y)][1], r=0), ...)
}
gaus3p(marday, catch, data=cat2)
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
cat$week <- cat$marday%/%7 + 1
# Don't need any zero catch data for this approach
cat2 <- cat[cat$catch > 0.5, ]
gaus3p <- function(x, y, ...) {
# fit a 3 parameter Gaussian curve
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y), b=sqrt(var(x)), c=x[y==max(y)][1], r=0), ...)
}
gaus3p(marday, catch, data=cat2)
head(cat2)
head(cat2)
?nls
gaus3p(cat2$marday, cat2$catch)
gaus3p <- function(x, y, ...) {
# fit a 3 parameter Gaussian curve
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1], r=0), ...)
}
gaus3p(cat2$marday, cat2$catch)
list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1])
x <- cat2$marday
y <- cat2$catch
list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1])
attach(cat2)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
x <- cat2$marday[cat2$slbarid==sub[1]]
y <- cat2$catch[cat2$slbarid==sub[1]]
list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1])
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...)
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]))
fit <- nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]))
coef(fit)
co <- coef(fit)
alpha=0.1
co <- coef(fit)
z <- qnorm(1-alpha/2)
co["b"] + c(-1, 1) * z * co["c"]
co["b"] + z * co["c"]
co["b"] - z * co["c"]
fit <- gaus3p(cat2$marday[cat2$slbarid==sub[1]], cat2$catch[cat2$slbarid==sub[1]])
timez(fit)
gaus3p <- function(x, y, ...) {
# fit a 3 parameter Gaussian curve
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...)
}
timez <- function(fit, alpha=0.1) {
# calculate start and end days for 1-alpha * 100% of distribution
co <- coef(fit)
z <- qnorm(1-alpha/2)
co["b"] + c(-1, 1) * z * co["c"]
}
fit <- gaus3p(cat2$marday[cat2$slbarid==sub[1]], cat2$catch[cat2$slbarid==sub[1]])
timez(fit)
head(cat2)
aggregate(catch ~ slbarid + year, sum)
aggregate(catch, lls(slbarid, year), sum)
?aggregate
aggregate(catch, list(slbarid, year), sum)
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
head(smry)
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
head(smry)
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
head(smry)
cat2[slbarid==128410003 & year==1993, ]
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$start <- NA
smry$end <- NA
for(i in sub) {
for(j in suy) {
sel <- slbarid==sub[i] & year==suy[j]
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
summary(smry)
plot(sort(smry$numdays))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$start <- NA
smry$end <- NA
for(i in sub) {
for(j in suy) {
sel <- slbarid==sub[i] & year==suy[j]
if(sum(sel) > 7) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
for(i in sub) {
for(j in suy) {
sel <- slbarid==sub[i] & year==suy[j]
if(!is.na(sel & sum(sel) > 7) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
for(i in sub) {
for(j in suy) {
sel <- slbarid==sub[i] & year==suy[j]
if(!is.na(sel) & sum(sel) > 7) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
warnings()
for(i in sub) {
for(j in suy) {
sel <- slbarid==sub[i] & year==suy[j]
print(i)
print(j)
if(!is.na(sel) & sum(sel) > 7) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
print(i)
print(j)
if(!is.na(sel) & sum(sel) > 7) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
sel
sum(sel)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
print(i)
print(j)
if(!is.na(sel) & sum(sel) >= 21) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
warnings()
sel
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
print(i)
print(j)
if(sum(sel[!is.na(sel)]) >= 21) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
sel
sum(sel)
cat2[sel, ]
?weighted.mean
?mean
?weighted.var
alpha <- 0.1
z <- qnorm(1-alpha/2)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
print(i)
print(j)
if(sum(sel[!is.na(sel)]) >= 7) {
x <- rep(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- mean(x) + c(-1, 1) * z * sd(x)
}
}}
head(smry)
??truncate
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$start <- NA
smry$end <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
mn <- mean(
print(i)
print(j)
if(sum(sel[!is.na(sel)]) >= 21) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
print(i)
print(j)
if(sum(sel[!is.na(sel)]) >= 21) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
sel
cat2[sel, ]
plot(marday[sel], catch[sel])
fit <- gaus3p(marday[sel], catch[sel])
?nls
fit <- gaus3p(marday[sel], catch[sel], maxiter=500)
fit <- gaus3p(marday[sel], catch[sel], nls.control(maxiter=500))
fit <- gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500))
?try
try(log("a"))
print(try(log("a"), TRUE))
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
fit
class(fit)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
print(i)
print(j)
if(sum(sel[!is.na(sel)]) >= 21) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
}}
search()
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$start <- NA
smry$end <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 21) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
}}
summary(smry)
dim(smry)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 7) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
}}
summary(smry)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 4) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
}}
summary(smry)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 1) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
}}
summary(smry)
smry2 <- smry[!is.na(smry$start), ]
dim(smry2)
head(smry2)
timez <- function(fit, alpha=0.1) {
# calculate start and end days for 1-alpha * 100% of distribution
co <- coef(fit)
z <- qnorm(1-alpha/2)
c(co["a"], co["b"], co["c"], co["b"] + c(-1, 1) * z * co["c"])
}
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$a
smry$b
smry$c
smry$start <- NA
smry$end <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 4) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("a", "b", "c", "start", "end")] <- timez(fit)
}
}
}}
smry2 <- smry[!is.na(smry$start), ]
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$a <- NA
smry$b <- NA
smry$c <- NA
smry$start <- NA
smry$end <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 4) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("a", "b", "c", "start", "end")] <- timez(fit)
}
}
}}
smry2 <- smry[!is.na(smry$start), ]
head(smry2)
plotdf(smry2)
graphics.off()
sel <- slbarid==111510001 & year==1993
sel <- slbarid==111510001 & year==1993
plot(marday[sel], catch[sel])
head(smry2)
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus2p <- function(x, y, ...) {
# fit a 2 parameter Gaussian curve, assume that peak is known
a <- max(y, na.rm=TRUE)
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...)
}
gaus3p(marday[sel], catch[sel])
gaus2p(marday[sel], catch[sel])
fit$a
coef(fit)
gaus2p <- function(x, y, ...) {
# fit a 2 parameter Gaussian curve, assume that peak is known
a <- max(y, na.rm=TRUE)
c("a"=a, coef(nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...))
}
gaus3p <- function(x, y, ...) {
# fit a 3 parameter Gaussian curve
coef(nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...))
}
gaus2p <- function(x, y, ...) {
# fit a 2 parameter Gaussian curve, assume that peak is known
a <- max(y, na.rm=TRUE)
c("a"=a, coef(nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...)))
}
timez <- function(co, alpha=0.1) {
# calculate start and end days for 1-alpha * 100% of distribution
z <- qnorm(1-alpha/2)
c(co["a"], co["b"], co["c"], co["b"] + c(-1, 1) * z * co["c"])
}
coe <- gaus2p(marday[sel], catch[sel])
coe
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
?par
?rnorm
pnorm((newday-mn)/s, mn, s)
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pnorm((newday-mn)/s, mn, s)
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
par(new=TRUE, xaxs="d")
lines(newday, pnorm((newday-mn)/s, mn, s), col="green")
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
par(new=TRUE, xaxs="d")
plot(newday, pnorm((newday-mn)/s, mn, s), type="l", col="green")
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
par(new=TRUE, xaxs="d")
plot(newday, pnorm((newday-mn)/s, mn, s), type="l", col="green")
pusr <- par("usr")
pusr
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
par(xaxs="i")
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pusr <- par("usr")
par(new=TRUE, xaxs="d")
plot(newday, pnorm((newday-mn)/s, mn, s), xlim=pusr[1:2], type="l", col="green")
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
par(xaxs="i")
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pusr <- par("usr")
par(new=TRUE)
plot(newday, pnorm((newday-mn)/s, mn, s), xlim=pusr[1:2], type="l", col="green")
(newday-mn)/s
pnorm((newday-mn)/s, mn, s)
?pnrom
?pnorm
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
par(xaxs="i")
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pusr <- par("usr")
par(new=TRUE)
plot(newday, dnorm((newday-mn)/s, mn, s), xlim=pusr[1:2], type="l", col="green")
dnorm((newday-mn)/s, mn, s)
require(graphics)
dnorm(0) == 1/sqrt(2*pi)
dnorm(1) == exp(-1/2)/sqrt(2*pi)
dnorm(1) == 1/sqrt(2*pi*exp(1))
## Using "log = TRUE" for an extended range :
par(mfrow = c(2,1))
plot(function(x) dnorm(x, log = TRUE), -60, 50,
     main = "log { Normal density }")
curve(log(dnorm(x)), add = TRUE, col = "red", lwd = 2)
mtext("dnorm(x, log=TRUE)", adj = 0)
mtext("log(dnorm(x))", col = "red", adj = 1)
x <- -60:50
dnorm(x)
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
par(xaxs="i")
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pusr <- par("usr")
par(new=TRUE)
plot(newday, dnorm((newday-mn)/s), xlim=pusr[1:2], type="l", col="green")
dnorm((newday-mn)/s)
dnorm(newday, mn, s)
y1 <- dnorm((newday-mn)/s)
y2 <- dnorm(newday, mn, s)
windows()
y1/y2
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
par(xaxs="i")
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pusr <- par("usr")
par(new=TRUE)
plot(newday, dnorm(newday, mn, s), xlim=pusr[1:2], type="l", col="green")
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$dmean <- NA
smry$dsd <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 2) {
x <- rep(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("dmean", "dsd")] <- c(mean(x), sd(x))
}
# if(sum(sel[!is.na(sel)]) >= 4) {
# coe <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
# if(class(coe)!="try-error") {
# smry[smry$slbarid==sub[i] & smry$year==suy[j], c("a", "b", "c", "start", "end")] <- timez(coe)
# }
# }
}}
smry2 <- smry[!is.na(smry$dmean), ]
dim(smry)
dim(smry2)
head(smry2)
smry2 <- smry[!is.na(smry$dmean), ]
alpha <- 0.01
z <- qnorm(1-alpha/2)
smry2$start <- smry2$dmean - z * smry2$dsd
smry2$end <- smry2$dmean + z * smry2$dsd
plotdf(smry2)
head(smry2)
head(barrier)
dim(barrier)
length(unique(barrier$slbarid))
match(smry2$slbarid, barrier$slbarid)
m <- match(smry2$slbarid, barrier$slbarid)
smry2[is.na(m), ]
smry2$slbarid[is.na(m)]
unique(smry2$slbarid[is.na(m)])
smry[smry$slbarid %in% unique(smry2$slbarid[is.na(m)]), ]
cat[cat$slbarid %in% unique(smry2$slbarid[is.na(m)]), ]
cat[match(unique(smry2$slbarid[is.na(m)]), cat$slbarid), ]
head(barrier)
sort(barrier$barrier.name)
barrier
barrier[c(9, 13), ]
cat[match(unique(smry2$slbarid[is.na(m)]), cat$slbarid), ]
match(unique(cat$slbarid), barrier$slbarid)
temp <- readWorksheet(wb, sheet=getSheets(wb)[3], startRow=1)
temp <- fixnames(temp)
temp$mint <- as.numeric(temp$mintemp..c.)
temp$maxt <- as.numeric(temp$maxtemp..c.)
temp$avgt <- as.numeric(temp$avgtemp..c.)
head(temp)
match(unique(temp$slbarid), barrier$slbarid)
m <- match(unique(temp$slbarid), barrier$slbarid)
m[is.na(m)]
unique(temp$slbarid)[is.na(m)]
unique(temp$slbarid)
temp[is.na(slbarid), ]
summary(temp)
temp[is.na(temp$slbarid), ]
dim(temp)
head(barrier)
barrier
temp[is.na(temp$slbarid), ]
temp$strcode[is.na(temp$slbarid), ]
temp$str.code[is.na(temp$slbarid)]
unique(temp$str.code[is.na(temp$slbarid)])
length(temp$str.code[is.na(temp$slbarid)])
table(temp$str.code)
head(temp)
head(temp)
temp$year <- year(cat$date)
temp$month <- month(cat$date)
temp$day <- day(cat$date)
temp$year <- year(temp$date)
temp$month <- month(temp$date)
temp$day <- day(temp$date)
temp$marday <- as.numeric(as.Date(paste(temp$year, temp$month, temp$day, sep="-")) - as.Date(paste0(temp$year, "-03-01")) + 1)
temp$slbarid[sel] <- 501910046
temp$barrier.name[sel] <- "DEXTER DAM"
temp$mint <- as.numeric(temp$mintemp..c.)
temp$maxt <- as.numeric(temp$maxtemp..c.)
temp$avgt <- as.numeric(temp$avgtemp..c.)
temp$year <- year(temp$date)
temp$month <- month(temp$date)
temp$day <- day(temp$date)
temp$marday <- as.numeric(as.Date(paste(temp$year, temp$month, temp$day, sep="-")) - as.Date(paste0(temp$year, "-03-01")) + 1)
head(temp)
first
?lab
lag
?lag
temp2 <- temp[order(temp$slbarid, temp$marday), ]
f <- first(temp$slbarid)
temp2[1:20, ]
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp$slbarid)
temp2[1:20, ]
lag(temp2$marday)[1:20]
lag(temp2$marday[1:20])
(temp2$marday[1:20])
lag(temp2$marday[1:20], 1)
lag(temp2$marday[1:20], 2)
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp$slbarid)
temp2dago <- c(NA, NA, temp$avgt)[1:length(temp$avgt)]
temp2dago[1:20]
f
cumsum(f)
f <- first(temp$slbarid)
f2 <- first(f)
f
f2
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp$slbarid)
f2 <- first(f)
temp2dago <- c(NA, NA, temp$avgt)[1:length(temp$avgt)]
temp2dago[f2==1] <- NA
temp2[1:500, ]
temp2dago
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp$slbarid)
f2 <- first(f)
temp$temp2dago <- c(NA, NA, temp$avgt)[1:length(temp$avgt)]
temp$temp2dago[f2==1] <- NA
f==1
seq(f)[f==1]
f
table(f)
length(f)
is.na(f)
sum(is.na(f))
cleanup()
q()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
# bring in the data, fix the names
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
temp <- readWorksheet(wb, sheet=getSheets(wb)[3], startRow=1)
temp <- fixnames(temp)
### estimate start and end times for barrier operation based on observed (truncated) distribution of catch days
# two barrier codes have typos in them
cat$slbarid[cat$slbarid==221310048] <- 221610048
cat$slbarid[cat$slbarid==27391001] <- 273910001
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
# Don't need any zero catch data for this approach
cat2 <- cat[cat$catch > 0.5, ]
attach(cat2)
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$dmean <- NA
smry$dsd <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 2) {
x <- rep(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("dmean", "dsd")] <- c(mean(x), sd(x))
}
}}
smry2 <- smry[!is.na(smry$dmean), ]
alpha <- 0.01
z <- qnorm(1-alpha/2)
smry2$start <- smry2$dmean - z * smry2$dsd
smry2$end <- smry2$dmean + z * smry2$dsd
detach(cat2)
### calculate two-day change in temperature for each marday
# one barrier is missing its code and name
sel <- temp$str.code==19
temp$slbarid[sel] <- 501910046
temp$barrier.name[sel] <- "DEXTER DAM"
temp$mint <- as.numeric(temp$mintemp..c.)
temp$maxt <- as.numeric(temp$maxtemp..c.)
temp$avgt <- as.numeric(temp$avgtemp..c.)
temp$year <- year(temp$date)
temp$month <- month(temp$date)
temp$day <- day(temp$date)
temp$marday <- as.numeric(as.Date(paste(temp$year, temp$month, temp$day, sep="-")) - as.Date(paste0(temp$year, "-03-01")) + 1)
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp$slbarid)
f2 <- first(f)
temp$temp2dago <- c(NA, NA, temp$avgt)[1:length(temp$avgt)]
temp$temp2dago[f2==1] <- NA
seq(f)[f==1]
look <- seq(f)[f==1]
look
look-5
look[-1]-5
paste(look[-1]-5, look[-length(look)]+5, sep=":")
paste(look[-1]-5, look[-length(look)]+5, sep=":", collapse=", ")
temp[c(1506:6, 2837:1516, 3240:2847, 4309:3250, 5663:4319, 6788:5673, 8258:6798, 9116:8268, 9452:9126, 10812:9462, 12173:10822, 12892:12183, 13828:12902, 
15503:13838, 16753:15513, 17732:16763, 18772:17742, 20220:18782, 21363:20230, 22867:21373, 22943:22877, 24506:22953, 24982:24516, 26073:24992, 26641:26083, 
28490:26651, 30028:28500, 31808:30038, 32133:31818, 32738:32143, 34338:32748, 35436:34348, 36875:35446, 38474:36885), ]
28490:26651, 30028:28500, 31808:30038, 32133:31818, 32738:32143, 34338:32748, 35436:34348, 36875:35446, 38474:36885), ]
temp[c(1506:6, 2837:1516, 3240:2847, 4309:3250, 5663:4319, 6788:5673, 8258:6798, 9116:8268, 9452:9126, 10812:9462, 12173:10822, 12892:12183, 13828:12902, 
15503:13838, 16753:15513, 17732:16763, 18772:17742, 20220:18782, 21363:20230, 22867:21373, 22943:22877, 24506:22953, 24982:24516, 26073:24992, 26641:26083, 
28490:26651, 30028:28500, 31808:30038, 32133:31818, 32738:32143, 34338:32748, 35436:34348, 36875:35446, 38474:36885), ]
paste(look-3, look+3, sep=":", collapse=", ")
temp[c(1508:1514, 2839:2845, 3242:3248, 4311:4317, 5665:5671, 6790:6796, 8260:8266, 9118:9124, 9454:9460, 10814:10820, 12175:12181, 12894:12900, 13830:13836, 
15505:15511, 16755:16761, 17734:17740, 18774:18780, 20222:20228, 21365:21371, 22869:22875, 22945:22951, 24508:24514, 24984:24990, 26075:26081, 26643:26649, 
28492:28498, 30030:30036, 31810:31816, 32135:32141, 32740:32746, 34340:34346, 35438:35444, 36877:36883, 38476:38482), ]
temp$tempdelta2 <- temp$avgt - temp$temp2dago
head(barrier)
head(cat2)
barrier2 <- merge(barrier, cat2)
head(barrier2)
barrier2 <- merge(barrier, smry2)
head(barrier2)
barrier2 <- merge(barrier, smry2, all=TRUE)
dim(barrier)
dim(smry2)
dim(barrier2)
summary(barrier2)
barrier2[is.na(barrier2$start), ]
sort(unique(cat$barrier.name))
dim(smry2)
dim(barrier2)
head(barrier2)
head(barrier2)
head(temp)
dput(names(temp))
dput(names(barrier))
head(barrier)
names(barrier) <- c("lake.code", "str.code", "slbarid", "barrier.name", "lat", "long", "miles2mouth", "feet2mouth", "gradient", "elevsiteft", "elevmouthft")
head(barrier)
# merge catch data with barrier data
barrier2 <- merge(barrier, smry2, all=TRUE)
dim(smry2)
dim(barrier2)
# no catch data for ORWELL BROOK or STERLING VALLEY
barrier2[is.na(barrier2$start), ]
head(smry2)
head(barrier2)
# merge temperature and barrier/catch data
barrier2$start <- round(barrier2$start)
barrier2$end <- round(barrier2$end)
head(barrier2)
intersect
intersect(names(barrier2), names(temp))
keep <- c("lake.code", "str.code", "str.code.1", "slbarid", "barrier.name", "samples", "avgt", "year", "marday", "tempdelta2")
incomm <- c("lake.code", "slbarid", "barrier.name", "str.code", "year")
barrier3 <- merge(barrier2, temp[, keep], by.x=c(incomm, "start"), by.y=c(incomm, "marday"))
head(barrier3)
barrier3 <- merge(barrier2, temp[, keep], by.x=c(incomm, "end"), by.y=c(incomm, "marday"), all.x=TRUE)
barrier4 <- merge(barrier3, temp[, keep], by.x=c(incomm, "start"), by.y=c(incomm, "marday"), all.x=TRUE)
head(barrier4)
barrier4[1:20, ]
keep <- c("lake.code", "str.code", "str.code.1", "slbarid", "barrier.name", "samples", "avgt", "year", "month", "day", "marday", "tempdelta2")
incomm <- c("lake.code", "slbarid", "barrier.name", "str.code", "year")
barrier3 <- merge(barrier2, temp[, keep], by.x=c(incomm, "end"), by.y=c(incomm, "marday"), all.x=TRUE)
barrier4 <- merge(barrier3, temp[, keep], by.x=c(incomm, "start"), by.y=c(incomm, "marday"), all.x=TRUE)
head(barrier4)
summary(barrier4)
dim(barrier4)
whatdate <- function(marday, year) {
marday + as.Date(paste0(year, "-03-01")) - 1
}
whatdate(1, 2013)
whatdate(1, 2014)
whatdate(-1, 2014)
whatdate(-1, 2013)
whatdate(-1, 2012)
summary(smry)
summary(smry2)
whatdate(5, 2013)
whatdate(152, 2013)
head(temp)
tapply(temp$marday, list(temp$slbarid, temp$year), range)
tapply(temp$marday, list(temp$slbarid, temp$year), min)
tapply(temp$marday, list(temp$slbarid, temp$year), min, na.rm=TRUE)
tapply(temp$marday, list(temp$slbarid, temp$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep="-"))
tapply(temp$marday, list(temp$slbarid, temp$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
temp$mint <- as.numeric(temp$mintemp..c.)
temp$maxt <- as.numeric(temp$maxtemp..c.)
temp$avgt <- as.numeric(temp$avgtemp..c.)
temp$year <- year(temp$date)
temp$month <- month(temp$date)
temp$day <- day(temp$date)
temp$marday <- as.numeric(as.Date(paste(temp$year, temp$month, temp$day, sep="-")) - as.Date(paste0(temp$year, "-03-01")) + 1)
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp2$slbarid)
f2 <- first(f)
temp2$temp2dago <- c(NA, NA, temp2$avgt)[1:length(temp2$avgt)]
temp2$temp2dago[f2==1] <- NA
temp2$tempdelta2 <- temp2$avgt - temp2$temp2dago
tapply(temp2$marday, list(temp2$slbarid, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
head(barrier2)
tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
options("max.print")
options(max.print=1000)
tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
cav
# temperature data available
tav <- tapply(temp2$marday, list(temp2$slbarid, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
dim(tav)
dim(cav)
match(dimnames(tav)[[1]], dimnames(cav)[[1]])
match(dimnames(tav)[[2]], dimnames(cav)[[2]])
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(temp2$slbarid, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(temp2$slbarid, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])]
dim(cav)
dim(tav)
dim(tav2)
tav2
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(temp2$slbarid, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])]
dimnames(tav2) <- dimnames(cav)
look <- !is.na(cav) & is.na(tav)
!is.na(cav)
is.na(tav)
look <- !is.na(cav) & is.na(tav2)
look
margtot(look)
addmargins(look)
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
addmargins(dont)
dont/(have+dont)
dim(dont)
addmargins(dont)
dim(addmargins(dont))
addmargins(dont)[38, ] / (addmargins(have)[38, ] + addmargins(dont)[38, ])
sort(addmargins(dont)[38, ] / (addmargins(have)[38, ] + addmargins(dont)[38, ]))
dim(dont)
sort(addmargins(dont)[22, ] / (addmargins(have)[22, ] + addmargins(dont)[22, ]))
sort(addmargins(dont)[, 22] / (addmargins(have)[, 22] + addmargins(dont)[, 22]))
head(temp2)
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$barrier.name, barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(temp2$barrier.name, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])]
dimnames(tav2) <- dimnames(cav)
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
addmargins(dont)
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(substring(barrier2$barrier.name, 1, 10), barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(substring(barrier2$barrier.name, 1, 10), temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])]
dimnames(tav2) <- dimnames(cav)
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
addmargins(dont)
dim(dont)
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(substring(barrier2$barrier.name, 1, 15), barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(substring(barrier2$barrier.name, 1, 15), temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])]
dimnames(tav2) <- dimnames(cav)
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
addmargins(dont)
show <- addmargins(dont)
ifelse(show==0, "", "need")
ifelse(show==0, 0, XXX)
ifelse(show==0, 0, 999)
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
show <- addmargins(dont)
show[show==1] <- 99
show
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
show <- addmargins(dont)
show[show==1] <- -99
show
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
show <- addmargins(dont)
show[show==1] <- -909
show
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
show <- addmargins(dont)
show[show==1] <- -999
show
summary(barrier4)
keep <- c("lake.code", "str.code", "str.code.1", "slbarid", "barrier.name", "samples", "avgt", "year", "marday", "tempdelta2")
incomm <- c("lake.code", "slbarid", "barrier.name", "str.code", "year")
barrier3 <- merge(barrier2, temp2[, keep], by.x=c(incomm, "end"), by.y=c(incomm, "marday"), all.x=TRUE)
barrier4 <- merge(barrier3, temp2[, keep], by.x=c(incomm, "start"), by.y=c(incomm, "marday"), all.x=TRUE)
barrier5 <- barrier4[!is.na(barrier4$start) & !is.na(barrier4$avgt.x) & !is.na(barrier4$avgt.y), ]
dim(barrier5)
barrier5
table(barrier5$barrier.name, barrier$year)
table(barrier5$barrier.name, barrier5$year)
addmargins(table(barrier5$barrier.name, barrier5$year))
dput(names(barrier5)
)
head(barrier)
barrier5 <- barrier4[!is.na(barrier4$start) & !is.na(barrier4$avgt.x) & !is.na(barrier4$avgt.y), 
c("lake.code", "slbarid", "barrier.name", "str.code", "str.code.1.x", "lat", "long", "gradient", 
"year", "numdays", "dmean", "dsd", "start", "end", "avgt.x", "tempdelta2.x", "avgt.y", "tempdelta2.y")]
head(barrier5)
barrier5
dim(barrier5)
addmargins(table(barrier5$barrier.name, barrier5$year))
?game
?gam
?lm
fit <- gam(start ~ s(lat) + s(long) + s(gradient) + s(avgt.x) + s(tempdelta2.x), weight=numdays, data=barrier5)
graphics.off(0
graphics.off()
plot(fit)
plot(fit)
summary(fit)
fit <- gam(start ~ s(lat, k=3) + s(long, k=3) + s(gradient, k=3) + s(avgt.x, k=3) + s(tempdelta2.x, k=3), weight=numdays, data=barrier5)
summary(fit)
plot(fit)
fit <- gam(start ~ s(lat, k=4) + s(long, k=4) + s(gradient, k=4) + s(avgt.x, k=4) + s(tempdelta2.x, k=4), weight=numdays, data=barrier5)
summary(fit)
plot(fit)
fit <- gam(start ~ s(lat, k=4) + s(long, k=4) + s(log(gradient), k=4) + s(avgt.x, k=4) + s(tempdelta2.x, k=4), weight=numdays, data=barrier5)
summary(barrier5)
plot(sort(barrier5$gradient))
(sort(barrier5$gradient))
fit <- gam(start ~ s(lat, k=4) + s(long, k=4) + s(log(gradient + 0.01), k=4) + s(avgt.x, k=4) + s(tempdelta2.x, k=4), weight=numdays, data=barrier5)
summary(fit)
plot(fit)
summary(barrier5)
hist(barrier5$avgt.x)
plot(sort(barrier5$avgt.x))
?map
rescale
sclae
search()
ls(6)
colr
?colr
library(plotrix)
rescale
colr
windows()
map(xlim=range(long), ylim=range(lat), type="n")
lines(map5)
points(long, lat, cex=rescale(start, c(0.1, 0.3)), col=colr(start, "blue", "yellow"), lwd=2)
attach(barrier5)
windows()
map(xlim=range(long), ylim=range(lat), type="n")
lines(map5)
points(long, lat, cex=rescale(start, c(0.1, 0.3)), col=colr(start, "blue", "yellow"), lwd=2)
rescale(start, c(0.1, 0.3))
points(long, lat, cex=rescale(start, c(1, 3)), col=colr(start, "blue", "yellow"), lwd=2)
map(xlim=range(long), ylim=range(lat), type="n")
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(1, 3)), col=colr(start, "blue", "yellow"), lwd=2)
map(xlim=range(long), ylim=range(lat), type="n")
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "yellow"), lwd=2)
windows(w=9, h=6.5)
map(xlim=range(long), ylim=range(lat), type="n", par=rep(0, 4))
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "yellow"), lwd=2)
map(xlim=range(long), ylim=range(lat), type="n", mar=rep(0, 4))
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "yellow"), lwd=2)
head(map5)
map(xlim=range(map5$x, na.rm=TRUE), ylim=range(map5$y, na.rm=TRUE), type="n", mar=rep(0, 4))
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "yellow"), lwd=2)
map(xlim=range(map5$x, na.rm=TRUE), ylim=range(map5$y, na.rm=TRUE), type="n", mar=rep(0, 4))
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "cyan"), lwd=2)
fit <- gam(start ~ s(lat) + s(long), weight=numdays, data=barrier5)
summary(fit)
windows(w=9, h=6.5)
map(xlim=range(map5$x, na.rm=TRUE), ylim=range(map5$y, na.rm=TRUE), type="n", mar=rep(0, 4))
lines(map5, col="lightgray")
#points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "cyan"), lwd=2)
points(long, lat, cex=rescale(fit$fitted, c(0.5, 6)), col=colr(fit$fitted, "blue", "cyan"), lwd=2)
show
show
cleanup()
q()
as.Date(paste(1995:2005, "04-27", sep="-")
)
as.Date(paste(1995:2005, "04-27", sep="-"))
library(lubridate)
day(as.Date(paste(1995:2005, "04-27", sep="-")))
?lubridate
wday(as.Date(paste(1995:2005, "04-27", sep="-")))
wday(as.Date(paste(1995:2005, "04-27", sep="-")), TRUE)
d <- as.Date(paste(1995:2005, "04-27", sep="-"))
cbind(d, wday(d, TRUE))
d
data.frame(d, wday(d, TRUE))
q()
Samsmall <- data.frame(Rain=sample(20))
Samsmall$Water_Balance <- NA
Samsmall$Evaporation<-5
# initialization
Samsmall$Water_Balance[1]=0
# loop for calculating water balance for a given dataset
ndays <- nrow(Samsmall)
for (iday in 2:ndays) {
  Samsmall$Water_Balance[iday] <- Samsmall$Water_Balance[iday-1] +
Samsmall$Rain[iday] - Samsmall$Evaporation[iday]
  if (Samsmall$Water_Balance[iday]<0){
    Samsmall$Water_Balance[iday]=0
  }else if(Samsmall$Water_Balance[iday]>100){
    Samsmall$Water_Balance[iday]=100
  }
}
Samsmall
cumsum(Samsmall$Rain) - 5
cumsum(Samsmall$Rain - Samsmall$Evaporation)
# example data
Samsmall <- data.frame(Rain=sample(20), Year=1930, Day=sample(20), Month=rep(1:2, 10))
Samsmall$Evaporation <- 5
# you can vectorize your for loop as follows
Samsmall$Water_Balance <- cumsum(Samsmall$Rain - Samsmall$Evaporation)
Samsmall$Water_Balance[Samsmall$Water_Balance < 0] <- 0
Samsmall$Water_Balance[Samsmall$Water_Balance > 100] <- 100
Samsmall
# example data
Samsmall <- data.frame(Year=1930, Month=rep(1:2, 10), Day=sample(20), Rain=sample(20))
Samsmall$Evaporation <- 5
# you can vectorize your for loop as follows
Samsmall$Water_Balance <- cumsum(Samsmall$Rain - Samsmall$Evaporation)
Samsmall$Water_Balance[Samsmall$Water_Balance < 0] <- 0
Samsmall$Water_Balance[Samsmall$Water_Balance > 100] <- 100
## Table of water balance for a specific year.
require(reshape2)
samsmall30<-subset(Samsmall,Year==1930)
attach(samsmall30)
#produce table with data
sam30<-dcast(samsmall30,Day~Month,value.var="Water_Balance")
#add column names as months
colnames(sam30)[2:13]<-month.abb[1:12]
sam30
?dcast
month.abbr
monthabbr
??month
month.abb
factor(Samsmall$Month, month.abb)
Samsmall
?factor
factor(Samsmall$Month, 1:12, month.abb)
tapply(Samsmall$Water_Balance, list(Samsmall$Day, Samsmall$Mon, Samsmall$Year))
tapply(Samsmall$Water_Balance, list(Samsmall$Day, Samsmall$Mon, Samsmall$Year), mean)
Samsmall$Mon <- factor(Samsmall$Month, 1:12, month.abb)
Samsmall
tapply(Samsmall$Water_Balance, list(Samsmall$Day, Samsmall$Mon, Samsmall$Year), mean)
# Fake data
Samsmall <- data.frame(Year=sample(1930:1033, 20, TRUE), Month=rep(1:2, 10), Day=sample(20), Rain=sample(20))
Samsmall$Evaporation <- 5
Samsmall$Water_Balance <- cumsum(Samsmall$Rain - Samsmall$Evaporation)
Samsmall$Water_Balance[Samsmall$Water_Balance < 0] <- 0
Samsmall$Water_Balance[Samsmall$Water_Balance > 100] <- 100
Samsmall$Mon <- factor(Samsmall$Month, 1:12, month.abb)
tapply(Samsmall$Water_Balance, list(Samsmall$Day, Samsmall$Mon, Samsmall$Year), mean)
# Fake data
Samsmall <- data.frame(Year=sample(1930:1933, 20, TRUE), Month=rep(1:2, 10), Day=sample(20), Rain=sample(20))
Samsmall$Evaporation <- 5
Samsmall$Water_Balance <- cumsum(Samsmall$Rain - Samsmall$Evaporation)
Samsmall$Water_Balance[Samsmall$Water_Balance < 0] <- 0
Samsmall$Water_Balance[Samsmall$Water_Balance > 100] <- 100
Samsmall$Mon <- factor(Samsmall$Month, 1:12, month.abb)
tapply(Samsmall$Water_Balance, list(Samsmall$Day, Samsmall$Mon, Samsmall$Year), mean)
library(dplyr)
i.data2 <- data.frame(sample(1:6, size=484, replace=T)) # simulate data to create a data frame
colnames(i.data2) <- "years.before.initiated" # add a column name
m.data2 <- mutate(i.data2,  years.before.initiated.cat =
                    cut(years.before.initiated, breaks=c(0,1,2,3,4,5,6),include.lowest=TRUE))
                        # create a new variable
g.data2 <- group_by(m.data2, years.before.initiated.cat) # group by years.before.initiated.cat
s.data2 <- summarise(g.data2, anl.count =n() ) # summarize to get the count
rb.data <- rbind(s.data2, c("Total", colSums(s.data2[,2, drop=FALSE]))) # row bind with the column total
rb.data
s.data2
class(s.data2)
dim(s.data2)
addmargins(s.data2)
addmargins
?addmargins
addmargins(s.data2)
addmargins(s.data2, 1)
addmargins(s.data2, 2)
c("Total", colSums(s.data2[,2, drop=FALSE]))
colSums(s.data2[,2, drop=FALSE])
margtot
cleanup()
q()
# C:\JVA\Consult\Stapanian\Amphib\Model selection with AIC.r
# which environmental variables best predict this index of amphibian biotic integrity
# relevant emails:
# 15 May 2013 - https://mail.google.com/mail/u/0/?shva=1#search/amphibian/13ea801401e50a84
#  8 Aug 2013 - https://mail.google.com/mail/u/1/?shva=1#inbox/1405defbc5969b40
# 27 Aug 2013 - https://mail.google.com/mail/u/1/?shva=1#inbox/140c042c5ba851fc
wb <- loadWorkbook("C:/JVA/Consult/Stapanian/Amphib/amphibians_Jean Apr18.xlsx")
dat <- readWorksheet(wb, sheet="Jean")
names(dat) <- make.names(casefold(names(dat)), unique=T, allow_=F)
dimnames(dat)[[1]] <- dat$site.code
rm(wb)
# Analysis 1 should include the following (17) as potential predictors: 
varz1 <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", "water", "forest", "wtld.forest", "wtld.emerg", 
"pasture", "row.crop", "suburban", "transitional", "rock", "urban")
varz1 <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", "water", "forest", "wtld.forest", "wtld.emerg", 
"pasture", "row.crop", "suburban", "transitional", "rock", "urban")
### data exploration ###
attach(dat)
# several variables need to be log transformed
logk <- function(x) {
mx <- min(x, na.rm=TRUE)
if(mx<0) {
x <- x + abs(mx)
mx <- 0
}
k <- min(x[x>0], na.rm=TRUE)/2
print(k)
log(x + min(x[x>0], na.rm=TRUE)/2)
}
tranvar <- logk(as.vector(dat[, c("water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")]))
names(tranvar) <- paste0("log", names(tranvar))
head(tranvar)
dat2 <- cbind(dat, tranvar)
rm(logk, tranvar)
detach(dat)
# Analysis 1 should include the following (17) as potential predictors: 
varz1 <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", "logwater", "logforest", "logwtld.forest", "logwtld.emerg", 
"logpasture", "logrow.crop", "logsuburban", "logtransitional", "logrock", "logurban")
v1namz <- c("ORAM~metric~1", "ORAM~metric~2", "ORAM~metric~3", "ORAM~metric~4", "ORAM~metric~5", "ORAM~metric~6", "OVIBI", 
"LDI[water]", "LDI[forest]", "LDI[wetland~forest]", "LDI[wetland~emergent]", "LDI[pasture]", "LDI[crop]", "LDI[suburban]", "LDI[transitional]", 
"LDI[rock]", "LDI[urban]")
# AbbreviationDescription                                                                             
# LDIwaterProp. standing water                                                              
# LDIforestProp. upland (non-hydric soils) forest                                   
# LDIwetland forestProp. wetland (hydric soils) forest                                         
# LDIwetland emergentProp. wetland dominated by emergent vegetation                
# LDIpastureProp. pasture
# LDIcropProp. agricultural row-crop land
# LDIsuburbanProp. suburban residential
# LDIrockProp. exposed rock substrate
# LDItransitionalProp. land being transitioned to an undefined use
# LDIurbanProp. urban area         
# ORAM metric 1Area (6)                                                                                                            
# ORAM metric 2Upland buffers and surrounding land use (14)
# ORAM metric 3Hydrology (30)          
# ORAM metric 4Habitat Alteration and Development (20)
# ORAM metric 5Special wetlands (10)
# ORAM metric 6Plant communities, interspersion, and microtopography (20)            
# OVIBI10 metrics describing wetland vegetation quality (100)
# get rid of four variables with few unique values
# metric5 (with 3 unique values), logtransitional (with 4), and metric1 and logrock (each with 6).
rid <- c(5, 15, 1, 16)
varz1 <- varz1[-rid]
v1namz <- v1namz[-rid]
attach(dat2)
ct <- t(
sapply(varz1, function(x) {
ct <- cor.test(dat2[, x], amphibi)
ctp <- ct$p.value
ctr <- as.vector(ct$estimate)
c(p=ctp, r=ctr)
})
)
title <- ifelse(ct[, "p"] < 0.05/length(varz1), paste0("bold('*'~", v1namz, ")"), v1namz)
windows(h=8, w=5.5)
#par(mfcol=c(6, 3), mar=c(2.5, 2, 1.5, 1), oma=c(0, 2.5, 0, 0), las=1, cex=0.7)
par(mfcol=c(5, 3), mar=c(2.5, 2, 1.5, 1), oma=c(0, 2.5, 0, 0), las=1, cex=0.7)
for(i in rev(order(ct[, "r"]))) plot(dat2[, varz1[i]], amphibi, xlab="", ylab="", main=as.expression(parse(text=title[i])))
mtext("AmphIBI", side=2, outer=TRUE, las=0, line=1)
suv <- sort(unique(veg.class))
windows(h=6.5, w=6.5)
map("state", mar=c(1, 1, 1, 1), region= "ohio", col="darkgray", lwd=2)
for(i in seq(suv)) {
sel <- veg.class==suv[i]
points(lon.dd[sel], lat.dd[sel], cex=2, lwd=2, pch=c(2, 1)[i], col=c("black", "gray")[i])
}
legend("bottomright", capwords(suv), pch=c(2, 1), col=c("black", "gray"), pt.lwd=2, pt.cex=2, cex=1.15, title="Veg. Class")
par(usr=c(-126, 94, 21, 193), xpd=NA)
polygon(c(-128, -128, -64, -64, -128), c(22, 52, 52, 22, 22), col="white", lwd=2)
map("state", add=T, mar=c(0, 0, 0, 0)) 
map("state", region="ohio", fill=T, add=T) 
detach(dat2)
rm(suv, i, sel, title)
round(ct[rev(order(ct[, "r"])), ], 4)
0.05/length(varz1)
# C:\JVA\Consult\Stapanian\AmphibSens\Explore v3.r
# relevant emails:
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/1439c3834064343b
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/143baffe32131385
# 13 Mar 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/144bb971f5eca226
# objectives
# Find the best predictive model of the following responses
# using as independent variables the 6 ORAM metrics, OVIBI score, and the 10 LDI metrics.
# 1. number of salamander species (x.ssp) 
# 2. % sensitive species (x.sen)
# 3. % tolerant species (x.ol)
# 4. Amphibian Quality Assessment Index (aqai)
# 5. presence/absence of [wood frogs or spotted salamanders] (spot.wdscore, binary)
plotimp <- function(rpartfit, ordered=TRUE, plot=TRUE, horiz=TRUE, col=colz[ord], xlab="", las=1, ...) {
# calculate importance of variables
# http://cran.at.r-project.org/web/packages/rpart/vignettes/longintro.pdf
# importance = An overall measure of variable importance is the sum of the goodness of split
# measures for each split for which it was the primary variable, plus goodness * (adjusted
# agreement) for all splits in which it was a surrogate.
# I scaled them to sum to 100
imp <- rpartfit$variable.importance
xvars <- attr(fit$terms, "term.labels")
implong <- imp[match(xvars, names(imp))]
names(implong) <- xvars
implong[is.na(implong)] <- 0
implong <- 100*implong/sum(implong)
if(ordered) {
ord <- order(implong)
} else {
ord <- rev(seq(implong))
}
if(plot) {
colz <- colr(seq(implong), "yellow", "blue")
barplot(implong[ord], horiz=horiz, col=col, xlab=xlab, las=las, ...)
}
implong
}
library(plotrix)
library(rpart)
wb <- loadWorkbook("C:/JVA/Consult/Stapanian/AmphibSens/amphibians_13FEB2014.xlsx")
dat <- readWorksheet(wb, sheet="Jean2")
names(dat) <- make.names(casefold(names(dat)), unique=T, allow_=F)
dat$spotwdn <- dat$spot.wdscore/10
dat$spotwdf <- as.factor(dat$spot.wdscore)
responsesn <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdn")
responses <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdf")
respnames <- c("Salamanders (# species)", "Sensitive  (% species)", "Tolerant  (% species)", "Amphibian Quality Assessment Index", 
"Presence of Wood F. or Spotted S.")
indeps <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", 
"water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")
indnames <- c("Oram 1", "Oram 2", "Oram 3", "Oram 4", "Oram 5", "Oram 6", "OVIBI", 
"LDI water", "LDI forest", "LDI wet. forest", "LDI wet. emergent", 
"LDI pasture", "LDI crop", "LDI suburban", "LDI transitional", "LDI rock", 
"LDI urban")
# other varz ... c("site.code", "ldi..1km.", "x.tolscore", "x.senscore")
# just for grins, develop one Y variable that encompasses all of the responses
pca <- princomp(dat[, responsesn], cor=TRUE)
Y <- pca$scores[, 1]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i])
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
saveimp[rev(order(apply(saveimp, 1, mean))), ]
x <- dat[, indeps]
y <- dat[, responsesn]
candidates <- list(c("metric4", "vibi.score"), 
c("metric4", "vibi.score"), 
c("metric4", "metric2"),
c("metric4", "metric3"),
c("metric4", "row.crop"))
# fit linear regression to the candidates variables
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
}
print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
chosen <- list(c("metric4", "vibi.score"), 
c("metric4"), 
c("metric4"),
c("metric4"),
c("metric4"))
# visualize the chosen variables
colz <- c("blue", "orange")
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 0, 0, 0))
for(i in (seq(responsesn))) {
if(i==1) {
plot(dat$metric4, y[, i], type="n", xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
for(j in 1:2) {
sel <- (dat$vibi.score < 60) == c(TRUE, FALSE)[j]
mycol <- colz[j]
points(dat$metric4[sel], jitter(y[sel, i]), cex=1.5, col=mycol)
lines(loess.smooth(dat$metric4[sel], y[sel, i], span=1, degree=2), col=mycol, lwd=2)
}
legend("topleft", paste("OVIBI", c("<", "\U2265"), "60"), col=colz, lwd=2)
} else {
if(i == 5) {
yy <- as.numeric(y[, i])-1
plot(dat$metric4, jitter(yy, factor=0.2), xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, yy, span=1, degree=2), lwd=2)
} else {
plot(dat$metric4, y[, i], xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, y[, i], span=1, degree=2), lwd=2)
}
}
}
mtext("ORAM 4", side=1, outer=TRUE, line=0.5)
dat[order(dat$metric4, Y), c("site.code", "metric4", "vibi.score", responses)]
fit
fit$terms
attr(fit$terms, "term.labels")
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray")
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
saveimp[rev(order(apply(saveimp, 1, mean))), ]
?barplot
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=indnames)
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
responsesn <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdn")
responses <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdf")
respnames <- c("Salamanders (# species)", "Sensitive  (% species)", "Tolerant  (% species)", "Amphibian Quality Assessment Index", 
"Presence of Wood F. or Spotted S.")
indeps <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", 
"water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")
indnames <- c("Oram 1", "Oram 2", "Oram 3", "Oram 4", "Oram 5", "Oram 6", "OVIBI", 
"LDI water", "LDI forest", "LDI wet. forest", "LDI wet. emergent", 
"LDI pasture", "LDI crop", "LDI suburban", "LDI transitional", "LDI rock", 
"LDI urban")
notthese <- c(1, 5, 15, 16)
indeps <- indeps[-notthese]
indnames <- indnames[-notthese]
# other varz ... c("site.code", "ldi..1km.", "x.tolscore", "x.senscore")
# just for grins, develop one Y variable that encompasses all of the responses
pca <- princomp(dat[, responsesn], cor=TRUE)
Y <- pca$scores[, 1]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=indnames)
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
saveimp[rev(order(apply(saveimp, 1, mean))), ]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=rev(indnames))
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
# C:\JVA\Consult\Stapanian\AmphibSens\Explore v3.r
# relevant emails:
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/1439c3834064343b
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/143baffe32131385
# 13 Mar 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/144bb971f5eca226
# objectives
# Find the best predictive model of the following responses
# using as independent variables the 6 ORAM metrics, OVIBI score, and the 10 LDI metrics.
# 1. number of salamander species (x.ssp) 
# 2. % sensitive species (x.sen)
# 3. % tolerant species (x.ol)
# 4. Amphibian Quality Assessment Index (aqai)
# 5. presence/absence of [wood frogs or spotted salamanders] (spot.wdscore, binary)
plotimp <- function(rpartfit, ordered=TRUE, plot=TRUE, horiz=TRUE, col=colz[ord], xlab="", las=1, ...) {
# calculate importance of variables
# http://cran.at.r-project.org/web/packages/rpart/vignettes/longintro.pdf
# importance = An overall measure of variable importance is the sum of the goodness of split
# measures for each split for which it was the primary variable, plus goodness * (adjusted
# agreement) for all splits in which it was a surrogate.
# I scaled them to sum to 100
imp <- rpartfit$variable.importance
xvars <- attr(fit$terms, "term.labels")
implong <- imp[match(xvars, names(imp))]
names(implong) <- xvars
implong[is.na(implong)] <- 0
implong <- 100*implong/sum(implong)
if(ordered) {
ord <- order(implong)
} else {
ord <- rev(seq(implong))
}
if(plot) {
colz <- colr(seq(implong), "yellow", "blue")
barplot(implong[ord], horiz=horiz, col=col, xlab=xlab, las=las, ...)
}
implong
}
library(plotrix)
library(rpart)
wb <- loadWorkbook("C:/JVA/Consult/Stapanian/AmphibSens/amphibians_13FEB2014.xlsx")
dat <- readWorksheet(wb, sheet="Jean2")
names(dat) <- make.names(casefold(names(dat)), unique=T, allow_=F)
dat$spotwdn <- dat$spot.wdscore/10
dat$spotwdf <- as.factor(dat$spot.wdscore)
responsesn <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdn")
responses <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdf")
respnames <- c("Salamanders (# species)", "Sensitive  (% species)", "Tolerant  (% species)", "Amphibian Quality Assessment Index", 
"Presence of Wood F. or Spotted S.")
indeps <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", 
"water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")
indnames <- c("ORAM 1", "ORAM 2", "ORAM 3", "ORAM 4", "ORAM 5", "ORAM 6", "OVIBI", 
"LDI water", "LDI forest", "LDI wet. forest", "LDI wet. emergent", 
"LDI pasture", "LDI crop", "LDI suburban", "LDI transitional", "LDI rock", 
"LDI urban")
notthese <- c(1, 5, 15, 16)
indeps <- indeps[-notthese]
indnames <- indnames[-notthese]
# other varz ... c("site.code", "ldi..1km.", "x.tolscore", "x.senscore")
# just for grins, develop one Y variable that encompasses all of the responses
pca <- princomp(dat[, responsesn], cor=TRUE)
Y <- pca$scores[, 1]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
### FIGURE 2 ###
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=rev(indnames))
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
par(mar=c(3, 8, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=rev(indnames))
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
responsesn <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdn")
responses <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdf")
respnames <- c("Salamanders (# species)", "Sensitive  (% species)", "Tolerant  (% species)", "Amphibian Quality Assessment Index", 
"Presence of Wood F. or Spotted S.")
respnames <- c("Pond-Breeding", "% Sensitive", "% Tolerant", "Amphibian QAI", "Presence of SS/WF")
indeps <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", 
"water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")
indnames <- c("ORAM 1", "ORAM 2", "ORAM 3", "ORAM 4", "ORAM 5", "ORAM 6", "OVIBI", 
"LDI water", "LDI forest", "LDI wet. forest", "LDI wet. emergent", 
"LDI pasture", "LDI crop", "LDI suburban", "LDI transitional", "LDI rock", 
"LDI urban")
notthese <- c(1, 5, 15, 16)
indeps <- indeps[-notthese]
indnames <- indnames[-notthese]
# other varz ... c("site.code", "ldi..1km.", "x.tolscore", "x.senscore")
# just for grins, develop one Y variable that encompasses all of the responses
pca <- princomp(dat[, responsesn], cor=TRUE)
Y <- pca$scores[, 1]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
### FIGURE 2 ###
windows(h=8, w=6.5)
par(mar=c(3, 8, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=rev(indnames))
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
saveimp[rev(order(apply(saveimp, 1, mean))), ]
x <- dat[, indeps]
y <- dat[, responsesn]
candidates <- list(c("metric4", "vibi.score"), 
c("metric4", "vibi.score"), 
c("metric4", "metric2"),
c("metric4", "metric3"),
c("metric4", "row.crop"))
# fit linear regression to the candidates variables
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
}
print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
chosen <- list(c("metric4", "vibi.score"), 
c("metric4"), 
c("metric4"),
c("metric4"),
c("metric4"))
# visualize the chosen variables
colz <- c("blue", "orange")
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 0, 0, 0))
for(i in (seq(responsesn))) {
if(i==1) {
plot(dat$metric4, y[, i], type="n", xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
for(j in 1:2) {
sel <- (dat$vibi.score < 60) == c(TRUE, FALSE)[j]
mycol <- colz[j]
points(dat$metric4[sel], jitter(y[sel, i]), cex=1.5, col=mycol)
lines(loess.smooth(dat$metric4[sel], y[sel, i], span=1, degree=2), col=mycol, lwd=2)
}
legend("topleft", paste("OVIBI", c("<", "\U2265"), "60"), col=colz, lwd=2)
} else {
if(i == 5) {
yy <- as.numeric(y[, i])-1
plot(dat$metric4, jitter(yy, factor=0.2), xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, yy, span=1, degree=2), lwd=2)
} else {
plot(dat$metric4, y[, i], xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, y[, i], span=1, degree=2), lwd=2)
}
}
}
mtext("ORAM 4", side=1, outer=TRUE, line=0.5)
# visualize the chosen variables
colz <- c("blue", "orange")
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 0, 0, 0))
for(i in (seq(responsesn))) {
if(i==1) {
plot(dat$metric4, y[, i], type="n", xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
for(j in 1:2) {
sel <- (dat$vibi.score < 60) == c(TRUE, FALSE)[j]
mycol <- colz[j]
points(dat$metric4[sel], jitter(y[sel, i]), cex=1.5, col=mycol, pch=j)
lines(loess.smooth(dat$metric4[sel], y[sel, i], span=1, degree=2), col=mycol, lwd=2)
}
legend("topleft", paste("OVIBI", c("<", "\U2265"), "60"), col=colz, lwd=2)
} else {
if(i == 5) {
yy <- as.numeric(y[, i])-1
plot(dat$metric4, jitter(yy, factor=0.2), xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, yy, span=1, degree=2), lwd=2)
} else {
plot(dat$metric4, y[, i], xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, y[, i], span=1, degree=2), lwd=2)
}
}
}
mtext("ORAM 4", side=1, outer=TRUE, line=0.5)
dat[order(dat$metric4, Y), c("site.code", "metric4", "vibi.score", responses)]
graphics.off()
head(dat)
head(dat)
dat[order(dat$metric4, Y), c("site.code", "metric4", "vibi.score", responses)]
?cor
?cor.test
?corr.test
utils:::menuInstallPkgs()
library(psych)
?corr.test
corr.test(dat[, c("metric3", "metric4")], dat[, c("x.ssp", "x.sen")], adjust="non")
corr.test(dat[, c("metric3", "metric4")], dat[, c("x.ssp", "x.sen")], adjust="none")
corr.test(dat[, c("metric3", "metric4")], dat[, c("x.ssp", "x.sen")], adjust="bonferroni")
corm <- corr.test(dat[, c("metric3", "metric4")], dat[, c("x.ssp", "x.sen")], adjust="none")
corm
print(corm)
print(corm, short=FALSE)
names(corm)
names(print(corm, short=FALSE))
corm$r
corm$p
cbind(corm$r, corm$p)
corm <- corr.test(dat[, c("metric3", "metric4")], dat[, c("x.ssp", "x.sen")], adjust="none")
ncolz <- dim(corm$r)[[2]]
cbind(corm$r, corm$p)[, rep(1:ncolz, rep(2, ncolz))]
corm <- corr.test(dat[, indeps], dat[, responses[-5]], adjust="none")
ncolz <- dim(corm$r)[[2]]
cbind(corm$r, corm$p)[, rep(1:ncolz, rep(2, ncolz))]
round(cbind(corm$r, corm$p)[, rep(1:ncolz, rep(2, ncolz))])
round(cbind(corm$r, corm$p)[, rep(1:ncolz, rep(2, ncolz))], 2)
rep(1:ncolz, rep(2, ncolz))
c(1:ncolz, ncolz+(1:ncolz))
dim(corm)
corm
dim(corm$r)
ncolz
1:2*ncolz
1:(2*ncolz)
matrix(1:(2*ncolz), nrow=2)
unlist(matrix(1:(2*ncolz), nrow=2))
as.vector(matrix(1:(2*ncolz), nrow=2))
as.vector(matrix(1:(2*ncolz), nrow=2, byrow=TRUE))
corm <- corr.test(dat[, indeps], dat[, responses[-5]], adjust="none")
ncolz <- dim(corm$r)[[2]]
cbind(corm$r, corm$p)[, as.vector(matrix(1:(2*ncolz), nrow=2, byrow=TRUE))]
round(cbind(corm$r, corm$p)[, as.vector(matrix(1:(2*ncolz), nrow=2, byrow=TRUE))], 2)
cleanup()
q()
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("jvamisc")
setwd("C:/JVA/R/Working Directory")
library(jvamisc)
?plotcor
?capwords
# example using a symmetric matrix
sr <- cor(swiss)
sord <- plotcor(sr)
sr[sord[[1]], sord[[2]]]
# example using an asymmetric matrix
lr <- cor(longley)[1:3, 4:7]
lord <- plotcor(lr)
lr[lord[[1]], lord[[2]]]
sord <- plotcor(sr)
capwords(c("using AIC for model selection"))
capwords(c("using AIC", "for MODEL selection"), strict=FALSE)
cleanup()
# C:\JVA\Consult\Stapanian\AmphibSens\Explore v3.r
# relevant emails:
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/1439c3834064343b
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/143baffe32131385
# 13 Mar 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/144bb971f5eca226
# objectives
# Find the best predictive model of the following responses
# using as independent variables the 6 ORAM metrics, OVIBI score, and the 10 LDI metrics.
# 1. number of salamander species (x.ssp) 
# 2. % sensitive species (x.sen)
# 3. % tolerant species (x.ol)
# 4. Amphibian Quality Assessment Index (aqai)
# 5. presence/absence of [wood frogs or spotted salamanders] (spot.wdscore, binary)
plotimp <- function(rpartfit, ordered=TRUE, plot=TRUE, horiz=TRUE, col=colz[ord], xlab="", las=1, ...) {
# calculate importance of variables
# http://cran.at.r-project.org/web/packages/rpart/vignettes/longintro.pdf
# importance = An overall measure of variable importance is the sum of the goodness of split
# measures for each split for which it was the primary variable, plus goodness * (adjusted
# agreement) for all splits in which it was a surrogate.
# I scaled them to sum to 100
imp <- rpartfit$variable.importance
xvars <- attr(fit$terms, "term.labels")
implong <- imp[match(xvars, names(imp))]
names(implong) <- xvars
implong[is.na(implong)] <- 0
implong <- 100*implong/sum(implong)
if(ordered) {
ord <- order(implong)
} else {
ord <- rev(seq(implong))
}
if(plot) {
colz <- colr(seq(implong), "yellow", "blue")
barplot(implong[ord], horiz=horiz, col=col, xlab=xlab, las=las, ...)
}
implong
}
library(plotrix)
library(rpart)
wb <- loadWorkbook("C:/JVA/Consult/Stapanian/AmphibSens/amphibians_13FEB2014.xlsx")
dat <- readWorksheet(wb, sheet="Jean2")
names(dat) <- make.names(casefold(names(dat)), unique=T, allow_=F)
dat$spotwdn <- dat$spot.wdscore/10
dat$spotwdf <- as.factor(dat$spot.wdscore)
responsesn <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdn")
responses <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdf")
respnames <- c("Salamanders (# species)", "Sensitive  (% species)", "Tolerant  (% species)", "Amphibian Quality Assessment Index", 
"Presence of Wood F. or Spotted S.")
respnames <- c("Pond-Breeding", "% Sensitive", "% Tolerant", "Amphibian QAI", "Presence of SS/WF")
indeps <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", 
"water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")
indnames <- c("ORAM 1", "ORAM 2", "ORAM 3", "ORAM 4", "ORAM 5", "ORAM 6", "OVIBI", 
"LDI water", "LDI forest", "LDI wet. forest", "LDI wet. emergent", 
"LDI pasture", "LDI crop", "LDI suburban", "LDI transitional", "LDI rock", 
"LDI urban")
notthese <- c(1, 5, 15, 16)
indeps <- indeps[-notthese]
indnames <- indnames[-notthese]
# other varz ... c("site.code", "ldi..1km.", "x.tolscore", "x.senscore")
# just for grins, develop one Y variable that encompasses all of the responses
pca <- princomp(dat[, responsesn], cor=TRUE)
Y <- pca$scores[, 1]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
### FIGURE 2 ###
windows(h=8, w=6.5)
par(mar=c(3, 8, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=rev(indnames))
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
saveimp[rev(order(apply(saveimp, 1, mean))), ]
x <- dat[, indeps]
y <- dat[, responsesn]
candidates <- list(c("metric4", "vibi.score"), 
c("metric4", "vibi.score"), 
c("metric4", "metric2"),
c("metric4", "metric3"),
c("metric4", "row.crop"))
# fit linear regression to the candidates variables
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
}
print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
chosen <- list(c("metric4", "vibi.score"), 
c("metric4"), 
c("metric4"),
c("metric4"),
c("metric4"))
# visualize the chosen variables
colz <- c("blue", "orange")
### FIGURE 3 ###
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 0, 0, 0))
for(i in (seq(responsesn))) {
if(i==1) {
plot(dat$metric4, y[, i], type="n", xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
for(j in 1:2) {
sel <- (dat$vibi.score < 60) == c(TRUE, FALSE)[j]
mycol <- colz[j]
points(dat$metric4[sel], jitter(y[sel, i]), cex=1.5, col=mycol, pch=j)
lines(loess.smooth(dat$metric4[sel], y[sel, i], span=1, degree=2), col=mycol, lwd=2)
}
legend("topleft", paste("OVIBI", c("<", "\U2265"), "60"), col=colz, lwd=2)
} else {
if(i == 5) {
yy <- as.numeric(y[, i])-1
plot(dat$metric4, jitter(yy, factor=0.2), xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, yy, span=1, degree=2), lwd=2)
} else {
plot(dat$metric4, y[, i], xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, y[, i], span=1, degree=2), lwd=2)
}
}
}
mtext("ORAM 4", side=1, outer=TRUE, line=0.5)
dat[order(dat$metric4, Y), c("site.code", "metric4", "vibi.score", responses)]
library(psych)
corm <- corr.test(dat[, indeps], dat[, responses[-5]], adjust="none")
ncolz <- dim(corm$r)[[2]]
cbind(corm$r, corm$p)[, as.vector(matrix(1:(2*ncolz), nrow=2, byrow=TRUE))]
windows(h=9, w=4.3)
ordz <- plotcor(corm$r, mar=c(0.1, 6, 4, 0.1))
corm$r[ordz[[1]], ordz[[2]]]
ordz <- plotcor(corm$r, mar=c(0.1, 6, 4, 0.1), atcex=0.5)
ordz <- plotcor(corm$r, mar=c(0.1, 6, 4, 0.1), atcex=1)
ordz <- plotcor(corm$r, mar=c(0.1, 6, 4, 0.1), atcex=.9)
r <- corm$r
dimnames(r) <- list(indnames, respnames[-5])
windows(h=9, w=4.3)
ordz <- plotcor(r, mar=c(0.1, 6, 4, 0.1), atcex=.9)
r[ordz[[1]], ordz[[2]]]
r <- corm$r
dimnames(r) <- list(indnames, respnames[-5])
windows(h=9, w=4.3)
ordz <- plotcor(r, mar=c(0.1, 8, 8, 0.1), atcex=.9)
r[ordz[[1]], ordz[[2]]]
cite(rpart)
cite("rpart")
citation("rpart")
3520-37-800
?plotcor
plotcor(cor(mtcars))
plotcor(cor(mtcars))
plotcor(cor(mtcars), mar=c(0.1, 3, 3, 0.1))
plotcor(cor(mtcars), mar=c(0.1, 4, 4, 0.1))
plotcorr
plotcor
cleanup()
search()
detach(5)
search()
url("https://github.com/JVAdams/jvamisc/blob/master/R/plotcor.r") 
ls()
a <- url("https://github.com/JVAdams/jvamisc/blob/master/R/plotcor.r") 
a
?url
?source
source("https://github.com/JVAdams/jvamisc/blob/master/R/plotcor.r") 
library(devtools)
source_url("https://github.com/JVAdams/jvamisc/blob/master/R/plotcor.r")
?source_url
ls()
source_url("https://gist.github.com/hadley/6872663/raw/hi.r")
cleanup()
library(jvamisc)
cleanup()
q()
walker <- 581
burke <- 497
n <- walker+burke
nsim <- 100
res <- rep(NA, nsim)
for(i in 1:nsim) {
res[i] <- sum(sample(0:1, n, TRUE))
}
res
hist(res)
hist(res)
abline(v=c(walker, burke), col="red")
hist(res/n)
abline(v=c(walker, burke)/n, col="red")
nsim <- 10000
res <- rep(NA, nsim)
for(i in 1:nsim) {
res[i] <- sum(sample(0:1, n, TRUE))
}
hist(res/n, nclass=25)
abline(v=c(walker, burke)/n, col="red")
table(res<burke)
mean(table(res<burke))
mean(res<burke)
nsim <- 100
res <- rep(NA, nsim)
for(i in 1:nsim) {
res[i] <- sum(sample(0:1, n, TRUE, prob=c(burke, walker)/n))
}
hist(res/n, nclass=25)
hist(res/n, nclass=25)
abline(v=0.5, col="red")
mean(res < 0.5)
nsim <- 10000
res <- rep(NA, nsim)
for(i in 1:nsim) {
res[i] <- sum(sample(0:1, n, TRUE, prob=c(burke, walker)/n))
}
hist(res/n, nclass=25)
abline(v=0.5, col="red")
mean(res < 0.5)
res < 0.5
sum(res < 0.5)
mean(res < 0.5*n)
q()
orderedx <- c(1, 1, 1, 1, 2, 6, 9, 100, 100, 100)
extremes=c(0, 100)
nconsec=2
his <- orderedx==extremes[2]
his
cumsum(his)
cumsum(his) > nconsec
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- cumsum(lo) <= nconsec
selnoh
selnohi
selnolo
lo
orderedx==extremes[1]
orderedx
orderedx <- c(0, 0, 0, 0, 2, 6, 9, 100, 100, 100)
extremes=c(0, 100)
nconsec=2
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- cumsum(lo) <= nconsec
lo
selnolo
keeponly <- function(orderedx, extremes=c(0, 100), nconsec=2) {
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- rev(cumsum(lo) <= nconsec)
selnolo & selnohi
}
keeponly(c(0, 0, 0, 0, 2, 6, 9, 100, 100, 100))
keeponly(c(0, 0, 2, 6, 9, 100, 100, 100))
cleanup()
# C:\JVA\Lamprey\ChemControl\Toxicity\LWCode.r - estimation of LC99.9 using automated Litchfield Wilcoxon (1959)
library(mgcv)
library(MASS)
library(tcltk)
###  functions  ###################################################################################################
probit <- function(prob) qnorm(prob)
inv.probit <- function(quan) pnorm(quan)
keeponly <- function(orderedx, extremes=c(0, 100), nconsec=2) {
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- rev(cumsum(lo) <= nconsec)
selnolo & selnohi
}
# corrected values from Litchfield and Wilcoxon Table 1
expected <- 1:49
corrected <- c(0.3, 0.7, 1.0, 1.3, 1.6, 2.0, 2.3, 2.6, 2.9, 3.2, 3.5, 3.8, 4.1, 4.4, 4.7, 4.9, 5.2, 5.5, 5.7, 6.0, 
6.2, 6.5, 6.7, 7.0, 7.2, 7.4, 7.6, 7.8, 8.1, 8.3, 8.4, 8.6, 8.8, 9.0, 9.2, 9.3, 9.5, 9.6, 9.8, 9.9, 10.0, 10.1, 
10.2, 10.3, 10.3, 10.4, 10.4, 10.4, 10.5)
expected.dif.5 <- abs(0.50 - expected/100)
correction <- corrected/100
fit.table1 <- gam(correction ~ s(expected.dif.5))
fill <- function (x) 
{
    y <- x
    last <- x[1]
    if (is.character(x)) {
        for (i in 2:length(x)) if (x[i] == "" | is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    else {
        for (i in 2:length(x)) if (is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    y
}
correct.val <- function(val) {
# given a value between 0 and 1, calculate a corrected value from Litchfield and Wilcoxon Table 1
correction <- predict(fit.table1, data.frame(expected.dif.5 = abs(0.5 - val)))
result1 <- ifelse(val < 0.5, correction, 1-correction)
result2 <- ifelse(val >= 0.01 & val <= 0.99, result1, val)
result2
}
rm(expected, corrected, expected.dif.5, correction)
chi.prop <- function(obs.prop, exp.prop, n) {
# chi squared value from observed and expected proportions and n
sum(n * (obs.prop - exp.prop)^2 / (exp.prop * (1 - exp.prop)))
}
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
y
}
startvals <- function(data) {
# define log10(lc50) and log10(lc999) starting values
fit <- lm(y ~ x, data=data)
lc50.1 <- -fit$coef[1]/fit$coef[2]
lc999.1 <- (probit(0.999) - fit$coef[1])/fit$coef[2]
sv <- c(lc50.1, lc999.1)
p <- pchi.from.LC(x=sv, data=data, list=F)
list(sv=sv, p=p)
}
LC <- function(pct, b0=int, b1=slope) {
as.numeric(10^( (probit(pct/100) - b0) / b1 ))
}
rawdat <- read.csv(C:/JVA/Lamprey/ChemControl/Toxicity/RawToxTestData424and501.csv, as.is=TRUE)
rawdat2 <- data.frame(lapply(rawdat, fill))
sut <- sort(unique(rawdat2$Test.ID))
i <- 1
sel <- rawdat2$Test.ID==sut[i]
dose=rawdat2$TFM.Conc...mg.L.[sel]
ndead=rawdat2$No..Dead[sel]
ntot=rawdat2$No..Tested[sel]
description=with(rawdat2[sel, ], paste(Test.ID, Source, Batch, Species))[1]
rawdat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/RawToxTestData424and501.csv", as.is=TRUE)
rawdat2 <- data.frame(lapply(rawdat, fill))
sut <- sort(unique(rawdat2$Test.ID))
i <- 1
sel <- rawdat2$Test.ID==sut[i]
dose=rawdat2$TFM.Conc...mg.L.[sel]
ndead=rawdat2$No..Dead[sel]
ntot=rawdat2$No..Tested[sel]
description=with(rawdat2[sel, ], paste(Test.ID, Source, Batch, Species))[1]
### A. The data and graph.
# A 1. Don't list > 2 consecutive 100% effects at the upper end or > 2 consecutive 0% effects at the lower end.
df <- data.frame(dose=dose, ndead=ndead, ntot=ntot)
df$nalive <- df$ntot - df$ndead
df$pdead <- df$ndead/df$ntot
df <- df[order(df$dose, df$pdead), ]
# get rid of any zero dosages (controls)
df <- df[df$dose > 0, ]
# get rid of consecutives ...
df2 <- df[keeponly(df$pdead), ]
# define three mortality categories, 0 for no dead, 100 for all dead, and 50 from any proportional mortality
df2$mcat <- rep(50, length(df2$pdead))
df2$mcat[df2$ntot==df2$nalive] <- 0
df2$mcat[df2$ntot==df2$ndead] <- 100
(var(df2$mcat) < 0.00000001 & df2$mcat[1] != 50) | dim(df2)[1] < 3)
(var(df2$mcat) < 0.00000001 & df2$mcat[1] != 50) | dim(df2)[1] < 3
# A 2. Plot doses against % effect on logarithmic-probability paper
df2$x <- log10(df2$dose)
df2$y <- probit(df2$pdead)
yr <- probit(c(0.001, 0.999))
df2$y[df2$pdead==0] <- yr[1]
df2$y[df2$pdead==1] <- yr[2]
# calculate starting values
pms <- sum(df2$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
df3 <- df2[df2$mcat==50, ]
svp <- startvals(df3)
}
# fit line to partial mortalities with last 0% and first 100%
if(pms==1 | is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][sum(df2$mcat==0), ], df2[df2$mcat==50, ], df2[df2$mcat==100, ][1, ])
svp <- startvals(df3)
}
# fit line to all the data
if(pms < 1 | is.na(svp$p)) {
svp <- startvals(df2)
}
# fit line to first 0% and last 100% alone
if(is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][1, ], df2[df2$mcat==100, ][sum(df2$mcat==100), ])
svp <- startvals(df3)
}
# B. 1., B. 2., and C. are all inside the function pchi.from.LC()
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
# C. The chi squared test
# find the LC50 and LC999 (on the log10 scale) that give the lowest p value for the chi-square
bestLC <- optim(par=svp$sv, fn=pchi.from.LC, data=df2)
estLCs <- bestLC$par
chi <- pchi.from.LC(estLCs, data=df2, list=T)
if(!is.na(chi$p) & chi$p < 0.05) print("Chi squared test indicates poor fit.")
rm(pms, svp, df3, bestLC)
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
LC25 <- LC(25)
LC50 <- LC(50)
LC50
as.numeric(10^estLCs[1])
N' <- 3
ls()
# L-W
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
# D. 1. Read from the line on the graph the dose for 16, 50, and 84% effects
LC16 <- LC(16)
LC50 <- LC(50) # same as 10^estLCs[1]
LC84 <- LC(84)
# D. 2. Calculate the slope function, S
S <- (LC84/LC50 + LC50/LC16) / 2
# D. 3. Obtain Nprime, the total number of animals tested at those doses with expected effects
LC84
df
df2
df2$dose > LC18 & df2$dose < LC84
df2$dose > LC16 & df2$dose < LC84
df2$ntot[df2$dose > LC16 & df2$dose < LC84]
sum(df2$ntot[df2$dose > LC16 & df2$dose < LC84])
=19/20
19/20
Nprime <- sum(df2$ntot[df2$dose > LC16 & df2$dose < LC84])
# D. 4. Calculate S to the exponent for the LC50
f50 <- S^(2.77/sqrt(Nprime))
# D. 5. Calculate the 95% confidence limits of the LC50 as
upper50 <- LC50 * f50
lower50 <- LC50 / f50
LC50
lower50
upper50
df2
rawdat
cleanup()
rawdat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/RawToxTestData424and501.csv", as.is=TRUE)
rawdat2 <- data.frame(lapply(rawdat, fill))
sut <- sort(unique(rawdat2$Test.ID))
sel <- rawdat2$Test.ID==4
dose=rawdat2$TFM.Conc...mg.L.[sel]
ndead=rawdat2$No..Dead[sel]
ntot=rawdat2$No..Tested[sel]
description=with(rawdat2[sel, ], paste(Test.ID, Source, Batch, Species))[1]
library(mgcv)
library(MASS)
library(tcltk)
###  functions  ###################################################################################################
probit <- function(prob) qnorm(prob)
inv.probit <- function(quan) pnorm(quan)
keeponly <- function(orderedx, extremes=c(0, 100), nconsec=2) {
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- rev(cumsum(lo) <= nconsec)
selnolo & selnohi
}
# corrected values from Litchfield and Wilcoxon Table 1
expected <- 1:49
corrected <- c(0.3, 0.7, 1.0, 1.3, 1.6, 2.0, 2.3, 2.6, 2.9, 3.2, 3.5, 3.8, 4.1, 4.4, 4.7, 4.9, 5.2, 5.5, 5.7, 6.0, 
6.2, 6.5, 6.7, 7.0, 7.2, 7.4, 7.6, 7.8, 8.1, 8.3, 8.4, 8.6, 8.8, 9.0, 9.2, 9.3, 9.5, 9.6, 9.8, 9.9, 10.0, 10.1, 
10.2, 10.3, 10.3, 10.4, 10.4, 10.4, 10.5)
expected.dif.5 <- abs(0.50 - expected/100)
correction <- corrected/100
fit.table1 <- gam(correction ~ s(expected.dif.5))
fill <- function (x) 
{
    y <- x
    last <- x[1]
    if (is.character(x)) {
        for (i in 2:length(x)) if (x[i] == "" | is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    else {
        for (i in 2:length(x)) if (is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    y
}
correct.val <- function(val) {
# given a value between 0 and 1, calculate a corrected value from Litchfield and Wilcoxon Table 1
correction <- predict(fit.table1, data.frame(expected.dif.5 = abs(0.5 - val)))
result1 <- ifelse(val < 0.5, correction, 1-correction)
result2 <- ifelse(val >= 0.01 & val <= 0.99, result1, val)
result2
}
rm(expected, corrected, expected.dif.5, correction)
chi.prop <- function(obs.prop, exp.prop, n) {
# chi squared value from observed and expected proportions and n
sum(n * (obs.prop - exp.prop)^2 / (exp.prop * (1 - exp.prop)))
}
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
y
}
startvals <- function(data) {
# define log10(lc50) and log10(lc999) starting values
fit <- lm(y ~ x, data=data)
lc50.1 <- -fit$coef[1]/fit$coef[2]
lc999.1 <- (probit(0.999) - fit$coef[1])/fit$coef[2]
sv <- c(lc50.1, lc999.1)
p <- pchi.from.LC(x=sv, data=data, list=F)
list(sv=sv, p=p)
}
LC <- function(pct, b0=int, b1=slope) {
as.numeric(10^( (probit(pct/100) - b0) / b1 ))
}
### A. The data and graph.
# A 1. Don't list > 2 consecutive 100% effects at the upper end or > 2 consecutive 0% effects at the lower end.
df <- data.frame(dose=dose, ndead=ndead, ntot=ntot)
df$nalive <- df$ntot - df$ndead
df$pdead <- df$ndead/df$ntot
df <- df[order(df$dose, df$pdead), ]
# get rid of any zero dosages (controls)
df <- df[df$dose > 0, ]
# get rid of consecutives ...
df2 <- df[keeponly(df$pdead), ]
# define three mortality categories, 0 for no dead, 100 for all dead, and 50 from any proportional mortality
df2$mcat <- rep(50, length(df2$pdead))
df2$mcat[df2$ntot==df2$nalive] <- 0
df2$mcat[df2$ntot==df2$ndead] <- 100
df2
(var(df2$mcat) < 0.00000001 & df2$mcat[1] != 50) | dim(df2)[1] < 3
# A 2. Plot doses against % effect on logarithmic-probability paper
df2$x <- log10(df2$dose)
df2$y <- probit(df2$pdead)
yr <- probit(c(0.001, 0.999))
df2$y[df2$pdead==0] <- yr[1]
df2$y[df2$pdead==1] <- yr[2]
# calculate starting values
pms <- sum(df2$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
df3 <- df2[df2$mcat==50, ]
svp <- startvals(df3)
}
# fit line to partial mortalities with last 0% and first 100%
if(pms==1 | is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][sum(df2$mcat==0), ], df2[df2$mcat==50, ], df2[df2$mcat==100, ][1, ])
svp <- startvals(df3)
}
# fit line to all the data
if(pms < 1 | is.na(svp$p)) {
svp <- startvals(df2)
}
# fit line to first 0% and last 100% alone
if(is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][1, ], df2[df2$mcat==100, ][sum(df2$mcat==100), ])
svp <- startvals(df3)
}
bestLC <- optim(par=svp$sv, fn=pchi.from.LC, data=df2)
estLCs <- bestLC$par
chi <- pchi.from.LC(estLCs, data=df2, list=T)
if(!is.na(chi$p) & chi$p < 0.05) print("Chi squared test indicates poor fit.")
rm(pms, svp, df3, bestLC)
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
# D. 1. Read from the line on the graph the dose for 16, 50, and 84% effects
LC16 <- LC(16)
LC50 <- LC(50) # same as 10^estLCs[1]
LC84 <- LC(84)
# D. 2. Calculate the slope function, S
S <- (LC84/LC50 + LC50/LC16) / 2
# D. 3. Obtain Nprime, the total number of animals tested at those doses with expected effects
#between 16 and 84%.
Nprime <- sum(df2$ntot[df2$dose > LC16 & df2$dose < LC84])
# D. 4. Calculate S to the exponent for the LC50
f50 <- S^(2.77/sqrt(Nprime))
# D. 5. Calculate the 95% confidence limits of the LC50 as
upper50 <- LC50 * f50
lower50 <- LC50 / f50
# E. Calculate the confidence limits of S ... 
### I'm skipping this step because it requires a Nomograph (no. 3) to estimate A
# F. Factors for significantly heterogeneous data ...
### I'm skipping this step
# G. Test for parallelism of two lines and estimate of relative potency
### I'm skipping this step
ls()
df2
chi
LC84
LC50
LC16
S
cleanup()
rawdat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/RawToxTestData424and501.csv", as.is=TRUE)
rawdat2 <- data.frame(lapply(rawdat, fill))
sut <- sort(unique(rawdat2$Test.ID))
sel <- rawdat2$Test.ID==4
dose=rawdat2$TFM.Conc...mg.L.[sel]
ndead=rawdat2$No..Dead[sel]
ntot=rawdat2$No..Tested[sel]
description=with(rawdat2[sel, ], paste(Test.ID, Source, Batch, Species))[1]
# C:\JVA\Lamprey\ChemControl\Toxicity\LWCode.r - estimation of LC99.9 using automated Litchfield Wilcoxon (1959)
library(mgcv)
library(MASS)
library(tcltk)
###  functions  ###################################################################################################
probit <- function(prob) qnorm(prob)
inv.probit <- function(quan) pnorm(quan)
keeponly <- function(orderedx, extremes=c(0, 100), nconsec=2) {
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- rev(cumsum(lo) <= nconsec)
selnolo & selnohi
}
# corrected values from Litchfield and Wilcoxon Table 1
expected <- 1:49
corrected <- c(0.3, 0.7, 1.0, 1.3, 1.6, 2.0, 2.3, 2.6, 2.9, 3.2, 3.5, 3.8, 4.1, 4.4, 4.7, 4.9, 5.2, 5.5, 5.7, 6.0, 
6.2, 6.5, 6.7, 7.0, 7.2, 7.4, 7.6, 7.8, 8.1, 8.3, 8.4, 8.6, 8.8, 9.0, 9.2, 9.3, 9.5, 9.6, 9.8, 9.9, 10.0, 10.1, 
10.2, 10.3, 10.3, 10.4, 10.4, 10.4, 10.5)
expected.dif.5 <- abs(0.50 - expected/100)
correction <- corrected/100
fit.table1 <- gam(correction ~ s(expected.dif.5))
fill <- function (x) 
{
    y <- x
    last <- x[1]
    if (is.character(x)) {
        for (i in 2:length(x)) if (x[i] == "" | is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    else {
        for (i in 2:length(x)) if (is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    y
}
correct.val <- function(val) {
# given a value between 0 and 1, calculate a corrected value from Litchfield and Wilcoxon Table 1
correction <- predict(fit.table1, data.frame(expected.dif.5 = abs(0.5 - val)))
result1 <- ifelse(val < 0.5, correction, 1-correction)
result2 <- ifelse(val >= 0.01 & val <= 0.99, result1, val)
result2
}
rm(expected, corrected, expected.dif.5, correction)
chi.prop <- function(obs.prop, exp.prop, n) {
# chi squared value from observed and expected proportions and n
sum(n * (obs.prop - exp.prop)^2 / (exp.prop * (1 - exp.prop)))
}
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
y
}
startvals <- function(data) {
# define log10(lc50) and log10(lc999) starting values
fit <- lm(y ~ x, data=data)
lc50.1 <- -fit$coef[1]/fit$coef[2]
lc999.1 <- (probit(0.999) - fit$coef[1])/fit$coef[2]
sv <- c(lc50.1, lc999.1)
p <- pchi.from.LC(x=sv, data=data, list=F)
list(sv=sv, p=p)
}
LC <- function(pct, b0=int, b1=slope) {
as.numeric(10^( (probit(pct/100) - b0) / b1 ))
}
### A. The data and graph.
# A 1. Don't list > 2 consecutive 100% effects at the upper end or > 2 consecutive 0% effects at the lower end.
df <- data.frame(dose=dose, ndead=ndead, ntot=ntot)
df$nalive <- df$ntot - df$ndead
df$pdead <- df$ndead/df$ntot
df <- df[order(df$dose, df$pdead), ]
# get rid of any zero dosages (controls)
df <- df[df$dose > 0, ]
# get rid of consecutives ...
df2 <- df[keeponly(df$pdead), ]
# define three mortality categories, 0 for no dead, 100 for all dead, and 50 from any proportional mortality
df2$mcat <- rep(50, length(df2$pdead))
df2$mcat[df2$ntot==df2$nalive] <- 0
df2$mcat[df2$ntot==df2$ndead] <- 100
# if we have < 3 observations or we only have all dead or all survive, we can't estimate LCs
if((var(df2$mcat) < 0.00000001 & df2$mcat[1] != 50) | dim(df2)[1] < 3) {
estLCs <- NA
chi <- NA
} else {
# A 2. Plot doses against % effect on logarithmic-probability paper
df2$x <- log10(df2$dose)
df2$y <- probit(df2$pdead)
yr <- probit(c(0.001, 0.999))
df2$y[df2$pdead==0] <- yr[1]
df2$y[df2$pdead==1] <- yr[2]
# calculate starting values
pms <- sum(df2$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
df3 <- df2[df2$mcat==50, ]
svp <- startvals(df3)
}
# fit line to partial mortalities with last 0% and first 100%
if(pms==1 | is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][sum(df2$mcat==0), ], df2[df2$mcat==50, ], df2[df2$mcat==100, ][1, ])
svp <- startvals(df3)
}
# fit line to all the data
if(pms < 1 | is.na(svp$p)) {
svp <- startvals(df2)
}
# fit line to first 0% and last 100% alone
if(is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][1, ], df2[df2$mcat==100, ][sum(df2$mcat==100), ])
svp <- startvals(df3)
}
# B. 1., B. 2., and C. are all inside the function pchi.from.LC()
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
# C. The chi squared test
# find the LC50 and LC999 (on the log10 scale) that give the lowest p value for the chi-square
bestLC <- optim(par=svp$sv, fn=pchi.from.LC, data=df2)
estLCs <- bestLC$par
chi <- pchi.from.LC(estLCs, data=df2, list=T)
if(!is.na(chi$p) & chi$p < 0.05) print("Chi squared test indicates poor fit.")
rm(pms, svp, df3, bestLC)
}
# L-W
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
# D. 1. Read from the line on the graph the dose for 16, 50, and 84% effects
LC16 <- LC(16)
LC50 <- LC(50) # same as 10^estLCs[1]
LC84 <- LC(84)
# D. 2. Calculate the slope function, S
S <- (LC84/LC50 + LC50/LC16) / 2
# D. 3. Obtain Nprime, the total number of animals tested at those doses with expected effects
#between 16 and 84%.
Nprime <- sum(df2$ntot[df2$dose > LC16 & df2$dose < LC84])
# D. 4. Calculate S to the exponent for the LC50
f50 <- S^(2.77/sqrt(Nprime))
# D. 5. Calculate the 95% confidence limits of the LC50 as
upper50 <- LC50 * f50
lower50 <- LC50 / f50
# E. Calculate the confidence limits of S ... 
### I'm skipping this step because it requires a Nomograph (no. 3) to estimate A
# F. Factors for significantly heterogeneous data ...
### I'm skipping this step
# G. Test for parallelism of two lines and estimate of relative potency
### I'm skipping this step
chi
LC84
LC50
LC16
S
Nprime
lower50
upper50
df2
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
print(data.frame(data, expected, cor.exp)
y
}
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
print(data.frame(data, expected, cor.exp))
y
}
pchi.from.LC(estLCs, data=df2, list=T)
o <- 50 
e <- 67
(o - e) / e^2
0.67*4
chi
search()
ls(7)
jvamisc:::chi
chi.n <- function(obs.n, exp.n) {
# chi squared value from observed and expected numbers
(obs.n - exp.n)^2 / (exp.n)
}
data
df
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
#chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
look <- chi.n(data$pdead*data$ntot)[sel], (cor.exp*data$ntot)[sel])
chi. <- sum(look)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
print(data.frame(data, expected, cor.exp))
y
}
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
#chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
look <- chi.n((data$pdead*data$ntot)[sel], (cor.exp*data$ntot)[sel])
chi. <- sum(look)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
print(data.frame(data, expected, cor.exp))
y
}
### A. The data and graph.
# A 1. Don't list > 2 consecutive 100% effects at the upper end or > 2 consecutive 0% effects at the lower end.
df <- data.frame(dose=dose, ndead=ndead, ntot=ntot)
df$nalive <- df$ntot - df$ndead
df$pdead <- df$ndead/df$ntot
df <- df[order(df$dose, df$pdead), ]
# get rid of any zero dosages (controls)
df <- df[df$dose > 0, ]
# get rid of consecutives ...
df2 <- df[keeponly(df$pdead), ]
# define three mortality categories, 0 for no dead, 100 for all dead, and 50 from any proportional mortality
df2$mcat <- rep(50, length(df2$pdead))
df2$mcat[df2$ntot==df2$nalive] <- 0
df2$mcat[df2$ntot==df2$ndead] <- 100
# if we have < 3 observations or we only have all dead or all survive, we can't estimate LCs
if((var(df2$mcat) < 0.00000001 & df2$mcat[1] != 50) | dim(df2)[1] < 3) {
estLCs <- NA
chi <- NA
} else {
# A 2. Plot doses against % effect on logarithmic-probability paper
df2$x <- log10(df2$dose)
df2$y <- probit(df2$pdead)
yr <- probit(c(0.001, 0.999))
df2$y[df2$pdead==0] <- yr[1]
df2$y[df2$pdead==1] <- yr[2]
# calculate starting values
pms <- sum(df2$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
df3 <- df2[df2$mcat==50, ]
svp <- startvals(df3)
}
# fit line to partial mortalities with last 0% and first 100%
if(pms==1 | is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][sum(df2$mcat==0), ], df2[df2$mcat==50, ], df2[df2$mcat==100, ][1, ])
svp <- startvals(df3)
}
# fit line to all the data
if(pms < 1 | is.na(svp$p)) {
svp <- startvals(df2)
}
# fit line to first 0% and last 100% alone
if(is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][1, ], df2[df2$mcat==100, ][sum(df2$mcat==100), ])
svp <- startvals(df3)
}
# B. 1., B. 2., and C. are all inside the function pchi.from.LC()
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
# C. The chi squared test
# find the LC50 and LC999 (on the log10 scale) that give the lowest p value for the chi-square
bestLC <- optim(par=svp$sv, fn=pchi.from.LC, data=df2)
estLCs <- bestLC$par
chi <- pchi.from.LC(estLCs, data=df2, list=T)
if(!is.na(chi$p) & chi$p < 0.05) print("Chi squared test indicates poor fit.")
rm(pms, svp, df3, bestLC)
}
# L-W
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
# D. 1. Read from the line on the graph the dose for 16, 50, and 84% effects
LC16 <- LC(16)
LC50 <- LC(50) # same as 10^estLCs[1]
LC84 <- LC(84)
# D. 2. Calculate the slope function, S
S <- (LC84/LC50 + LC50/LC16) / 2
# D. 3. Obtain Nprime, the total number of animals tested at those doses with expected effects
#between 16 and 84%.
Nprime <- sum(df2$ntot[df2$dose > LC16 & df2$dose < LC84])
# D. 4. Calculate S to the exponent for the LC50
f50 <- S^(2.77/sqrt(Nprime))
# D. 5. Calculate the 95% confidence limits of the LC50 as
upper50 <- LC50 * f50
lower50 <- LC50 / f50
# E. Calculate the confidence limits of S ... 
### I'm skipping this step because it requires a Nomograph (no. 3) to estimate A
# F. Factors for significantly heterogeneous data ...
### I'm skipping this step
# G. Test for parallelism of two lines and estimate of relative potency
### I'm skipping this step
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
#chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
look <- chi.n((data$pdead*data$ntot)[sel], (cor.exp*data$ntot)[sel])
chi. <- sum(look)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
looky <- data.frame(data, expected, cor.exp)
looky$chicont <- NA
looky$chicont[sel] <- look
print(looky)
y
}
pchi.from.LC(estLCs, data=df2, list=T)
.065*8
cleanup()
q()
??contour
# C:\JVA\Lamprey\ChemControl\Toxicity\nomogram.r
epct <- rep(c(50, 95, 99), rep(3, 3))
omepct <- c(50, 30, 20, 30, 10, 5, 10, 5, 2)
chicontdivn <- c(1, .35, .16, 1.9, .22, .052, 1, .25, .04)
library(lattice)
contourplot(chicontdivn ~ epct + omepct)
# C:\JVA\Lamprey\ChemControl\Toxicity\nomogram.r
epct <- rep(c(50, 95, 99), rep(3, 3))
omepct <- c(50, 30, 20, 30, 10, 5, 10, 5, 2)
chicontdivn <- c(1, .35, .16, 1.9, .22, .052, 1, .25, .04)
n <- 8
e <- n*epct
op <- omepct + epct
o <- n*opct
mycont <- (o - e)^2/e
mycontdivn <- mycont/n
cbind(o, e, mycont, mycontdivn, op, epct, chicontdivn)
ep <- rep(c(50, 95, 99), rep(3, 3))
omepct <- c(50, 30, 20, 30, 10, 5, 10, 5, 2)
chicontdivn <- c(1, .35, .16, 1.9, .22, .052, 1, .25, .04)
n <- 8
e <- n*ep
op <- omepct + ep
o <- n*op
mycont <- (o - e)^2/e
mycontdivn <- mycont/n
cbind(o, e, mycont, mycontdivn, op, ep, chicontdivn)
ep <- rep(c(50, 95, 99), rep(3, 3))
omepct <- c(50, 30, 20, 30, 10, 5, 10, 5, 2)
chicontdivn <- c(1, .35, .16, 1.9, .22, .052, 1, .25, .04)
n <- 8
e <- n*ep/100
op <- omepct + ep
o <- n*op/100
mycont <- (o - e)^2/e
mycontdivn <- mycont/n
cbind(o, e, mycont, mycontdivn, op, ep, chicontdivn)
plot(mycontdivn, chicontdivn)
library(Design)
utils:::menuInstallPkgs()
A <- 1:10
C <- 1:10
B <- A + C
windows()
plot(0:1, 0:1, type="n", xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-5)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-10)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-5)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-10)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(0.1, 4))
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-5)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-10)
?axis
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4))
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A, line=-3)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-8)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-13)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A, line=-3)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-8)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-13)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A, line=-3)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-13)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-23)
ep2 <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1 <- rev(100-ep2)
chicont <- 
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005), seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005),  seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.005),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
length(ep2)
length(chicont)
ep1
rescale
library(plotrix)
rescale
# labels
ep2 <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1 <- rev(100-ep2)
opmep <- ep1[-(1:6)]
chicont <- 
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005), seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005),  seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.005),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
length(ep2)
length(chicont)
# scales
A <- log(ep1)
C <- log(chicont)
Br <- range(A) + range(C)
library(plotrix)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=A, labels=ep1, line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=opmep, line=-13)
axis(2, at=C, labels=chicont, line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=ep1, line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=opmep, line=-13)
axis(2, at=rescale(C, 0:1), labels=chicont, line=-23)
ep1
as.character(ep1)
ep2
as.character(ep2)
?fuzzy
??fuzzy
round(ep1, 2)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep1), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-5)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-5, tick=FALSE, adj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-7, tick=FALSE, adj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
?axis
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-7, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-4, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
# labels
ep2 <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1 <- rev(100-ep2)
opmep <- ep1[-(1:6)]
chicont <- 
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
length(ep2)
length(chicont)
# scales
A <- log(ep1)
C <- log(chicont)
Br <- range(A) + range(C)
library(plotrix)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
# ticks
ep2 <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1 <- rev(100-ep2)
opmep <- ep1[-(1:6)]
chicont <- 
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
# labels
ep2l <- c(50, 70, 80, 90, 95, 97, 98, 99, seq(99.5, 99.9, 0.1), 99.95, 99.96, 99.97, 99.98)
ep1l <- rev(100-ep2l)
opmepl <- ep1l[-(1:3)]
chicontl <- c(seq(0.001, 0.005, 0.001), seq(0.01, 0.05, 0.01), seq(0.1, 0.5, 0.1), 1, 2)
# scales
A <- log(ep1)
C <- log(chicont)
Br <- range(A) + range(C)
library(plotrix)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=FALSE, line=-13)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmepl), Br), 0:1), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23, lwd=2)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=FALSE, line=-13)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23, tck=0.01)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmepl), Br), 0:1), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23, lwd.ticks=2)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=FALSE, line=-13)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmepl), Br), 0:1), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23, lwd.ticks=2)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmepl), Br), 0:1), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
range(A)
range(B)
range(C)
range(A) + range(C)
Br
exp(range(A))
exp(Br)
exp(range(B))
exp(range(C))
?rescale
Br
diff(Br)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=(log(opmep)-Br[1])/diff(Br), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log(opmepl)-Br[1])/diff(Br), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
# scales
A <- log(ep1)
C <- log(chicont)
Br <- (range(A) + range(C)) / 2
library(plotrix)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=(log(opmep)-Br[1])/diff(Br), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log(opmepl)-Br[1])/diff(Br), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
c(0.001, 0.2)
a <- c(0.001, 0.2)
pretty(a)
pretty(log10(a))
10^pretty(log10(a))
?pretty
axisTicks(c(0.001, 0.2), TRUE)
axisTicks(c(0.001, 0.2), FALSE)
axisTicks(log(c(0.001, 0.2)), TRUE)
Br
exp(Br)
cleanup()
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log(opmep), TRUE, nint=15)
chicontl <- axisTicks(log(chicont), TRUE, nint=15)
# scales
A <- log(ep1)
C <- log(chicont)
B <- (A + C) / 2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
rescale(log(ep1l), 0:1)
ep1l
ep2
ep1
ep2l
log(ep2)
axisTicks(log(ep2), TRUE)
ep2
axisTicks(ep2, TRUE)
plot(10*(0:10), log = "y"); (pu <- par("usr"))
aX(2, print(ya <- axisTicks(pu[3:4], log = TRUE)))  # y axis
##--- Demonstrating correspondence between graphics'
##--- axis() and the graphics-engine agnostic  axisTicks() :
require("graphics")
plot(10*(0:10)); (pu <- par("usr"))
aX <- function(side, at, ...)
    axis(side, at = at, labels = FALSE, lwd.ticks = 2, col.ticks = 2,
         tck = 0.05, ...)
aX(1, print(xa <- axisTicks(pu[1:2], log = FALSE)))  # x axis
aX(2, print(ya <- axisTicks(pu[3:4], log = FALSE)))  # y axis
axisTicks(pu[3:4], log = FALSE, n = 10)
plot(10*(0:10), log = "y"); (pu <- par("usr"))
aX(2, print(ya <- axisTicks(pu[3:4], log = TRUE)))  # y axis
pu[3:4]
10*(0:10)
c(10, 100)
axisTicks(c(10, 100), TRUE)
axisTicks(log(c(10, 100)), TRUE)
axisTicks(log10(c(10, 100)), TRUE)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C) / 2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=25)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=25)
chicontl <- axisTicks(log10(chicont), TRUE, nint=25)
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C) / 2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- log10(chicont) / 2
B <- (A + C) / 2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + 2*C) / 2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- 2*log10(chicont)
B <- (A + C)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- 100*c(0.05, 50)
chicont <- 100*c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C + 2)/2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
A
10^A
10^B
a0^C
10^C
axisTicks(log10(ep2), TRUE, nint=15)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- sort(unique(c(ep2, axisTicks(log10(ep2), TRUE, nint=15))))
ep1l <- rev(100-ep2l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=15))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C + 2)/2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=15))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C + 2)/2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C + 2)/2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
axisTicks(log10(ep1), TRUE, nint=25)
axisTicks(log10(ep1), TRUE, nint=55)
axisTicks(log10(ep1), TRUE, nint=105)
axisTicks
A
B
C
10^A
10^B
10^C
0.001^2/0.02
.0447^/.02
.0447^2/.02
2^2/40
31.62^2/50
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- 2*c(0.05, 50)
chicont <- 100*c(0.001, 0.2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- 2*c(0.05, 50)
chicont <- 100*c(0.001, 0.2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- 2*c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmep <- B
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
B
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmep <- 10^B
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmep <- 10^(B/2)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmep <- 10^(B)
opmepl <- sort(unique(c(10^(B/2), axisTicks(log10(B/2), TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
chicontladj <- chicontl/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmepl <- sort(unique(c(10^(B), axisTicks(log10(B), TRUE, nint=25))))
opmepladj <- sort(unique(c(10^(B/2), axisTicks(log10(B/2), TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(log10(opmepl), 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
axisTicks(log10(B), TRUE, nint=25)
B
opmepl <- sort(unique(c(10^(B), axisTicks(B, TRUE, nint=25))))
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=25))))
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
chicontladj <- chicontl/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmepl <- sort(unique(c(10^(B), axisTicks(B, TRUE, nint=25))))
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(log10(opmepl), 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
graphics.off()
cleanup()
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=15))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj <- chicontl/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmepl <- sort(unique(c(10^(B), axisTicks(B, TRUE, nint=15))))
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(log10(opmepl), 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
opmepl
opmepladj
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=15))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj <- chicontl/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl <- 2*log(opmepladj)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(log10(opmepl), 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
opmepladj
B
10^(B/2)
opmepl <- 2*log10(opmepladj)
opmepl
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=15))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj <- chicontl/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl <- 2*log10(opmepladj)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
ep1l
opmepl
opmepladj
ep2l
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l <- rev(100-ep1l)
# label B using the observed - expected percentage scale
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl <- 2*log10(opmepladj)
# label C using the contrib/n scale
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj <- chicontl/100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl/100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj.)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl/100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj.)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl./100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
chicontl
signif(chicontl, 1)
signif(chicontl, 1) - chicontl
signif(chicontl, 1) - chicontl == 0
mod(chicontl, 2)
chicontl %*% 2
chicontl %/% 2
bigtix <- function(x, fudge=10) {
onedigit <- signif(x, 1) - round(x, fudge) == 0
j1 <- (x %/% 1) == 0
j2 <- (x %/% 2) == 0
j5 <- (x %/% 5) == 0
onedigit & (j1 | j2 | j5)
}
ep2l
ep2l[bigtix(ep2l)]
bigtix(ep2l)
ep1l[bigtix(ep1l)]
bigtix(ep1l)
ep1l
x <- ep1l
fudge=10
onedigit <- signif(x, 1) - round(x, fudge) == 0
j1 <- (x %/% 1) == 0
j2 <- (x %/% 2) == 0
j5 <- (x %/% 5) == 0
onedigit
j1
?"%/%"
signif(x, 1)
scientific(signif(x, 1))
?format
format(signif(x, 1), sci=TRUE)
substring(format(signif(x, 1), sci=TRUE), 1, 1)
bigtix <- function(x, fudge=10, roundingto=c(1, 2, 5)) {
onedigit <- signif(x, 1) - round(x, fudge) == 0
gooddigit <- substring(format(signif(x, 1), sci=TRUE), 1, 1) %in% roundingto
onedigit & gooddigit
}
ep2l. <- ep1l[bigtix(ep1l)]
ep2l
ep2l.
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj.)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl./100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
bigtix <- function(x, fudge=10, roundingto=c(1, 2, 5)) {
onedigit <- signif(x, 1) - round(x, fudge) == 0
gooddigit <- substring(format(signif(x, 1), sci=TRUE), 1, 1) %in% roundingto
onedigit & gooddigit
}
ep1l. <- ep1l[bigtix(ep1l)]
ep2l. <- rev(100 - ep1l.)
opmepladj. <- opmepladj[bigtix(opmepladj)]
opmepl <- 2*log10(opmepladj)
chicontl. <- chicontl[bigtix(chicontl)]
chicontladj <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
ep1l. <- ep1l[bigtix(ep1l)]
ep2l. <- rev(100 - ep1l.)
opmepladj. <- opmepladj[bigtix(opmepladj)]
opmepl. <- 2*log10(opmepladj)
chicontl. <- chicontl[bigtix(chicontl)]
chicontladj. <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
opmepl
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj.)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl./100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
bigtix <- function(x, fudge=10, roundingto=c(1, 2, 5)) {
onedigit <- signif(x, 1) - round(x, fudge) == 0
gooddigit <- substring(format(signif(x, 1), sci=TRUE), 1, 1) %in% roundingto
onedigit & gooddigit
}
ep1l. <- ep1l[bigtix(ep1l)]
ep2l. <- rev(100 - ep1l.)
opmepladj. <- opmepladj[bigtix(opmepladj)]
opmepl. <- 2*log10(opmepladj.)
chicontl. <- chicontl[bigtix(chicontl)]
chicontladj. <- chicontl./100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
ep1l. <- sort(unique(range(ep1l), ep1l[bigtix(ep1l)]))
ep2l. <- rev(100 - ep1l.)
opmepladj. <- sort(unique(range(opmepladj), opmepladj[bigtix(opmepladj)]))
opmepl. <- 2*log10(opmepladj.)
chicontl. <- sort(unique(range(chicontl), chicontl[bigtix(chicontl)]))
chicontladj. <- chicontl./100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
graphics.off()
cleanup()
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj.)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl./100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
bigtix <- function(x, fudge=10, roundingto=c(1, 2, 5)) {
onedigit <- signif(x, 1) - round(x, fudge) == 0
gooddigit <- substring(format(signif(x, 1), sci=TRUE), 1, 1) %in% roundingto
onedigit & gooddigit
}
ep1l. <- sort(unique(range(ep1l), ep1l[bigtix(ep1l)]))
ep2l. <- rev(100 - ep1l.)
opmepladj. <- sort(unique(range(opmepladj), opmepladj[bigtix(opmepladj)]))
opmepl. <- 2*log10(opmepladj.)
chicontl. <- sort(unique(range(chicontl), chicontl[bigtix(chicontl)]))
chicontladj. <- chicontl./100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
ep1l. <- sort(unique(c(range(ep1l), ep1l[bigtix(ep1l)])))
ep2l. <- rev(100 - ep1l.)
opmepladj. <- sort(unique(c(range(opmepladj), opmepladj[bigtix(opmepladj)])))
opmepl. <- 2*log10(opmepladj.)
chicontl. <- sort(unique(c(range(chicontl), chicontl[bigtix(chicontl)])))
chicontladj. <- chicontl./100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=c(1, 1, 3, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=2, line=-c(3, 13, 23))
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=2, line=-c(3, 13, 23), adj=0.8)
?mtext
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=2, line=-c(3, 13, 23), adj=0.5, padj=0.8)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=2, line=-c(3, 13, 23), adj=0.5, padj=8)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=2, line=-c(3, 13, 23), adj=0.5, padj=-25)
locator()
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(12, 51, 90))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=c(1, 1, 3, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(12, 51, 90))
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.90))
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.90), line=2)
par(xaxs="i", yaxs="i", mar=c(1, 1, 2, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.90), line=1)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=c(1, 1, 2, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-14)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-25)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.90), line=1)
locator()
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=c(1, 1, 2, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-14, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-25, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-14)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-25)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.95), line=1)
par(xaxs="i", yaxs="i", mar=c(1, 1, 2, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-14, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-25, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-14)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-25)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.90), line=1)
x <- 1:100
lx <- log10(x)
llx <- log10(lx)
windows()
plot(x, lx)
plot(x, llx)
ls
lx
ep1l
x <- ep1l
lx <- log10(x)
lx
diff(lx)
llx <- log10(lx)
sx <- sqrt(x)
lsx <- log10(sx)
x
sx
lsx
plot(lsx, lsx, axes=FALSE)
axis(2, at=lsx, labels=x)
axis(2, at=lsx, labels=x, las=1)
plot(lsx, lsx, axes=FALSE)
axis(2, at=lsx, labels=x, las=1)
windows(h=9, w=6.5)
par(mar=c(1, 10, 1, 10))
plot(lsx, lsx, axes=FALSE)
axis(2, at=lsx, labels=x, las=1)
plot(lsx, lsx, axes=FALSE)
axis(2, at=lsx, labels=round(x, 4), las=1)
q()
# quit and restart R
# install from local folder
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("LW1949")
setwd("C:/JVA/R/Working Directory")
library(LW1949)
rawdat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/RawToxTestData424and501.csv", as.is=TRUE)
rawdat2 <- data.frame(lapply(rawdat, fill))
sut <- sort(unique(rawdat2$Test.ID))
sel <- rawdat2$Test.ID==4
dose=rawdat2$TFM.Conc...mg.L.[sel]
ndead=rawdat2$No..Dead[sel]
ntot=rawdat2$No..Tested[sel]
description=with(rawdat2[sel, ], paste(Test.ID, Source, Batch, Species))[1]
### A. The data and graph.
# A 1. Don't list > 2 consecutive 100% effects at the upper end or > 2 consecutive 0% effects at the lower end.
df <- data.frame(dose=dose, ndead=ndead, ntot=ntot)
df$nalive <- df$ntot - df$ndead
df$pdead <- df$ndead/df$ntot
df <- df[order(df$dose, df$pdead), ]
# get rid of any zero dosages (controls)
df <- df[df$dose > 0, ]
# get rid of consecutives ...
dfsub <- df[keeponly(df$pdead), ]
# define three mortality categories, 0 for no dead, 100 for all dead, and 50 from any proportional mortality
dfsub$mcat <- mcat(dfsub)
# A 2. Plot doses against % effect on logarithmic-probability paper
dfsub$x <- log10(dfsub$dose)
dfsub$y <- probit(dfsub$pdead)
yr <- probit(c(0.001, 0.999))
dfsub$y[dfsub$pdead==0] <- yr[1]
dfsub$y[dfsub$pdead==1] <- yr[2]
gamfit <- gamtable1()
# calculate starting values
pms <- sum(dfsub$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
dfpart <- dfsub[dfsub$mcat==50, ]
svp <- startvals(dfpart, gamfit)
}
#' Determine Starting Values for LC50\% and LC99.9\%
#'
#' Determine starting values for the LC50\% and LC99.9\% (both on the log10 scale).
#' @param dat A data frame of raw toxicity data, including these two variables:
#'ldose = dose (the concentration of the applied chemical on the log10 scale), 
#'and pbpdead, the proportion of dead individuals (on the probit scale, with 0s converted to 0.1\% and 1s converted to 99.9\%).
#' @param fitA model object that can be used to predict the corrected values (as proportions) from \code{distexpprop5}, 
#'the distance from the expected values (as proportions) and 0.5.  Typically the output from \code{\link{gamtable1}()}.
#' @return A list with two elements: sv, a numeric vector of length two giving the starting values for the LC50\% and LC99.9\%,
#'and p, a numeric scalar giving the P value of the associated chi-squared statistic.
#' @export
#' @examples 
#' test <- data.frame(
#' dose=c(0.0625, 0.125, 0.25, 0.5), 
#' ntot=rep(8, 4), 
#' pdead = c(0.125, 0.5, 0.5, 0.875))
#' test$ldose <- log10(test$dose)
#' test$pbpdead <- probit(test$pdead)
#' gamfit <- gamtable1()
#' startvals(test, gamfit)
startvals <- function(dat, fit) {
# define log10(lc50) and log10(lc999) starting values
fit <- lm(pbpdead ~ ldose, data=dat)
lc50.1 <- -fit$coef[1]/fit$coef[2]
lc999.1 <- (probit(0.999) - fit$coef[1])/fit$coef[2]
sv <- c(lc50.1, lc999.1)
p <- pchiLC(LCs=sv, dat=dat, fit, outlist=FALSE)
list(sv=sv, p=p)
}
# A 2. Plot doses against % effect on logarithmic-probability paper
dfsub$ldose <- log10(dfsub$dose)
dfsub$pbpdead <- probit(dfsub$pdead)
yr <- probit(c(0.001, 0.999))
dfsub$pbpdead[dfsub$pdead==0] <- yr[1]
dfsub$pbpdead[dfsub$pdead==1] <- yr[2]
gamfit <- gamtable1()
# calculate starting values
pms <- sum(dfsub$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
dfpart <- dfsub[dfsub$mcat==50, ]
svp <- startvals(dfpart, gamfit)
}
#' P Value of a Chi-Squared Statistic for a Does Response Curve
#'
#' Calculate the P value of the chi-squared statistic for a given dose response curve relating log dose to proportion affected on the 
#'probit scale.
#' @param LCs A numeric vector of estimated lethal concentrations on the log10 scale.  
#'The first element is the LC50\%, the second is the LC99.9\%.These two points define the does response curve.
#' @param dat A data frame of raw toxicity data, including these four variables:
#'dose (the concentration of the applied chemical), ntot (the number of individuals tested), pdead (the proportion of dead individuals), 
#'and mcat (mortality category =0 for none dead, =100 for all dead, and =50 for any partial mortality).
#' @param fitA model object that can be used to predict the corrected values (as proportions) from \code{distexpprop5}, 
#'the distance from the expected values (as proportions) and 0.5.  Typically the output from \code{\link{gamtable1}()}.
#' @param outlistA logical scalar indicating if the output should be a list or a scalar, default FALSE.
#' @return If \code{outlist=TRUE}, a list with three elements: chistat, a numeric scalar, the chi-squared statistic; 
#'pval, a numeric scalar, its associated P value; and df, an integer, the degrees of freedom of \code{chistat}.
#'If \code{outlist=FALSE}, a numeric scalar, the negative P value of the chi-squared statistic (see details).
#' @export
#' @detailsThis function is used as part of a routine that attempts to find the dose response curve that minimizes the 
#'P value from the chi-squared statistic measuring the distance between the observed and expected values.  
#' Following Litchfield and Wilcoxon (1949), records for any 0\% or 100\% dose with expected values < 0.01\% or > 99.99\% are deleted,
#'and expected values are corrected using the \code{\link{correctval}} function.
#' @seealso \code{\link{chi2}} and \code{\link{chisq.test}}.
#' @references J. T. Litchfield, Jr. and F. Wilcoxon.  1949. 
#' \href{http://jpet.aspetjournals.org/content/96/2/99.short}{A simplified method of evaluating dose-effect experiments}.
#' Journal of Pharmacology and Experimental Therapeutics 99(2):99-113.
#' @examples 
#' test <- data.frame(
#' dose=c(0.0625, 0.125, 0.25, 0.5), 
#' ntot=rep(8, 4), 
#' ndead = c(0, 4, 6, 8))
#' test$pdead <- test$ndead/test$ntot
#' test$mcat <- mcat(test)
#' gamfit <- gamtable1()
#' pchiLC(c(0.125, 0.5), test, gamfit)
pchiLC <- function(LCs, dat, fit, outlist=FALSE) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- LCs[1]
LC999 <- LCs[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- invprobit(int + slope*log10(dat$dose))
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | dat$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(dat$mcat==50, expected, correctval(expected, fit))
if(n > 2) {
### C. The chi squared test
chilist <- chi2((dat$pdead*dat$ntot)[sel], (cor.exp*dat$ntot)[sel])
} else {
chilist <- list(chistat=NA, pval=NA, df=NA)
}
# save the p value as a negative for minimization by optim()
if(outlist) y <- chilist else y <- -chilist$pval
y
}
# A 2. Plot doses against % effect on logarithmic-probability paper
dfsub$ldose <- log10(dfsub$dose)
dfsub$pbpdead <- probit(dfsub$pdead)
yr <- probit(c(0.001, 0.999))
dfsub$pbpdead[dfsub$pdead==0] <- yr[1]
dfsub$pbpdead[dfsub$pdead==1] <- yr[2]
gamfit <- gamtable1()
# calculate starting values
pms <- sum(dfsub$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
dfpart <- dfsub[dfsub$mcat==50, ]
svp <- startvals(dfpart, gamfit)
}
# fit line to partial mortalities with last 0% and first 100%
if(pms==1 | is.na(svp$p)) {
dfpart <- rbind(dfsub[dfsub$mcat==0, ][sum(dfsub$mcat==0), ], dfsub[dfsub$mcat==50, ], dfsub[dfsub$mcat==100, ][1, ])
svp <- startvals(dfpart, gamfit)
}
# fit line to all the data
if(pms < 1 | is.na(svp$p)) {
svp <- startvals(dfsub, gamfit)
}
# fit line to first 0% and last 100% alone
if(is.na(svp$p)) {
dfpart <- rbind(dfsub[dfsub$mcat==0, ][1, ], dfsub[dfsub$mcat==100, ][sum(dfsub$mcat==100), ])
svp <- startvals(dfpart)
}
# B. 1., B. 2., and C. are all inside the function pchiLC()
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
# C. The chi squared test
# find the LC50 and LC999 (on the log10 scale) that give the lowest p value for the chi-square
bestLC <- optim(par=svp$sv, fn=pchiLC, data=dfsub)
estLCs <- bestLC$par
chi <- pchiLC(estLCs, data=dfsub, list=T)
if(!is.na(chi$p) & chi$p < 0.05) warning("Chi squared test indicates poor fit.")
bestLC <- optim(par=svp$sv, fn=pchiLC, dat=dfsub, fit=gamfit)
estLCs <- bestLC$par
chi <- pchiLC(estLCs, data=dfsub, list=T)
if(!is.na(chi$p) & chi$p < 0.05) warning("Chi squared test indicates poor fit.")
bestLC <- optim(par=svp$sv, fn=pchiLC, dat=dfsub, fit=gamfit)
estLCs <- bestLC$par
chi <- pchiLC(estLCs, dat=dfsub, fit=gamfit, outlist=TRUE)
if(!is.na(chi$pval) & chi$pval < 0.05) warning("Chi squared test indicates poor fit.")
bestLC <- optim(par=svp$sv, fn=pchiLC, dat=dfsub, fit=gamfit)
estLCs <- bestLC$par
chi <- pchiLC(estLCs, dat=dfsub, fit=gamfit, outlist=TRUE)
if(!is.na(chi$pval) & chi$pval < 0.05) warning("Chi squared test indicates poor fit.")
rm(pms, svp, dfpart, bestLC)
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
# D. 1. Read from the line on the graph the dose for 16, 50, and 84% effects
LC16 <- LC(16, b0=int, b1=slope)
LC50 <- LC(50, b0=int, b1=slope) # same as 10^estLCs[1]
LC84 <- LC(84, b0=int, b1=slope)
# D. 2. Calculate the slope function, S
S <- (LC84/LC50 + LC50/LC16) / 2
# D. 3. Obtain Nprime, the total number of animals tested at those doses with expected effects
#between 16 and 84%.
Nprime <- sum(dfsub$ntot[dfsub$dose > LC16 & dfsub$dose < LC84])
# D. 4. Calculate S to the exponent for the LC50
f50 <- S^(2.77/sqrt(Nprime))
# D. 5. Calculate the 95% confidence limits of the LC50 as
upper50 <- LC50 * f50
lower50 <- LC50 / f50
cleanup()
q()
# quit and restart R
# install from local folder
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("artiFISHal")
setwd("C:/JVA/R/Working Directory")
library(artiFISHal)
?artiFISHal
q()
# quit and restart R
# install from local folder
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("LW1949")
setwd("C:/JVA/R/Working Directory")
library(LW1949)
?LW1949
cleanup()
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("artiFISHal")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
?glm
?family
?glm
?glm.object
??glm.object
??glm
?lm
?dose.p
predlinear <- function(pct, b0, b1) {
as.numeric(10^( (probit(pct/100) - b0) / b1 ))
}
predlinear(c(16, 50, 84, 99.9), 1.700875, 2.199559)
library(LW1949)
predlinear(c(16, 50, 84, 99.9), 1.700875, 2.199559)
predlinear <- function(pct, b0, b1) {
y <- as.numeric(10^( (probit(pct/100) - b0) / b1 ))
names(y) <- paste0("ED", pct)
y
}
predlinear(c(16, 50, 84, 99.9), 1.700875, 2.199559)
predprobit <- function(pct, pfit) {
logED <- dose.p(pfit, cf=1:2, p=pct/100)
ED <- 10^c(logDpct + c(0, -1.96, 1.96) * attr(logDpct, "SE"))
ED
}
fitprobit(mydat)
fitprobit <- function(DEdata) {
sel <- DEdata$dose > 0
glm(cbind(nfx, ntot-nfx) ~ log10(dose), family=binomial(link=probit), data=DEdata[sel, ])
}
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
datMat <- matrix(rep(1,100),nrow=10)
op=par(oma=c(1,1,1,1),mar=c(1,1,1,1),lwd = 0.2,cex=.5)
nf <- layout(matrix(c(0,1,0,2,3,4),2,3,byrow=TRUE), widths=c(1,6,1),heights=c(1,3), respect=TRUE)
par(mar=c(3,0.5,3,0),mgp=c(0,1,-2.2))
barplot(seq(1,10),width=1,xlim=c(0,ncol(datMat)),xlab="",space=0,col="blue",border = "white" )
box("inner", lty="dotted", col="green")
box("outer", lty="solid", col="green")
par(mar=c(0,0,0,0),mgp=c(0,1,-1))
barplot(-seq(1,10),ylim=c(0,nrow(datMat)),width=1.025,horiz=TRUE,,axes= T,space=0,col="blue", border = "white" )
par(mar=c(1,0,0,0))
x.len=ncol(datMat)
y.len=nrow(datMat)
single.col= 'chartreuse4'
double.col= 'blue4'
triple.col= '#FFFF33'
four.col= '#FF7F00'
five.col= '#E41A1C'
colors=c('grey90',single.col, double.col,triple.col,four.col,five.col);
image(x=1:x.len, y=1:y.len, z=t(datMat), col = colors, breaks=c(-0.5,0.5 ,1.5 ,2.5 ,3.5 ,4.5 ,5.5),axes = FALSE, ann=F);
abline(h=seq(0.5,0.5+y.len),col='white',lwd=0.5);
abline(v=seq(0.5,0.5+x.len),col='white',lwd=0.5)
par(mar=c(0,0,0,0),mgp=c(0,1,0))
barplot(seq(1,10),ylim=c(0,nrow(datMat)),width=.5,horiz=TRUE,axes =FALSE, space=0,col="blue",border ="white" )
axis(side=1)
datMat <- matrix(rep(1,100),nrow=10)
x.len=ncol(datMat)
y.len=nrow(datMat)
single.col= 'chartreuse4'
double.col= 'blue4'
triple.col= '#FFFF33'
four.col= '#FF7F00'
five.col= '#E41A1C'
colors=c('grey90',single.col, double.col,triple.col,four.col,five.col);
op=par(oma=c(1,1,1,1),mar=c(1,1,1,1),lwd = 0.2,cex=.5)
nf <- layout(matrix(c(0,1,0,2,3,4),2,3,byrow=TRUE), widths=c(1,6,1),heights=c(1,3), respect=TRUE)
par(mar=c(3,0.5,3,0),mgp=c(0,1,-2.2))
barplot(seq(1,10),width=1,xlim=c(0,ncol(datMat)),xlab="",space=0,col="blue",border = "white" )
box("inner", lty="dotted", col="green")
box("outer", lty="solid", col="green")
par(mar=c(0,0,0,0),mgp=c(0,1,-1))
barplot(-seq(1,10),ylim=c(0,nrow(datMat)),width=1.025,horiz=TRUE,,axes= T,space=0,col="blue", border = "white" )
par(mar=c(1,0,0,0))
image(x=1:x.len, y=1:y.len, z=t(datMat), col = colors, breaks=c(-0.5,0.5 ,1.5 ,2.5 ,3.5 ,4.5 ,5.5),axes = FALSE, ann=F);
abline(h=seq(0.5,0.5+y.len),col='white',lwd=0.5);
abline(v=seq(0.5,0.5+x.len),col='white',lwd=0.5)
locator()
a <- image(x=1:x.len, y=1:y.len, z=t(datMat), col = colors, breaks=c(-0.5,0.5 ,1.5 ,2.5 ,3.5 ,4.5 ,5.5),axes = FALSE, ann=F);
a
par("usr")
seq(1,10)
?barplot
datMat <- matrix(rep(1,100),nrow=10)
x.len=ncol(datMat)
y.len=nrow(datMat)
single.col= 'chartreuse4'
double.col= 'blue4'
triple.col= '#FFFF33'
four.col= '#FF7F00'
five.col= '#E41A1C'
colors=c('grey90',single.col, double.col,triple.col,four.col,five.col)
op=par(oma=c(1,1,1,1),mar=c(1,1,1,1),lwd = 0.2,cex=.5)
nf <- layout(matrix(c(0,1,0,2,3,4),2,3,byrow=TRUE), widths=c(1,6,1),heights=c(1,3), respect=TRUE)
par(mar=c(3,0.5,3,0),mgp=c(0,1,-2.2))
barplot(seq(1,10),width=1,xlim=c(0,ncol(datMat)),xlab="",space=0,col="blue",border = "white" )
box("inner", lty="dotted", col="green")
box("outer", lty="solid", col="green")
locator()
barplot(-seq(1,10),offset=0.5, ylim=c(0,nrow(datMat)),width=1.025,horiz=TRUE,,axes= T,space=0,col="blue", border = "white" )
op=par(oma=c(1,1,1,1),mar=c(1,1,1,1),lwd = 0.2,cex=.5)
nf <- layout(matrix(c(0,1,0,2,3,4),2,3,byrow=TRUE), widths=c(1,6,1),heights=c(1,3), respect=TRUE)
par(mar=c(3,0.5,3,0),mgp=c(0,1,-2.2))
barplot(seq(1,10),width=1,xlim=c(0,ncol(datMat)),xlab="",space=0,col="blue",border = "white" )
box("inner", lty="dotted", col="green")
box("outer", lty="solid", col="green")
par(mar=c(0,0,0,0),mgp=c(0,1,-1))
barplot(-seq(1,10),offset=0.5, ylim=c(0,nrow(datMat)),width=1.025,horiz=TRUE,,axes= T,space=0,col="blue", border = "white" )
op=par(oma=c(1,1,1,1),mar=c(1,1,1,1),lwd = 0.2,cex=.5)
nf <- layout(matrix(c(0,1,0,2,3,4),2,3,byrow=TRUE), widths=c(1,6,1),heights=c(1,3), respect=TRUE)
par(mar=c(3,0.5,3,0),mgp=c(0,1,-2.2))
barplot(seq(1,10),width=1,xlim=c(0,ncol(datMat)),xlab="",space=0,col="blue",border = "white" )
box("inner", lty="dotted", col="green")
box("outer", lty="solid", col="green")
par(mar=c(0,0,0,0),mgp=c(0,1,-1))
barplot(-seq(1,10),offset=0.5, ylim=c(0,nrow(datMat)),width=1.025,horiz=TRUE,,axes= T,space=0,col="blue", border = "white" )
op=par(oma=c(1,1,1,1),mar=c(1,1,1,1),lwd = 0.2,cex=.5)
nf <- layout(matrix(c(0,1,0,2,3,4),2,3,byrow=TRUE), widths=c(1,6,1),heights=c(1,3), respect=TRUE)
par(mar=c(3,0.5,3,0),mgp=c(0,1,-2.2))
barplot(seq(1,10),width=1,xlim=c(0,ncol(datMat)),xlab="",space=0,col="blue",border = "white" )
box("inner", lty="dotted", col="green")
box("outer", lty="solid", col="green")
locator()
a <- barplot(seq(1,10),width=1,xlim=c(0,ncol(datMat)),xlab="",space=0,col="blue",border = "white" )
a
datMat <- matrix(rep(1,100),nrow=10)
x.len=ncol(datMat)
y.len=nrow(datMat)
single.col= 'chartreuse4'
double.col= 'blue4'
triple.col= '#FFFF33'
four.col= '#FF7F00'
five.col= '#E41A1C'
colors=c('grey90',single.col, double.col,triple.col,four.col,five.col)
op=par(oma=c(1,1,1,1),mar=c(1,1,1,1),lwd = 0.2,cex=.5)
nf <- layout(matrix(c(0,1,0,2,3,4),2,3,byrow=TRUE), widths=c(1,6,1),heights=c(1,3), respect=TRUE)
par(mar=c(3,0.5,3,0),mgp=c(0,1,-2.2))
barplot(seq(1,10),offset=0.5,width=1,xlim=c(0,ncol(datMat)),xlab="",space=0,col="blue",border = "white" )
box("inner", lty="dotted", col="green")
box("outer", lty="solid", col="green")
par(mar=c(0,0,0,0),mgp=c(0,1,-1))
barplot(-seq(1,10),offset=0.5, ylim=c(0,nrow(datMat)),width=1.025,horiz=TRUE,,axes= T,space=0,col="blue", border = "white" )
par(mar=c(1,0,0,0))
a <- image(x=1:x.len, y=1:y.len, z=t(datMat), col = colors, breaks=c(-0.5,0.5 ,1.5 ,2.5 ,3.5 ,4.5 ,5.5),axes = FALSE, ann=F)
abline(h=seq(0.5,0.5+y.len),col='white',lwd=0.5)
abline(v=seq(0.5,0.5+x.len),col='white',lwd=0.5)
par(mar=c(0,0,0,0),mgp=c(0,1,0))
barplot(seq(1,10),offset=0.5,ylim=c(0,nrow(datMat)),width=.5,horiz=TRUE,axes =FALSE, space=0,col="blue",border ="white" )
axis(side=1)
op=par(oma=c(1,1,1,1),mar=c(1,1,1,1),lwd = 0.2,cex=.5)
nf <- layout(matrix(c(0,1,0,2,3,4),2,3,byrow=TRUE), widths=c(1,6,1),heights=c(1,3), respect=TRUE)
par(mar=c(3,0.5,3,0),mgp=c(0,1,-2.2))
barplot(seq(1,10),offset=0.5,width=1,xlim=c(0,ncol(datMat)),xlab="",space=0,col="blue",border = "white" )
box("inner", lty="dotted", col="green")
box("outer", lty="solid", col="green")
locator()
par("usr")
cleanup()
q()
# C:\JVA\Consult\Stapanian\AmphibSens\Explore v3.r
# relevant emails:
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/1439c3834064343b
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/143baffe32131385
# 13 Mar 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/144bb971f5eca226
# objectives
# Find the best predictive model of the following responses
# using as independent variables the 6 ORAM metrics, OVIBI score, and the 10 LDI metrics.
# 1. number of salamander species (x.ssp) 
# 2. % sensitive species (x.sen)
# 3. % tolerant species (x.ol)
# 4. Amphibian Quality Assessment Index (aqai)
# 5. presence/absence of [wood frogs or spotted salamanders] (spot.wdscore, binary)
plotimp <- function(rpartfit, ordered=TRUE, plot=TRUE, horiz=TRUE, col=colz[ord], xlab="", las=1, ...) {
# calculate importance of variables
# http://cran.at.r-project.org/web/packages/rpart/vignettes/longintro.pdf
# importance = An overall measure of variable importance is the sum of the goodness of split
# measures for each split for which it was the primary variable, plus goodness * (adjusted
# agreement) for all splits in which it was a surrogate.
# I scaled them to sum to 100
imp <- rpartfit$variable.importance
xvars <- attr(fit$terms, "term.labels")
implong <- imp[match(xvars, names(imp))]
names(implong) <- xvars
implong[is.na(implong)] <- 0
implong <- 100*implong/sum(implong)
if(ordered) {
ord <- order(implong)
} else {
ord <- rev(seq(implong))
}
if(plot) {
colz <- colr(seq(implong), "yellow", "blue")
barplot(implong[ord], horiz=horiz, col=col, xlab=xlab, las=las, ...)
}
implong
}
library(plotrix)
library(rpart)
wb <- loadWorkbook("C:/JVA/Consult/Stapanian/AmphibSens/amphibians_13FEB2014.xlsx")
dat <- readWorksheet(wb, sheet="Jean2")
names(dat) <- make.names(casefold(names(dat)), unique=T, allow_=F)
dat$spotwdn <- dat$spot.wdscore/10
dat$spotwdf <- as.factor(dat$spot.wdscore)
responsesn <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdn")
responses <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdf")
respnames <- c("Salamanders (# species)", "Sensitive  (% species)", "Tolerant  (% species)", "Amphibian Quality Assessment Index", 
"Presence of Wood F. or Spotted S.")
respnames <- c("Pond-Breeding", "% Sensitive", "% Tolerant", "Amphibian QAI", "Presence of SS/WF")
indeps <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", 
"water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")
indnames <- c("ORAM 1", "ORAM 2", "ORAM 3", "ORAM 4", "ORAM 5", "ORAM 6", "OVIBI", 
"LDI water", "LDI forest", "LDI wet. forest", "LDI wet. emergent", 
"LDI pasture", "LDI crop", "LDI suburban", "LDI transitional", "LDI rock", 
"LDI urban")
notthese <- c(1, 5, 15, 16)
indeps <- indeps[-notthese]
indnames <- indnames[-notthese]
# other varz ... c("site.code", "ldi..1km.", "x.tolscore", "x.senscore")
# just for grins, develop one Y variable that encompasses all of the responses
pca <- princomp(dat[, responsesn], cor=TRUE)
Y <- pca$scores[, 1]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
### FIGURE 2 ###
windows(h=8, w=6.5)
par(mar=c(3, 8, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=rev(indnames))
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
saveimp[rev(order(apply(saveimp, 1, mean))), ]
x <- dat[, indeps]
y <- dat[, responsesn]
candidates <- list(c("metric4", "vibi.score"), 
c("metric4", "vibi.score"), 
c("metric4", "metric2"),
c("metric4", "metric3"),
c("metric4", "row.crop"))
# fit linear regression to the candidates variables
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
}
print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
chosen <- list(c("metric4", "vibi.score"), 
c("metric4"), 
c("metric4"),
c("metric4"),
c("metric4"))
# visualize the chosen variables
colz <- c("blue", "orange")
### FIGURE 3 ###
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 0, 0, 0))
for(i in (seq(responsesn))) {
if(i==1) {
plot(dat$metric4, y[, i], type="n", xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
for(j in 1:2) {
sel <- (dat$vibi.score < 60) == c(TRUE, FALSE)[j]
mycol <- colz[j]
points(dat$metric4[sel], jitter(y[sel, i]), cex=1.5, col=mycol, pch=j)
lines(loess.smooth(dat$metric4[sel], y[sel, i], span=1, degree=2), col=mycol, lwd=2)
}
legend("topleft", paste("OVIBI", c("<", "\U2265"), "60"), col=colz, lwd=2)
} else {
if(i == 5) {
yy <- as.numeric(y[, i])-1
plot(dat$metric4, jitter(yy, factor=0.2), xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, yy, span=1, degree=2), lwd=2)
} else {
plot(dat$metric4, y[, i], xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, y[, i], span=1, degree=2), lwd=2)
}
}
}
mtext("ORAM 4", side=1, outer=TRUE, line=0.5)
dat[order(dat$metric4, Y), c("site.code", "metric4", "vibi.score", responses)]
library(psych)
corm <- corr.test(dat[, indeps], dat[, responses[-5]], adjust="none")
ncolz <- dim(corm$r)[[2]]
cbind(corm$r, corm$p)[, as.vector(matrix(1:(2*ncolz), nrow=2, byrow=TRUE))]
r <- corm$r
dimnames(r) <- list(indnames, respnames[-5])
windows(h=9, w=4.3)
ordz <- plotcor(r, mar=c(0.1, 8, 8, 0.1), atcex=.9)
r[ordz[[1]], ordz[[2]]]
fit
coef(fit)
summary(fit)
coef(summary(fit))
a <- coef(summary(fit))
dimnames(a)[[1]]
data.frame(dimnames(a)[[1]], a)
unlist(data.frame(dimnames(a)[[1]], a))
cbind(dimnames(a)[[1]], format(round(a, 3))
)
cbind(dimnames(a)[[1]], format(round(a, 3)))
t(cbind(dimnames(a)[[1]], format(round(a, 3))))
unlist(t(cbind(dimnames(a)[[1]], format(round(a, 3)))))
as.vector(t(cbind(dimnames(a)[[1]], format(round(a, 3)))))
as.vector(t(cbind(dimnames(a)[[1]], format(round(a, 3)))))
# fit linear regression to the candidates variables
res <- matrix(NA, nrow=length(responsesn), ncol=5*(2+1))
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
co <- coef(summary(fit))
res[i, ] <- as.vector(t(cbind(dimnames(co)[[1]], format(round(co, 3)))))
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
co <- coef(summary(fit))
res[i, ] <- as.vector(t(cbind(dimnames(co)[[1]], format(round(co, 3)))))
}
print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
res
res
fit
co <- coef(summary(fit))
co
cbind(dimnames(co)[[1]], format(round(co, 3)))
rbind(c(" ", dimnames(co)[[2]]), cbind(dimnames(co)[[1]], format(round(co, 3)))
)
co <- coef(summary(fit))
conames <- rbind(c(" ", dimnames(co)[[2]]), cbind(dimnames(co)[[1]], format(round(co, 3))))
res[i, ] <- as.vector(t(conames))
conames
t(conames)
as.vector(t(conames))
c("", "est", "se", "t/z", "p")
# fit linear regression to the candidates variables
res <- matrix(NA, nrow=length(responsesn), ncol=5*(2+1), dimnames=list(responsesn, rep(c("", "est", "se", "t/z", "p"), (2:1))))
res <- matrix(NA, nrow=length(responsesn), ncol=5*(2+1), dimnames=list(responsesn, rep(c("", "est", "se", "t/z", "p"), (2+1))))
res
# fit linear regression to the candidates variables
res <- matrix(NA, nrow=length(responsesn), ncol=5*(2+1), dimnames=list(responsesn, rep(c("", "est", "se", "t/z", "p"), (2+1))))
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
co <- coef(summary(fit))
res[i, ] <- as.vector(t(cbind(dimnames(co)[[1]], format(round(co, 3)))))
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
co <- coef(summary(fit))
res[i, ] <- as.vector(t(cbind(dimnames(co)[[1]], format(round(co, 3)))))
}
#print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
res
# fit linear regression to the candidates variables
res <- matrix(NA, nrow=length(responsesn), ncol=5*(2+1), dimnames=list(responsesn, rep(c("Param", "Est", "SE", "t/z", "P"), (2+1))))
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
co <- coef(summary(fit))
res[i, ] <- as.vector(t(cbind(dimnames(co)[[1]], format(round(co, 3)))))
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
co <- coef(summary(fit))
res[i, ] <- as.vector(t(cbind(dimnames(co)[[1]], format(round(co, 3)))))
}
#print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
res
co <- coef(summary(fit))
dn <- dimnames(co)[[1]]
dn2 <- indnames[match(dn, indeps)]
as.vector(t(cbind(n2, format(round(co, 3)))))
as.vector(t(cbind(dn2, format(round(co, 3)))))
# fit linear regression to the candidates variables
res <- matrix(NA, nrow=length(responsesn), ncol=5*(2+1), dimnames=list(responsesn, rep(c("Param", "Est", "SE", "t/z", "P"), (2+1))))
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
co <- coef(summary(fit))
dn <- dimnames(co)[[1]]
dn2 <- indnames[match(dn, indeps)]
res[i, ] <- as.vector(t(cbind(dn2, format(round(co, 3)))))
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
dn <- dimnames(co)[[1]]
dn2 <- indnames[match(dn, indeps)]
res[i, ] <- as.vector(t(cbind(dn2, format(round(co, 3)))))
}
#print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
res
# fit linear regression to the candidates variables
res <- matrix(NA, nrow=length(responsesn), ncol=5*(2+1), dimnames=list(responsesn, rep(c("Param", "Est", "SE", "t/z", "P"), (2+1))))
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
co <- coef(summary(fit))
dn <- dimnames(co)[[1]]
dn2 <- indnames[match(dn, indeps)]
res[i, ] <- as.vector(t(cbind(dn2, format(round(co, 3)))))
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
co <- coef(summary(fit))
dn <- dimnames(co)[[1]]
dn2 <- indnames[match(dn, indeps)]
res[i, ] <- as.vector(t(cbind(dn2, format(round(co, 3)))))
}
#print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
res
# fit linear regression to the candidates variables
res <- matrix(NA, nrow=length(responsesn), ncol=5*(2+1), dimnames=list(respnames, rep(c("Param", "Est", "SE", "t/z", "P"), (2+1))))
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
co <- coef(summary(fit))
dn <- dimnames(co)[[1]]
dn2 <- indnames[match(dn, indeps)]
res[i, ] <- as.vector(t(cbind(dn2, format(round(co, 3)))))
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
co <- coef(summary(fit))
dn <- dimnames(co)[[1]]
dn2 <- indnames[match(dn, indeps)]
res[i, ] <- as.vector(t(cbind(dn2, format(round(co, 3)))))
}
#print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
res
write.csv(res, "C:/JVA/Consult/Stapanian/AmphibSens/results.csv")
q()
cleanup()
W <- 15:25
P <- 2*W
C <- sqrt(P^2 + (W/2)^2)
plot(P, C)
eqscplot(P, C)
library(MASS)
eqscplot(P, C)
abline(lsfit(P, C))
P <- w
P <- W
C <- sqrt(P^2 + (W/2)^2)
eqscplot(P, C)
abline(lsfit(P, C))
P
C
fit <- lm(C ~ P)
plot(fit)
P
C
sqrt(1.25)
fit
summary(fit)
# JVA C:\JVA\Consult\Grundel\Karner Heat\Patterson\2014-11-03 Sensor script.r
# TAP "D:\Tammy\ClimateKBBProject\FieldData\HOBOdata2012\WorkingFolder\cvsfiles"Marchv2.r Sensor Data Processing
# 4) could you create additional wide files that are cut into shorter time blocks? 
# 1 year or 6 months or 4 months? This is because excel will not open the entire data set of 2+ years. 
# Excel 2010 limit 1,048,576 rows, 16,384 columns
# This allows for almost 40 records per hour for three years solid in the rows.
date()
tammyfiles <- c(
csvfiles   = "D:\\Tammy\\ClimateKBBProject\\FieldData\\HOBOdata2012\\WorkingFolder\\cvsfilessubset\\",
fiddler    = "D:\\Tammy\\ClimateKBBProject\\FieldData\\HOBOdata2012\\WorkingFolder\\results\\Fiddler2010.csv",
resultsdir = "D:\\Tammy\\ClimateKBBProject\\FieldData\\HOBOdata2012\\WorkingFolder\\results")
ralphfiles <- c(
csvfiles   = "D:\\1 SPSS\\SPSSDATA\\Kbb Climate Change\\Hobo Pendant Sensor Data\\R Scripts of Hobo Reading\\Trial\\",
fiddler    = "D:\\1 SPSS\\SPSSDATA\\Kbb Climate Change\\Hobo Pendant Sensor Data\\R Scripts of Hobo Reading\\TrialElim\\Fiddler2010.csv",
resultsdir = "D:\\1 SPSS\\SPSSDATA\\Kbb Climate Change\\Hobo Pendant Sensor Data\\R Scripts of Hobo Reading\\result")
jeanfiles <- c(
csvfiles   = "C:\\JVA\\Consult\\Grundel\\Karner Heat\\Patterson\\csvfiles2014-11-03\\",
fiddler    = "C:\\JVA\\Consult\\Grundel\\Karner Heat\\Patterson\\results\\Fiddler2010.csv",
resultsdir = "C:\\JVA\\Consult\\Grundel\\Karner Heat\\Patterson\\results")
# no longer need to comment out all the file names
# just indicate which set of file names you want to use here
usethesefiles <- jeanfiles
library(reshape)
library(car)
library(rtf)
### define several functions
startrtf <- function(file=NULL, dir=getwd(), width=8.5, height=11, omi=c(1, 1, 1, 1), quiet=FALSE) {
# create a new RTF file readable by Word
if(is.null(file)) file <- paste0("RGeneratedDocument", Sys.Date())
dirfiledoc <- if(length(grep(".doc", file))>0) paste(dir, file, sep="/") else paste(dir, paste0(file, ".doc"), sep="/")
if(!quiet) cat(paste0("New RTF document created, ", dirfiledoc, "\n"))
RTF(dirfiledoc, width=width, height=height, omi=omi)
}
figu <- function(..., FIG=fig, rtf=doc, w=NULL, h=NULL, rf=300) {
wf <- if(is.null(w)) 6.5 else w
hf <- if(is.null(h)) 8 else h
addNewLine(this=rtf)
addPlot(this=rtf, plot.fun=FIG, width=wf, height=hf, res=rf)
}
endrtf <- function(rtf=doc, details=FALSE, ...) {
if(details==TRUE) {
addPageBreak(rtf, ...)
addSessionInfo(rtf)
}
done(rtf)
}
combine.csv <- function(mydir) {
# combine all csv files in a given directory into a single data frame
# file names
filenames <- list.files(mydir)[grep(".csv", list.files(mydir))]
nfiles <- length(filenames)
# create an empty list where all the files will be stored
files.list <- vector(mode="list", length=nfiles)
for(i in 1:nfiles) {
# read the data into a temporary file
temp <- read.csv(paste(mydir, filenames[i], sep=""), as.is=TRUE, skip=1)[, 1:4]
names(temp) <- c("no", "datetime", "temp", "intensity")
# get rid of records with all missing values
temp <- temp[!apply(is.na(temp[, c(1, 3:4)]), 1, all), ]
# add a new column identifying the source file
temp$source <- filenames[i]
# put the data into the list
files.list[[i]] <- temp
}
# combined each of the files from the list into one single file
do.call(rbind, files.list)
}
capwords <- function(s, strict = FALSE) {
    cap <- function(s) paste(toupper(substring(s,1,1)),
                  {s <- substring(s,2); if(strict) tolower(s) else s},
                             sep = "", collapse = " " )
    sapply(strsplit(s, split = " "), cap, USE.NAMES = !is.null(names(s)))
}
exploreplot <- function(df, title1) {
par(mfcol=c(2, length(sul)), mar=c(3, 3.5, 1, 0), oma=c(2, 2, 4, 1))
for(i in seq(along=sul)) {
sel <- df$location==sul[i] & df$site==sus[j] & !is.na(df$dtime)
sel1 <- sel & !is.na(df$intensity)
sel2 <- sel & !is.na(df$temp)
if(sum(sel1)>0) {
plot(df$dtime[sel1], df$intensity[sel1], xlab="", ylab="", las=1)
} else {
plot(1, 1, type="n", xlab="", ylab="", axes=FALSE)
}
mtext(capwords(sul[i]), side=3, line=1)
if(i==1) mtext("Intensity  (lum/ft)", side=2, line=3.5)
if(sum(sel2)>0) {
plot(df$dtime[sel2], df$temp[sel2], xlab="", ylab="", las=1)
} else {
plot(1, 1, type="n", xlab="", ylab="", axes=FALSE)
}
if(i==1) mtext("Temperature (F)", side=2, line=3.5)
}
mtext("Date time", side=1, outer=TRUE)
mtext(paste(sus[j], title1, sep="  -  "), side=3, font=2, outer=TRUE, line=2)
invisible()
}
# create a data frame that contains all csv files in directory
df <- combine.csv(usethesefiles["csvfiles"])
rm(combine.csv)
# define site and location from source file names, use lowercase letters only
prefix <- sapply(strsplit(df$source, "\\."), "[", 1)
df$site <- casefold(sapply(strsplit(prefix, "_"), "[", 1))
sensor.loc <- casefold(sapply(strsplit(prefix, "_"), "[", 2))
df$sensor <- substring(sensor.loc, 1, 7)
df$location <- casefold(substring(sensor.loc, 8, 9))
rm(prefix, sensor.loc)
# number of characters used in date/time variable
dtlen <- nchar(df$datetime)
# print out any records with missing date/time information
df[dtlen==0, ]
# create new date/time variable, with corrected times in the format "2011-07-14 16:15:00"
# it looks like records with date/time length ranging from 13 to 16 are all formatted "7/14/2011 16:15"
# and those with date/time length 20 are all formatted "07/14/11 04:15:00 PM"
dt <- rep("", length(dtlen))
dt[dtlen > 12 & dtlen < 17] <- as.character(strptime(df$datetime[dtlen > 12 & dtlen < 17], "%m/%d/%Y %H:%M"))
dt[dtlen > 19] <- as.character(strptime(df$datetime[dtlen > 19], "%m/%d/%y %I:%M:%S %p"))
date.time <- strsplit(dt, " ")
just.date <- sapply(date.time, "[", 1)
just.time <- strsplit(sapply(date.time, "[", 2), ":")
hh <- sapply(just.time, "[", 1)
mm <- sapply(just.time, "[", 2)
mm <- ifelse(mm < 29.5, 15, 45)
### Ralph, you need this line of code which was in SensorData3.r
### It creates a new variable "dtime" which has the corrected time (__:15 or __:45)
df$dtime <- strptime(paste(just.date, " ", hh, ":", mm, sep=""), "%Y-%m-%d %H:%M")
rm(dt, date.time, just.date, just.time, hh, mm)
# no elimination file, all data considered "good"
df.good <- df
# read in sunrise/sunset data
fiddler <- read.csv(usethesefiles["fiddler"], as.is=TRUE, header=FALSE, skip=2, col.names=c("date", "rise", "set", "light.hrs"))
# fiddler$date looks like this:"7/10/2010"
# fiddler$rise and set look like this:"20:24"
fiddler$sunrise <- strptime(paste(fiddler$date, fiddler$rise), "%m/%d/%Y %H:%M")
fiddler$sunset <- strptime(paste(fiddler$date, fiddler$set), "%m/%d/%Y %H:%M")
fiddler$just.date <- substring(as.character(fiddler$sunrise), 1, 10)
# merge the data with the sunrise/sunset data
df.good$just.date <- substring(as.character(df.good$dtime), 1, 10)
df.long <- merge(df.good, fiddler, all.x=TRUE)
df.long$daylight <- ifelse(df.long$dtime >= df.long$sunrise & df.long$dtime < df.long$sunset, 1, 0)
df.long$xdtime <- paste("x", df.long$dtime)
rm(fiddler, df.good)
# save graphs of uncorrected data to an rtf file
# explore the data
sus <- sort(unique(df.long$site))
sul <- sort(unique(df.long$location))
fig <- function() exploreplot(df.long, "Uncorrected")
j <- 1
fig()
rm(sul, sus)
ls()
rm(C, P, W)
ls()
### note that I am only keeping a character version of the date/time, "xdtime", so that Excel won't mess it up ###
df.long <- df.long[order(df.long$site, df.long$location, df.long$dtime), c("xdtime", "daylight", "site", "sensor", "location", "intensity", "temp")]
# rearrange the long data into a wide format
df2 <- melt(df.long, id.vars=c("site", "location", "xdtime", "sensor", "daylight"), measure.vars=c("intensity", "temp"))
df2$slv <- paste(df2$site, substring(df2$location, 1, 2), df2$sensor, substring(df2$variable, 1, 2), sep="_")
df.wide <- as.data.frame(tapply(df2$value, list(paste(df2$xdtime, df2$daylight, sep="_"), df2$slv), mean))
xdtime.lt <- strsplit(dimnames(df.wide)[[1]], "_")
xdtime <- sapply(xdtime.lt, "[", 1)
daylight <- sapply(xdtime.lt, "[", 2)
df.wide <- cbind(xdtime, daylight, df.wide)
row.names(df.wide) <- seq(dim(df.wide)[1])
rm(xdtime.lt, xdtime, daylight)
# rearrange the long data into a "semi-long" format
df2$locvar <- paste(substring(df2$location, 1, 2), substring(df2$variable, 1, 2), sep="_")
df.semi <- as.data.frame(tapply(df2$value, list(paste(df2$xdtime, df2$daylight, df2$site, sep="_"), df2$locvar), mean))
xdtime.lt.site <- strsplit(dimnames(df.semi)[[1]], "_")
df.semi$xdtime <- sapply(xdtime.lt.site, "[", 1)
df.semi$daylight <- sapply(xdtime.lt.site, "[", 2)
df.semi$site <- sapply(xdtime.lt.site, "[", 3)
columns <- sort(names(df.semi)[!(names(df.semi) %in% c("xdtime", "daylight", "site"))])
df.semi <- df.semi[order(df.semi$site, df.semi$xdtime), c("xdtime", "daylight", "site", columns)]
row.names(df.semi) <- seq(dim(df.semi)[1])
rm(df2, xdtime.lt.site)
# look at the first few rows of each dataframe
table(df.long$site, df.long$location)
head(df.long)
head(df.semi)
df.wide[1:6, 1:min(10, dim(df.wide)[2])]
dim(df.long)
head(df.long)
cleanup()
search()
graphics.off()
# JVA C:\JVA\Consult\Grundel\Karner Heat\Patterson\2014-11-03 Sensor script.r
# TAP "D:\Tammy\ClimateKBBProject\FieldData\HOBOdata2012\WorkingFolder\cvsfiles"Marchv2.r Sensor Data Processing
# 4) could you create additional wide files that are cut into shorter time blocks? 
# 1 year or 6 months or 4 months? This is because excel will not open the entire data set of 2+ years. 
# Excel 2010 limit 1,048,576 rows, 16,384 columns
# This allows for almost 40 records per hour for three years solid in the rows.
date()
tammyfiles <- c(
csvfiles   = "D:\\Tammy\\ClimateKBBProject\\FieldData\\HOBOdata2012\\WorkingFolder\\cvsfilessubset\\",
fiddler    = "D:\\Tammy\\ClimateKBBProject\\FieldData\\HOBOdata2012\\WorkingFolder\\results\\Fiddler2010.csv",
resultsdir = "D:\\Tammy\\ClimateKBBProject\\FieldData\\HOBOdata2012\\WorkingFolder\\results")
ralphfiles <- c(
csvfiles   = "D:\\1 SPSS\\SPSSDATA\\Kbb Climate Change\\Hobo Pendant Sensor Data\\R Scripts of Hobo Reading\\Trial\\",
fiddler    = "D:\\1 SPSS\\SPSSDATA\\Kbb Climate Change\\Hobo Pendant Sensor Data\\R Scripts of Hobo Reading\\TrialElim\\Fiddler2010.csv",
resultsdir = "D:\\1 SPSS\\SPSSDATA\\Kbb Climate Change\\Hobo Pendant Sensor Data\\R Scripts of Hobo Reading\\result")
jeanfiles <- c(
csvfiles   = "C:\\JVA\\Consult\\Grundel\\Karner Heat\\Patterson\\csvfiles2014-11-03\\",
fiddler    = "C:\\JVA\\Consult\\Grundel\\Karner Heat\\Patterson\\results\\Fiddler2010.csv",
resultsdir = "C:\\JVA\\Consult\\Grundel\\Karner Heat\\Patterson\\results")
# no longer need to comment out all the file names
# just indicate which set of file names you want to use here
usethesefiles <- jeanfiles
library(reshape)
library(car)
library(rtf)
### define several functions
startrtf <- function(file=NULL, dir=getwd(), width=8.5, height=11, omi=c(1, 1, 1, 1), quiet=FALSE) {
# create a new RTF file readable by Word
if(is.null(file)) file <- paste0("RGeneratedDocument", Sys.Date())
dirfiledoc <- if(length(grep(".doc", file))>0) paste(dir, file, sep="/") else paste(dir, paste0(file, ".doc"), sep="/")
if(!quiet) cat(paste0("New RTF document created, ", dirfiledoc, "\n"))
RTF(dirfiledoc, width=width, height=height, omi=omi)
}
figu <- function(..., FIG=fig, rtf=doc, w=NULL, h=NULL, rf=300) {
wf <- if(is.null(w)) 6.5 else w
hf <- if(is.null(h)) 8 else h
addNewLine(this=rtf)
addPlot(this=rtf, plot.fun=FIG, width=wf, height=hf, res=rf)
}
endrtf <- function(rtf=doc, details=FALSE, ...) {
if(details==TRUE) {
addPageBreak(rtf, ...)
addSessionInfo(rtf)
}
done(rtf)
}
combine.csv <- function(mydir) {
# combine all csv files in a given directory into a single data frame
# file names
filenames <- list.files(mydir)[grep(".csv", list.files(mydir))]
nfiles <- length(filenames)
# create an empty list where all the files will be stored
files.list <- vector(mode="list", length=nfiles)
for(i in 1:nfiles) {
# read the data into a temporary file
temp <- read.csv(paste(mydir, filenames[i], sep=""), as.is=TRUE, skip=1)[, 1:4]
names(temp) <- c("no", "datetime", "temp", "intensity")
# get rid of records with all missing values
temp <- temp[!apply(is.na(temp[, c(1, 3:4)]), 1, all), ]
# add a new column identifying the source file
temp$source <- filenames[i]
# put the data into the list
files.list[[i]] <- temp
}
# combined each of the files from the list into one single file
do.call(rbind, files.list)
}
capwords <- function(s, strict = FALSE) {
    cap <- function(s) paste(toupper(substring(s,1,1)),
                  {s <- substring(s,2); if(strict) tolower(s) else s},
                             sep = "", collapse = " " )
    sapply(strsplit(s, split = " "), cap, USE.NAMES = !is.null(names(s)))
}
exploreplot <- function(df, title1) {
par(mfcol=c(2, length(sul)), mar=c(3, 3.5, 1, 0), oma=c(2, 2, 4, 1))
for(i in seq(along=sul)) {
sel <- df$location==sul[i] & df$site==sus[j] & !is.na(df$dtime)
sel1 <- sel & !is.na(df$intensity)
sel2 <- sel & !is.na(df$temp)
if(sum(sel1)>0) {
plot(df$dtime[sel1], df$intensity[sel1], xlab="", ylab="", las=1)
} else {
plot(1, 1, type="n", xlab="", ylab="", axes=FALSE)
}
mtext(capwords(sul[i]), side=3, line=1)
if(i==1) mtext("Intensity  (lum/ft)", side=2, line=3.5)
if(sum(sel2)>0) {
plot(df$dtime[sel2], df$temp[sel2], xlab="", ylab="", las=1)
} else {
plot(1, 1, type="n", xlab="", ylab="", axes=FALSE)
}
if(i==1) mtext("Temperature (F)", side=2, line=3.5)
}
mtext("Date time", side=1, outer=TRUE)
mtext(paste(sus[j], title1, sep="  -  "), side=3, font=2, outer=TRUE, line=2)
invisible()
}
# create a data frame that contains all csv files in directory
df <- combine.csv(usethesefiles["csvfiles"])
rm(combine.csv)
# define site and location from source file names, use lowercase letters only
prefix <- sapply(strsplit(df$source, "\\."), "[", 1)
df$site <- casefold(sapply(strsplit(prefix, "_"), "[", 1))
sensor.loc <- casefold(sapply(strsplit(prefix, "_"), "[", 2))
df$sensor <- substring(sensor.loc, 1, 7)
df$location <- casefold(substring(sensor.loc, 8, 9))
rm(prefix, sensor.loc)
# number of characters used in date/time variable
dtlen <- nchar(df$datetime)
# print out any records with missing date/time information
df[dtlen==0, ]
# create new date/time variable, with corrected times in the format "2011-07-14 16:15:00"
# it looks like records with date/time length ranging from 13 to 16 are all formatted "7/14/2011 16:15"
# and those with date/time length 20 are all formatted "07/14/11 04:15:00 PM"
dt <- rep("", length(dtlen))
dt[dtlen > 12 & dtlen < 17] <- as.character(strptime(df$datetime[dtlen > 12 & dtlen < 17], "%m/%d/%Y %H:%M"))
dt[dtlen > 19] <- as.character(strptime(df$datetime[dtlen > 19], "%m/%d/%y %I:%M:%S %p"))
date.time <- strsplit(dt, " ")
just.date <- sapply(date.time, "[", 1)
just.time <- strsplit(sapply(date.time, "[", 2), ":")
hh <- sapply(just.time, "[", 1)
mm <- sapply(just.time, "[", 2)
mm <- ifelse(mm < 29.5, 15, 45)
### Ralph, you need this line of code which was in SensorData3.r
### It creates a new variable "dtime" which has the corrected time (__:15 or __:45)
df$dtime <- strptime(paste(just.date, " ", hh, ":", mm, sep=""), "%Y-%m-%d %H:%M")
rm(dt, date.time, just.date, just.time, hh, mm)
# no elimination file, all data considered "good"
df.good <- df
# read in sunrise/sunset data
fiddler <- read.csv(usethesefiles["fiddler"], as.is=TRUE, header=FALSE, skip=2, col.names=c("date", "rise", "set", "light.hrs"))
# fiddler$date looks like this:"7/10/2010"
# fiddler$rise and set look like this:"20:24"
fiddler$sunrise <- strptime(paste(fiddler$date, fiddler$rise), "%m/%d/%Y %H:%M")
fiddler$sunset <- strptime(paste(fiddler$date, fiddler$set), "%m/%d/%Y %H:%M")
fiddler$just.date <- substring(as.character(fiddler$sunrise), 1, 10)
# merge the data with the sunrise/sunset data
df.good$just.date <- substring(as.character(df.good$dtime), 1, 10)
df.long <- merge(df.good, fiddler, all.x=TRUE)
df.long$daylight <- ifelse(df.long$dtime >= df.long$sunrise & df.long$dtime < df.long$sunset, 1, 0)
df.long$xdtime <- paste("x", df.long$dtime)
rm(fiddler, df.good)
# save graphs of uncorrected data to an rtf file
# explore the data
sus <- sort(unique(df.long$site))
sul <- sort(unique(df.long$location))
with(df.long, table(df.long$dtime, site))
a <- with(df.long, table(dtime, site))
sub <- df.long[1:100, ]
table(sub$dtime, sub$site)
class(sub)
sub$dtime
sub$site
table(sub$site)
table(sub$dtime)
sub <- df.long[1:100, ]
table(sub$xdtime, sub$site)
head(df.long)
sub <- df.long[1:100, ]
table(sub$xdtime, paste(sub$site, sub$location))
sub <- df.long[1:100, ]
table(sub$xdtime, paste(sub$site, sub$location))
tapply(sub$sensor, paste(sub$site, sub$location, sub$xdtime), function(x) length(unique(x)))
aggregate(sensor ~ site + location + xdtime, function(x) length(unique(x)), data=sub)
sensorcount <- aggregate(sensor ~ site + location + xdtime, function(x) length(unique(x)), data=sub)
sensorcount[sensorcount$sensor > 1, ]
sensorcount <- aggregate(sensor ~ site + location + xdtime, function(x) length(unique(x)), data=df.long)
sensorcount[sensorcount$sensor > 1, ]
head(df.long)
head(df.long)
head(sensorcount)
names(sensorcount)
dput(names(sensorcount))
dput(names(df.long))
# check to see if there are any sensor overlaps at a given  site, location, and time
sensorcount <- aggregate(sensor ~ site + location + xdtime, function(x) length(unique(x)), data=df.long)
# if there are any records with mulitple sensors at a given site, location, and time the csv files or the df.long file should be 
sel <- sensorcount$sensor > 1
if(sum(sel)>0) {
multsens <- merge(sensorcount[sel, c("site", "location", "xdtime"], 
df.long[, c("source", "site", "location", "datetime", "xdtime", "sensor", "temp", "intensity")], all.x=TRUE)
warning("Records with multiple sensors at a given site, location, and time.")
orint(multsens)
}
sel
sum(sel)
sum(sel)>0
sel <- sensorcount$sensor > 1
if(sum(sel)>0) {
multsens <- merge(sensorcount[sel, c("site", "location", "xdtime")], 
df.long[, c("source", "site", "location", "datetime", "xdtime", "sensor", "temp", "intensity")], all.x=TRUE)
warning("Records with multiple sensors at a given site, location, and time.")
print(multsens)
}
dim(sensorcount)
sel <- c(3, 20, 50, 500)
if(sum(sel)>0) {
multsens <- merge(sensorcount[sel, c("site", "location", "xdtime")], 
df.long[, c("source", "site", "location", "datetime", "xdtime", "sensor", "temp", "intensity")], all.x=TRUE)
warning("Records with multiple sensors at a given site, location, and time.")
print(multsens)
}
print(multsens[, c("source", "site", "location", "datetime", "xdtime", "sensor", "temp", "intensity")])
print(multsens[, c("source", "site", "location", "xdtime", "datetime", "sensor", "temp", "intensity")])
# save graphs of uncorrected data to an rtf file
# explore the data
sus <- sort(unique(df.long$site))
sul <- sort(unique(df.long$location))
doc <- startrtf("Uncorrected", dir=usethesefiles["resultsdir"], width=11, height=8.5, omi=c(0.5, 0.5, 0.5, 0.5))
fig <- function() exploreplot(df.long, "Uncorrected")
for(j in seq(along=sus)) {
figu("", h=7, w=10)
}
endrtf()
rm(sul, sus)
### note that I am only keeping a character version of the date/time, "xdtime", so that Excel won't mess it up ###
df.long <- df.long[order(df.long$site, df.long$location, df.long$dtime), c("xdtime", "daylight", "site", "sensor", "location", "intensity", "temp")]
# rearrange the long data into a wide format
df2 <- melt(df.long, id.vars=c("site", "location", "xdtime", "sensor", "daylight"), measure.vars=c("intensity", "temp"))
df2$slv <- paste(df2$site, substring(df2$location, 1, 2), df2$sensor, substring(df2$variable, 1, 2), sep="_")
df.wide <- as.data.frame(tapply(df2$value, list(paste(df2$xdtime, df2$daylight, sep="_"), df2$slv), mean))
xdtime.lt <- strsplit(dimnames(df.wide)[[1]], "_")
xdtime <- sapply(xdtime.lt, "[", 1)
daylight <- sapply(xdtime.lt, "[", 2)
df.wide <- cbind(xdtime, daylight, df.wide)
row.names(df.wide) <- seq(dim(df.wide)[1])
head(df.wide)
# rearrange the long data into a wide format
df2 <- melt(df.long, id.vars=c("site", "location", "xdtime", "daylight"), measure.vars=c("intensity", "temp"))
df2$slv <- paste(df2$site, substring(df2$location, 1, 2), substring(df2$variable, 1, 2), sep="_")
df.wide <- as.data.frame(tapply(df2$value, list(paste(df2$xdtime, df2$daylight, sep="_"), df2$slv), mean))
xdtime.lt <- strsplit(dimnames(df.wide)[[1]], "_")
xdtime <- sapply(xdtime.lt, "[", 1)
daylight <- sapply(xdtime.lt, "[", 2)
df.wide <- cbind(xdtime, daylight, df.wide)
row.names(df.wide) <- seq(dim(df.wide)[1])
head(df.wide)
dim(df.wide)
# rearrange the long data into a "semi-long" format
df2$locvar <- paste(substring(df2$location, 1, 2), substring(df2$variable, 1, 2), sep="_")
df.semi <- as.data.frame(tapply(df2$value, list(paste(df2$xdtime, df2$daylight, df2$site, sep="_"), df2$locvar), mean))
xdtime.lt.site <- strsplit(dimnames(df.semi)[[1]], "_")
df.semi$xdtime <- sapply(xdtime.lt.site, "[", 1)
df.semi$daylight <- sapply(xdtime.lt.site, "[", 2)
df.semi$site <- sapply(xdtime.lt.site, "[", 3)
columns <- sort(names(df.semi)[!(names(df.semi) %in% c("xdtime", "daylight", "site"))])
df.semi <- df.semi[order(df.semi$site, df.semi$xdtime), c("xdtime", "daylight", "site", columns)]
row.names(df.semi) <- seq(dim(df.semi)[1])
rm(df2, xdtime.lt.site)
# look at the first few rows of each dataframe
table(df.long$site, df.long$location)
head(df.long)
head(df.semi)
df.wide[1:6, 1:min(10, dim(df.wide)[2])]
# write the data to three new csv files
write.csv(df.long, paste(usethesefiles["resultsdir"], "SensorsLong.csv", sep="\\"), row.names=FALSE)
write.csv(df.semi, paste(usethesefiles["resultsdir"], "SensorsSemi.csv", sep="\\"), row.names=FALSE)
write.csv(df.wide, paste(usethesefiles["resultsdir"], "SensorsWide.csv", sep="\\"), row.names=FALSE)
dim(df.wide)
head(df)
summary(df)
# JVA C:\JVA\Consult\Grundel\Karner Heat\Patterson\2014-11-03 Sensor script.r
# TAP "D:\Tammy\ClimateKBBProject\FieldData\HOBOdata2012\WorkingFolder\cvsfiles"Marchv2.r Sensor Data Processing
# 4) could you create additional wide files that are cut into shorter time blocks? 
# 1 year or 6 months or 4 months? This is because excel will not open the entire data set of 2+ years. 
# Excel 2010 limit 1,048,576 rows, 16,384 columns
# This allows for almost 40 records per hour for three years solid in the rows.
date()
tammyfiles <- c(
csvfiles   = "D:\\Tammy\\ClimateKBBProject\\FieldData\\HOBOdata2012\\WorkingFolder\\cvsfilessubset\\",
fiddler    = "D:\\Tammy\\ClimateKBBProject\\FieldData\\HOBOdata2012\\WorkingFolder\\results\\Fiddler2010.csv",
resultsdir = "D:\\Tammy\\ClimateKBBProject\\FieldData\\HOBOdata2012\\WorkingFolder\\results")
ralphfiles <- c(
csvfiles   = "D:\\1 SPSS\\SPSSDATA\\Kbb Climate Change\\Hobo Pendant Sensor Data\\R Scripts of Hobo Reading\\Trial\\",
fiddler    = "D:\\1 SPSS\\SPSSDATA\\Kbb Climate Change\\Hobo Pendant Sensor Data\\R Scripts of Hobo Reading\\TrialElim\\Fiddler2010.csv",
resultsdir = "D:\\1 SPSS\\SPSSDATA\\Kbb Climate Change\\Hobo Pendant Sensor Data\\R Scripts of Hobo Reading\\result")
jeanfiles <- c(
csvfiles   = "C:\\JVA\\Consult\\Grundel\\Karner Heat\\Patterson\\csvfiles2014-11-03\\",
fiddler    = "C:\\JVA\\Consult\\Grundel\\Karner Heat\\Patterson\\results\\Fiddler2010.csv",
resultsdir = "C:\\JVA\\Consult\\Grundel\\Karner Heat\\Patterson\\results")
# no longer need to comment out all the file names
# just indicate which set of file names you want to use here
usethesefiles <- jeanfiles
library(reshape)
library(car)
library(rtf)
### define several functions
startrtf <- function(file=NULL, dir=getwd(), width=8.5, height=11, omi=c(1, 1, 1, 1), quiet=FALSE) {
# create a new RTF file readable by Word
if(is.null(file)) file <- paste0("RGeneratedDocument", Sys.Date())
dirfiledoc <- if(length(grep(".doc", file))>0) paste(dir, file, sep="/") else paste(dir, paste0(file, ".doc"), sep="/")
if(!quiet) cat(paste0("New RTF document created, ", dirfiledoc, "\n"))
RTF(dirfiledoc, width=width, height=height, omi=omi)
}
figu <- function(..., FIG=fig, rtf=doc, w=NULL, h=NULL, rf=300) {
wf <- if(is.null(w)) 6.5 else w
hf <- if(is.null(h)) 8 else h
addNewLine(this=rtf)
addPlot(this=rtf, plot.fun=FIG, width=wf, height=hf, res=rf)
}
endrtf <- function(rtf=doc, details=FALSE, ...) {
if(details==TRUE) {
addPageBreak(rtf, ...)
addSessionInfo(rtf)
}
done(rtf)
}
combine.csv <- function(mydir) {
# combine all csv files in a given directory into a single data frame
# file names
filenames <- list.files(mydir)[grep(".csv", list.files(mydir))]
nfiles <- length(filenames)
# create an empty list where all the files will be stored
files.list <- vector(mode="list", length=nfiles)
for(i in 1:nfiles) {
# read the data into a temporary file
temp <- read.csv(paste(mydir, filenames[i], sep=""), as.is=TRUE, skip=1)[, 1:4]
names(temp) <- c("no", "datetime", "temp", "intensity")
# get rid of records with all missing values
temp <- temp[!apply(is.na(temp[, c(1, 3:4)]), 1, all), ]
# add a new column identifying the source file
temp$source <- filenames[i]
# put the data into the list
files.list[[i]] <- temp
}
# combined each of the files from the list into one single file
do.call(rbind, files.list)
}
capwords <- function(s, strict = FALSE) {
    cap <- function(s) paste(toupper(substring(s,1,1)),
                  {s <- substring(s,2); if(strict) tolower(s) else s},
                             sep = "", collapse = " " )
    sapply(strsplit(s, split = " "), cap, USE.NAMES = !is.null(names(s)))
}
exploreplot <- function(df, title1) {
par(mfcol=c(2, length(sul)), mar=c(3, 3.5, 1, 0), oma=c(2, 2, 4, 1))
for(i in seq(along=sul)) {
sel <- df$location==sul[i] & df$site==sus[j] & !is.na(df$dtime)
sel1 <- sel & !is.na(df$intensity)
sel2 <- sel & !is.na(df$temp)
if(sum(sel1)>0) {
plot(df$dtime[sel1], df$intensity[sel1], xlab="", ylab="", las=1)
} else {
plot(1, 1, type="n", xlab="", ylab="", axes=FALSE)
}
mtext(capwords(sul[i]), side=3, line=1)
if(i==1) mtext("Intensity  (lum/ft)", side=2, line=3.5)
if(sum(sel2)>0) {
plot(df$dtime[sel2], df$temp[sel2], xlab="", ylab="", las=1)
} else {
plot(1, 1, type="n", xlab="", ylab="", axes=FALSE)
}
if(i==1) mtext("Temperature (F)", side=2, line=3.5)
}
mtext("Date time", side=1, outer=TRUE)
mtext(paste(sus[j], title1, sep="  -  "), side=3, font=2, outer=TRUE, line=2)
invisible()
}
# create a data frame that contains all csv files in directory
df <- combine.csv(usethesefiles["csvfiles"])
rm(combine.csv)
# define site and location from source file names, use lowercase letters only
prefix <- sapply(strsplit(df$source, "\\."), "[", 1)
df$site <- casefold(sapply(strsplit(prefix, "_"), "[", 1))
sensor.loc <- casefold(sapply(strsplit(prefix, "_"), "[", 2))
df$sensor <- substring(sensor.loc, 1, 7)
df$location <- casefold(substring(sensor.loc, 8, 9))
rm(prefix, sensor.loc)
# number of characters used in date/time variable
dtlen <- nchar(df$datetime)
# print out any records with missing date/time information
df[dtlen==0, ]
# create new date/time variable, with corrected times in the format "2011-07-14 16:15:00"
# it looks like records with date/time length ranging from 13 to 16 are all formatted "7/14/2011 16:15"
# and those with date/time length 20 are all formatted "07/14/11 04:15:00 PM"
dt <- rep("", length(dtlen))
dt[dtlen > 12 & dtlen < 17] <- as.character(strptime(df$datetime[dtlen > 12 & dtlen < 17], "%m/%d/%Y %H:%M"))
dt[dtlen > 19] <- as.character(strptime(df$datetime[dtlen > 19], "%m/%d/%y %I:%M:%S %p"))
date.time <- strsplit(dt, " ")
just.date <- sapply(date.time, "[", 1)
just.time <- strsplit(sapply(date.time, "[", 2), ":")
hh <- sapply(just.time, "[", 1)
mm <- sapply(just.time, "[", 2)
dummy <- rep(1, length(mm))
recordsperhr <- aggregate(dummy ~ site + location + sensor + hh, sum, data=df)
dim(recordsperhr)
recordsperhr
head(df)
recordsperday <- aggregate(dummy ~ site + location + sensor + just.date, sum, data=df)
recordsperday
table(recordsperday$dummy)
head(df)
head(df.good)
head(df.long)
head(recordsperday)
# read in sunrise/sunset data
fiddler <- read.csv(usethesefiles["fiddler"], as.is=TRUE, header=FALSE, skip=2, col.names=c("date", "rise", "set", "light.hrs"))
# fiddler$date looks like this:"7/10/2010"
# fiddler$rise and set look like this:"20:24"
fiddler$sunrise <- strptime(paste(fiddler$date, fiddler$rise), "%m/%d/%Y %H:%M")
fiddler$sunset <- strptime(paste(fiddler$date, fiddler$set), "%m/%d/%Y %H:%M")
fiddler$just.date <- substring(as.character(fiddler$sunrise), 1, 10)
head(fiddler)
q()
cleanup()
ls()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
q()
pkgin("LW1949")
search()
detach()
search()
utils:::menuInstallLocal()
cleanup()
q()
pkgin("LW1949")
cleanup()
q()
# bring in the data
library(XLConnect)
wb <- loadWorkbook("C:/JVA/Consult/Bunnell/Shunt/dreissenid densities by ponar.xlsx")
dat <- readWorksheet(wb, sheet=get.sheets(wb)[1], startRow=1)
get.sheets(wb)
?sheet
??sheet
getSheets(wb)
dat <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
head(dat)
summary(dat)
plotdf(dat)
class(dat$date)
plot(dat$date)
plot(sort(dat$date))
library(lubridate)
m <- month(dat$date)
plot(sort(dat$date), type="n")
text(sort(dat$date), m)
plot(sort(dat$date), sort(dat$date), type="n")
text(sort(dat$date), sort(dat$date), m)
table(m)
plot(dat$date, m)
dat[m==5, ]
dat$seas <- cut(m, c(3, 6, 8, 10), labels=c("spr", "sum", "fal")
)
head(dat)
?cut
dat$seas <- cut(m, c(3, 6, 8, 10), labels=c("spr", "sum", "fal"), ordered_result=TRUE)
?varcomp
#' Startup
#'
#' One function with all the commands I typically want run at the start of an R session.
#' @param maxp Integer scalar, maximum number of lines printed, default 500.
#' @param ndecInteger scalar, maximum width of fixed notation before switching to scientific notation, default 10. 
#' @param contCharacter scalar, prompt used for lines which continue past first command line, default \code{"... "}.
#' @param pkgsCharacter vector, packages to be loaded, default
#'\code{c("rJava", "XLConnect", "maps", "mapproj", "RColorBrewer", "mgcv", "jvamisc")}.
#' @param mirrorCharacter scalar, CRAN mirror, default \code{"http://streaming.stat.iastate.edu/CRAN/"}.
#' @param helptCharacter scalar, type of help, default "html".
#' @param facLogical scalar, use factors rather than character strings, default FALSE.
#' @param noplotsLogical scalar, remove "saved" plots, e.g., from past runs of \code{\link[jvamisc]{dfplot}}, default TRUE.
#' @param showLogical scalar, list objects in current environment, default TRUE.
#' @export
#' @seealso\code{\link{options}}, \code{\link{help}}.
#' @examplesjvaFirst()
jvaFirst <- function(
maxp=500, ndec=10, cont="... ",
pkgs = c("rJava", "XLConnect", "maps", "mapproj", "RColorBrewer", "mgcv", "MASS", "jvamisc"),
mirror="http://streaming.stat.iastate.edu/CRAN/", 
helpt="html", fac=FALSE, noplots=TRUE, show=TRUE) {
# don't print more than maxp rows
options(max.print=maxp)
# prefer long decimals rather than scientific notation
options(scipen=ndec)
# make it more obvious when line of code is continued on the next line
# from Tony Fischetti, http://www.onthelambda.com/2014/09/17/fun-with-rprofile-and-customizing-r-startup/
options(continue=cont)
# attach packages
sshhh <- function(a.package) suppressWarnings(suppressPackageStartupMessages(library(a.package, character.only=TRUE)))
sapply(pkgs, sshhh)
# set CRAN mirror
repo <- getOption("repos")
repo["CRAN"] <- mirror
options(repos=repo)
# prefer compiled HTML help
options(help_type=helpt)
# prefer characters rather than factors
options(stringsAsFactors=fac)
# get rid of any "saved" plots, e.g., from past runs of dfplot()
if(noplots) .SavedPlots <- NULL
# my personal functions
if(show) {
already <- ls(".GlobalEnv")
print(already)
}
}
.First
.First <- jvaFirst
.First()
q()
pkgin("artiFISHal")
q()
cleanup()
q()
pkgin("jvamisc")
cleanup()
q()
pkgin("jvamisc")
pkgman("jvamisc")
q()
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat
plotdf(dat)
head(dat)
attach(dat)
table(Sample, Rinse, Spiked_1)
dim(table(Sample, Rinse, Spiked_1))
dim(table(paste(Spiked_1, Sample), Rinse)
)
table(paste(Spiked_1, Sample), Rinse)
table(paste(Spiked_1, Sample, "-"), Rinse)
table(paste(Spiked_1, Sample, sep="-"), Rinse)
head(dat)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
ax2 <- prettylog(exp(Log_EC))
ax2
prettylog
ax2 <- prettylog(exp(Log_EC))
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, ylab="E. Coli concentration  (log scale)", axis=FALSE)
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, ylab="E. Coli concentration  (log scale)", axes=FALSE)
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=j+1, col=i, type="b", lwd=2)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
sus
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- c(0:3, 1:3)
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=i+1, type="b", lwd=2)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=i+1, type="b", lwd=2)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
search()
ls(4)
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
blindcolz
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", c("Shoreline wrack", "Spiked sample"), pch=suspch[j], col=blindcolz[i+1], lwd=2, lty=i)
legend("topright", c("Shoreline wrack", "Spiked sample"), col=blindcolz[1:2], lwd=2, lty=1:2)
q()
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
ax2 <- prettylog(exp(Log_EC))
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", c("Shoreline wrack", "Spiked sample"), col=blindcolz[2:3], lwd=2, lty=1:2)
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
ax2
ax2 <- prettylog(exp(Log_EC), 1:10, 10)
ax2
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
ax2 <- prettylog(exp(Log_EC), c(1, 2, 5), 10)
ax2
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
ax2 <- prettylog(exp(Log_EC), c(1, 2, 5))
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
head(dat)
search()
detach()
dat <- dat[order(dat$Spiked_1, dat$Sample, dat$Rinse), ]
dat
dat1 <- dat[dat$Rinse==1, ]
dat1
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
merge(dat, dat1[, c("Spiked_1", "Sample", "Rinse", "Log_EC1")])
merge(dat, dat1[, c("Spiked_1", "Sample", "Rinse", "Log_EC1")], all.x=TRUE)
dat
dat1[, c("Spiked_1", "Sample", "Rinse", "Log_EC1")]
merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
library(XLConnect)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
head(dat)
dat
search()
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
ax2 <- prettylog(exp(Log_EC), c(1, 2, 5))
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
windows()
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
windows()
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_ECDiff, type="n", xlab="Rinses  (number)", ylab="Change in E. Coli concentration  (log scale)")
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_ECDiff[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
library(XLConnect)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
dat
log(dat$ECProp)
library(XLConnect)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
windows()
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
search()
detach(3)
ax2 <- prettylog(ECProp, c(1, 2, 5))
windows()
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (proportion on log scale)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
windows()
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, ECProp, type="n", xlab="Rinses  (number)", ylab="E. Coli concentration  (proportion on log scale)")
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], ECProp[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
windows()
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
ax2 <- prettylog(ECProp, c(1, 2, 5))
windows()
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. Coli (proportional change in concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. Coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
search()
ls(4)
startrtf
?startrtf
date
date()
?date
Sys.Date
Sys.Date()
graphics.off()
cleanup()
search()
detach()
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
dstartrtf
## Not run: 
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
para("First paragraph.")
tab <- head(cars)
tabl("First few rows of cars data.", row.names=FALSE)
heading("Heading 2", 2)
para("Second paragraph.")
fig <- function() {
plot(cars)
lo <- loess(cars$dist ~ cars$speed)
lines(lo$x, lo$fitted)
}
figu("Speed vs. distance from the cars data.")
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. Coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates"
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).", 
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. Coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. Coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. Coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. Coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates"
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).", 
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. Coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. Coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. Coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. Coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates"
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).", 
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. Coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. Coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. Coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. Coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).", 
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. Coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. Coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. Coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. Coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).")
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. Coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. Coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. Coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. Coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).")
tab <- tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
tabl("E. Coli concentrations (natural log transformed) after 1 to 8 rinses from a single spiked sample(LV1, LV2, LV3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3).")
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. Coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. Coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. Coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
tab
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. Coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).")
tab <- tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
attach(dat)
tab <- tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
tab
search()
detach()
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. Coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).")
attach(dat)
tab <- tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
tabl("E. Coli concentrations (natural log transformed) after 1 to 8 rinses from a single spiked sample(LV1, LV2, LV3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3).")
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. Coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. Coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. Coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. Coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).")
attach(dat)
tab <- tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
tabl("E. Coli concentrations (natural log transformed) after 1 to 8 rinses from a single spiked sample(LV1, LV2, LV3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3).")
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. Coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. Coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. Coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. Coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).")
attach(dat)
tab <- tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
tabl("E. coli concentrations (natural log transformed) after 1 to 8 rinses from a single spiked sample(LV1, LV2, LV3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3).  Rinses are in columns, samples are in rows.")
attach(dat)
tapply(!is.na(Log_EC), list(paste(Spiked_1, Sample, sep="-"), Rinse), sum)
tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
search()
detach()
detach()
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).")
attach(dat)
tab <- tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
tabl("E. coli concentrations (natural log transformed) after 1 to 8 rinses from a single spiked sample(LV1, LV2, LV3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3).  Rinses are in columns, samples are in rows.")
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
search()
detach()
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).")
attach(dat)
tab <- tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean)
tabl("E. coli concentrations (natural log transformed) after 1 to 8 rinses from a single spiked sample(LV1, LV2, LV3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3).  Rinses are in columns, samples are in rows.")
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
tab
format(tab)
?format.default
format(tab, na.encode="-")
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).")
attach(dat)
tab <- format(tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean))
tabl("E. coli concentrations (natural log transformed) after 1 to 8 rinses from a single spiked sample(LV1, LV2, LV3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3).  Rinses are in columns, samples are in rows.")
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).")
attach(dat)
tab <- format(tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean))
tabl("E. coli concentrations (natural log transformed) after 1 to 8 rinses from a single spiked sample(LV1, LV2, LV3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3).  Rinses are in columns, samples are in rows.")
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. coli concentrations versus number of rinses from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample(LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
# C:\JVA\Consult\Przybyla-Kelly\Rinsing\Rinse.r
library(XLConnect)
doc <- startrtf(file=paste0(Sys.Date(), "Rinsing"), dir="C:/JVA/Consult/Przybyla-Kelly/Rinsing")
heading("Visualize Sequential Rinsing Data from Kasia Przybyla-Kelly")
heading(paste0(Sys.Date(), " - Jean V. Adams"), 2)
# read in the data
wb <- loadWorkbook("C:/JVA/Consult/Przybyla-Kelly/Rinsing/Sequential rinsing.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1])
rm(wb)
dat1 <- dat[dat$Rinse==1, ]
dat1$Log_EC1 <- dat1$Log_EC
dat <- merge(dat, dat1[, c("Spiked_1", "Sample", "Log_EC1")], all.x=TRUE)
dat$EC <- exp(dat$Log_EC)
dat$Log_ECDiff <- dat$Log_EC - dat$Log_EC1
dat$ECProp <- dat$EC/exp(dat$Log_EC1)
para("I am assuming that the E. coli data included in the spreadsheet ** Sequential rinsing.xlsx ** are natural log transformed,",
" not log10 transformed.")
para("E. coli concentrations were taken from a single spiked sample and four field field samples (shoreline wrack).",
"  The spiked sample was created from the shoreline wrack of LV beach, homogenized, split into 3 replicates",
" (LV1, LV2, LV3) and each replicate was spiked with same E. coli concentration.",
"  Spiked samples were rinsed 7 times, and E. coli after each rinse was measured.",
"  The field samples included LS1, PL1, PL2, PL3.  All were analysed for E. coli concentrations.",  
"  Each was rinsed multiple times in order to get subsequent E. coli concentrations in a series of sequential rinsing.",  
"  Each sample had a different initial E. coli concentration, and each had different amount of rinses (4-8).")
attach(dat)
tab <- format(tapply(Log_EC, list(paste(Spiked_1, Sample, sep="-"), Rinse), mean))
tabl("E. coli concentrations (natural log transformed) after 1 to 8 rinses from a single spiked sample(LV1, LV2, LV3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3).  Rinses are in columns, samples are in rows.")
sug <- sort(unique(Spiked_1))
sus <- sort(unique(Sample))
suspch <- as.character(c(0:3, 1:3))
ax2 <- prettylog(EC, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, Log_EC, type="n", xlab="Rinses  (number)", ylab="E. coli  (concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], Log_EC[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("E. coli concentrations versus number of rinses from a single spiked sample (LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
ax2 <- prettylog(ECProp, c(1, 2, 5))
fig <- function() {
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rinse, log(ECProp), type="n", xlab="Rinses  (number)", ylab="E. coli (proportional change from initial concentration)", axes=FALSE)
for(i in seq(sug)) {
for(j in seq(sus)) {
sel <- Spiked_1 == sug[i] & Sample == sus[j]
if(sum(sel)>0) {
points(Rinse[sel], log(ECProp)[sel], pch=suspch[j], col=blindcolz[i+1], type="b", lwd=2, lty=i)
}
}}
axis(1)
axis(2, at=log(ax2), labels=ax2)
box()
legend("topright", rev(c("Shoreline wrack", "Spiked sample")), col=rev(blindcolz[2:3]), lwd=2, lty=rev(1:2))
}
figu("Proportional change in E. coli concentrations from the first rinse versus number of rinses",
" from a single spiked sample (LV1, LV2, LV3, plot characters 1-3)",
" and four field field samples (shoreline wrack LS1, PL1, PL2, PL3, plot characters 0-3).", h=6.5, w=6.5, newpage="port")
endrtf()
detach(dat)
cleanup()
q()
pkgin("artiFISHal")
?SimFish
cleanup()
q()
dfclip()
df <- dfclip()
df
dput(df)
delta <- df$row.names[-1] - df$row.names[-length(df$row.names)]
delta
first(delta)
first(delta) & delta==1
cumsum(first(delta) & delta==1)
cumsum(last(delta) & delta==1)
fdelta[delta==1]
fdelta <- first(delta)
fdelta[delta==1]
cumsum(fdelta[delta==1])
cleanup()
q()
main=structure(list(ID = c(1L, 1L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 4L), 
Diff = c(10L, 10L, 11L, 11L, 11L, 12L, 12L, 12L, 13L, 23L
), players = structure(c(1L, 2L, 2L, 1L, 1L, 3L, 4L, 3L, 
4L, 4L), .Label = c("A", "B", "C", "D"), class = "factor"), 
win = c(0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L)), .Names = c("ID", 
"Diff", "players", "win"), class = "data.frame", row.names = c(NA, 
-10L))
names1=structure(list(A = c(TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE), B = c(FALSE, TRUE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE), C = c(FALSE, FALSE, FALSE, 
FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE), D = c(FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE)), .Names = c("A", 
"B", "C", "D"), class = "data.frame", row.names = c(NA, -10L))
mat=structure(list(A = c(TRUE, NA, NA, NA, TRUE, NA, FALSE, FALSE, 
NA, NA), B = c(FALSE, NA, NA, NA, FALSE, NA, FALSE, FALSE, NA, 
NA), C = c(FALSE, NA, NA, NA, FALSE, NA, FALSE, TRUE, NA, NA), 
D = c(FALSE, NA, NA, NA, FALSE, NA, TRUE, FALSE, NA, NA)), .Names = c("A", 
"B", "C", "D"), class = "data.frame", row.names = c(NA, -10L))
p<-c(1,5,7,8)
c<-p
colnames(mat)<-names(names1)
mat[c,]<-names1[c,]
n_media<-4
r<-rep(0.5,n_media)
q<-which(is.na(mat[,1]))
main
names1
mat
ls()
cleanup()
main=structure(list(ID = c(1L, 1L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 4L), 
Diff = c(10L, 10L, 11L, 11L, 11L, 12L, 12L, 12L, 13L, 23L
), players = structure(c(1L, 2L, 2L, 1L, 1L, 3L, 4L, 3L, 
4L, 4L), .Label = c("A", "B", "C", "D"), class = "factor"), 
win = c(0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L)), .Names = c("ID", 
"Diff", "players", "win"), class = "data.frame", row.names = c(NA, 
-10L))
names1=structure(list(A = c(TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE), B = c(FALSE, TRUE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE), C = c(FALSE, FALSE, FALSE, 
FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE), D = c(FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE)), .Names = c("A", 
"B", "C", "D"), class = "data.frame", row.names = c(NA, -10L))
mat=structure(list(A = c(TRUE, NA, NA, NA, TRUE, NA, FALSE, FALSE, 
NA, NA), B = c(FALSE, NA, NA, NA, FALSE, NA, FALSE, FALSE, NA, 
NA), C = c(FALSE, NA, NA, NA, FALSE, NA, FALSE, TRUE, NA, NA), 
D = c(FALSE, NA, NA, NA, FALSE, NA, TRUE, FALSE, NA, NA)), .Names = c("A", 
"B", "C", "D"), class = "data.frame", row.names = c(NA, -10L))
p<-c(1,5,7,8)
colnames(mat)<-names(names1)
mat[p,]<-names1[p,]
r<-rep(0.5,4)
q<-which(is.na(mat[,1]))
main
names1
mat
p
r
q
repeat
{
    p<-p+1
    p<-intersect(q,p)
    l<-main[p,"Diff"]-main[p-1,"Diff"]
    k <- t(outer(r, l, "^"))
    mat[p,]<-mat[p-1,]*k+names1[p,]
    q<-which(is.na(mat[,1]))
    if(length(q)==0)break
}
ls()
l
k
mat
q()
cleanup()
df <- dfclip()
df
cumsum(rev(table(table(cumsum(c(TRUE,diff(df$row.names)!=1))))))
diff(df$row.names)
diff(df$row.names)!=1
(cumsum(c(TRUE,diff(df$row.names)!=1)))
table(cumsum(c(TRUE,diff(df$row.names)!=1)))
table(table(cumsum(c(TRUE,diff(df$row.names)!=1))))
rev(table(table(cumsum(c(TRUE,diff(df$row.names)!=1)))))
cumsum(rev(table(table(cumsum(c(TRUE,diff(df$row.names)!=1))))))
cumsum(c(TRUE,diff(df$row.names)!=1))
dim(df)
cumsum(c(TRUE,diff(df$row.names)!=1)) & diff(df$row
delta <- c(TRUE,diff(df$row.names)!=1)
cumsum(delta)[delta==1]
delta <- c(TRUE,diff(df$row.names)!=1)
cumsum(delta)[delta==1]
cumsum(delta)
delta
cumsum(delta[delta==1])
delta[delta==1]
delta
delta <- c(NA, diff(df$row.names))
delat
delta
delta <- c(0, diff(df$row.names))
cumsum(delta==1)
delta
cumsum(delta!=1)
cbind(delta, cumsum(delta!=1))
delta <- c(0, diff(df$row.names))
tally <- cumsum(delta!=1)
tally[delta==1]
table(tally[delta==1])
table(table(tally[delta==1]))
df$row.names
cbind(df$row.names, delta, tally)
table(tally[delta==1])
table(tally[delta==1])+1
table(table(tally[delta==1])+1)
tmp <- table(rle(cumsum(c(1L, diff(df$row.names)) != 1L))$lengths)
cumsum(rev(tmp))
dput(df)
cleanup()
df <- structure(list(
row.names = c(51L, 52L, 64L, 65L, 66L, 77L, 78L, 84L, 85L, 117L), 
Tx = c(33.9, 33, 32.8, 32.7, 34.9, 33.6, 34.6, 32.9, 35.1, 32), 
Hx = c(43.48, 41.03, 37.74, 44.53, 42.43, 38.74, 45.46, 41.67, 43.15, 37.11), 
Tn = c(24.9, 22.5, 23.3, 22.3, 23.5, 21.8, 27.1, 24.1, 25, 20)), 
.Names = c("row.names", "Tx", "Hx", "Tn"), class = "data.frame", 
row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))
delta <- c(0, diff(df$row.names))
tally <- cumsum(delta!=1)
table(table(tally[delta==1])+1)
table(table(tally[delta==1])+1)
count[names(count) %in% c(2, 3)]
count <- table(table(tally[delta==1])+1)
count[names(count) %in% c(2, 3)]
twoplus <- sum(count[names(count) %in% c(2, 3)])
df <- structure(list(
row.names = c(51L, 52L, 64L, 65L, 66L, 77L, 78L, 84L, 85L, 117L), 
Tx = c(33.9, 33, 32.8, 32.7, 34.9, 33.6, 34.6, 32.9, 35.1, 32), 
Hx = c(43.48, 41.03, 37.74, 44.53, 42.43, 38.74, 45.46, 41.67, 43.15, 37.11), 
Tn = c(24.9, 22.5, 23.3, 22.3, 23.5, 21.8, 27.1, 24.1, 25, 20)), 
.Names = c("row.names", "Tx", "Hx", "Tn"), class = "data.frame", 
row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))
delta <- c(0, diff(df$row.names))
tally <- cumsum(delta!=1)
count <- table(table(tally[delta==1])+1)
twoplus <- sum(count[names(count) > 1.999])
threeplus <- sum(count[names(count) > 2.999])
twoplus
threeplus
cleanup()
q()
dat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/Nomo1Digi.csv")
dat
head(dat)
dat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/Nomo1Digi.csv")
A <- c(0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5, 10, 20, 30, 50)
ya <- dat$y1[dat$group==1]
plot(ya, A)
length(ya)
length(A)
plot(ya)
plot(rep(1, length(ya)), ya)
ya
A
plot(rep(1, length(ya)), ya, log="y")
signif(ya, 1)
ya
A
signif(ya, 1)
length(ya)
length(A)
dfclip()
dat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/Nomo1Digi.csv")
A <- c(0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5, 10, 20, 30, 50)
ya <- dat$y1[dat$group==1]
plot(ya, A)
plot(log(ya), A)
A <- c(0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5, 10, 20, 30, 50)
ya <- log(dat$y1[dat$group==1])
plot(ya, A)
plot(A, ya)
plot(A, ya)
lines(A, log(A))
lines(A, log10(A))
lines(A, sqrt(A))
plot(log(A), ya)
abline(lsfit(log(A), ya))
fit <- lm(log(A) ~ ya)
summary(fit)
logit
logit2prob
search()
ls(3)
??logit
library(boot)
?logit
A
logit(A/100)
plot(logit(A/100), ya)
??probit
B <- c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50)
yb <- log(dat$y1[dat$group==2])
length(B)
length(yb)
B <- c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50)
yb <- log(dat$y1[dat$group==2])
plot(log(B), yb)
abline(lsfit(log(B), yb))
summary(lm(log(B) ~ yb))
C <- c(0.001, 0.002, 0.003, 0.004, 0.005, 
0.01, 0.02, 0.03, 0.04, 0.05, 
0.1, 0.2, 0.3, 0.4, 0.5, 1, 2)
yc <- log(dat$y1[dat$group==3])
plot(log(C), yc)
abline(lsfit(log(C), yc))
summary(lm(log(C) ~ yc))
=2*.346
2*.346
.692 + .27
3.56+.91
2*.91/.96
exp(4.47)
1/exp(4.47)
# C:\JVA\Lamprey\ChemControl\Toxicity\Nomo1.r
dat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/Nomo1Digi.csv")
A <- c(0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5, 10, 20, 30, 50)
ya <- log(dat$y1[dat$group==1])
plot(log(A), ya)
abline(lsfit(log(A), ya))
summary(lm(log(A) ~ ya))
B <- c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50)
yb <- log(dat$y1[dat$group==2])
plot(log(B), yb)
abline(lsfit(log(B), yb))
summary(lm(log(B) ~ yb))
C <- c(0.001, 0.002, 0.003, 0.004, 0.005, 
0.01, 0.02, 0.03, 0.04, 0.05, 
0.1, 0.2, 0.3, 0.4, 0.5, 1, 2)
yc <- log(dat$y1[dat$group==3])
plot(log(C), yc)
abline(lsfit(log(C), yc))
summary(lm(log(C) ~ yc))
0.9095632 + 2 * 0.0006336
0.9112315 - 2 * 0.0006751
0.9112315 + 0.9095632
(0.9112315 + 0.9095632)
(0.9112315 + 0.9095632)/2
log(B)/(0.91*yb)
CI(log(B)/(0.91*yb))
CI(log(C)/(0.91*yc))
length(A)
length(B)
length(C)
sel <- c(1, length(A))
summary(lm(log(A[sel]) ~ ya[sel]))
sel <- c(1, length(B))
summary(lm(log(B[sel]) ~ yb[sel]))
sel <- c(1, length(C))
summary(lm(log(C[sel]) ~ yc[sel]))
2*.346/.91
.27/.96
76+28
CI(log(B)-(0.91*yb))
CI(log(C)-(0.91*yc))
CI(log(A)-(0.91*ya))
CI(log(B)-(0.91*yb))
CI(log(C)-(0.91*yc))
CI(log(A)-(0.91*ya))
CI(log(B)-(0.91*yb))
CI(log(C)-(0.91*yc))
log(100) - 2*0.3461 - 3.5573
newya <- (log(A) + 0.35567)/0.91
newyb <- (log(B) - 0.3461)/0.91
newyc <- (log(C) + 3.5573)/0.91
windows()
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
points(rep(1, length(newya)), newya)
text(rep(1, length(newya)), newya, A, pos=2)
points(rep(2, length(newyb)), newyb)
text(rep(2, length(newyb)), newyb, B, pos=2)
points(rep(3, length(newyc)), newyc)
text(rep(3, length(newyc)), newyc, C, pos=2)
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
points(rep(1, length(newya)), newya)
text(rep(1, length(newya)), newya, A, pos=4)
points(rep(2, length(newyb)), newyb)
text(rep(2, length(newyb)), newyb, B, pos=4)
points(rep(3, length(newyc)), newyc)
text(rep(3, length(newyc)), newyc, C, pos=4)
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
points(rep(0.9, length(ya)), ya, col="red", pch=3)
points(rep(1, length(newya)), newya)
text(rep(1, length(newya)), newya, A, pos=4)
points(rep(1.9, length(yb)), yb, col="red", pch=3)
points(rep(2, length(newyb)), newyb)
text(rep(2, length(newyb)), newyb, B, pos=4)
points(rep(2.9, length(yc)), yc, col="red", pch=3)
points(rep(3, length(newyc)), newyc)
text(rep(3, length(newyc)), newyc, C, pos=4)
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
points(rep(0.9, length(ya)), ya, col="red")
points(rep(1, length(newya)), newya, pch=3, type="l")
text(rep(1, length(newya)), newya, A, pos=4)
points(rep(1.9, length(yb)), yb, col="red")
points(rep(2, length(newyb)), newyb, pch=3, type="l")
text(rep(2, length(newyb)), newyb, B, pos=4)
points(rep(2.9, length(yc)), yc, col="red")
points(rep(3, length(newyc)), newyc, pch=3, type="l")
text(rep(3, length(newyc)), newyc, C, pos=4)
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
points(rep(1, length(ya)), ya, col="red")
points(rep(1, length(newya)), newya, pch=3, type="o")
text(rep(1, length(newya)), newya, A, pos=4)
points(rep(2, length(yb)), yb, col="red")
points(rep(2, length(newyb)), newyb, pch=3, type="o")
text(rep(2, length(newyb)), newyb, B, pos=4)
points(rep(3, length(yc)), yc, col="red")
points(rep(3, length(newyc)), newyc, pch=3, type="o")
text(rep(3, length(newyc)), newyc, C, pos=4)
showmarks()
??show.marks
??show
showmarks <- function() {
cat("for more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
windows(h=9)
par(mar=rep(1, 4))
n <- c(6, 25, 8, 30, 30)
plot(c(1, 10), -c(1, 15), type="n", xlab="", ylab="", axes=F)
for(i in 1:n[1]) lines(c(1, 10), -rep(i, 2), lty=i, cex=3, lwd=3)
x <- rep(1:10, 3)
y <- rep(7:9, rep(10, 3))
for(i in 1:n[2]) points(x[i], -y[i], pch=i, cex=3)
x <- rep(1:10, 3)
y <- rep(10:11, rep(10, 2))
for(i in 1:n[3]) points(x[i], -y[i], pch=15, cex=5, col=i)
y <- rep(11:13, rep(10, 3))
cols <- rainbow(30)
for(i in 1:n[4]) points(x[i], -y[i], pch=15, cex=5, col=cols[i])
y <- rep(14:15, rep(10, 2))
for(i in 1:n[5]) text(x[i], -y[i], "Font", font=i)
}
showmarks()
search()
ls(4)
blindcolz
showmarks <- function() {
cat("For more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
par(mar=rep(1, 4))
n <- c(6, 25, 8, 30, 30)
plot(c(1, 10), -c(1, 15), type="n", xlab="", ylab="", axes=F)
for(i in 1:n[1]) lines(c(1, 10), -rep(i, 2), lty=i, cex=3, lwd=3)
x <- rep(1:10, 3)
y <- rep(7:9, rep(10, 3))
for(i in 1:n[2]) points(x[i], -y[i], pch=i, cex=3)
x <- rep(1:10, 3)
y <- rep(10:11, rep(10, 2))
for(i in 1:n[3]) points(x[i], -y[i], pch=15, cex=5, col=i)
y <- rep(11:13, rep(10, 3))
cols <- rainbow(30)
cols <- blindcolz
for(i in 1:n[4]) points(x[i], -y[i], pch=15, cex=5, col=cols[i])
y <- rep(14:15, rep(10, 2))
for(i in 1:n[5]) text(x[i], -y[i], "Font", font=i)
}
showmarks()
for(i in 1:n[4]) points(x[i], -y[i], pch=15, cex=5, col=cols[i], bg="yellow")
n <- c(6, 25, 8, 30, 30)
for(i in 1:n[4]) points(x[i], -y[i], pch=15, cex=5, col=cols[i], bg="yellow")
x <- rep(1:10, 3)
for(i in 1:n[4]) points(x[i], -y[i], pch=15, cex=5, col=cols[i], bg="yellow")
y <- rep(11:13, rep(10, 3))
for(i in 1:n[4]) points(x[i], -y[i], pch=15, cex=5, col=cols[i], bg="yellow")
cols <- blindcolz
for(i in 1:n[4]) points(x[i], -y[i], pch=15, cex=5, col=cols[i], bg="yellow")
?points
for(i in 1:n[4]) points(x[i], -y[i], pch=22, cex=5, col=cols[i], bg="yellow")
for(i in 1:n[4]) points(x[i], -y[i], pch=22, cex=5, bg=cols[i], col="yellow")
for(i in 1:n[4]) points(x[i], -y[i], pch=22, cex=5, bg=cols[i])
for(i in 1:n[4]) points(x[i], -y[i], pch=22, cex=5, bg=cols[i], lwd=2)
#' Show Marks
#'
#' Show marks used in graphing, including line types, plotting symbols, default colors, color blind friendly colors (`blindcolz`), and fonts.
#' @export
#' @examples 
#' showmarks()
showmarks <- function() {
cat("For more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
par(mar=rep(1, 4))
n <- c(6, 25, 8, 30, 30)
plot(c(1, 10), -c(1, 15), type="n", xlab="", ylab="", axes=F)
for(i in 1:n[1]) lines(c(1, 10), -rep(i, 2), lty=i, cex=3, lwd=3)
x <- rep(1:10, 3)
y <- rep(7:9, rep(10, 3))
for(i in 1:n[2]) points(x[i], -y[i], pch=i, cex=3)
x <- rep(1:10, 3)
y <- rep(10:11, rep(10, 2))
for(i in 1:n[3]) points(x[i], -y[i], pch=22, cex=5, bg=i)
y <- rep(11:13, rep(10, 3))
cols <- blindcolz
for(i in 1:n[4]) points(x[i], -y[i], pch=22, cex=5, bg=cols[i])
y <- rep(14:15, rep(10, 2))
for(i in 1:n[5]) text(x[i], -y[i], "Font", font=i)
}
showmarks()
windows()
showmarks()
showmarks <- function() {
cat("For more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
par(mar=rep(1, 4))
n <- c(6, 25, 8, length(blindcolz), 30)
plot(c(1, 10), -c(1, 15), type="n", xlab="", ylab="", axes=F)
for(i in 1:n[1]) lines(c(1, 10), -rep(i, 2), lty=i, cex=3, lwd=3)
x <- rep(1:10, 3)
y <- rep(7:9, rep(10, 3))
for(i in 1:n[2]) points(x[i], -y[i], pch=i, cex=3)
x <- rep(1:10, 3)
y <- rep(10:11, rep(10, 2))
for(i in 1:n[3]) points(x[i], -y[i], pch=22, cex=5, bg=i)
y <- rep(11:13, rep(10, 3))
cols <- blindcolz
for(i in 1:n[4]) points(x[i], -y[i], pch=22, cex=5, bg=cols[i])
y <- rep(14:15, rep(10, 2))
for(i in 1:n[5]) text(x[i], -y[i], "Font", font=i)
}
showmarks()
showmarks <- function() {
cat("For more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
par(mar=rep(1, 4))
n <- c(6, 25, 10, length(blindcolz), 30)
plot(c(1, 10), -c(1, 15), type="n", xlab="", ylab="", axes=F)
for(i in 1:n[1]) lines(c(1, 10), -rep(i, 2), lty=i, cex=3, lwd=3)
x <- rep(1:10, 3)
y <- rep(7:9, rep(10, 3))
for(i in 1:n[2]) points(x[i], -y[i], pch=i, cex=3)
x <- rep(1:10, 3)
y <- rep(10:11, rep(10, 2))
for(i in 1:n[3]) points(x[i], -y[i], pch=22, cex=5, bg=i)
y <- rep(11:13, rep(10, 3))
cols <- blindcolz
for(i in 1:n[4]) points(x[i], -y[i], pch=22, cex=5, bg=cols[i])
y <- rep(14:15, rep(10, 2))
for(i in 1:n[5]) text(x[i], -y[i], "Font", font=i)
}
showmarks()
n[2]/10
ceiling(n/10)
cat("For more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
par(mar=rep(1, 4))
# number of marks in each group
n <- c(6, 25, 8, length(blindcolz), 30)
# number of rows for the marks in each group
rowsn <- ceiling(n/10)
rowsn[1] <- n[1]
rowsn
seq(rowsn)
lapply(rowsn, seq)
unlist(lapply(rowsn, seq))
cumsum(unlist(lapply(rowsn, seq)))
rep(1:length(rowsn), rowsn)
groupn <- rep(1:length(rowsn), rowsn)
groupn
length(groupn)
match(1, groupn)
match(groupn, 1)
groupn==1
rowsn
rowz <- 1:length(groupn)
rowz
rowz
rowz[groupn==1]
groupn
rowz[groupn==2]
rowsn
#' Show Marks
#'
#' Show marks used in graphing, including line types, plotting symbols, default colors, color blind friendly colors (`blindcolz`), and fonts.
#' @export
#' @examples 
#' showmarks()
showmarks <- function() {
cat("For more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
par(mar=rep(1, 4))
# number of marks in each group
n <- c(6, 25, 8, length(blindcolz), 30)
# number of rows for the marks in each group
rowsn <- ceiling(n/10)
rowsn[1] <- n[1]
groupn <- rep(1:length(rowsn), rowsn)
rowz <- 1:length(groupn)
plot(c(1, 10), -rowz, type="n", xlab="", ylab="", axes=F)
for(i in rowz[groupn==1]) lines(c(1, 10), -rep(i, 2), lty=i, cex=3, lwd=3)
x <- rep(1:10, 3)
y <- rep(rowz[groupn==2], rep(10, rowsn[2]))
for(i in rowz[groupn==2]) points(x[i], -y[i], pch=i, cex=3)
y <- rep(rowz[groupn==3], rep(10, rowsn[3]))
for(i in rowz[groupn==3]) points(x[i], -y[i], pch=22, cex=5, bg=i)
y <- rep(rowz[groupn==4], rep(10, rowsn[4]))
for(i in rowz[groupn==4]) points(x[i], -y[i], pch=22, cex=5, bg=blindcolz[i])
y <- rep(rowz[groupn==5], rep(10, rowsn[5]))
for(i in rowz[groupn==5]) text(x[i], -y[i], "Font", font=i)
}
cat("For more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
par(mar=rep(1, 4))
# number of marks in each group
n <- c(6, 25, 8, length(blindcolz), 30)
# number of rows for the marks in each group
rowsn <- ceiling(n/10)
rowsn[1] <- n[1]
groupn <- rep(1:length(rowsn), rowsn)
rowz <- 1:length(groupn)
plot(c(1, 10), -rowz, type="n", xlab="", ylab="", axes=F)
for(i in rowz[groupn==1]) lines(c(1, 10), -rep(i, 2), lty=i, cex=3, lwd=3)
x <- rep(1:10, 3)
y <- rep(rowz[groupn==2], rep(10, rowsn[2]))
for(i in rowz[groupn==2]) points(x[i], -y[i], pch=i, cex=3)
y <- rep(rowz[groupn==3], rep(10, rowsn[3]))
for(i in rowz[groupn==3]) points(x[i], -y[i], pch=22, cex=5, bg=i)
y <- rep(rowz[groupn==4], rep(10, rowsn[4]))
for(i in rowz[groupn==4]) points(x[i], -y[i], pch=22, cex=5, bg=blindcolz[i])
y <- rep(rowz[groupn==5], rep(10, rowsn[5]))
for(i in rowz[groupn==5]) text(x[i], -y[i], "Font", font=i)
rowz
range(rowz)
cat("For more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
par(mar=rep(1, 4))
# number of marks in each group
n <- c(6, 25, 8, length(blindcolz), 30)
# number of rows for the marks in each group
rowsn <- ceiling(n/10)
rowsn[1] <- n[1]
groupn <- rep(1:length(rowsn), rowsn)
rowz <- 1:length(groupn)
plot(c(1, 10), -range(rowz), type="n", xlab="", ylab="", axes=F)
for(i in rowz[groupn==1]) lines(c(1, 10), -rep(i, 2), lty=i, cex=3, lwd=3)
x <- rep(1:10, 3)
y <- rep(rowz[groupn==2], rep(10, rowsn[2]))
for(i in rowz[groupn==2]) points(x[i], -y[i], pch=i, cex=3)
y <- rep(rowz[groupn==3], rep(10, rowsn[3]))
for(i in rowz[groupn==3]) points(x[i], -y[i], pch=22, cex=5, bg=i)
y <- rep(rowz[groupn==4], rep(10, rowsn[4]))
for(i in rowz[groupn==4]) points(x[i], -y[i], pch=22, cex=5, bg=blindcolz[i])
y <- rep(rowz[groupn==5], rep(10, rowsn[5]))
for(i in rowz[groupn==5]) text(x[i], -y[i], "Font", font=i)
rep(rowz[groupn==5], rep(10, rowsn[5]))
rep(14:15, rep(10, 2))
x <- rep(1:10, 3)
y <- rep(rowz[groupn==2], rep(10, rowsn[2]))
for(i in seq(y)) points(x[i], -y[i], pch=i,  cex=3)
cat("For more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
par(mar=rep(1, 4))
# number of marks in each group
n <- c(6, 25, 8, length(blindcolz), 30)
# number of rows for the marks in each group
rowsn <- ceiling(n/10)
rowsn[1] <- n[1]
groupn <- rep(1:length(rowsn), rowsn)
rowz <- 1:length(groupn)
plot(c(1, 10), -range(rowz), type="n", xlab="", ylab="", axes=F)
for(i in rowz[groupn==1]) lines(c(1, 10), -rep(i, 2), lty=i, cex=3, lwd=3)
x <- rep(1:10, 3)
y <- rep(rowz[groupn==2], rep(10, rowsn[2]))
for(i in seq(y)) points(x[i], -y[i], pch=i,  cex=3)
y <- rep(rowz[groupn==3], rep(10, rowsn[3]))
for(i in seq(y)) points(x[i], -y[i], pch=22, cex=5, bg=i)
y <- rep(rowz[groupn==4], rep(10, rowsn[4]))
for(i in seq(y)) points(x[i], -y[i], pch=22, cex=5, bg=blindcolz[i])
y <- rep(rowz[groupn==5], rep(10, rowsn[5]))
for(i in seq(y))   text(x[i], -y[i], "Font", font=i)
x <- rep(1:10, 3)
y <- rep(rowz[groupn==2], rep(10, rowsn[2]))
for(i in seq(y)) points(x[i], -y[i], pch=i,  cex=3)
x
y
rowzn
rowz
rowsn
y
seq(y)
rowz[groupn==1]\
rowz[groupn==1]
cat("For more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
par(mar=rep(1, 4))
# number of marks in each group
n <- c(6, 25, 8, length(blindcolz), 30)
# number of rows for the marks in each group
rowsn <- ceiling(n/10)
rowsn[1] <- n[1]
groupn <- rep(1:length(rowsn), rowsn)
rowz <- 1:length(groupn)
plot(c(1, 10), -range(rowz), type="n", xlab="", ylab="", axes=F)
for(i in 1:n[1]) lines(c(1, 10), -rep(i, 2), lty=i, cex=3, lwd=3)
x <- rep(1:10, max(rowsn[-1]))
y <- rep(rowz[groupn==2], rep(10, rowsn[2]))
for(i in 1:n[2]) points(x[i], -y[i], pch=i,  cex=3)
y <- rep(rowz[groupn==3], rep(10, rowsn[3]))
for(i in 1:n[3]) points(x[i], -y[i], pch=22, cex=5, bg=i)
y <- rep(rowz[groupn==4], rep(10, rowsn[4]))
for(i in 1:n[4]) points(x[i], -y[i], pch=22, cex=5, bg=blindcolz[i])
y <- rep(rowz[groupn==5], rep(10, rowsn[5]))
for(i in 1:n[5])   text(x[i], -y[i], "Font", font=i)
cat("For more color info see\nhttp://research.stowers-institute.org/efg/R/Color/Chart/index.htm\n")
par(mar=rep(1, 4))
# number of marks in each group
n <- c(6, 25, 8, length(blindcolz), 20)
# number of rows for the marks in each group
rowsn <- ceiling(n/10)
rowsn[1] <- n[1]
groupn <- rep(1:length(rowsn), rowsn)
rowz <- 1:length(groupn)
plot(c(1, 10), -range(rowz), type="n", xlab="", ylab="", axes=F)
for(i in 1:n[1]) lines(c(1, 10), -rep(i, 2), lty=i, cex=3, lwd=3)
x <- rep(1:10, max(rowsn[-1]))
y <- rep(rowz[groupn==2], rep(10, rowsn[2]))
for(i in 1:n[2]) points(x[i], -y[i], pch=i,  cex=3)
y <- rep(rowz[groupn==3], rep(10, rowsn[3]))
for(i in 1:n[3]) points(x[i], -y[i], pch=22, cex=5, bg=i)
y <- rep(rowz[groupn==4], rep(10, rowsn[4]))
for(i in 1:n[4]) points(x[i], -y[i], pch=22, cex=5, bg=blindcolz[i])
y <- rep(rowz[groupn==5], rep(10, rowsn[5]))
for(i in 1:n[5])   text(x[i], -y[i], "Font", font=i)
windows()
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
text(rep(0.9, length(ya)), ya, ">", col="red")
points(rep(1, length(ya)), ya, col="red")
points(rep(1, length(newya)), newya, pch=3, type="o")
text(rep(1, length(newya)), newya, A, pos=4)
#points(rep(2, length(yb)), yb, col="red")
points(rep(2, length(newyb)), newyb, pch=3, type="o")
text(rep(2, length(newyb)), newyb, B, pos=4)
#points(rep(3, length(yc)), yc, col="red")
points(rep(3, length(newyc)), newyc, pch=3, type="o")
text(rep(3, length(newyc)), newyc, C, pos=4)
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
text(rep(0.9, length(ya)), ya, ">", col="red")
text(rep(0.9, length(ya)), newya, A, pos=2, col="red")
points(rep(1, length(ya)), ya, col="red")
points(rep(1, length(newya)), newya, pch=3, type="o")
text(rep(1, length(newya)), newya, A, pos=4)
#points(rep(2, length(yb)), yb, col="red")
points(rep(2, length(newyb)), newyb, pch=3, type="o")
text(rep(2, length(newyb)), newyb, B, pos=4)
#points(rep(3, length(yc)), yc, col="red")
points(rep(3, length(newyc)), newyc, pch=3, type="o")
text(rep(3, length(newyc)), newyc, C, pos=4)
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
text(rep(0.9, length(ya)), ya, ">", col="red")
text(rep(0.9, length(ya)), ya, A, pos=2, col="red")
#points(rep(1, length(ya)), ya, col="red")
points(rep(1, length(newya)), newya, pch=3, type="o")
text(rep(1, length(newya)), newya, A, pos=4)
#points(rep(2, length(yb)), yb, col="red")
points(rep(2, length(newyb)), newyb, pch=3, type="o")
text(rep(2, length(newyb)), newyb, B, pos=4)
#points(rep(3, length(yc)), yc, col="red")
points(rep(3, length(newyc)), newyc, pch=3, type="o")
text(rep(3, length(newyc)), newyc, C, pos=4)
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
text(rep(0.9, length(ya)), ya, ">", col="red")
text(rep(0.9, length(ya)), ya, A, pos=2, col="red", cex=0.8)
#points(rep(1, length(ya)), ya, col="red")
points(rep(1, length(newya)), newya, pch=3, type="o")
text(rep(1, length(newya)), newya, A, pos=4)
#points(rep(2, length(yb)), yb, col="red")
points(rep(2, length(newyb)), newyb, pch=3, type="o")
text(rep(2, length(newyb)), newyb, B, pos=4)
#points(rep(3, length(yc)), yc, col="red")
points(rep(3, length(newyc)), newyc, pch=3, type="o")
text(rep(3, length(newyc)), newyc, C, pos=4)
newya-ya
windows()
hist(newya-ya)
hist(newya-ya, nclass=20)
sel <- abs(newya - ya) > 0.2
sel <- abs(newya - ya) > 0.2
windows()
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
text(rep(0.9, length(ya[sel])), ya[sel], ">", col="red")
text(rep(0.9, length(ya[sel])), ya[sel], A[sel], pos=2, col="red", cex=0.8)
#points(rep(1, length(ya)), ya, col="red")
points(rep(1, length(newya)), newya, pch=3, type="o")
text(rep(1, length(newya)), newya, A, pos=4)
#points(rep(2, length(yb)), yb, col="red")
points(rep(2, length(newyb)), newyb, pch=3, type="o")
text(rep(2, length(newyb)), newyb, B, pos=4)
#points(rep(3, length(yc)), yc, col="red")
points(rep(3, length(newyc)), newyc, pch=3, type="o")
text(rep(3, length(newyc)), newyc, C, pos=4)
cut <- 0.2
sel <- abs(newya - ya) > cut
windows()
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
text(rep(0.9, length(ya[sel])), ya[sel], ">", col="red")
text(rep(0.9, length(ya[sel])), ya[sel], A[sel], pos=2, col="red", cex=0.8)
#points(rep(1, length(ya)), ya, col="red")
points(rep(1, length(newya)), newya, pch=3, type="o")
text(rep(1, length(newya)), newya, A, pos=4)
#points(rep(2, length(yb)), yb, col="red")
points(rep(2, length(newyb)), newyb, pch=3, type="o")
text(rep(2, length(newyb)), newyb, B, pos=4)
#points(rep(3, length(yc)), yc, col="red")
points(rep(3, length(newyc)), newyc, pch=3, type="o")
text(rep(3, length(newyc)), newyc, C, pos=4)
cut <- 0.1
sel <- abs(newya - ya) > cut
windows()
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc))
text(rep(0.9, length(ya[sel])), ya[sel], ">", col="red")
text(rep(0.9, length(ya[sel])), ya[sel], A[sel], pos=2, col="red", cex=0.8)
#points(rep(1, length(ya)), ya, col="red")
points(rep(1, length(newya)), newya, pch=3, type="o")
text(rep(1, length(newya)), newya, A, pos=4)
#points(rep(2, length(yb)), yb, col="red")
points(rep(2, length(newyb)), newyb, pch=3, type="o")
text(rep(2, length(newyb)), newyb, B, pos=4)
#points(rep(3, length(yc)), yc, col="red")
points(rep(3, length(newyc)), newyc, pch=3, type="o")
text(rep(3, length(newyc)), newyc, C, pos=4)
plot(1, 1, type="n", xlim=c(0.5, 3.5), ylim=range(newya, newyb, newyc), xlab="", ylab="", axes=FALSE)
text(rep(0.9, length(ya[sel])), ya[sel], ">", col="red")
text(rep(0.9, length(ya[sel])), ya[sel], A[sel], pos=2, col="red", cex=0.8)
#points(rep(1, length(ya)), ya, col="red")
points(rep(1, length(newya)), newya, pch=3, type="o")
text(rep(1, length(newya)), newya, A, pos=4)
#points(rep(2, length(yb)), yb, col="red")
points(rep(2, length(newyb)), newyb, pch=3, type="o")
text(rep(2, length(newyb)), newyb, B, pos=4)
#points(rep(3, length(yc)), yc, col="red")
points(rep(3, length(newyc)), newyc, pch=3, type="o")
text(rep(3, length(newyc)), newyc, C, pos=4)
q()
cleanup()
?cheat
pkgup("jvamisc")
q()
