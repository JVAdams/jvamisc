dat[[i]]$FY <- trtyears[i]
}
dats <- do.call(rbind.fill, dat)
# combine Chem.Opt and Stream into a single field
dats$Chem.Opt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
dats <- dats[, -match("Stream", names(dats))]
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
dats$areaha <- as.numeric(dats$Area..ha.)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Cost
dats$days <- dats$Staff.Days
chemopt <- dats$Chem.Opt
chemopt <- gsub("-", " ", chemopt)
str <- sapply(strsplit(chemopt, " "), "[", 2)
dats[str > "99]", ]
ls()
head(base3)
base3[subdex(base3, year==2011), ]
sort(str
)
# combine Chem.Opt and Stream into a single field
chemopt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
# then fix chemopts
chemopt <- gsub("-", " ", chemopt)
str <- sapply(strsplit(chemopt, " "), "[", 2)
dats[str > "99]", ]
chemopt[str > "99]"] <- paste("[S 572]", chemopt[str > "99]"])
str <- sapply(strsplit(chemopt, " "), "[", 2)
sort(str)
str <- sapply(strsplit(chemopt, " "), "[", 3)
str
nchar(str)
str <- sapply(strsplit(chemopt, " "), "[", 2)
streamcode <- substring(str, 1, nchar(str)-1)
streamcode
lk <- sapply(strsplit(chemopt, " "), "[", 1)
sort(lk)
table(lk)
dats[lk=="[C", ]
substring(sapply(strsplit(chemopt, " "), "[", 1), 2, 2)
head(base3)
base3$uid
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
dats$areaha <- as.numeric(dats$Area..ha.)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Cost
dats$days <- dats$Staff.Days
# combine Chem.Opt and Stream into a single field
chemopt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
# then fix chemopts
chemopt <- gsub("-", " ", chemopt)
str <- sapply(strsplit(chemopt, " "), "[", 2)
dats[str > "99]", ]
chemopt[str > "99]"] <- paste("[S 572]", chemopt[str > "99]"])
str <- sapply(strsplit(chemopt, " "), "[", 2)
streamcode <- as.numeric(substring(str, 1, nchar(str)-1))
scode <- ifelse(streamcode>10000, streamcode-10000, streamcode)
agent <- ifelse(streamcode>10000, "FWS", "DFO")
lkcode <- recode(substring(sapply(strsplit(chemopt, " "), "[", 1), 2, 2), c("S", "M", "H", "E", "O", "C"), 1:6)
uid <- paste(lkcode, agent, format(scode), sep="-")
uid
ls()
match(base3$uid, uid)
base3[is.na(match(base3$uid, uid)), ]
comb[comb$uid=="2-FWS-143", ]
comb[comb$uid=="2-FWS-143" & comb$year==2011, ]
head(dats)
head(dats)
dats$costperbigkill <- dats$Larvae.100mm
head(dats)
base3[is.na(match(base3$uid, dats$uid[dats$lentic])), ]
dats$uid[dats$lentic]
head(dats)
dats$lentic
dats$uid[dats$lentic]
dats$uid
dat <- vector("list", length(trtyears))
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat[[i]] <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
dat[[i]]$FY <- trtyears[i]
}
dats <- do.call(rbind.fill, dat)
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
dats$areaha <- as.numeric(dats$Area..ha.)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
# combine Chem.Opt and Stream into a single field
dats$Chem.Opt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
dats <- dats[, -match("Stream", names(dats))]
# then convert chemopts to uid's
chemopt <- dats$Chem.Opt
chemopt <- gsub("-", " ", chemopt)
str <- sapply(strsplit(chemopt, " "), "[", 2)
dats[str > "99]", ]
chemopt[str > "99]"] <- paste("[S 572]", chemopt[str > "99]"])
str <- sapply(strsplit(chemopt, " "), "[", 2)
streamcode <- as.numeric(substring(str, 1, nchar(str)-1))
scode <- ifelse(streamcode>10000, streamcode-10000, streamcode)
agent <- ifelse(streamcode>10000, "FWS", "DFO")
lkcode <- recode(substring(sapply(strsplit(chemopt, " "), "[", 1), 2, 2), c("S", "M", "H", "E", "O", "C"), 1:6)
dats$uid <- paste(lkcode, agent, format(scode), sep="-")
base3[is.na(match(base3$uid, dats$uid[dats$lentic])), ]
look <- base3[is.na(match(base3$uid, dats$uid[dats$lentic])), ]
look[order(look$year, look$uid), ]
head(base3)
base3
dim(base3)
split(base3, year)
head(base3)
split(base3, base3$year)
basey <- split(base3, base3$year)
lapply(basey, with, cumsum(iaha))
lapply(basey, with, cumsum(iaha)/sum(iaha))
lapply(basey, with, median(cumsum(iaha)/sum(iaha)))
lapply(basey, with, cumsum(iaha)/sum(iaha)-0.5)
lapply(basey, with, abs(cumsum(iaha)/sum(iaha)-0.5))
lapply(basey, with, which.min(abs(cumsum(iaha)/sum(iaha)-0.5)))
basey <- split(base3, base3$year)
lapply(basey, with, {
cumiaha <- cumsum(iaha)
cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]
)
basey <- split(base3, base3$year)
lapply(basey, with, {
cumiaha <- cumsum(iaha)
cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]
}
)
basey <- split(base3, base3$year)
lapply(basey, with, {
cumiaha <- cumsum(iaha)
ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))])
}
)
basey
aggregate(base3$iaha, list(year=base3$year), cumsum)$x
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
base3
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) 
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3
attach(dats)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=FY-2008, xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=FY-2008)
abline(h=staffdaycut/1000, lty=2)
detach(dats)
attach(dats)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=FY-2008, xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=FY[lentic]-2008)
abline(h=staffdaycut/1000, lty=2)
detach(dats)
head(dats)
attach(dats)
table(lentic, FY)
search()
detach()
# C:\JVA\Lamprey\Larvae\Lentic\ReadRankLists.r
library(plyr)
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
staffcostperday <- c(1002, 1075, 1017, 1017)
gbcostperkg <- c(22.40, 22.66, 22.66, 22.66)
daysperha <- 0.4
kgperha <- 175
gbcostperha <- daysperha * staffcostperday + gbcostperkg * kgperha
staffdaycut <- 6400
dat <- vector("list", length(trtyears))
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat[[i]] <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
dat[[i]]$FY <- trtyears[i]
}
dats <- do.call(rbind.fill, dat)
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
dats$areaha <- as.numeric(dats$Area..ha.)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
# combine Chem.Opt and Stream into a single field
dats$Chem.Opt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
dats <- dats[, -match("Stream", names(dats))]
attach(dats)
table(lentic, FY)
mytable(lentic, FY)
mytable(lentic, areah)
mytable(lentic, FY)
mytable(lentic, areaha)
mytable(FY, lentic)
mytable(round(areaha), lentic)
dats[lentic, ]
dats[lentic, 1:7]
dats[!is.na(areaha), 1:7]
detach(dats)
detach(dats)
# combine Chem.Opt and Stream into a single field
dats$Chem.Opt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
dats <- dats[, -match("Stream", names(dats))]
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE)
dats$areaha <- as.numeric(dats$Area..ha.)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
attach(dats)
mytable(FY, lentic)
mytable(round(areaha), lentic)
dats[lentic & is.na(areaha), ]
search()
detach()
dats$areaha <- as.numeric(dats$Area..ha.)
dats$lentic <- grepl("lent", dats$Chem.Opt, ignore.case=TRUE) & !is.na(dats$areaha)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
attach(dats)
mytable(FY, lentic)
mytable(round(areaha), lentic)
mytable(FY, lentic)
mytable(round(areaha), lentic)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=FY-2008, xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=FY[lentic]-2008)
abline(h=staffdaycut/1000, lty=2)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=FY[lentic]-2008)
abline(h=staffdaycut/1000, lty=2)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
summary(dats)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(Staff.Days.1)], 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(Staff.Days.1)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", sort(unique(FY)), blindcolz[2:5])
FY
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5])
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(Staff.Days.1)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=1)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(Staff.Days.1)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16, title="Treatment Year")
dput(names(dat))
dput(names(dats))
head(dats)
rankdat <- dats[, c("FY", "Rank", "lentic", "LakeID", "Chem.Opt", "areaha", "biglarvkill", "costperbigkill", "days")]
head(rankdat)
format(staffdaycut, big.mark=",")
cleanup()
graphics.off()
search()
detach()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
info
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < 3 ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between 3 and 10 ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > 10 ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four years, survey years 2010-2013 corresponding to treatment years 2011-2014.",
"  For each year, I removed the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, Staff.Days.1/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(Staff.Days.1)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], Staff.Days.1[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16, title="Treatment Year")
detach(rankdat)
}
figu("Solid-filled circles represent lentic ChemOpts in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
search()
detach()
cleanup()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
info
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < 3 ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between 3 and 10 ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > 10 ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four years, survey years 2010-2013 corresponding to treatment years 2011-2014.",
"  For each year, I removed the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(cumdays)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], cumdays[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16, title="Treatment Year")
detach(rankdat)
}
figu("Solid-filled circles represent lentic ChemOpts in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
cleanup()
search()
detach()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
info
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < 3 ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between 3 and 10 ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > 10 ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four years, survey years 2010-2013 corresponding to treatment years 2011-2014.",
"  For each year, I removed the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, col=blindcolz[FY-2009], xlim=range(Rank[!is.na(cumdays)]), 
xlab="Rank", ylab="Cumulative staff days  (thousands)")
points(Rank[lentic], cumdays[lentic]/1000, pch=16, col=blindcolz[FY[lentic]-2009])
abline(h=staffdaycut/1000, lty=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16, title="Treatment Year")
detach(rankdat)
}
figu("Solid-filled circles represent lentic ChemOpts in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
endrtf()
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=blindcolz[FY[!lentic]-2009])
points(Rank[lentic],  cumdays[lentic]/1000,  col=blindcolz[FY[lentic]-2009], cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=16, title="Treatment Year")
detach(rankdat)
}
windows()
fig()
showmarks()
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=blindcolz[FY[!lentic]-2009])
points(Rank[lentic],  cumdays[lentic]/1000,  col=blindcolz[FY[lentic]-2009], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=2, lwd=2, title="Treatment Year")
detach(rankdat)
}
fig()
blindcolz
fig <- function() {
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=blindcolz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=blindcolz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=blindcolz[2:5], pch=2, lwd=2, title="Treatment Year")
detach(rankdat)
}
fig()
fig <- function() {
colz <- blindcolz[c(2, 3, 7, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, title="Treatment Year")
detach(rankdat)
}
fig()
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, title="Treatment Year")
detach(rankdat)
}
fig()
head(rankdat)
stringin("mary", rankdat$chemopt)
para
library(raster)
?raster
rst <- raster(matrix(1:100, ncol=10), 0, 360, -90, 90, crs="+proj=merc")
rst
raster
args(raster)
raster.matrix
raster:::raster.matrix
showMethods("raster")
showMethods("raster.matrix")
?rotate
rst <- raster(matrix(1:100, ncol=10), 0, 360, -90, 90, crs="+proj=merc")
r2 <- rotate(rst)
rst
r2
cleanup()
q()
tweethead()
q()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
info
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < 3 ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between 3 and 10 ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > 10 ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
endrtf()
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
windows()
fig()
ls()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
info
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, sizecuts, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,"
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 m2 plots depending on the size of the ChemOpt).",
"  In a single simulations a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from the larvae available.",
"  The density of large (> 100 mm) sea lampreys was calculated from these and adjusted for gear efficiency,")
para("large density = large catch / survey area / 0.08.", italic=TRUE)
para("If the large density was greater than ", trtcut, " per m2, then the ChemOpt was selected for treatment.",
"  This approach was then repeated for surveys with less effort, < 6 plots per ChemOpt.",
"  And the whole works was repeated for a total of ", nsim, " simulations.")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 m2 plots depending on the size of the ChemOpt).",
"  In a single simulations a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from the larvae available.",
"  The density of large (> 100 mm) sea lampreys was calculated from these and adjusted for gear efficiency,")
para("large density = large catch / survey area / 0.08.", italic=TRUE)
para("If the large density was greater than ", trtcut, " per m2, then the ChemOpt was selected for treatment.",
"  This approach was then repeated for surveys with less effort, < 6 plots per ChemOpt.",
"  And the whole works was repeated for a total of ", nsim, " simulations.")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 m2 plots depending on the size of the ChemOpt).",
"  In a single simulations a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from the larvae available.",
"  The density of large (> 100 mm) sea lampreys was calculated from these and adjusted for gear efficiency,")
para("large density = large catch / survey area / 0.08.", italic=TRUE)
para("If the large density was greater than ", trtcut, " per m2, then the ChemOpt was selected for treatment.",
"  This approach was then repeated for surveys with less effort, < 6 plots per ChemOpt.",
"  And the whole works was repeated for a total of ", nsim, " simulations.")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
cleanup()
search()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
# library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, sizecuts, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 m2 plots depending on the size of the ChemOpt).",
"  In a single simulations a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from the larvae available.",
"  The density of large (> 100 mm) sea lampreys was calculated from these and adjusted for gear efficiency,")
para("large density = large catch / survey area / 0.08.", italic=TRUE)
nsim <- 1000
para("If the large density was greater than ", trtcut, " per m2, then the ChemOpt was selected for treatment.",
"  This approach was then repeated for surveys with less effort, < 6 plots per ChemOpt.",
"  And the whole works was repeated for a total of ", nsim, " simulations.")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, cumdays/1000, type="n", xlim=range(Rank[!is.na(cumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], cumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  cumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
endrtf()
ls()
daysperha <- 0.4
gbcostperha
staffdaycut
daysperha
totcostperha <- gbcostperha
totcostperha
format(totcostperha, big.mark=",", ndec=2)
?format.default
format(totcostperha, big.mark=",", nsmall=2)
paste9)format(totcostperha, big.mark=",", nsmall=2)
paste0("$", format(totcostperha, big.mark=",", nsmall=2))
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", ")
daysperha
ls()
head(base3)
head(rankdat)
# C:\JVA\Lamprey\Larvae\Lentic\ReadRankLists.r
library(plyr)
trtyears <- 2011:2014
rfiles <- c(
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2010/FY2011 Rank List_2_1_2011.xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection Fall 2011/FY2012 Final  Rank List Jan 12  2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream Selection fall 2012/FY2013_Rank_List_Dec5_2012 (2).xls",
"C:/JVA/Lamprey/Larvae/Ranking/Stream selection fall 2013/FY2014_Rank_List_Jan_30 (2).xlsx")
rsheets <- c("RankList", "RankList", "RankList", "2014_RankList")
startrowz <- c(183, 165, 175, 104)
staffcostperday <- c(1002, 1075, 1017, 1017)
gbcostperkg <- c(22.40, 22.66, 22.66, 22.66)
daysperha <- 0.4
kgperha <- 175
totcostperha <- daysperha * staffcostperday + gbcostperkg * kgperha
staffdaycut <- 6400
rm(staffcostperday, gbcostperkg, kgperha)
dat <- vector("list", length(trtyears))
for(i in seq(trtyears)) {
wb <- loadWorkbook(rfiles[i])
dat[[i]] <- readWorksheet(wb, sheet=rsheets[i], startRow=startrowz[i])
dat[[i]]$FY <- trtyears[i]
}
dats <- do.call(rbind.fill, dat)
# combine Chem.Opt and Stream into a single field
dats$chemopt <- with(dats, ifelse(is.na(Chem.Opt), Stream, Chem.Opt))
dats$areaha <- as.numeric(dats$Area..ha.)
dats$lentic <- grepl("lent", dats$chemopt, ignore.case=TRUE) & !is.na(dats$areaha)
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
dats$cumdays <- dats$Staff.Days.1
head(dats)
dats[, c("FY", "Rank", "lentic", "chemopt", "cost", "biglarvkill", "costperbigkill", "days", "cumdays")]
dats$areaha <- as.numeric(dats$Area..ha.)
dats$lentic <- grepl("lent", dats$chemopt, ignore.case=TRUE) & !is.na(dats$areaha)
dats$cost <- dats$Cost
dats$biglarvkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
dats$cumdays <- dats$Staff.Days.1
dats[, c("FY", "Rank", "lentic", "chemopt", "cost", "biglarvkill", "costperbigkill", "days", "cumdays")]
dats[, c("FY", "Rank", "cumdays")]
dats$origcumdays <- dats$Staff.Days.1
rankdat <- dats[, c("FY", "Rank", "lentic", "chemopt", "cost", "biglarvkill", "costperbigkill", "days", "origcumdays")]
head(rankdat)
dim(rankdat)
table(rankdat$lentic)
table(rankdat$lentic, rankdat$origcumdays<6400)
table(rankdat$origcumdays<6400)
mytable(rankdat$lentic, rankdat$origcumdays<6400)
rankdat[is.na(rankdat$origcumdays), ]
rankdat <- dats[dats$biglarvkill>0, c("FY", "Rank", "lentic", "chemopt", "cost", "biglarvkill", "costperbigkill", "days", "origcumdays")]
dim(rankdat)
mytable(rankdat$lentic, rankdat$origcumdays<6400)
rankdat[subdex(rankdat, lentic & origcumdays<6400), ]
rankdat[subdex(rankdat, !lentic & origcumdays<6400), ]
names(rankdat)
dput(names(rankdat))
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "biglarvkill", "costperbigkill", "days")]
ranklentfree
with(ranklentfree, tapply(days, FY, cumsum))
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum)))
staffdaycut
head(rankdat)
rankdat[rankdat$Rank==1, ]
with(rankdat[rankdat$Rank==1, ], origcumdays - days)
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "biglarvkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum)))
cumdays
staffdaycut
susy <- 2010:2013
suty <- susy+1
suty
match(ranklentfree$FY, suty)
susy <- 2010:2013
suty <- susy+1
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "biglarvkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
cumdays
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "biglarvkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
dim(ranklentfree)
ranklentfree
dats$areaha <- as.numeric(dats$Area..ha.)
dats$lentic <- grepl("lent", dats$chemopt, ignore.case=TRUE) & !is.na(dats$areaha)
dats$cost <- dats$Cost
dats$bigkill <- dats$Killed
dats$costperbigkill <- dats$Larvae.100mm
dats$days <- dats$Staff.Days
dats$origcumdays <- dats$Staff.Days.1
rankdat <- dats[dats$bigkill>0, c("FY", "Rank", "lentic", "chemopt", "cost", "bigkill", "costperbigkill", "days", "origcumdays")]
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "biglarvkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
head(ranklentfree)
ls()
head(base3)
head(op)
head(base3)
# subset survey data meeting criteria
opsub <- op[paste(op$year, op$uid) %in% paste(base3$year, base3$uid), ]
dim(op)
dim(opsub)
nsim <- 10
susy <- 2010:2013
suty <- susy+1
results <- vector("list", length(suty))
names(results) <- suty
seq(along=suty)
y <- 1
df <- opsub[opsub$year==susy[y], ]
idz <- sort(unique(df$uid))
trtp <- array(NA, dim=c(length(idz), length(sunp)), dimnames=list(idz, sunp))
dim(df)
df
head(base3)
match(df$uid, base3$uid[base3$year==suty[y]])
table(df$uid)
with(base3, table(year, uid))
with(base3, table(uid, year))
table(df$uid)
suty[y]
susy
match(df$uid, base3$uid[base3$year==susy[y]])
base3$iaha[match(df$uid, base3$uid[base3$year==susy[y]])]
cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
sizecuts <- c(3, 10)
cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
library(sampling)
?strata
base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])]
base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])
base3$iaha[match(df$uid, base3$uid[base3$year==susy[y]])]
base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])]
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])]
effort <- c(2, 4, 6)
effort[base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])]]
cleanup()
search()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
# subset survey data meeting criteria
opsub <- op[paste(op$year, op$uid) %in% paste(base3$year, base3$uid), ]
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 10
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
date()
results <- vector("list", length(suty))
names(results) <- suty
y <- 1
df <- opsub[opsub$year==susy[y], ]
idz <- sort(unique(df$uid))
reducedeffort <- effort[base3$sizecat[match(df$uid, base3$uid[base3$year==susy[y]])]]
fulleffort <- rep(6, length(reducedeffort))
trtp <- array(NA, dim=c(length(idz), 2), dimnames=list(idz, c("Full", "Reduced")))
p <- 1
trtm <- array(NA, dim=c(length(idz), nsim), dimnames=list(idz, 1:nsim))
k <- 1
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
# density of big larvae ... compare to trtcut
survm2 <- tapply(df2$baream2, df2$uid, sum)
large <- tapply(df2$newnbig, df2$uid, sum)
lrgdens <- large/survm2/0.08
trtm[, k] <- as.numeric(lrgdens>trtcut)
head(base3)
head(opsub)
names(base3)
dput(names(base3))
args(merge)
?merge
dim(opsub)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat")], all.y=TRUE)
dim(opsub)
head(opsub)
head(rankdat)
head(df)
head(ranklentfree)
### calculations from surveyed data
# infested area
ia <- df$iaha[match(df2$uid, df$uid)]
# cost
cost <- totcostperha*ia
# kill of big larvae
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
bigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/bigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=sort(unique(df2$uid)), cost=cost, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
large
ia
match(df2$uid, df$uid)
match(df$uid, df2$uid)
df$iaha
large
suu <- sort(unique(df2$uid))
# infested area
ia <- df$iaha[match(df$uid, suu)]
ia
match(df$uid, suu)
match(suu, df$uid)
ia <- df$iaha[match(suu, df$uid)]
ia
[match(suu, df$uid)
match(suu, df$uid)
df$iaha
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 10
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
search()
date()
results <- vector("list", length(suty))
names(results) <- suty
df <- opsub[opsub$year==susy[y], ]
idz <- sort(unique(df$uid))
reducedeffort <- effort[df$sizecat]
fulleffort <- rep(6, length(reducedeffort))
trtp <- array(NA, dim=c(length(idz), 2), dimnames=list(idz, c("Full", "Reduced")))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
trtm <- array(NA, dim=c(length(idz), nsim), dimnames=list(idz, 1:nsim))
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
suu <- sort(unique(df2$uid))
# infested area
ia <- df$iaha[match(suu, df$uid)]
# cost
cost <- totcostperha*ia
# kill of big larvae
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
bigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/bigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, bigkill=bigkill, costperbigkill=costperbigkill, days=days)
ia
totcostperha
### calculations from surveyed data
suu <- sort(unique(df2$uid))
# infested area
ia <- df$iaha[match(suu, df$uid)]
# cost
cost <- totcostperha[y]*ia
# kill of big larvae
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
bigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/bigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, bigkill=bigkill, costperbigkill=costperbigkill, days=days)
tempdf
# combine with ranklist data
both <- rbind(ranklentfree[ranklentfree$year == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both
ranklentfree[ranklentfree$year == suty[y], ]
suty
ranklentfree$year
ranklentfree
head(ranklentfree)
both <- rbind(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both
both$cumdays <- cumsum(both$days)
head(both)
head(best3)
head(base3)
library(plyr)
rbind.fill
 sum(both$bigkill[both$cumdays < (staffdaycut + daysabovelist[y])])
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
results
cleanup()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 10
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
idz <- sort(unique(df$uid))
reducedeffort <- effort[df$sizecat]
fulleffort <- rep(6, length(reducedeffort))
trtp <- array(NA, dim=c(length(idz), 2), dimnames=list(idz, c("Full", "Reduced")))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
suu <- sort(unique(df2$uid))
# infested area
ia <- df$iaha[match(suu, df$uid)]
# "real" big kill ... based on all survey data
bigkill <- df$bigkill[match(suu, df$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[both$cumdays < (staffdaycut + daysabovelist[y])])/1000000
}
}
}
rm(y, df, idz, trtp, p, trtm, k, nuid, rowz, df2, L, i, survm2, large, lrgdens, res)
date()
ls()
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
reducedeffort <- effort[df$sizecat]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df$iaha[match(suu, df$uid)]
# "real" big kill ... based on all survey data
bigkill <- df$bigkill[match(suu, df$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[both$cumdays < (staffdaycut + daysabovelist[y])])/1000000
}
}
}
rm(y, df, suu, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
results
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
reducedeffort <- effort[df$sizecat]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[both$cumdays < (staffdaycut + daysabovelist[y])])/1000000
}
}
}
results
rowz
nsim
?strata
head(df)
df$uid
fulleffort
length(fulleffort)
data=swissmunicipalities
data=data[order(data$REG),]
data(swissmunicipalities)
data=swissmunicipalities
data=data[order(data$REG),]
data
dim(data)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
indx <- match(suu, df$uid)
indx
reducedeffort <- effort[df$sizecat[indx]]
reducedeffort
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[both$cumdays < (staffdaycut + daysabovelist[y])])/1000000
}
}
}
results
y <- 1
p <- 1
k <- 1
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
both
both$cumdays < (staffdaycut + daysabovelist[y])
staffdaycut
sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
results
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
results
(both$cumdays + daysabovelist[y]) < staffdaycut
both$cumdays
daysabovelist[y]
staffdaycut
staffdaycut - daysabovelist[y]
dim(both)
dim(tempdf)
dim(ranklentfree)
dim(ranklentfree[ranklentfree$FY == suty[y], ])
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(ranklentfree[ranklentfree$FY == suty[y], ], tempdf)
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
results
dim(both)
dim(tempdf)
dim(ranklentfree)
dim(ranklentfree[ranklentfree$FY == suty[y], ])
both
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
both
tempdf
a <- ranklentfree[ranklentfree$FY == suty[y], ]
head(a)
rbind.fill(tempdf, head(a))
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
tempdf
ia
large
survm2
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
estbigkill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
tempdf
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
results
both
both[, -2]
daysabovelist[y]
daysabovelist
staffdaycut - daysabovelist
y
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 10
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
results
CI
CI(1:10)
apply(results, 2:3, CI)
col(apply(results, 2:3, CI))
cis <- apply(results, 2:3, CI)
cis[1, , ]
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
rm
cm
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
plot(1, 1, type="n")
points(rm, m, col=cm)
rm
m
plot(1, 1, xlim=range(rm), ylim=range(cis), type="n")
points(rm, m, col=cm)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm), ylim=range(cis), type="n")
points(rm, m, col=cm)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm+cm/10
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm), ylim=range(cis), type="n")
points(xm, m, col=cm)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm+cm/10
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n")
points(xm, m, col=cm)
?cheat
cis
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=cm)
arrows(xm, cis[2, , ], xm, cis[3, , ], col=cm, length=0.1, angle=90, code=3)
cm/10
mean(cm/10)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/10
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=cm)
arrows(xm, cis[2, , ], xm, cis[3, , ], col=cm, length=0.1, angle=90, code=3)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/10
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=cm)
arrows(xm, cis[2, , ], xm, cis[3, , ], col=cm, length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
colx
colz
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/10
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis[2, , ], xm, cis[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/6
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis[2, , ], xm, cis[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/4
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis[2, , ], xm, cis[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
cleanup()
graphics.off()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 100
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
cis <- apply(results, 2:3, CI)
m <- cis[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/4
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis[2, , ], xm, cis[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
nsim
results
cis
cis0 <- cis - cis[c(1, 1, 1), , ]
cis0
cis0 <- cis - cis[c(1, 1, 1), , ]
m <- cis0[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/4
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis0), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis0[2, , ], xm, cis0[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
cis0 <- 1000*(cis - cis[c(1, 1, 1), , ])
m <- cis0[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/4
colz <- blindcolz[2:3]
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(cis0), type="n", xaxt="n", xlab="Treatment year", ylab="Millions of larvae killed")
points(xm, m, col=colz[cm])
arrows(xm, cis0[2, , ], xm, cis0[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
blindcolz
graphics.off()
cleanup()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment effectiveness) / (total area surveyed * 0.08 gear efficiency),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
#if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
para("The results are shown in the following figures.")
fig <- function() {
m <- x[1, , ]
rm <- row(m)
cm <- col(m)
xm <- rm + (cm - mean(cm))/4
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(1, 1, xlim=range(rm)+c(-1, 1)*0.5, ylim=range(x), type="n", xaxt="n", xlab="Treatment year", ylab=ylabb)
points(xm, m, col=colz[cm])
arrows(xm, x[2, , ], xm, x[3, , ], col=colz[cm], length=0.1, angle=90, code=3)
axis(1, at=seq(suty), labels=suty)
}
# summary in millions
cis <- apply(results, 2:3, CI)
# summary relative to average, in thousands
cis0 <- 1000*(cis - cis[c(1, 1, 1), , ])
colz <- blindcolz[2:3]
x <- cis
ylabb <- "Millions of larvae killed"
figu("Comparison of ", nsim, " simulations of full survey effort (orange) and reduced survey effort (blue)", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=5, w=5)
x <- cis0
ylabb <- "Thousands of larvae killed  (relative to average)"
figu("Comparison of ", nsim, " simulations of full survey effort (orange) and reduced survey effort (blue)", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=5, w=5)
endrtf()
rm(i, b)
ls()
rm(cis, cis0, colz, x)
ls()
dim(results)
results[, 1, 1]
results[, 1, ]
windows()results[, 1, ]
windows()
boxplot(results[, 1, ])
boxplot(results[, 1, ], log="y")
boxplot(results[, 1, ])
windows()
par(mfrow=c(1, 4))
for(i in 1:4) {
boxplot(results[, i, ])
}
windows()
par(mfrow=c(1, 4), cex=1.5, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=1, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE)
mtext("Millions of larvae killed", side=2, outer=TRUE)
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
fig <- {
par(mfrow=c(1, 4), cex=1.5, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=1, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.5)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.5)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
fig <- function() {
par(mfrow=c(1, 4), cex=1.5, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=1, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.5)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.5)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
fig <- function() {
par(mfrow=c(1, 4), cex=1.5, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=1, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.5)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.5)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
?par
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, col=blindcolz[4], xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, col=blindcolz[4], xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(5, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, col=blindcolz[4], xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
dim(results)
apply(results, 2, function(x) (max(x) + min(x))/2)
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
apply(results, 2, function(x) (max(x) - min(x))/2)
max(apply(results, 2, function(x) (max(x) - min(x))/2))
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
ymid
ymid-yspread
ymid + c(-1, 1)*yspread
ymid[1] + c(-1, 1)*yspread
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(5, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, col=blindcolz[4], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
fig()
windows()
fig()
?boxplot
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(5, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, border=blindcolz[4], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
blindcolz
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha will be surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha will be surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha will be surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three arbitrarily-assigned size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calcuated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(6, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, border=blindcolz[7], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", nsim, " simulations of full and reduced survey effort", 
" in the assessment of lentic ChemOpts with granular Bayluscide.", h=8.5, w=6.5)
endrtf()
heading
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
heading(paste0("QUICK SUMMARY:  Reducing the survey effort on small lentic areas (< 10 ha)",
" has little effect on the estimated number of large larvae killed", 2)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha were surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha were surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha were surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calculated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("This was repeated ", format(nsim, big.mark=",") , " times.",
"  Each time, the total number of large larvae killed by the treatment was recorded.",
"  The number of large larvae killed for each stream was simply the number in the real life rank list.",
"  The number of large larvae killed for each lentic area was the best number that we have,",
" the estimate based on all of the available data (at least 6 500 m2 plots)."
"  Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(6, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, border=blindcolz[7], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", format(nsim, big.mark=",") , 
" simulations of full and reduced survey effort in the assessment of lentic ChemOpts with granular Bayluscide.", 
"  Note that the y-axes are scaled so that a difference of 20,000 large larvae looks the same in all years.", h=8.5, w=6.5)
endrtf()
graphics.off()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
heading(paste0("QUICK SUMMARY:  Reducing the survey effort on small lentic areas (< 10 ha)",
" has little effect on the estimated number of large larvae killed"), 2)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha were surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha were surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha were surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calculated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("This was repeated ", format(nsim, big.mark=",") , " times.",
"  Each time, the total number of large larvae killed by the treatment was recorded.",
"  The number of large larvae killed for each stream was simply the number in the real life rank list.",
"  The number of large larvae killed for each lentic area was the best number that we have,",
" the estimate based on all of the available data (at least 6 500 m2 plots)."
"  Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(6, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, border=blindcolz[7], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", format(nsim, big.mark=",") , 
" simulations of full and reduced survey effort in the assessment of lentic ChemOpts with granular Bayluscide.", 
"  Note that the y-axes are scaled so that a difference of 20,000 large larvae looks the same in all years.", h=8.5, w=6.5)
endrtf()
# C:\JVA\Lamprey\Larvae\Lentic\LenticSubsample v3.r
library(sampling)
library(plyr)
doc <- startrtf(file=paste(Sys.Date(), "Lentic"), dir="C:/JVA/Lamprey/Larvae/Lentic")
heading("Ranking Lentic Areas for Treatment - effect of reduced assessment effort")
heading(paste("Draft -", Sys.Date()))
heading("Action item from September 2014 LATF (agenda item 4-i-i)", 2)
heading(paste0("Adams will explore the effects of sampling lentic areas for ranking at the same frequency as lotic samples",
" (two, three or four plots depending on habitat)."), 3)
heading(paste0("QUICK SUMMARY:  Reducing the survey effort on small lentic areas (< 10 ha)",
" has little effect on the estimated number of large larvae killed"), 2)
strz <- read.csv("C:/JVA/Lamprey/All_streams_lat_longs.csv", as.is=TRUE)
# bring in US data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/Historical US Lentic surveys.xlsx")
usop <- readWorksheet(wb, sheet=getSheets(wb)[1])
usln <- readWorksheet(wb, sheet=getSheets(wb)[2])
usia <- readWorksheet(wb, sheet=getSheets(wb)[3])
# bring in Canada data
wb <- loadWorkbook("C:/JVA/Lamprey/Larvae/Lentic/DFO_Lentic_Analysis.xlsx")
caop <- readWorksheet(wb, sheet=getSheets(wb)[1])
caln <- readWorksheet(wb, sheet=getSheets(wb)[2])
caia <- readWorksheet(wb, sheet=getSheets(wb)[3])
rm(wb)
# combine op data
names(usop) <- c("id", "lake", "stream", "year", "date", "baream2")
# add in freq from lengths file
names(usln) <- c("id", "len", "freq")
look <- aggregate(usln$freq, list(id=usln$id), sum)
look$freq <- look$x
look2 <- merge(usop, look[, c("id", "freq")], all.x=TRUE)
look2$freq[is.na(look2$freq)] <- 0
look2$agent <- "FWS"
look2$branch <- ""
look2$branchn <- ""
look2$purpose <- ""
names(caop) <- c("year", "lake", "stream", "branch", "branchn", "date", "id", "lscode", "freq", "purpose", "baream2")
# total up freq for both lscodes (I think 2=larvae, 3=transformer)
look <- aggregate(caop$freq, caop[, !(names(caop) %in% c("freq", "lscode"))], sum)
look$freq <- look$x
look$agent <- "DFO"
colz <- c("agent", "id", "branch", "branchn", "lake", "stream", "year", "date", "baream2", "freq", "purpose")
op <- rbind(look2[, colz], look[, colz])
# ??? one id in us lengths file has no match in us ops file
usop[usop$id==228711, ]
tab <- usln[usln$id==228711, ]
tabl("One ID in the FWS lengths file has no match in the survey file.", row.names=FALSE)
rm(usop, look, look2, caop, colz)
# combine ln data
usln$agent <- "FWS"
usln$streamn <- ""
usln$purposed <- ""
para("In the DFO data, there are separate codes for larvae (2) and recently metamorphosed juveniles (3).",
"  In the FWS data, only data for larvae are entered.",
"  So, I used only the larval data (2) from DFO.")
# Code 2 are larvae and code 3 are transformers - we will use only larvae
# Code 8 is ichthyomyzon larvae, I am not using them
names(caln) <- c("streamn", "branch", "id", "date", "lscode", "len", "purposed")
caln$agent <- "DFO"
caln$freq <- 1
caln <- caln[caln$lscode == 2, ]
colz <- c("agent", "id", "streamn", "len", "freq", "purposed")
ln <- rbind(usln[, colz], caln[, colz])
prop <- aggregate(ln$len>100, ln[, c("agent", "id")], sum)
prop$nbig <- prop$x
prop$ntot <- aggregate(ln$freq, ln[, c("agent", "id")], sum)$x
prop$pbig <- prop$nbig/prop$ntot
# head(prop)
op <- merge(op, prop[, c("agent", "id", "nbig", "pbig")], all.x=TRUE)
op$nbig[is.na(op$nbig)] <- 0
op$ajdens <- op$freq/op$baream2/0.08
op$ajdensbig <- op$nbig/op$baream2/0.08
# look$ntot[is.na(look$ntot)] <- 0
# ??? there were two cases where the catch from the lengths file didn't match the op file
# look[abs(look$ntot - look$freq)>0.001, ]
# caln[caln$id=="LA030406", ]
# caln[caln$id=="LA970411", ]
# ??? this got fixed when I got rid of the lscode==8 records earlier
rm(usln, caln, colz, prop)
# combine ia data
names(usia) <- c("lake", "stream", "infaream2")
usia$agent <- "FWS"
names(caia) <- c("lake", "stream", "reach", "upyear", "infaream2")
caia$agent <- "DFO"
caia$lake <- recode(caia$lake, substring(Lakenames, 1, 1), 1:5)
colz <- c("agent", "lake", "stream", "infaream2")
ia <- rbind(usia[, colz], caia[, colz])
rm(usia, caia, colz)
# summary table
look <- aggregate(op$stream, op[, c("agent", "lake")], function(x) length(unique(x)))
look$nstream <- look$x
look$nyear <- aggregate(op$year, op[, c("agent", "lake")], function(x) length(unique(x)))$x
look$minyr <- aggregate(op$year, op[, c("agent", "lake")], min)$x
look$maxyr <- aggregate(op$year, op[, c("agent", "lake")], max)$x
look$lake <- recode(look$lake, 1:5, Lakenames)
tab <- look[, c("lake", "agent", "nstream", "nyear", "minyr", "maxyr")]
rm(look)
tabl("Summary of lentic data provided by FWS and DFO for this analysis,",
" including the umber of ChemOpts (nstream), number of years (nyear), and range of years (minyr, maxyr).")
# hist(op$year)
# hist(rep(ln$len, ln$freq))
# okay, don't need to worry about multiple dates in a given year and id
with(op, {
ylasi <- paste(year, lake, agent, stream, id)
a <- table(ylasi, id)
print(table(apply(a>0, 1, sum)))
print(table(apply(a>0, 2, sum)))
})
op$uid <- paste(op$lake, op$agent, format(op$stream), sep="-")
# combine survey data (op) with infested area (ia) and stream info (strz)
comb. <- merge(op, ia, all.x=TRUE)
comb <- merge(comb., strz[, c("lake", "stream", "strname", "lat", "long")], all.x=TRUE)
rm(comb.)
if(FALSE) {
# do all the surveyed lentic areas have an infested area associated with them?
comb[is.na(comb$infaream2), ]
# plotdf(comb[is.na(comb$infaream2), ])
comb[!is.na(comb$infaream2) & comb$branchn %in% c("Nipigon Bay", "Byng Inlet"), ]
strz[subdex(strz, lake==3 & stream %in% c(726, 745)), ]
with(comb, table(year[is.na(infaream2)], branchn[is.na(infaream2)]))
}
# summarize information needed for ranking
attach(comb)
bylist <- list(uid=uid, year=year)
info <- aggregate(baream2, bylist, sum)[, 1:2]
info$nplots <- aggregate(!is.na(baream2), bylist, sum)$x
info$survm2 <- aggregate(baream2, bylist, sum)$x
info$catch <- aggregate(freq, bylist, sum)$x
info$large <- aggregate(nbig, bylist, sum)$x
info$iaha <- aggregate(infaream2, bylist, mean, na.rm=TRUE)$x/10000
detach(comb)
info$lrgdens <- info$large/info$survm2/0.08
info <- info[order(info$year, -info$lrgdens, -info$large, -info$catch, -info$survm2), ]
info <- info[, c("year", "uid", "iaha", "nplots", "survm2", "catch", "large", "lrgdens")]
rm(bylist)
# select a subset with solid data
base2 <- info[subdex(info, nplots >= 6 & survm2 >= (6*500)), ]
table(base2$year)
para("In order to have a solid collection of survey data from which to subsample,",
" I subsetted the data to use only those ChemOpt-years with at least 6 survey plots covering an area of at least 6*500 m2.",
"  Next, in order to have a good number of ChemOpts each year to compare rankings,",
" I further subsetted the data to only those years with at least 10 ChemOpts meeting the initial criteria.",
"  This left me with 13 ChemOpts in 2010 and 2011 and 11 ChemOpts in 2012 and 2013 (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5)
barplot(table(base2$year), horiz=TRUE, las=1, xlab="No. of ChemOpts")
abline(v=10, lty=2)
}
figu("Number of ChemOpts each year with at least 6 survey plots covering an area of at least 6*500 m2.", h=5, w=5)
base3 <- base2[subdex(base2, year > 2009.5), ]
rm(base2)
han <- base3$iaha
quantile(han, (1:2)/3)
sizecuts <- c(3, 10)
sizecat <- cut(han, c(0, sizecuts, 1000), labels=FALSE)
ord <- order(han)
para("In order to explore whether we can use a reduced survey effort and still satisfactorily rank lentic ChemOpts for treatment,",
" I divided the lentic ChemOpts into three size groups to which different levels of effort would be applied through simulation.",
"  Lentic ChemOpts with infested areas < ", sizecuts[1], " ha were surveyed (in the simulation) with 2 500 m2 Bayluscide plots,",
" those with infested areas between ", sizecuts[1], " and ", sizecuts[2], " ha were surveyed with 4 500 m2 plots,",
" and those with infested areas > ", sizecuts[2], " ha were surveyed with 6 plots (Figure ", jvamiscenv$figcount, ").")
fig <- function() {
par(mar=c(4, 4, 1, 1), cex=1.5, las=1)
plot(seq(han), han, log="y", type="n", xlab="Lentic ChemOpts, sorted by size", ylab="Infested area  (ha)")
abline(h=sizecuts, lty=2)
points(seq(han), han[ord], pch=16, col=blindcolz[sizecat[ord]+1])
axis(2, at=sizecuts)
}
figu("Three size categories of Lentic ChemOpts used in the simulation.", h=5, w=5)
rm(han, ord)
base3$cumiaha <- unlist(aggregate(base3$iaha, list(year=base3$year), cumsum)$x)
base3$rank <- unlist(aggregate(-base3$lrgdens, list(year=base3$year), rank)$x)
basey <- split(base3, base3$year)
trtcut <- lapply(basey, with, ceiling(cumiaha[which.min(abs(cumiaha/sum(iaha)-0.5))]))
base3$trt <- unlist(lapply(seq(trtcut), function(i) basey[[i]]$cumiaha <= trtcut[[i]]) )
base3$sizecat <- cut(base3$iaha, c(0, sizecuts, 1000), labels=FALSE)
base3$bigkill <- with(base3, lrgdens * iaha * 10000 * 0.75)
# subset survey data meeting criteria
opsub <- merge(op, base3[, c("year", "uid", "iaha", "sizecat", "bigkill")], all.y=TRUE)
# bring in ranklists from FY 2011-2014 (survey years 2010-2013)
source("C:/JVA/Lamprey/Larvae/Lentic/ReadRankLists.r")
para("A separate analysis was run for each of the four survey years, 2010-2013, corresponding to treatment years 2011-2014.",
"  For each year, I removed all of the lentic ChemOpts from the real life rank lists (Figure ", jvamiscenv$figcount, ").",
"  Then two types of simulations were run for each year,",
" one at the full survey effort (6 500 m2 plots for every lentic ChemOpt),",
" and one at the reduced survey effort (6, 4, or 2 500 m2 plots depending on the size of the ChemOpt).")
fig <- function() {
colz <- blindcolz[c(7, 3, 2, 4)]
attach(rankdat)
par(mar=c(4, 4, 1, 1), las=1, cex=1.5)
plot(Rank, origcumdays/1000, type="n", xlim=range(Rank[!is.na(origcumdays)]), xlab="Rank", ylab="Cumulative staff days  (thousands)")
abline(h=staffdaycut/1000, lty=2)
points(Rank[!lentic], origcumdays[!lentic]/1000, col=colz[FY[!lentic]-2010])
points(Rank[lentic],  origcumdays[lentic]/1000,  col=colz[FY[lentic]-2010], pch=2, cex=1.5, lwd=2)
legend("topleft", as.character(sort(unique(FY))), col=colz, pch=2, lwd=2, lty=0, title="Treatment Year")
detach(rankdat)
}
figu("Lentic ChemOpts (triangles) in the real life rank lists.",
"  The cumulative cut off in all four years was ", format(staffdaycut, big.mark=","), " staff days (dashed line).", h=5, w=5)
rm(trtcut)
para("For each lentic ChemOpt in a single simulation, a random selection of survey plots was chosen from all those available (with replacement).",
"  For each selected survey plot, a bootstrap sample of larvae were chosen from all the larvae measured in that plot.",
"  These random selections were then treated as the survey data for each lentic ChemOpt.",
"  The cost/kill of large (> 100 mm) sea lampreys in each ChemOpt was calculated as the ratio of")
para("cost = total cost per ha * infested area", italic=TRUE)
para("and")
para("kill = (total catch of large larvae * infested area * 0.75 treatment eff) / (total area surveyed * 0.08 gear eff),", italic=TRUE)
para("where the total costs per ha for treatment years 2011-2014 were ",
paste(paste0("$", format(totcostperha, big.mark=",", nsmall=2)), collapse=", "),
", respectively.",
"  And the total number of staff days to treat each ChemOpt was calculated as,")
para("days = ", daysperha, " * the infested area.", italic=TRUE)
para("Finally, the randomly generated lentic ChemOpts were ranked along with the actual streams from the rank list.",
"  All ChemOpts were ranked by the cost/kill of large larvae, and only those ChemOpts that could be treated in <= ",
format(staffdaycut, big.mark=","), " staff days were selected for treatment.")
nsim <- 1000
susy <- 2010:2013
suty <- susy+1
# calculate the number of staff days above the rank list for each year
daysabovelist <- with(rankdat[rankdat$Rank==1, ], origcumdays - days)
# subset of non-lentic ChemOpts whose effort sums to fewer than the staff day cut off
ranklentfree <- rankdat[!rankdat$lentic, c("FY", "chemopt", "cost", "bigkill", "costperbigkill", "days")]
# cumdays <- unlist(with(ranklentfree, tapply(days, FY, cumsum))) + daysabovelist[match(ranklentfree$FY, suty)]
# ranklentfree <- ranklentfree[cumdays <= staffdaycut, ]
totcostperha
staffdaycut
daysperha
# three levels of sampling effort for each of the three size categories
effort <- c(2, 4, 6)
# make sure opsub is ordered by year and uid ... for strata() function
opsub <- opsub[order(opsub$year, opsub$uid), ]
if(FALSE) {
### this takes about 2.5 minutes ###
date()
results <- array(NA, dim=c(nsim, length(suty), 2), dimnames=list(1:nsim, suty, c("Full", "Reduced")))
for(y in seq(along=suty)) {
df <- opsub[opsub$year==susy[y], ]
suu <- sort(unique(df$uid))
indx <- match(suu, df$uid)
reducedeffort <- effort[df$sizecat[indx]]
fulleffort <- rep(6, length(reducedeffort))
# run one simulation (p=1) for the full effort and one (p=2) for the reduced effort
for(p in 1:2) {
for(k in 1:nsim) {
# stratified subsample of bayer plots from each stream (with replacement)
if(p==1) {
rowz <- strata(df, stratanames="uid", fulleffort, method="srswr")$ID_unit
} else {
rowz <- strata(df, stratanames="uid", reducedeffort, method="srswr")$ID_unit
}
df2 <- df[rowz, ]
# random sample of big larvae from observed catch (basically a bootstrap resample with replacement)
L <- dim(df2)[1]
df2$newnbig <- rep(NA, L)
for(i in 1:dim(df2)[1]) {
if(df2$freq[i]==0) {
df2$newnbig[i] <- 0
} else {
df2$newnbig[i] <- sum(sample(rep(0:1, c(df2$freq[i]-df2$nbig[i], df2$nbig[i])), replace=TRUE))
}
}
### calculations from surveyed data
# infested area
ia <- df2$iaha[match(suu, df2$uid)]
# "real" big kill ... based on all survey data
bigkill <- df2$bigkill[match(suu, df2$uid)]
# cost
cost <- totcostperha[y]*ia
# "estimated" kill of big larvae ... based on resampled survey data
large <- tapply(df2$newnbig, df2$uid, sum)
survm2 <- tapply(df2$baream2, df2$uid, sum)
estbigkill <- (large*ia*0.75)/(survm2/10000*0.08)
# cost per kill
costperbigkill <- cost/estbigkill
# staff days
days <- ia * daysperha
tempdf <- data.frame(FY=suty[y], chemopt=suu, cost=cost, estbigkill=estbigkill, bigkill=bigkill, costperbigkill=costperbigkill, 
days=days)
# combine with ranklist data
both <- rbind.fill(tempdf, ranklentfree[ranklentfree$FY == suty[y], ])
both <- both[order(both$costperbigkill), ]
both$cumdays <- cumsum(both$days)
results[k, y, p] <- sum(both$bigkill[(both$cumdays + daysabovelist[y]) < staffdaycut])/1000000
}
}
}
rm(y, df, suu, indx, reducedeffort, fulleffort, p, k, rowz, df2, L, i, ia, bigkill, cost, large, survm2, estbigkill, costperbigkill, days, 
tempdf, both)
date()
}
para("This was repeated ", format(nsim, big.mark=",") , " times.",
"  Each time, the total number of large larvae killed by the treatment was recorded.",
"  The number of large larvae killed for each stream was simply the number in the real life rank list.",
"  The number of large larvae killed for each lentic area was the best number that we have,",
" the estimate based on all of the available data (at least 6 500 m2 plots).",
"  Reducing the lentic survey effort has little effect on the estimated number of large larvae killed (Figure ", 
jvamiscenv$figcount, ").")
ymid <- apply(results, 2, function(x) (max(x) + min(x))/2)
yspread <- max(apply(results, 2, function(x) (max(x) - min(x))/2))
fig <- function() {
par(mfrow=c(1, 4), cex=1.2, mar=c(6, 4, 1, 1), oma=c(2, 2, 0, 0))
for(i in 1:4) {
boxplot(results[, i, ], las=2, border=blindcolz[7], ylim=ymid[i] + c(-1, 1)*yspread, xlab="", ylab="")
}
mtext("Lentic Survey Effort", side=1, outer=TRUE, cex=1.2)
mtext("Millions of larvae killed", side=2, outer=TRUE, cex=1.2)
}
figu("Comparison of the estimated number of large larvae killed in ", format(nsim, big.mark=",") , 
" simulations of full and reduced survey effort in the assessment of lentic ChemOpts with granular Bayluscide.", 
"  Note that the y-axes are scaled so that a difference of 20,000 large larvae looks the same in all years.", h=8.5, w=6.5)
endrtf()
q()
tweethead()
q()
options("httr_oauth_cache")
origop <- options("httr_oauth_cache")
origop
class(origop)
length(origop)
options(httr_oauth_cache=origop)
#' Tweet Headlines
#'
#' Tweet the latest headlines from the specified website.
#' @param tweetA logical scalar indicating if tweets should be posted, default TRUE.
#' @param usernameA character scalar, giving the name of the twitter user.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @param websiteA character scalar, giving the name of the website, from which to pull headlines.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @param credentialsA character vector of length four, giving the twitter_api_key, the twitter_api_secret, 
#'the twitter_access_token, and the twitter_access_token_secret.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @return A named vector with the \code{Mean}, lower and upper confidence limits (\code{L} and \code{U}), 
#' and the number of observations \code{N}.
#' @detailsThis function is customized to work on a particular website.  It's not for general use. 
#'To store information in local .Renviron file, use \code{writeLines(c("username=xxx", "website=xxx", 
#'"twitter_api_key=xxx", "twitter_api_secret=xxx", "twitter_access_token=xxx", "twitter_access_token_secret=xxx"), 
#'file.path(getwd(), ".Renviron"))}.
#' @importtwitteR RCurl
#' @export
#' @references
#'
#' Simon Munzert.  19 Jan 2015.
#' Programming a Twitter bot - and the rescue from procrastination.
#' \emph{http://www.r-datacollection.com/blog/Programming-a-Twitter-bot/}
#'
#' Simon Munzert.  21 Dec 2014.
#' How to conduct a tombola with R.
#' \emph{www.r-datacollection.com/blog/How-to-conduct-a-tombola-with-R/}
#' @examples 
#' \dontrun{
#' tweethead(FALSE)
#' tweethead()
#' }
tweethead <- function(tweet=TRUE, username=NULL, website=NULL, credentials=NULL) {
if(is.null(credentials)) {
api_key <- Sys.getenv("twitter_api_key")
api_secret <- Sys.getenv("twitter_api_secret")
access_token <- Sys.getenv("twitter_access_token")
access_token_secret <- Sys.getenv("twitter_access_token_secret")
} else {
api_key <- credentials[1]
api_secret <- credentials[2]
access_token <- credentials[3]
access_token_secret <- credentials[4]
}
# connect to Twitter
origop <- options("httr_oauth_cache")
options(httr_oauth_cache=TRUE)
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
options(httr_oauth_cache=origop)
# grab headlines from website
# read in html source code
base.url <- Sys.getenv("website")
base.html <- getURLContent(base.url)[[1]]
# pull off links that say "More"
links <- strsplit(base.html, "ID=")[[1]]
links2 <- sapply(strsplit(links, "</a>"), "[", 1)[-1]
more.codes <- substring(stringin("more", links2), 1, 5)
more.urls <- paste0(base.url, "index.php?ID=", more.codes)
# pull off headline, photo url, photo caption
pull <- function(thisurl) {
thishtml <- getURLContent(thisurl)[[1]]
# headline
headlong <- strsplit(thishtml, "<font size=6><b>")[[1]][2]
head <- strsplit(headlong, "</b>")[[1]][1]
# photo url
photolong <- strsplit(thishtml, "<img src='./Photos/")[[1]]
if(length(photolong)>1) {
photolong <- photolong[2]
photo <- strsplit(photolong, "'><br>")[[1]][1]
photo.url <- paste0(base.url, "Photos/", photo)
} else {
photo.url <- ""
}
# photo caption
caplong <- strsplit(thishtml, "<br><font size=2><b>")[[1]]
if(length(caplong)>1) {
caplong <- caplong[2]
cap <- strsplit(caplong, "</b>")[[1]][1]
} else {
cap <- ""
}
c(article.url=thisurl, headline=head, photo.url=photo.url, photo.caption=cap)
}
# get new tweets ready
m <- do.call(rbind, lapply(more.urls, pull))
currentheads <- apply(m[, 2:1], 1, paste, collapse=". ")
### grab latest tweets
adj <- getUser(Sys.getenv("username"))
oldtweets <- twListToDF(userTimeline(adj, n=15, excludeReplies=TRUE))[, c("text", "favoriteCount", "retweetCount", "created")]
names(oldtweets)[names(oldtweets)=="created"] <- "createdUTC"
### tweet all new tweets that haven't been tweeted before
totweet <- currentheads[!(substring(currentheads, 1, 30) %in% substring(oldtweets$text, 1, 30))]
if(length(totweet) > 0) {
if(tweet) {
lapply(rev(totweet), updateStatus, lat=45.141473, long=-89.152339)
} else {
cat(paste("\n\n***  This is what would be posted if tweet=TRUE.\n\n"))
print(totweet)
cat("\n\n")
}
} else {
cat(paste0("\n\n***  No new headlines since last tweet, ", 
format(max(oldtweets$createdUTC), "%a %b %e %I:%M %p", tz=Sys.timezone()), ".\n\n\n"))
}
list(oldtweets=oldtweets, currentheads=currentheads, totweet=totweet)
}
tweethead()
library(httr)
library(RCurl)
#' Tweet Headlines
#'
#' Tweet the latest headlines from the specified website.
#' @param tweetA logical scalar indicating if tweets should be posted, default TRUE.
#' @param usernameA character scalar, giving the name of the twitter user.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @param websiteA character scalar, giving the name of the website, from which to pull headlines.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @param credentialsA character vector of length four, giving the twitter_api_key, the twitter_api_secret, 
#'the twitter_access_token, and the twitter_access_token_secret.
#' The default, NULL, uses information stored in local .Renviron file (see Details).
#' @return A named vector with the \code{Mean}, lower and upper confidence limits (\code{L} and \code{U}), 
#' and the number of observations \code{N}.
#' @detailsThis function is customized to work on a particular website.  It's not for general use. 
#'To store information in local .Renviron file, use \code{writeLines(c("username=xxx", "website=xxx", 
#'"twitter_api_key=xxx", "twitter_api_secret=xxx", "twitter_access_token=xxx", "twitter_access_token_secret=xxx"), 
#'file.path(getwd(), ".Renviron"))}.
#' @importtwitteR RCurl
#' @export
#' @references
#'
#' Simon Munzert.  19 Jan 2015.
#' Programming a Twitter bot - and the rescue from procrastination.
#' \emph{http://www.r-datacollection.com/blog/Programming-a-Twitter-bot/}
#'
#' Simon Munzert.  21 Dec 2014.
#' How to conduct a tombola with R.
#' \emph{www.r-datacollection.com/blog/How-to-conduct-a-tombola-with-R/}
#' @examples 
#' \dontrun{
#' tweethead(FALSE)
#' tweethead()
#' }
tweethead <- function(tweet=TRUE, username=NULL, website=NULL, credentials=NULL) {
if(is.null(credentials)) {
api_key <- Sys.getenv("twitter_api_key")
api_secret <- Sys.getenv("twitter_api_secret")
access_token <- Sys.getenv("twitter_access_token")
access_token_secret <- Sys.getenv("twitter_access_token_secret")
} else {
api_key <- credentials[1]
api_secret <- credentials[2]
access_token <- credentials[3]
access_token_secret <- credentials[4]
}
# connect to Twitter
origop <- options("httr_oauth_cache")
options(httr_oauth_cache=TRUE)
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
options(httr_oauth_cache=origop)
# grab headlines from website
# read in html source code
base.url <- Sys.getenv("website")
base.html <- getURLContent(base.url)[[1]]
# pull off links that say "More"
links <- strsplit(base.html, "ID=")[[1]]
links2 <- sapply(strsplit(links, "</a>"), "[", 1)[-1]
more.codes <- substring(stringin("more", links2), 1, 5)
more.urls <- paste0(base.url, "index.php?ID=", more.codes)
# pull off headline, photo url, photo caption
pull <- function(thisurl) {
thishtml <- getURLContent(thisurl)[[1]]
# headline
headlong <- strsplit(thishtml, "<font size=6><b>")[[1]][2]
head <- strsplit(headlong, "</b>")[[1]][1]
# photo url
photolong <- strsplit(thishtml, "<img src='./Photos/")[[1]]
if(length(photolong)>1) {
photolong <- photolong[2]
photo <- strsplit(photolong, "'><br>")[[1]][1]
photo.url <- paste0(base.url, "Photos/", photo)
} else {
photo.url <- ""
}
# photo caption
caplong <- strsplit(thishtml, "<br><font size=2><b>")[[1]]
if(length(caplong)>1) {
caplong <- caplong[2]
cap <- strsplit(caplong, "</b>")[[1]][1]
} else {
cap <- ""
}
c(article.url=thisurl, headline=head, photo.url=photo.url, photo.caption=cap)
}
# get new tweets ready
m <- do.call(rbind, lapply(more.urls, pull))
currentheads <- apply(m[, 2:1], 1, paste, collapse=". ")
### grab latest tweets
adj <- getUser(Sys.getenv("username"))
oldtweets <- twListToDF(userTimeline(adj, n=15, excludeReplies=TRUE))[, c("text", "favoriteCount", "retweetCount", "created")]
names(oldtweets)[names(oldtweets)=="created"] <- "createdUTC"
### tweet all new tweets that haven't been tweeted before
totweet <- currentheads[!(substring(currentheads, 1, 30) %in% substring(oldtweets$text, 1, 30))]
if(length(totweet) > 0) {
if(tweet) {
lapply(rev(totweet), updateStatus, lat=45.141473, long=-89.152339)
} else {
cat(paste("\n\n***  This is what would be posted if tweet=TRUE.\n\n"))
print(totweet)
cat("\n\n")
}
} else {
cat(paste0("\n\n***  No new headlines since last tweet, ", 
format(max(oldtweets$createdUTC), "%a %b %e %I:%M %p", tz=Sys.timezone()), ".\n\n\n"))
}
list(oldtweets=oldtweets, currentheads=currentheads, totweet=totweet)
}
tweethead()
library(twitteR)
search()
tweethead()
?cheat()
cleanup()
q()
library(data.table)
v <- data.table(x=runif(10000),x2 = runif(10000),  x3=runif(10000),x4=runif(10000))
v[,Names:=rownames(v)]
dim(v)
Sys.time()->StartTEST1
v[,  as.list(quantile(.SD,c(.1,.90),na.rm=TRUE)), by=Names]
Sys.time()->EndTEST1
head(v)
dim(v)
apply(v, 1, quantile, c(0.1, 0.9))
v[1:2, ]
v <- data.table(x=runif(10000),x2 = runif(10000),  x3=runif(10000),x4=runif(10000))
apply(v, 1, quantile, c(0.1, 0.9))
a <- apply(v, 1, quantile, c(0.1, 0.9))
dim(a)
class(a)
head(a)
dim(a)
a[, 1:5]
library(data.table)
v <- data.table(x=runif(10000),x2 = runif(10000),  x3=runif(10000),x4=runif(10000))
Sys.time()->StartTEST1
a <- apply(v, 1, quantile, c(0.1, 0.9))
Sys.time()->EndTEST1
StartTEST1
EndTEST1
EndTEST1 - StartTEST1
v[,Names:=rownames(v)]
#test 1 using .SD but not .SDcols
Sys.time()->StartTEST1
v[,  as.list(quantile(.SD,c(.1,.90),na.rm=TRUE)), by=Names]
Sys.time()->EndTEST1
#test 2 using .SD and .SDcols
Sys.time()->StartTEST2
v[,  as.list(quantile(.SD,c(.1,.90),na.rm=TRUE)), by=Names,.SDcols=1:4]
Sys.time()->EndTEST2
#test 3 using colnames directly. This is the fastest I found
Sys.time()->StartTEST3
v[,  as.list(quantile(c(x ,       x2,        x3,        x4 ),c(.1,.90),na.rm=TRUE)), by=Names]
Sys.time()->EndTEST3
# melting the database and doing quantile by summary. This is the second fastest, which is ironic given that the database has to be melted first
library(reshape2)
Sys.time()->StartTEST4
vs<-melt(v)
vs[,  as.list(quantile(value,c(.1,.90),na.rm=TRUE)), by=Names]
Sys.time()->EndTEST4
EndTEST1-StartTEST1
EndTEST2-StartTEST2
EndTEST3-StartTEST3
EndTEST4-StartTEST4
?colmeans
?rowMeans
rowMeans
cleanup()
?cheat
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
for(i in c(1:3, 5:8)) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
}
datlist
lapply(datlist, head)
dat4a <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=24)
dat4b <- readWorksheet(wb, sheet=gs[4], startRow=27)
head(dat4a)
head(dat4b)
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=24)
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
lapply(datlist, names)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
for(i in c(1:3, 5:8)) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
}
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=24)
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
# assign new names for easier combining of data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2"),
c("lot", "lc9992", "junk" "ph2", "alk2", "junk2", "junk3", "lc251"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
# assign new names for easier combining of data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
lapply(datlist, head)
library(plyr)
args(do.call)
dat <- do.call(rbind.fill, datlist)
dim(dat)
head(dat)
apply(dat, 2, all.na)
apply(is.na(dat), 2, is.all)
?all
apply(is.na(dat), 2, all)
apply(is.na(dat), 1, all)
dat[apply(is.na(dat), 1, all), ]
# remove rows with all missing data
dat2 <- dat[!apply(is.na(dat), 1, all), ]
head(dat2)
dat2
apply(is.na(dat), 2, all)
sort(apply(is.na(dat), 2, all))
# remove rows and columns with all missing data
dat2 <- dat[!apply(is.na(dat), 1, all), !apply(is.na(dat), 2, all)]
dat2
mytable(dat$sp1)
mytable(dat$sp2)
mytable(dat$sp)
names(dat)
sort(names(dat))
sort(names(dat2))
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat$sp1)
mytable(dat$sp2)
mytable(dat$sp)
the2s <- dat[, c("lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat[subdex(dat, sp=="SL"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")
the2s <- dat[, c("lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat[subdex(dat, sp=="SL"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
# remove rows and columns with all missing data
the2s2 <- the2s[!apply(is.na(the2s), 1, all), !apply(is.na(the2s), 2, all)]
thespsls2 <- thespsls[!apply(is.na(thespsls), 1, all), !apply(is.na(thespsls), 2, all)]
the2s2
sort(the2s2$lc502)
the2s2$lc502 > "L"
sum(the2s2$lc502 > "L")
sum(subdex(the2s2, lc502 > "L"))
sum(subdex(the2s2, lc9992 > "L"))
dat
dat2
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ])
dat2[228, ]
dat2[dat2$lot=="031229A", ]
dat2[subdex(dat2, lot=="031229A"), ]
# C:\JVA\Lamprey\ChemControl\Resistance\MS\ToxOverTime.r
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
for(i in c(1:3, 5:8)) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
datlist[[i]]$tab <- gs[i]
}
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=24)
datlist[[4]]$tab <- gs[4]
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
datlist[[9]]$tab <- gs[4]
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
dat <- do.call(rbind.fill, datlist)
# remove rows and columns with all missing data
dat2 <- dat[!apply(is.na(dat), 1, all), !apply(is.na(dat), 2, all)]
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
dat2[subdex(dat2, lot=="031229A"), ]
# remove rows and columns with all missing data
tabcol <- match("tab", names(dat))
dat2 <- dat[!apply(is.na(dat[, -tabcol]), 1, all), !apply(is.na(dat), 2, all)]
dim(dat)
dim(dat2)
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
dat2[subdex(dat2, lot=="031229A"), ]
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ])
dat2[subdex(dat2, lot=="031229A"), ]
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat$sp1)
mytable(dat$sp2)
mytable(dat$sp)
the2s <- dat[, c("lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat[subdex(dat, sp=="SL"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
# remove rows and columns with all missing data
the2s2 <- the2s[!apply(is.na(the2s), 1, all), !apply(is.na(the2s), 2, all)]
thespsls2 <- thespsls[!apply(is.na(thespsls), 1, all), !apply(is.na(thespsls), 2, all)]
dat3 <- dat2[!apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
dim(dat)
dim(dat2)
dim(dat3)
dat3
sort(dat3$lot)
apply(dat3[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")], 1, paste, collapse="*")
lclook <- apply(dat3[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")], 1, paste, collapse="*")
stringin("lc", lclook)
grepl("lc", lclook)
grepl("lc", lclook, ignore.case=TRUE)
sum(grepl("lc", lclook, ignore.case=TRUE))
dat4 <- dat3[!grepl("lc", lclook, ignore.case=TRUE), ]
dim(dat)
dim(dat2)
dim(dat3)
dim(dat4)
dat4
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat$sp1)
mytable(dat$sp2)
mytable(dat$sp)
the2s <- dat[, c("lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat[subdex(dat, sp=="SL"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
the2s
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
the2s
dim(dat4)
dat4 <- dat3[!(grepl("lc", lclook, ignore.case=TRUE) | grepl("h", lclook, ignore.case=TRUE)), ]
dim(dat4)
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
the2s2
dat3[grepl("h", lclook, ignore.case=TRUE), ]
grepl("h", lclook, ignore.case=TRUE)
dat4 <- dat3[!(grepl("lc", lclook, ignore.case=TRUE) | grepl("h", lclook, ignore.case=TRUE)), ]
dat4
dat4[, c("lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
# C:\JVA\Lamprey\ChemControl\Resistance\MS\ToxOverTime.r
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
for(i in c(1:3, 5:8)) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
datlist[[i]]$tab <- gs[i]
}
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=24)
datlist[[4]]$tab <- gs[4]
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
datlist[[9]]$tab <- gs[4]
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
dat <- do.call(rbind.fill, datlist)
# remove rows and columns with all missing data
tabcol <- match("tab", names(dat))
dat2 <- dat[!apply(is.na(dat[, -tabcol]), 1, all), !apply(is.na(dat), 2, all)]
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ])
# ask Karen about KI with missing LC
dat3 <- dat2[!apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
# remove rows with "lc" or "h" in the LC columns
lclook <- apply(dat3[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")], 1, paste, collapse="*")
dat4 <- dat3[!(grepl("lc", lclook, ignore.case=TRUE) | grepl("h", lclook, ignore.case=TRUE)), ]
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
the2s
thespsls2
names(the2s)
names(thespsls2)
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the2s) <- names(thespsls)
sldat <- rbind(the2s, thespsls)
sldat$sp <- "SL"
# grab rainbow trout data ... all the "1"s and sp="RBT"
the1s <- dat4[, c("lot", "sp1", "so1", "ph1", "alk1", "lc251", "lc501")]
thesprbts <- dat4[subdex(dat4, sp=="RBT"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the1s) <- names(thesprbts)
rbtdat <- rbind(the1s, thesprbts)
rbtdat$sp <- "RBT"
# combine the works
both <- rbind.fill(sldat, rbtdat)
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the2s) <- names(thespsls)[-6]
sldat <- rbind(the2s, thespsls)
sldat$sp <- "SL"
# grab rainbow trout data ... all the "1"s and sp="RBT"
the1s <- dat4[, c("lot", "sp1", "so1", "ph1", "alk1", "lc251", "lc501")]
thesprbts <- dat4[subdex(dat4, sp=="RBT"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the1s) <- names(thesprbts)[-8]
rbtdat <- rbind(the1s, thesprbts)
rbtdat$sp <- "RBT"
# combine the works
both <- rbind.fill(sldat, rbtdat)
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the2s) <- names(thespsls)[-6]
sldat <- rbind.fill(the2s, thespsls)
sldat$sp <- "SL"
# grab rainbow trout data ... all the "1"s and sp="RBT"
the1s <- dat4[, c("lot", "sp1", "so1", "ph1", "alk1", "lc251", "lc501")]
thesprbts <- dat4[subdex(dat4, sp=="RBT"), c("lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the1s) <- names(thesprbts)[-8]
rbtdat <- rbind.fill(the1s, thesprbts)
rbtdat$sp <- "RBT"
# combine the works
both <- rbind.fill(sldat, rbtdat)
dim(both)
summary(both)
head(both)
# these columns should be numeric (ph  alk lc50 lc999 lc25) ... check to see if it's okay to convert
attach(both)
mytable(ph[is.na(as.numeric(ph))])
table(ph[is.na(as.numeric(ph))])
unique(ph[is.na(as.numeric(ph))])
casefold
# investigate non-numeric entries
nonn <- function(x) {
if(!is.character(x)) stop("x is not a character variable")
asn <- as.numeric(x)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
is.na(asn) & !is.na(x) & !x%in%possiblemissings
}
search()
nonn(ph)
ph[nonn(ph)]
comment <- rep("", length(ph))
newph <- as.numeric(ph)
comment[nonn(ph)] <- paste0(comment[nonn(ph)], " ph: ", ph[nonn(ph)])
comment
?as.numeric
?warning
 of options("warn")
options("warn")
# investigate non-numeric entries
nonn <- function(x) {
if(!is.character(x)) stop("x is not a character variable")
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
is.na(asn) & !is.na(x) & !x%in%possiblemissings
}
comment <- rep("", length(ph))
comment[nonn(ph)] <- paste0(comment[nonn(ph)], "ph:", ph[nonn(ph)], " ")
newph <- as.numeric(ph)
options("warn")
options(warn=0)
options(warn= -9)
options(warn= -1)
options(warn=-1)
options(warn=0)
origopt <- options("warn")
origopt
options(warn=origopt)
options(warn=origopt$warn)
# investigate non-numeric entries
nonn <- function(x) {
if(!is.character(x)) stop("x is not a character variable")
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
is.na(asn) & !is.na(x) & !x%in%possiblemissings
}
comment <- rep("", length(ph))
comment[nonn(ph)] <- paste0(comment[nonn(ph)], "ph:", ph[nonn(ph)], " ")
newph <- as.numeric(ph)
plot
plot.default
# investigate non-numeric entries
nonn <- function(x, justindex=FALSE, varname=NULL) {
if(!is.character(x)) stop("x is not a character variable")
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
sel <- is.na(asn) & !is.na(x) & !x%in%possiblemissings
if(justindex) {
return(sel)
} else {
note <- rep("", length(x))
if(is.null(varname)) varname <- deparse(substitute(x))
note[sel] <- paste0(varname, ":" x[sel])
return(cbind(asn, note))
}
}
# investigate non-numeric entries
nonn <- function(x, justindex=FALSE, varname=NULL) {
if(!is.character(x)) stop("x is not a character variable")
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
sel <- is.na(asn) & !is.na(x) & !x%in%possiblemissings
if(justindex) {
return(sel)
} else {
if(is.null(varname)) varname <- deparse(substitute(x))
note <- rep("", length(x))
note[sel] <- paste0(varname, ":" x[sel])
return(cbind(asn, note))
}
}
# investigate non-numeric entries
nonn <- function(x, justindex=FALSE, varname=NULL) {
if(!is.character(x)) stop("x is not a character variable")
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
sel <- is.na(asn) & !is.na(x) & !x%in%possiblemissings
if(justindex) {
return(sel)
} else {
if(is.null(varname)) varname <- deparse(substitute(x))
note <- rep("", length(x))
note[sel] <- paste0(varname, ":", x[sel])
return(cbind(asn, note))
}
}
nonn(ph)
# investigate non-numeric entries
nonn <- function(x, justindex=FALSE, varname=NULL) {
if(!is.character(x)) stop("x is not a character variable")
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
sel <- is.na(asn) & !is.na(x) & !x%in%possiblemissings
if(justindex) {
return(sel)
} else {
if(is.null(varname)) varname <- deparse(substitute(x))
note <- rep("", length(x))
note[sel] <- paste0(varname, ":", x[sel])
return(list(asn, note))
}
}
nonn(ph)
lapply(both[, c("ph", "alk", "lc25", "lc50", "lc999")], nonn)
tonum <- lapply(both[, c("ph", "alk", "lc25", "lc50", "lc999")], nonn)
numz <- sapply(tonum, "[", 1)
notez <- sapply(tonum, "[", 2)
numz
data.frame(sapply(tonum, "[", 1))
notez
numz <- data.frame(sapply(tonum, "[", 1))
notez <- do.call(cbind, sapply(tonum, "[", 2))
numz
notez
notez <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse=",")
notez
notez <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
notez
detach(both)
detach(both)
# these columns should be numeric (ph  alk lc25 lc50 lc999) ... check to see if it's okay to convert
colz <- c("ph", "alk", "lc25", "lc50", "lc999")
tonum <- lapply(both[, colz], nonn)
both[, colz] <- data.frame(sapply(tonum, "[", 1))
both$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
sel <- both$comment!=""
both[sel, ]
# C:\JVA\Lamprey\ChemControl\Resistance\MS\ToxOverTime.r
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
for(i in c(1:3, 5:8)) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
datlist[[i]]$tab <- gs[i]
}
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=24)
datlist[[4]]$tab <- gs[4]
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
datlist[[9]]$tab <- gs[4]
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
dat <- do.call(rbind.fill, datlist)
# remove rows and columns with all missing data
tabcol <- match("tab", names(dat))
dat2 <- dat[!apply(is.na(dat[, -tabcol]), 1, all), !apply(is.na(dat), 2, all)]
dat2
sort(dat2$lot)
table(dat2$tab)
keywords <- c("Clar", "H&S 2", "H&S d", "Kin", "Wey")
grepl(keywords, dat2$lot)
?grep
?"grepl"
q()
?grep
lapply(keywords, grepl, dat2$lot)
sapply(keywords, grepl, dat2$lot)
dat2[apply(sapply(keywords, grepl, dat2$lot), 1, any), ]
dat2[apply(sapply(keywords, grepl, dat2$lot), 1, any), ]
a <- dat2[apply(sapply(keywords, grepl, dat2$lot), 1, any), ]
a[order(a$lot), ]
a <- dat2[apply(sapply(keywords, grepl, dat2$lot), 1, any), ]
a[order(a$tab, a$lot), ]
dat2[dat2$tab=="Clariant 2001,02,04,05,08", ]
q()
tweethead()
q()
?readWorksheet
?readWorksheet
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
firstline <- datlist
for(i in 1:8) {
firstline[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=1, endRow=1, header=FALSE)
firstline[[i]]$tab <- gs[i]
if(i != 4) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
datlist[[i]]$tab <- gs[i]
}
}
firstline
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=24)
datlist[[4]]$tab <- gs[4]
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
datlist[[9]]$tab <- gs[4]
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
dat <- do.call(rbind.fill, datlist)
fir <- do.call(rbind.fill, firstline)
fir
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
dat <- do.call(rbind.fill, datlist)
dat$row <- 1:dim(dat)[1]
fir <- do.call(rbind.fill, firstline)
names(fir) <- c("lot", "tab")
fir$row <- 0
head(fir)
head(dat)
# C:\JVA\Lamprey\ChemControl\Resistance\MS\ToxOverTime.r
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
firstline <- datlist
for(i in 1:8) {
firstline[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=1, endRow=1, header=FALSE)
firstline[[i]]$tab <- gs[i]
if(i != 4) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
datlist[[i]]$tab <- gs[i]
}
}
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=24)
datlist[[4]]$tab <- gs[4]
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
datlist[[9]]$tab <- gs[4]
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
dat <- do.call(rbind.fill, datlist)
dat$row <- 1:dim(dat)[1]
fir <- do.call(rbind.fill, firstline)
names(fir) <- c("lot", "tab")
fir$row <- 0
datb <- rbind.fill(dat, fir)
datb <- with(datb, datb[order(tab, row), ])
# remove rows and columns with all missing data
tabcol <- match("tab", names(datb))
dat2 <- datb[!apply(is.na(datb[, -tabcol]), 1, all), !apply(is.na(datb), 2, all)]
head(dat2)
head(dat2)
keywords <- c("Clar", "H&S 2", "H&S d", "Kin", "Wey", "Iof")
a <- dat2[apply(sapply(keywords, grepl, dat2$lot), 1, any), ]
a[order(a$tab, a$lot), ]
a[order(a$tab, a$lot), c("tab", "lot")]
# C:\JVA\Lamprey\ChemControl\Resistance\MS\ToxOverTime.r
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
firstline <- datlist
for(i in 1:8) {
firstline[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=1, endRow=1, header=FALSE)
firstline[[i]]$tab <- gs[i]
if(i != 4) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
datlist[[i]]$tab <- gs[i]
}
}
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=26)
datlist[[4]]$tab <- gs[4]
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
datlist[[9]]$tab <- gs[4]
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
dat <- do.call(rbind.fill, datlist)
dat$row <- 1:dim(dat)[1]
fir <- do.call(rbind.fill, firstline)
names(fir) <- c("lot", "tab")
fir$row <- 0
datb <- rbind.fill(dat, fir)
datb <- with(datb, datb[order(tab, row), ])
# remove rows and columns with all missing data
tabcol <- match("tab", names(datb))
dat2 <- datb[!apply(is.na(datb[, -tabcol]), 1, all), !apply(is.na(datb), 2, all)]
keywords <- c("Clar", "H&S 2", "H&S d", "Kin", "Wey", "Iof")
a <- dat2[apply(sapply(keywords, grepl, dat2$lot), 1, any), ]
a[order(a$tab, a$lot), c("tab", "lot")]
a[order(a$tab, a$row), c("tab", "lot")]
?cheat
a$lot
gsub([[:alpha:]], "", a$lot)
gsub("[[:alpha:]]", "", a$lot)
gsub("[[:alpha:]]|[[:punct:]]", "", a$lot)
gsub("[[:alpha:]]|[[:punct:]]|[[:space:]]", "", a$lot)
keywords <- c("Clar", "H&S 2", "H&S d", "Kin", "Wey", "Iof")
keysel <- apply(sapply(keywords, grepl, dat2$lot), 1, any)
dat2$year <- NA
dat2$year[keysel] <- gsub("[[:alpha:]]|[[:punct:]]|[[:space:]]", "", dat2$lot[keysel])
head(dat2)
fill
# remove rows and columns with all missing data
tabcol <- match("tab", names(datb))
dat2 <- datb[!apply(is.na(datb[, -tabcol]), 1, all), !apply(is.na(datb), 2, all)]
# tease out the years from the header rows
keywords <- c("Clar", "H&S 2", "H&S d", "Kin", "Wey", "Iof")
keysel <- apply(sapply(keywords, grepl, dat2$lot), 1, any)
dat2$header <- ""
dat2$header[keysel] <- dat2$lot[keysel]
dat2$year <- NA
dat2$year[keysel] <- gsub("[[:alpha:]]|[[:punct:]]|[[:space:]]", "", dat2$lot[keysel])
dat2 <- with(dat2, dat2[order(tab, row), ])
dat2$header <- fill(dat2$header)
dat2$year <- fill(dat2$year)
dat2
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ])
# ask Karen about KI with missing LC
dat3 <- dat2[!apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
# remove rows with "lc" or "h" in the LC columns
lclook <- apply(dat3[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")], 1, paste, collapse="*")
dat4 <- dat3[!(grepl("lc", lclook, ignore.case=TRUE) | grepl("h", lclook, ignore.case=TRUE)), ]
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 1:21]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 1:21])
# ask Karen about KI with missing LC
dat3 <- dat2[!apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
# remove rows with "lc" or "h" in the LC columns
lclook <- apply(dat3[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")], 1, paste, collapse="*")
dat4 <- dat3[!(grepl("lc", lclook, ignore.case=TRUE) | grepl("h", lclook, ignore.case=TRUE)), ]
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21]
names(datb)
tabcol <- match(c("tab", "row"), names(datb))
tabcol
# C:\JVA\Lamprey\ChemControl\Resistance\MS\ToxOverTime.r
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
firstline <- datlist
for(i in 1:8) {
firstline[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=1, endRow=1, header=FALSE)
firstline[[i]]$tab <- gs[i]
if(i != 4) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
datlist[[i]]$tab <- gs[i]
}
}
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=26)
datlist[[4]]$tab <- gs[4]
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
datlist[[9]]$tab <- gs[4]
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
# combine data frames within each list, then combine the two lists
dat <- do.call(rbind.fill, datlist)
dat$row <- 1:dim(dat)[1]
fir <- do.call(rbind.fill, firstline)
names(fir) <- c("lot", "tab")
fir$row <- 0
datb <- rbind.fill(dat, fir)
# remove rows and columns with all missing data
tabcol <- match(c("tab", "row"), names(datb))
dat2 <- datb[!apply(is.na(datb[, -tabcol]), 1, all), !apply(is.na(datb), 2, all)]
# tease out the years from the header rows
keywords <- c("Clar", "H&S 2", "H&S d", "Kin", "Wey", "Iof")
keysel <- apply(sapply(keywords, grepl, dat2$lot), 1, any)
dat2$header <- ""
dat2$header[keysel] <- dat2$lot[keysel]
dat2$year <- NA
dat2$year[keysel] <- gsub("[[:alpha:]]|[[:punct:]]|[[:space:]]", "", dat2$lot[keysel])
dat2 <- with(dat2, dat2[order(tab, row), ])
dat2$header <- fill(dat2$header)
dat2$year <- fill(dat2$year)
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 1:21]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 1:21])
# ask Karen about KI with missing LC
dat3 <- dat2[!apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
# remove rows with "lc" or "h" in the LC columns
lclook <- apply(dat3[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")], 1, paste, collapse="*")
dat4 <- dat3[!(grepl("lc", lclook, ignore.case=TRUE) | grepl("h", lclook, ignore.case=TRUE)), ]
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21])
# ask Karen about KI with missing LC
dat3 <- dat2[!apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
# remove rows with "lc" or "h" in the LC columns
lclook <- apply(dat3[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")], 1, paste, collapse="*")
dat4 <- dat3[!(grepl("lc", lclook, ignore.case=TRUE) | grepl("h", lclook, ignore.case=TRUE)), ]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21], 11)
dim(dat4)
dat4
dat4
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("tab", "header", "lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("tab", "header", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the2s) <- names(thespsls)[-8]
sldat <- rbind.fill(the2s, thespsls)
sldat$sp <- "SL"
# grab rainbow trout data ... all the "1"s and sp="RBT"
the1s <- dat4[, c("tab", "header", "lot", "sp1", "so1", "ph1", "alk1", "lc251", "lc501")]
thesprbts <- dat4[subdex(dat4, sp=="RBT"), c("tab", "header", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the1s) <- names(thesprbts)[-10]
rbtdat <- rbind.fill(the1s, thesprbts)
rbtdat$sp <- "RBT"
# combine the works
both <- rbind.fill(rbtdat, sldat)
both <- with(both, both[order(tab, lot), ])
both
sldat
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("tab", "header", "lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("tab", "header", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
head(
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("tab", "header", "lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("tab", "header", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
head(
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("tab", "header", "lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("tab", "header", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
head(the2s)
dat4
both
dat4
both
# remove rows with all missing data
both2 <- both[!apply(is.na(both[, c("so", "ph", "alk", "lc25", "lc50", "lc999"]), 1, all), ]
# remove rows with all missing data
both2 <- both[!apply(is.na(both[, c("so", "ph", "alk", "lc25", "lc50", "lc999")]), 1, all), ]
dim(both)
dim(both2)
both2
with(both2, both2[order(sp, year, ph), ])
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("tab", "header", "row", "year", "lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("tab", "header", "row", "year", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the2s) <- names(thespsls)[-10]
sldat <- rbind.fill(the2s, thespsls)
sldat$sp <- "SL"
# grab rainbow trout data ... all the "1"s and sp="RBT"
the1s <- dat4[, c("tab", "header", "row", "year", "lot", "sp1", "so1", "ph1", "alk1", "lc251", "lc501")]
thesprbts <- dat4[subdex(dat4, sp=="RBT"), c("tab", "header", "row", "year", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the1s) <- names(thesprbts)[-12]
rbtdat <- rbind.fill(the1s, thesprbts)
rbtdat$sp <- "RBT"
# combine the works
both <- rbind.fill(rbtdat, sldat)
both <- with(both, both[order(tab, lot), ])
# remove rows with all missing data
both2 <- both[!apply(is.na(both[, c("so", "ph", "alk", "lc25", "lc50", "lc999")]), 1, all), ]
with(both2, both2[order(sp, year, ph), ])
with(both2, both2[order(sp, year, ph), ], -(1:2))
with(both2, both2[order(sp, year, ph), -(1:2)])
# investigate non-numeric entries
nonn <- function(x, justindex=FALSE, varname=NULL) {
if(!is.character(x)) stop("x is not a character variable")
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
sel <- is.na(asn) & !is.na(x) & !x%in%possiblemissings
if(justindex) {
return(sel)
} else {
if(is.null(varname)) varname <- deparse(substitute(x))
note <- rep("", length(x))
note[sel] <- paste0(varname, ":", x[sel])
return(list(asn, note))
}
}
# these columns should be numeric (ph  alk lc25 lc50 lc999) ... check to see if it's okay to convert
colz <- c("ph", "alk", "lc25", "lc50", "lc999")
tonum <- lapply(both2[, colz], nonn)
both2[, colz] <- data.frame(sapply(tonum, "[", 1))
both2$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
sel <- both2$comment!=""
both2[sel, ]
lapply(both2[, colz], nonn)
# investigate non-numeric entries
nonn <- function(x, justindex=FALSE, varname=NULL) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
sel <- is.na(asn) & !is.na(x) & !x%in%possiblemissings
if(justindex) {
return(sel)
} else {
if(is.null(varname)) varname <- deparse(substitute(x))
note <- rep("", length(x))
note[sel] <- paste0(varname, ":", x[sel])
return(list(asn, note))
}
}
lapply(both2[, colz], nonn)
lapply(colz, function(v) nonn(both2[, v], varname=v))
# remove rows with all missing data
both2 <- both[!apply(is.na(both[, c("so", "ph", "alk", "lc25", "lc50", "lc999")]), 1, all), ]
with(both2, both2[order(sp, year, ph), ])
# investigate non-numeric entries
nonn <- function(x, justindex=FALSE, varname=NULL) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
sel <- is.na(asn) & !is.na(x) & !x%in%possiblemissings
if(justindex) {
return(sel)
} else {
if(is.null(varname)) varname <- deparse(substitute(x))
note <- rep("", length(x))
note[sel] <- paste0(varname, ":", x[sel])
return(list(asn, note))
}
}
# these columns should be numeric (ph  alk lc25 lc50 lc999) ... check to see if it's okay to convert
colz <- c("ph", "alk", "lc25", "lc50", "lc999")
lapply(colz, function(v) nonn(both2[, v], varname=v))
tonum <- lapply(colz, function(v) nonn(both2[, v], varname=v))
both3 <- both2
both3[, colz] <- data.frame(sapply(tonum, "[", 1))
both3$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
sel <- both3$comment!=""
both3[sel, ]
summary(both3)
cleanup()
search()
# C:\JVA\Lamprey\ChemControl\Resistance\MS\ToxOverTime.r
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
firstline <- datlist
for(i in 1:8) {
firstline[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=1, endRow=1, header=FALSE)
firstline[[i]]$tab <- gs[i]
if(i != 4) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
datlist[[i]]$tab <- gs[i]
}
}
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=26)
datlist[[4]]$tab <- gs[4]
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
datlist[[9]]$tab <- gs[4]
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
# combine data frames within each list, then combine the two lists
dat <- do.call(rbind.fill, datlist)
dat$row <- 1:dim(dat)[1]
fir <- do.call(rbind.fill, firstline)
names(fir) <- c("lot", "tab")
fir$row <- 0
datb <- rbind.fill(dat, fir)
rm(wb, gs, startrowz, firstline datlist, newnames, i, dat, fir)
# remove rows and columns with all missing data
tabcol <- match(c("tab", "row"), names(datb))
dat2 <- datb[!apply(is.na(datb[, -tabcol]), 1, all), !apply(is.na(datb), 2, all)]
# tease out the years from the header rows
keywords <- c("Clar", "H&S 2", "H&S d", "Kin", "Wey", "Iof")
keysel <- apply(sapply(keywords, grepl, dat2$lot), 1, any)
dat2$header <- ""
dat2$header[keysel] <- dat2$lot[keysel]
dat2$year <- NA
dat2$year[keysel] <- as.numeric(gsub("[[:alpha:]]|[[:punct:]]|[[:space:]]", "", dat2$lot[keysel]))
dat2 <- with(dat2, dat2[order(tab, row), ])
dat2$header <- fill(dat2$header)
dat2$year <- fill(dat2$year)
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21], 11)
# ask Karen about KI with missing LC
dat3 <- dat2[!apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
# remove rows with "lc" or "h" in the LC columns
lclook <- apply(dat3[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")], 1, paste, collapse="*")
dat4 <- dat3[!(grepl("lc", lclook, ignore.case=TRUE) | grepl("h", lclook, ignore.case=TRUE)), ]
rm(tabcol, dat2, keywords, keysel, dat3, lclook)
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("tab", "header", "row", "year", "lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("tab", "header", "row", "year", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the2s) <- names(thespsls)[-10]
sldat <- rbind.fill(the2s, thespsls)
sldat$sp <- "SL"
# grab rainbow trout data ... all the "1"s and sp="RBT"
the1s <- dat4[, c("tab", "header", "row", "year", "lot", "sp1", "so1", "ph1", "alk1", "lc251", "lc501")]
thesprbts <- dat4[subdex(dat4, sp=="RBT"), c("tab", "header", "row", "year", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the1s) <- names(thesprbts)[-12]
rbtdat <- rbind.fill(the1s, thesprbts)
rbtdat$sp <- "RBT"
# combine the works
both <- rbind.fill(rbtdat, sldat)
both <- with(both, both[order(tab, lot), ])
# remove rows with all missing data
both2 <- both[!apply(is.na(both[, c("so", "ph", "alk", "lc25", "lc50", "lc999")]), 1, all), ]
with(both2, both2[order(sp, year, ph), ])
rm(the2s, thespsls, sldat, the1s, thesprbts, rbtdat, both)
# investigate non-numeric entries
nonn <- function(x, justindex=FALSE, varname=NULL) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
sel <- is.na(asn) & !is.na(x) & !x%in%possiblemissings
if(justindex) {
return(sel)
} else {
if(is.null(varname)) varname <- deparse(substitute(x))
note <- rep("", length(x))
note[sel] <- paste0(varname, ":", x[sel])
return(list(asn, note))
}
}
# these columns should be numeric (ph  alk lc25 lc50 lc999) ... check to see if it's okay to convert
colz <- c("ph", "alk", "lc25", "lc50", "lc999")
tonum <- lapply(colz, function(v) nonn(both2[, v], varname=v))
both3 <- both2
both3[, colz] <- data.frame(sapply(tonum, "[", 1))
both3$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
sel <- both3$comment!=""
both3[sel, ]
summary(both3)
rm(nonn, colz, tonum, sel)
ls()
rm(wb, gs, startrowz, firstline, datlist, newnames, i, dat, fir)
ls()
# C:\JVA\Lamprey\ChemControl\Resistance\MS\ToxOverTime.r
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
firstline <- datlist
for(i in 1:8) {
firstline[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=1, endRow=1, header=FALSE)
firstline[[i]]$tab <- gs[i]
if(i != 4) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
datlist[[i]]$tab <- gs[i]
}
}
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=26)
datlist[[4]]$tab <- gs[4]
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
datlist[[9]]$tab <- gs[4]
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
# combine data frames within each list, then combine the two lists
dat <- do.call(rbind.fill, datlist)
dat$row <- 1:dim(dat)[1]
fir <- do.call(rbind.fill, firstline)
names(fir) <- c("lot", "tab")
fir$row <- 0
datb <- rbind.fill(dat, fir)
rm(wb, gs, startrowz, firstline, datlist, newnames, i, dat, fir)
# remove rows and columns with all missing data
tabcol <- match(c("tab", "row"), names(datb))
dat2 <- datb[!apply(is.na(datb[, -tabcol]), 1, all), !apply(is.na(datb), 2, all)]
# tease out the years from the header rows
keywords <- c("Clar", "H&S 2", "H&S d", "Kin", "Wey", "Iof")
keysel <- apply(sapply(keywords, grepl, dat2$lot), 1, any)
dat2$header <- ""
dat2$header[keysel] <- dat2$lot[keysel]
dat2$year <- NA
dat2$year[keysel] <- as.numeric(gsub("[[:alpha:]]|[[:punct:]]|[[:space:]]", "", dat2$lot[keysel]))
dat2 <- with(dat2, dat2[order(tab, row), ])
dat2$header <- fill(dat2$header)
dat2$year <- fill(dat2$year)
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21], 11)
# ask Karen about KI with missing LC
dat3 <- dat2[!apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
# remove rows with "lc" or "h" in the LC columns
lclook <- apply(dat3[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")], 1, paste, collapse="*")
dat4 <- dat3[!(grepl("lc", lclook, ignore.case=TRUE) | grepl("h", lclook, ignore.case=TRUE)), ]
rm(datb, tabcol, dat2, keywords, keysel, dat3, lclook)
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("tab", "header", "row", "year", "lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("tab", "header", "row", "year", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the2s) <- names(thespsls)[-10]
sldat <- rbind.fill(the2s, thespsls)
sldat$sp <- "SL"
# grab rainbow trout data ... all the "1"s and sp="RBT"
the1s <- dat4[, c("tab", "header", "row", "year", "lot", "sp1", "so1", "ph1", "alk1", "lc251", "lc501")]
thesprbts <- dat4[subdex(dat4, sp=="RBT"), c("tab", "header", "row", "year", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the1s) <- names(thesprbts)[-12]
rbtdat <- rbind.fill(the1s, thesprbts)
rbtdat$sp <- "RBT"
# combine the works
both <- rbind.fill(rbtdat, sldat)
both <- with(both, both[order(tab, lot), ])
# remove rows with all missing data
both2 <- both[!apply(is.na(both[, c("so", "ph", "alk", "lc25", "lc50", "lc999")]), 1, all), ]
with(both2, both2[order(sp, year, ph), ])
rm(dat4, the2s, thespsls, sldat, the1s, thesprbts, rbtdat, both)
# investigate non-numeric entries
nonn <- function(x, justindex=FALSE, varname=NULL) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
sel <- is.na(asn) & !is.na(x) & !x%in%possiblemissings
if(justindex) {
return(sel)
} else {
if(is.null(varname)) varname <- deparse(substitute(x))
note <- rep("", length(x))
note[sel] <- paste0(varname, ":", x[sel])
return(list(asn, note))
}
}
# these columns should be numeric (ph  alk lc25 lc50 lc999) ... check to see if it's okay to convert
colz <- c("ph", "alk", "lc25", "lc50", "lc999")
tonum <- lapply(colz, function(v) nonn(both2[, v], varname=v))
both3 <- both2
both3[, colz] <- data.frame(sapply(tonum, "[", 1))
both3$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
sel <- both3$comment!=""
both3[sel, ]
summary(both3)
rm(both2, nonn, colz, tonum, sel)
ls()
plotdf(both3)
attach(both3)
plot(year, lc50, col=as.factor(sp))
windows()
par(mar=c(4, 4, 1, 1))
plot(year, lc50, type="n", ylim=range(lc25, lc50, lc999), xlab="Year", ylab="Lethal Concentration  (ppm)")
points(year, lc25, col=as.factor(sp))
points(year, lc50, col=as.factor(sp))
points(year, lc999, col=as.factor(sp))
par(mar=c(4, 4, 1, 1))
plot(year, lc50, type="n", ylim=range(lc25, lc50, lc999, na.rm=TRUE), xlab="Year", ylab="Lethal Concentration  (ppm)")
points(year, lc25, col=as.factor(sp))
points(year, lc50, col=as.factor(sp))
points(year, lc999, col=as.factor(sp))
par(mar=c(4, 4, 1, 1))
plot(year, lc50, type="n", ylim=range(lc25, lc50, lc999, na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
points(year, lc25, col=as.factor(sp))
points(year, lc50, col=as.factor(sp)+2)
points(year, lc999, col=as.factor(sp)+4)
spc <- as.numeric(as.factor(sp))
windows()
par(mar=c(4, 4, 1, 1))
plot(year, lc50, type="n", ylim=range(lc25, lc50, lc999, na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
points(year, lc25, col=spc)
points(year, lc50, col=spc+2)
points(year, lc999, col=spc+4)
summary(both3)
summary(both3[sp=="SL", ])
summary(both3[sp=="RBT", ])
summary(both3[sp=="SL", ])
colz <- blindcolz[2:4]
windows()
par(mar=c(4, 4, 1, 1), mfrow=c(2, 1))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
text(year[sel], lc25[sel], "2", col=colz[1])
text(year[sel], lc50[sel], "5", col=colz[2])
text(year[sel], lc999[sel], "9", col=colz[3])
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
text(year[sel], lc25[sel], "2", col=colz[1])
text(year[sel], lc50[sel], "5", col=colz[2])
text(year[sel], lc999[sel], "9", col=colz[3])
par(mar=c(4, 4, 1, 1), mfrow=c(2, 1))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel]), col=colz[1])
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel]), col=colz[2])
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel]), col=colz[3])
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel]), col=colz[1])
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel]), col=colz[2])
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel]), col=colz[3])
jy <- jitter(year)
colz <- blindcolz[2:4]
jy <- jitter(year)
windows()
par(mar=c(4, 4, 1, 1), mfrow=c(2, 1))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel]), col=colz[1])
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel]), col=colz[2])
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel]), col=colz[3])
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel]), col=colz[1])
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel]), col=colz[2])
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel]), col=colz[3])
par(mar=c(4, 4, 1, 1), mfrow=c(2, 1))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel]), col=colz[2])
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel]), col=colz[3])
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel]), col=colz[1])
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel]), col=colz[2])
par(mar=c(4, 4, 1, 1), mfrow=c(2, 1))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel], deg=2), col=colz[3], lwd=2)
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="Year", ylab="Lethal Concentration  (ppm)")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel], deg=2), col=colz[1], lwd=2)
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
par(mar=c(3, 3, 1, 1), oma=c(2, 2, 0, 0), mfrow=c(2, 1))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="")
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel], deg=2), col=colz[3], lwd=2)
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel], deg=2), col=colz[1], lwd=2)
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
mtext("Year", side=1, outer=TRUE)
mtext("Lethal Concentration  (ppm)", side=2, outer=TRUE)
par(mar=c(3, 3, 1, 1), oma=c(1, 1, 0, 0), mfrow=c(2, 1))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="")
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel], deg=2), col=colz[3], lwd=2)
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel], deg=2), col=colz[1], lwd=2)
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
mtext("Year", side=1, outer=TRUE)
mtext("Lethal Concentration  (ppm)", side=2, outer=TRUE)
legend("topleft", c("LC25", "LC50", "LC99.9"), col=colz, pch=c("2", "5", "9"))
par(mar=c(3, 3, 1, 1), oma=c(1, 1, 0, 0), mfrow=c(2, 1))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="")
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel], deg=2), col=colz[3], lwd=2)
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel], deg=2), col=colz[1], lwd=2)
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
legend("topleft", c("LC99.9", "LC50", "LC25"), col=rev(colz), pch=c("9", "5", "2"))
mtext("Year", side=1, outer=TRUE)
mtext("Lethal Concentration  (ppm)", side=2, outer=TRUE)
legend("topleft", c("LC99.9", "LC50", "LC25"), col=rev(colz), pch=c("9", "5", "2"), font=2)
legend("topleft", c("LC99.9", "LC50", "LC25"), col=rev(colz), pch=c("9", "5", "2"), p.font=2)
?legend
par(mar=c(3, 3, 3, 1), oma=c(1, 1, 0, 0), mfrow=c(2, 1))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="", main="Sea Lamprey")
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel], deg=2), col=colz[3], lwd=2)
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="", main="Rainbow Trout")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel], deg=2), col=colz[1], lwd=2)
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
legend("topleft", c("LC99.9", "LC50", "LC25"), col=rev(colz), pch=c("9", "5", "2"))
mtext("Year", side=1, outer=TRUE)
mtext("Lethal Concentration  (ppm)", side=2, outer=TRUE)
par(mar=c(3, 3, 2, 1), oma=c(1, 1, 0, 0), mfrow=c(2, 1))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="", main="Sea Lamprey")
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel], deg=2), col=colz[3], lwd=2)
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="", main="Rainbow Trout")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel], deg=2), col=colz[1], lwd=2)
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
legend("topleft", c("LC99.9", "LC50", "LC25"), col=rev(colz), pch=c("9", "5", "2"))
mtext("Year", side=1, outer=TRUE)
mtext("Lethal Concentration  (ppm)", side=2, outer=TRUE)
par(mar=c(3, 3, 2, 1), oma=c(1, 1, 0, 0), mfrow=c(2, 1))
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="", main="Rainbow Trout")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel], deg=2), col=colz[1], lwd=2)
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
legend("topleft", c("LC99.9", "LC50", "LC25"), col=rev(colz), pch=c("9", "5", "2"))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="", main="Sea Lamprey")
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel], deg=2), col=colz[3], lwd=2)
mtext("Year", side=1, outer=TRUE)
mtext("Lethal Concentration  (ppm)", side=2, outer=TRUE)
cleanup()
q()
# C:\JVA\Lamprey\ChemControl\Resistance\MS\ToxOverTime.r
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
firstline <- datlist
for(i in 1:8) {
firstline[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=1, endRow=1, header=FALSE)
firstline[[i]]$tab <- gs[i]
if(i != 4) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
datlist[[i]]$tab <- gs[i]
}
}
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=26)
datlist[[4]]$tab <- gs[4]
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
datlist[[9]]$tab <- gs[4]
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
# combine data frames within each list, then combine the two lists
dat <- do.call(rbind.fill, datlist)
dat$row <- 1:dim(dat)[1]
fir <- do.call(rbind.fill, firstline)
names(fir) <- c("lot", "tab")
fir$row <- 0
datb <- rbind.fill(dat, fir)
rm(wb, gs, startrowz, firstline, datlist, newnames, i, dat, fir)
# remove rows and columns with all missing data
tabcol <- match(c("tab", "row"), names(datb))
dat2 <- datb[!apply(is.na(datb[, -tabcol]), 1, all), !apply(is.na(datb), 2, all)]
# tease out the years from the header rows
keywords <- c("Clar", "H&S 2", "H&S d", "Kin", "Wey", "Iof")
keysel <- apply(sapply(keywords, grepl, dat2$lot), 1, any)
dat2$header <- ""
dat2$header[keysel] <- dat2$lot[keysel]
dat2$year <- NA
dat2$year[keysel] <- as.numeric(gsub("[[:alpha:]]|[[:punct:]]|[[:space:]]", "", dat2$lot[keysel]))
dat2 <- with(dat2, dat2[order(tab, row), ])
dat2$header <- fill(dat2$header)
dat2$year <- fill(dat2$year)
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21], 11)
# ask Karen about KI with missing LC
dat3 <- dat2[!apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
# remove rows with "lc" or "h" in the LC columns
lclook <- apply(dat3[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")], 1, paste, collapse="*")
dat4 <- dat3[!(grepl("lc", lclook, ignore.case=TRUE) | grepl("h", lclook, ignore.case=TRUE)), ]
rm(datb, tabcol, dat2, keywords, keysel, dat3, lclook)
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("tab", "header", "row", "year", "lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("tab", "header", "row", "year", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the2s) <- names(thespsls)[-10]
sldat <- rbind.fill(the2s, thespsls)
sldat$sp <- "SL"
# grab rainbow trout data ... all the "1"s and sp="RBT"
the1s <- dat4[, c("tab", "header", "row", "year", "lot", "sp1", "so1", "ph1", "alk1", "lc251", "lc501")]
thesprbts <- dat4[subdex(dat4, sp=="RBT"), c("tab", "header", "row", "year", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the1s) <- names(thesprbts)[-12]
rbtdat <- rbind.fill(the1s, thesprbts)
rbtdat$sp <- "RBT"
# combine the works
both <- rbind.fill(rbtdat, sldat)
both <- with(both, both[order(tab, lot), ])
# remove rows with all missing data
both2 <- both[!apply(is.na(both[, c("so", "ph", "alk", "lc25", "lc50", "lc999")]), 1, all), ]
with(both2, both2[order(sp, year, ph), ])
rm(dat4, the2s, thespsls, sldat, the1s, thesprbts, rbtdat, both)
# investigate non-numeric entries
nonn <- function(x, justindex=FALSE, varname=NULL) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
sel <- is.na(asn) & !is.na(x) & !x%in%possiblemissings
if(justindex) {
return(sel)
} else {
if(is.null(varname)) varname <- deparse(substitute(x))
note <- rep("", length(x))
note[sel] <- paste0(varname, ":", x[sel])
return(list(asn, note))
}
}
# these columns should be numeric (ph  alk lc25 lc50 lc999) ... check to see if it's okay to convert
colz <- c("ph", "alk", "lc25", "lc50", "lc999")
tonum <- lapply(colz, function(v) nonn(both2[, v], varname=v))
both3 <- both2
both3[, colz] <- data.frame(sapply(tonum, "[", 1))
both3$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
sel <- both3$comment!=""
both3[sel, ]
summary(both3)
rm(both2, nonn, colz, tonum, sel)
plotdf(both3)
attach(both3)
colz <- blindcolz[2:4]
jy <- jitter(year)
windows()
par(mar=c(3, 3, 2, 1), oma=c(1, 1, 0, 0), mfrow=c(2, 1))
sel <- sp=="RBT"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="", main="Rainbow Trout")
text(jy[sel], lc25[sel], "2", col=colz[1])
lines(loess.smooth(year[sel], lc25[sel], deg=2), col=colz[1], lwd=2)
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
legend("topleft", c("LC99.9", "LC50", "LC25"), col=rev(colz), pch=c("9", "5", "2"))
sel <- sp=="SL"
plot(year, lc50, type="n", ylim=range(lc25[sel], lc50[sel], lc999[sel], na.rm=TRUE), las=1, xlab="", ylab="", main="Sea Lamprey")
text(jy[sel], lc50[sel], "5", col=colz[2])
lines(loess.smooth(year[sel], lc50[sel], deg=2), col=colz[2], lwd=2)
text(jy[sel], lc999[sel], "9", col=colz[3])
lines(loess.smooth(year[sel], lc999[sel], deg=2), col=colz[3], lwd=2)
mtext("Year", side=1, outer=TRUE)
mtext("Lethal Concentration  (ppm)", side=2, outer=TRUE)
ls()
graphics.off()
cleanup()
# C:\JVA\Lamprey\ChemControl\Resistance\MS\HBQA.r
library(lubridate)
library(LW1949)
source("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/ReadSlaght.r")
dat <- Slaghtdat
rm(Slaghtdat)
sel <- grepl("s", dat$species, ignore.case=TRUE) & grepl("h", dat$water, ignore.case=TRUE)
sub <- dat[sel, ]
dim(sub)
summary(sub)
summary(sub)
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawData.RData")
all.main$Year <- year(all.main$Start_Date)
mi <- match(all.sub$ID, all.main$ID)
all.sub$Year <- all.main$Year[mi]
all.main$fg <- paste(all.main$Folder, all.main$group)
all.sub$fg <- all.main$fg[mi]
rm(mi)
hb <- all.main[all.main$Folder=="Slaght", ]
hb2 <- hb[hg$Water_Name=="Lake Huron", ]
hbs <- all.sub[all.sub$ID %in% hb2$ID & all.sub$Species==2, ]
hb2 <- hb2[hb2$ID %in% hbs$ID, ]
mytable(hb2$Year)
mytable(round(hb2$Duration))
length(unique(hb2$group))
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawData.RData")
all.main$Year <- year(all.main$Start_Date)
mi <- match(all.sub$ID, all.main$ID)
all.sub$Year <- all.main$Year[mi]
all.main$fg <- paste(all.main$Folder, all.main$group)
all.sub$fg <- all.main$fg[mi]
rm(mi)
hb <- all.main[all.main$Folder=="Slaght", ]
hb2 <- hb[hb$Water_Name=="Lake Huron", ]
hbs <- all.sub[all.sub$ID %in% hb2$ID & all.sub$Species==2, ]
hb2 <- hb2[hb2$ID %in% hbs$ID, ]
mytable(hb2$Year)
mytable(round(hb2$Duration))
length(unique(hb2$group))
dim(hb2)
head(hb2)
head(hbs)
table(round(hb2$Duration))
mytable(round(hb2$Duration))
sub24 <- with(hbs, hbs[round(Hours) <= 25, ])
dim(hbs)
dim(sub24)
mytable(round(hbs$Hours))
# total up the results for each test (ID)
c <- with(hbs, tapply(conc_use, ID, mean, na.rm=TRUE))
n <- with(hbs, tapply(Number_Tested, ID, max, na.rm=TRUE))
d <- with(hbs, tapply(Test_Dead, ID, sum, na.rm=TRUE))
h <- with(hbs, tapply(Hours, ID, max, na.rm=TRUE))
p <- with(hbs, tapply(pH_use, ID, mean, na.rm=TRUE))
y <- with(hbs, tapply(Year, ID, mean, na.rm=TRUE))
e <- with(hbs, tapply(Number_Tested, ID, sd, na.rm=TRUE))
mytable(e)
sel <- is.na(e) | e > 0
e[sel]
cleanup()
# C:\JVA\Lamprey\ChemControl\Resistance\Analysis\AnalyzeRaw.r
library(lubridate)
library(LW1949)
library(lattice)
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawData.RData")
all.main$Year <- year(all.main$Start_Date)
mi <- match(all.sub$ID, all.main$ID)
all.sub$Year <- all.main$Year[mi]
all.main$fg <- paste(all.main$Folder, all.main$group)
all.sub$fg <- all.main$fg[mi]
rm(mi)
mytable(all.main$Folder)
with(all.main, tapply(ID, Folder, range))
with(all.main, tapply(group, Folder, range))
source("C:/JVA/Lamprey/ChemControl/Resistance/Boogaard/ReadBoogaard.r")
head(boogdat, 3)
boogdat$year <- year(boogdat$date)
b2 <- boogdat[boogdat$x.nic.nom==0, ]
names(b2) <- recode(names(b2), c("dead", "total", "tfm", "ph.ave"), c("ndead", "ntest", "conc", "ph"))
b2$hours <- 12
head(b2, 3)
decade <- function(y) {
10*floor(y/10)
}
numuniq <- function(x) length(unique(x))
a <- with(all.main, tapply(fg, list(decade(Year), paste(Chemical=="TFM", Test_Type)), numuniq))[, c(7, 4, 5, 1)]
b <- with(boogdat, tapply(group, list(decade(year), x.nic.nom==0), numuniq))[, 2:1]
yrz <- as.numeric(c(dimnames(b)[[1]], dimnames(a)[[1]]))
yrz <- seq(min(yrz), max(yrz), 10)
a <- a[match(yrz, dimnames(a)[[1]]), ]
b <- b[match(yrz, dimnames(b)[[1]]), ]
a[is.na(a)] <- 0
b[is.na(b)] <- 0
a
b
a[, 3:4] <- a[, 3:4] + b
dimnames(a)[[1]] <- yrz
a
rm(b2, numuniq, a, b, yrz)
### focus on Static, TFM only to start
# subset data for analysis
msel <- subdex(all.main, Test_Type=="Static" & Chemical=="TFM")
ssel <- subdex(all.sub, Species==2)
################################### first subset #######################################
ids <- intersect(all.main$ID[msel], all.sub$ID[ssel])
main <- all.main[all.main$ID %in% ids, ]
sub <- all.sub[subdex(all.sub, ID %in% ids & Species==2), ]
rm(msel, ssel, ids)
### determine what concentration and pH values to use
replaceval <- function(id, target1, mean2) {
# start with the target value
usethis <- target1
# if the target value is missing, use the mean of the line-by-line values
idnotarg <- sort(unique(id[is.na(target1)]))
usethis[id %in% idnotarg] <- mean2[id %in% idnotarg]
usethis
}
meannozero <- function(x) {
mean(x[x>0 & !is.na(x)])
}
meanz <- with(sub, aggregate(cbind(concentration_t, pH_t), list(ID=ID), meannozero))
names(meanz) <- c("ID", "conc_mean", "pH_mean")
sub <- merge(sub, meanz, all=TRUE)
sub$conc_use <- with(sub, replaceval(ID, Conc_Target, conc_mean))
sub$pH_use <- with(sub, replaceval(ID, pH_Target, pH_mean))
rm(replaceval, meannozero, meanz)
### total up the results for each group of tests
h <- with(sub, tapply(Hours, fg, max, na.rm=TRUE))
p <- with(sub, tapply(pH_use, fg, mean, na.rm=TRUE))
y <- with(sub, tapply(Year, fg, mean, na.rm=TRUE))
dat <- data.frame(hours=h, ph=p, year=y)
head(dat)
dat2 <- dat[subdex(dat, hours>0 & hours<100), ]
dat2 <- dat2[!subdex(dat2, ph<1 | ph>14), ]
quintade <- function(y) {
5*floor(y/5)
}
with(dat2, mytable(quintade(year), !is.na(ph)) )
with(dat2, mytable(year, !is.na(ph)) )
rm(h, p, y, dat)
ls()
args(save)
?save
save(main, sub, file="C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawStaticData.RData")
head(main)
head(sub)
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawStaticData.RData")
mainhb <- with(main, main[Folder=="Slaght" & Water_Name=="Lake Huron", ])
subhb <- with(sub, sub[ID %in% mainhb$ID & Species==2, ]
mainhb <- mainhb[mainhb$ID %in% subhb$ID, ]
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawStaticData.RData")
mainhb <- with(main, main[Folder=="Slaght" & Water_Name=="Lake Huron", ])
subhb <- with(sub, sub[ID %in% mainhb$ID & Species==2, ])
mainhb <- mainhb[mainhb$ID %in% subhb$ID, ]
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawStaticData.RData")
mainhb <- with(main, main[Folder=="Slaght" & Water_Name=="Lake Huron", ])
subhb <- with(sub, sub[ID %in% mainhb$ID & Species==2, ])
mainhb <- mainhb[mainhb$ID %in% subhb$ID, ]
mytable(mainhb$Year)
mytable(round(mainhb$Duration))
length(unique(mainhb$group))
mytable(round(mainhb$Duration))
mytable(round(subhb$Hours))
# total up the results for each test (ID)
c <- with(subhb, tapply(conc_use, ID, mean, na.rm=TRUE))
n <- with(subhb, tapply(Number_Tested, ID, max, na.rm=TRUE))
d <- with(subhb, tapply(Test_Dead, ID, sum, na.rm=TRUE))
h <- with(subhb, tapply(Hours, ID, max, na.rm=TRUE))
p <- with(subhb, tapply(pH_use, ID, mean, na.rm=TRUE))
y <- with(subhb, tapply(Year, ID, mean, na.rm=TRUE))
e <- with(subhb, tapply(Number_Tested, ID, sd, na.rm=TRUE))
mytable(e)
sel <- is.na(e) | e > 0
e[sel]
mainhb[mainhb$ID %in% names(e[sel]), ]
subhb[subhb$ID %in% names(e[sel]), ]
dat24 <- data.frame(ndead=d, ntest=n, hours=h, conc=c, ph=p, year=y)
dat24$hours
mytable(round(dat24$hours))
dat24 <- data.frame(ndead=d, ntest=n, hours=h, conc=c, ph=p, year=y)
# there are some cases where the ID has a max check time less than 18 hours, even tho the group had max check time of > 18
# for now, just get rid of these IDs
dat24 <- dat24[subdex(dat24, conc>0 & ntest>0 & round(hours)>18 & e==0), ]
dat24$fg <- main9$fg[match(dimnames(dat24)[[1]], main9$ID)]
dat24 <- data.frame(ndead=d, ntest=n, hours=h, conc=c, ph=p, year=y)
# there are some cases where the ID has a max check time less than 18 hours, even tho the group had max check time of > 18
# for now, just get rid of these IDs
dat24 <- dat24[subdex(dat24, conc>0 & ntest>0 & round(hours)>18 & e==0), ]
dat24$fg <- mainhb$fg[match(dimnames(dat24)[[1]], mainhb$ID)]
dim(dat24)
summary(dat24)
rm(ids9, c, n, d, h, p, y, e, sel)
ls()
cleanup()
# C:\JVA\Lamprey\ChemControl\Resistance\MS\HBQA1990s.r
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawStaticData.RData")
mainhb <- with(main, main[Folder=="Slaght" & Water_Name=="Lake Huron", ])
subhb <- with(sub, sub[ID %in% mainhb$ID & Species==2, ])
mainhb <- mainhb[mainhb$ID %in% subhb$ID, ]
mytable(mainhb$Year)
mytable(round(mainhb$Duration))
length(unique(mainhb$group))
mytable(round(mainhb$Duration))
mytable(round(subhb$Hours))
# total up the results for each test (ID)
c <- with(subhb, tapply(conc_use, ID, mean, na.rm=TRUE))
n <- with(subhb, tapply(Number_Tested, ID, max, na.rm=TRUE))
d <- with(subhb, tapply(Test_Dead, ID, sum, na.rm=TRUE))
h <- with(subhb, tapply(Hours, ID, max, na.rm=TRUE))
p <- with(subhb, tapply(pH_use, ID, mean, na.rm=TRUE))
y <- with(subhb, tapply(Year, ID, mean, na.rm=TRUE))
e <- with(subhb, tapply(Number_Tested, ID, sd, na.rm=TRUE))
mytable(e)
sel <- is.na(e) | e > 0
e[sel]
mainhb[mainhb$ID %in% names(e[sel]), ]
subhb[subhb$ID %in% names(e[sel]), ]
dat24 <- data.frame(ndead=d, ntest=n, hours=h, conc=c, ph=p, year=y)
# there are some cases where the ID has a max check time less than 18 hours, even tho the group had max check time of > 18
# for now, just get rid of these IDs
dat24 <- dat24[subdex(dat24, conc>0 & ntest>0 & round(hours)>18 & e==0), ]
dat24$fg <- mainhb$fg[match(dimnames(dat24)[[1]], mainhb$ID)]
rm(c, n, d, h, p, y, e, sel)
ls()
########################################################################################################################################
datl <- split(dat24, dat24$fg)
fLW <- vector("list", length(datl))
pctalive <- 50
lc50 <- vector("list", length(datl))
meanph <- numeric(length(datl))
sdph <- numeric(length(datl))
yr <- numeric(length(datl))
nkeep <- numeric(length(datl))
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
for(i in seq(datl)) {
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
length(datl)
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
#for(i in seq(datl)) {
for(i in 1:20) {
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
#for(i in seq(datl)) {
for(i in 21:39) {
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
#for(i in seq(datl)) {
for(i in 1:10) {
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
#for(i in seq(datl)) {
for(i in 1:5) {
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
#for(i in seq(datl)) {
for(i in 1:3) {
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
#for(i in seq(datl)) {
for(i in 1) {
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
#for(i in seq(datl)) {
for(i in 2) {
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
i
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
fitLW
mydat
?fitLW
fitLW(mydat)
head(mainhb)
mainhb[mainhb$fg=="Slaght 11", ]
# C:\JVA\Lamprey\ChemControl\Resistance\Slaght\ReadSlaght.r
library(plyr)
makedate <- function(x) {
sel <- !is.na(x)
x1 <- x[sel]
# replace all punctuation marks with hyphens
x2 <- gsub("[[:punct:]]", "-", x1)
# break up string into three parts
x3 <- strsplit(x2, "-")
# if 3rd string is length 4, move it to 1st
nc3 <- lapply(x3, function(y) 
{
if(nchar(y)[3] > 3) y[c(3, 1, 2)] else y
}
)
# combine three parts again
x[sel] <- sapply(nc3, paste, collapse="-")
as.POSIXlt(x)
}
mydir <- "C:/JVA/Lamprey/ChemControl/Resistance/Slaght/"
myfiles <- "Historical TFM Testing.xlsx"
datlist <- vector("list", length(myfiles))
for(i in seq_along(myfiles)) {
wb <- loadWorkbook(paste0(mydir, myfiles[i]))
mysheets <- getSheets(wb)
sheetlist <- vector("list", length(mysheets))
for(j in seq_along(mysheets)) {
dat <- readWorksheet(wb, sheet=getSheets(wb)[j])
names(dat) <- jvanames(names(dat))
dat$Folder <- "Slaght"
dat$File <- myfiles[i]
dat$Sheet <- mysheets[j]
dat$Row <- 1:dim(dat)[1]
if(class(dat$start.date)[1]=="character") dat$start.date <- makedate(substring(dat$start.date, 1, 10))
if(class(dat$end.date)[1]=="character") dat$end.date <- makedate(substring(dat$start.date, 1, 10))
sheetlist[[j]] <- dat
}
datlist[[i]] <- do.call(rbind.fill, sheetlist)
}
Slaghtdat <- datlist[[1]]
# the cumulative number of dead was recorded only when there was a new death (same for ill)
# so, a series of numbers like 0, 1, 0, 2, 0 represents new dead 0, 1, 0, 1, 0, and true cumulative dead 0, 1, 1, 2, 2
# to make these numbers conform to the number of dead recorded in other data sheets, they will be converted to "new dead"
convert <- function(cumsortof, firstrow) {
# convert so-called cumulative dead/ill numbers to real new dead/ill numbers
cumdead <- cumsortof
# change all zeroes to missings
cumdead[!is.na(cumdead) & cumdead < 0.5] <- NA
# first, if the first row of so-called cumdead is missing, set the number of new dead to zero
cumdead[!is.na(firstrow) & is.na(cumsortof)] <- 0
# then, fill in the remaining missing values with the previous value
cumdead <- fill(cumdead)
# then calculate the new dead as the difference along the cumdead
cumdeadb4 <- c(NA, cumdead[-length(cumdead)])
newdead <- ifelse(!is.na(firstrow), cumdead, cumdead-cumdeadb4)
newdead
}
Slaghtdat$ill <- convert(Slaghtdat$cumulative..ill, Slaghtdat$species)
Slaghtdat$dead <- convert(Slaghtdat$cumulative..dead, Slaghtdat$species)
Slaghtdat$ID <- cumsum(!is.na(Slaghtdat$start.date))
# fill in the blanks for most of the columns
Slaghtdat <- with(Slaghtdat, Slaghtdat[order(Sheet, Row, ID), ])
leavethese <- c("check.time", "discomfort", "cumulative..ill", "cumulative..dead", "ill", "dead",
"specific.comment..regarding.just.the.corresponding.line.of.data.")
sel <- names(Slaghtdat) %in% leavethese
Slaghtdat[, !sel] <- data.frame(lapply(Slaghtdat[, !sel], fill, first(Slaghtdat$ID)))
Slaghtdat <- with(Slaghtdat, Slaghtdat[order(Sheet, Row, ID), ])
head(Slaghtdat)
cleanup()
search()
search()
detach(5)
search()
source("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/ReadRawData v2.r")
source("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/AnalyzeRaw v3.r")
ls()
cleanup()
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawStaticData.RData")
mainhb <- with(main, main[Folder=="Slaght" & Water_Name=="Lake Huron", ])
subhb <- with(sub, sub[ID %in% mainhb$ID & Species==2, ])
mainhb <- mainhb[mainhb$ID %in% subhb$ID, ]
mytable(mainhb$Year)
mytable(round(mainhb$Duration))
length(unique(mainhb$group))
mytable(round(mainhb$Duration))
mytable(round(subhb$Hours))
# total up the results for each test (ID)
c <- with(subhb, tapply(conc_use, ID, mean, na.rm=TRUE))
n <- with(subhb, tapply(Number_Tested, ID, max, na.rm=TRUE))
d <- with(subhb, tapply(Test_Dead, ID, sum, na.rm=TRUE))
h <- with(subhb, tapply(Hours, ID, max, na.rm=TRUE))
p <- with(subhb, tapply(pH_use, ID, mean, na.rm=TRUE))
y <- with(subhb, tapply(Year, ID, mean, na.rm=TRUE))
e <- with(subhb, tapply(Number_Tested, ID, sd, na.rm=TRUE))
mytable(e)
sel <- is.na(e) | e > 0
e[sel]
mainhb[mainhb$ID %in% names(e[sel]), ]
subhb[subhb$ID %in% names(e[sel]), ]
dat24 <- data.frame(ndead=d, ntest=n, hours=h, conc=c, ph=p, year=y)
# there are some cases where the ID has a max check time less than 18 hours, even tho the group had max check time of > 18
# for now, just get rid of these IDs
dat24 <- dat24[subdex(dat24, conc>0 & ntest>0 & round(hours)>18 & e==0), ]
dat24$fg <- mainhb$fg[match(dimnames(dat24)[[1]], mainhb$ID)]
rm(c, n, d, h, p, y, e, sel)
########################################################################################################################################
datl <- split(dat24, dat24$fg)
fLW <- vector("list", length(datl))
pctalive <- 50
lc50 <- vector("list", length(datl))
meanph <- numeric(length(datl))
sdph <- numeric(length(datl))
yr <- numeric(length(datl))
nkeep <- numeric(length(datl))
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
#for(i in seq(datl)) {
for(i in 2) {
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
options(warn=1)
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
for(i in seq(datl)) {
#for(i in 2) {
print(i)
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
length(datl)
i <- 1
print(i)
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
mydat
cleanup()
source("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/ReadRawData v2.r")
source("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/AnalyzeRaw v3.r")
cleanup()
graphics.off()
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawStaticData.RData")
mainhb <- with(main, main[Folder=="Slaght" & Water_Name=="Lake Huron", ])
subhb <- with(sub, sub[ID %in% mainhb$ID & Species==2, ])
mainhb <- mainhb[mainhb$ID %in% subhb$ID, ]
mytable(mainhb$Year)
mytable(round(mainhb$Duration))
length(unique(mainhb$group))
mytable(round(mainhb$Duration))
mytable(round(subhb$Hours))
# total up the results for each test (ID)
c <- with(subhb, tapply(conc_use, ID, mean, na.rm=TRUE))
n <- with(subhb, tapply(Number_Tested, ID, max, na.rm=TRUE))
d <- with(subhb, tapply(Test_Dead, ID, sum, na.rm=TRUE))
h <- with(subhb, tapply(Hours, ID, max, na.rm=TRUE))
p <- with(subhb, tapply(pH_use, ID, mean, na.rm=TRUE))
y <- with(subhb, tapply(Year, ID, mean, na.rm=TRUE))
e <- with(subhb, tapply(Number_Tested, ID, sd, na.rm=TRUE))
mytable(e)
sel <- is.na(e) | e > 0
e[sel]
mainhb[mainhb$ID %in% names(e[sel]), ]
subhb[subhb$ID %in% names(e[sel]), ]
dat24 <- data.frame(ndead=d, ntest=n, hours=h, conc=c, ph=p, year=y)
# there are some cases where the ID has a max check time less than 18 hours, even tho the group had max check time of > 18
# for now, just get rid of these IDs
dat24 <- dat24[subdex(dat24, conc>0 & ntest>0 & round(hours)>18 & e==0), ]
dat24$fg <- mainhb$fg[match(dimnames(dat24)[[1]], mainhb$ID)]
rm(c, n, d, h, p, y, e, sel)
########################################################################################################################################
datl <- split(dat24, dat24$fg)
fLW <- vector("list", length(datl))
pctalive <- 50
lc50 <- vector("list", length(datl))
meanph <- numeric(length(datl))
sdph <- numeric(length(datl))
yr <- numeric(length(datl))
nkeep <- numeric(length(datl))
options(warn=1)
#pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
for(i in seq(datl)) {
#for(i in 2) {
print(i)
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
meanph[i] <- mean(mydat$ph, na.rm=TRUE)
sdph[i] <- sd(mydat$ph, na.rm=TRUE)
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
#graphics.off()
options(warn=0)
length(datl)
lapply(datl, dim)
sapply(datl, dim)
t(sapply(datl, dim))
i
mydat
mainhb$fg==mydat$fg[1]
mainhb[mainhb$fg==mydat$fg[1], ]
estimable <- function(DEdata) {
nonmiss <- !is.na(DEdata$dose) & !is.na(DEdata$pfx)
#if(sum(nonmiss) < 1.5) {
if(length(unique(DEdata$dose[nonmiss])) < 1.5) {
out <- FALSE
} else {
out <- !(var(DEdata$dose[nonmiss]) < 0.00000001 | var(DEdata$pfx[nonmiss]) < 0.00000001)
}
if(!out) warning("Does-effect relation not estimable.")
out
}
#' Apply Litchfield and Wilcoxon Evaluation of Dose-Effect Experiments
#'
#' Automatically apply Litchfield and Wilcoxon's (1949) evaluation of dose-effect experiments.
#' @param DEdata A data frame of dose-effect data (typically, the output from \code{\link{dataprep}})
#'containing at least eight variables: dose, ntot, nfx, pfx, log10dose, bitpfx, fxcateg, and LWkeep.
#' @return A list of length three:
#' \itemize{
#'   \item \code{chi} = the chi-squared statistic with associated P value and degrees of freedom,
#'   \item \code{params} = the estimated intercept and slope of the dose-response curve on the log10 probit scale,
#'   \item \code{LWest} = the Litchfield Wilcoxon estimates of ED50 with 95\% confidence intervals and other metrics used in their 
#'step-by-step approach (ED16, ED84, S, N', and fED50).
#' }
#' @export
#' @references Litchfield, JT Jr. and F Wilcoxon.  1949.
#' A simplified method of evaluating dose-effect experiments. 
#' Journal of Pharmacology and Experimental Therapeutics 99(2):99-113.
#' \href{http://jpet.aspetjournals.org/content/96/2/99.abstract}{[link]}. 
#' @examples 
#' dose <- c(0.0625, 0.125, 0.25, 0.5, 1)
#' ntested <- rep(8, 5)
#' nalive <- c(1, 4, 4, 7, 8)
#' mydat <- dataprep(dose=dose, ntot=ntested, nfx=nalive)
#' mydat
#' fitLW(mydat)
fitLW <- function(DEdata) {
if(!estimable(DEdata)) {
out <- list(chi=rep(NA, 3), params=rep(NA, 2), LWest=rep(NA, 8))
} else {
dfsub <- DEdata[DEdata$LWkeep, ]
df0 <- dfsub[dfsub$fxcateg==0, ]
df100 <- dfsub[dfsub$fxcateg==100, ]
# fit a smooth GAM function to expected and corrected values in Table 1 of Litchfield and Wilcoxon (1949)
gamfit <- gamtable1()
# calculate starting values for the int and slope using simple linear regression
# pms <- sum(dfsub$fxcateg==50)
pms <- length(unique(dfsub$dose[dfsub$fxcateg==50]))
sv <- c(NA, NA)
svchi <- NA
# fit line to partial effects alone
if(pms > 1) {
dfpart <- dfsub[dfsub$fxcateg==50, ]
sv <- fitlinear(dfpart, gamfit)
svchi <- assessfit(sv, dfpart, gamfit)
}
# fit line to partial effects with last 0% and first 100%
if(pms==1 | is.na(svchi)) {
dfpart <- rbind(df0[with(df0, which.max(conc)), ], dfsub[dfsub$fxcateg==50, ], df100[with(df100, which.min(conc)), ])
sv <- fitlinear(dfpart, gamfit)
svchi <- assessfit(sv, dfpart, gamfit)
}
# fit line to all the data
if(pms < 1 | is.na(svchi)) {
sv <- fitlinear(dfpart, gamfit)
svchi <- assessfit(sv, dfpart, gamfit)
}
# fit line to first 0% and last 100% alone
if(is.na(svchi)) {
dfpart <- rbind(df0[with(df0, which.min(conc)), ], dfsub[dfsub$fxcateg==50, ], df100[with(df100, which.max(conc)), ])
sv <- fitlinear(dfpart, gamfit)
svchi <- assessfit(sv, dfpart, gamfit)
}
### B1, B2, and C are all inside the function assessfit()
# B1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
# B2. Using the expected effect, record a corrected value for each 0 and 100% effect
### C. The chi squared test
# find the parameters that yield the best fit in the log10dose * probit space, by minimizing the chi squared
estparams <- optim(par=sv, fn=assessfit, DEdata=dfsub, fit=gamfit)$par
chi <- assessfit(estparams, DEdata=dfsub, fit=gamfit, simple=FALSE)
if(is.na(chi$chi["pval"])) {
warning("Chi squared test cannot be conducted when fewer than two expected values are between 0.01% and 99.99%.")
} else {
if(chi$chi["pval"] < 0.05) {
warning("Chi squared test indicates poor fit.")
}
}
### D1. Read from the line on the graph the dose for 16, 50, and 84% effects
ED16 <- predlinear(16, estparams, simple=TRUE)
ED50 <- predlinear(50, estparams, simple=TRUE)
ED84 <- predlinear(84, estparams, simple=TRUE)
# D2. Calculate the Litchfield and Wilcoxon (1949) slope function, S
S <- (ED84/ED50 + ED50/ED16) / 2
# D3. Obtain Nprime, the total number of animals tested at those doses with expected effects between 16 and 84%.
Nprime <- sum(dfsub$ntot[dfsub$dose > ED16 & dfsub$dose < ED84])
# D4. Calculate S to the exponent for the ED50
fED50 <- S^(2.77/sqrt(Nprime))
# D5. Calculate the 95% confidence limits of the ED50
if(is.finite(fED50)) {
upper50 <- ED50 * fED50
lower50 <- ED50 / fED50
} else {
upper50 <- NA
lower50 <- NA
warning("Confidence bounds cannot be estimated when no expected values are between 16% and 84%.")
}
# E. Calculate the confidence limits of S (requires mysterious Nomograph No. 3)
# E1. Calculate the dosage range as a ratio, R
R <- max(dfsub$dose)/min(dfsub$dose)
# E2. Calculate A from equation 6 in Appendix (Nomograph 3)
A <- 10^( 1.1*(log10(S))^2 / log10(R) )
# E3. Calculate K (the number of doses) and fS (Nomograph 2)
K <- dim(dfsub)[1]
fS <- A^( 10*(K-1) / (K * sqrt(Nprime)) )
# E4. Calculate the 95% confidence limits of S
upperS <- S * fS
lowerS <- S / fS
### I'm skipping the rest of the steps
# F. Factors for significantly heterogeneous data
# G. Test for parallelism of two lines and estimate of relative potency
out <- list(chi=chi, params=estparams, 
LWest=c(ED50=ED50, lower=lower50, upper=upper50, ED16=ED16, ED84=ED84, 
S=S, lowerS=lowerS, upperS=upperS, Nprime=Nprime, fED50=fED50, fS=fS))
}
out
}
fitLW(mydat)
mydat
estimable(mydat)
DEdata <- mydat
dfsub <- DEdata[DEdata$LWkeep, ]
df0 <- dfsub[dfsub$fxcateg==0, ]
df100 <- dfsub[dfsub$fxcateg==100, ]
# fit a smooth GAM function to expected and corrected values in Table 1 of Litchfield and Wilcoxon (1949)
gamfit <- gamtable1()
# calculate starting values for the int and slope using simple linear regression
# pms <- sum(dfsub$fxcateg==50)
pms <- length(unique(dfsub$dose[dfsub$fxcateg==50]))
sv <- c(NA, NA)
svchi <- NA
pms
if(pms==1 | is.na(svchi)) {
dfpart <- rbind(df0[with(df0, which.max(conc)), ], dfsub[dfsub$fxcateg==50, ], df100[with(df100, which.min(conc)), ])
sv <- fitlinear(dfpart, gamfit)
svchi <- assessfit(sv, dfpart, gamfit)
}
is.na(svchi)
(pms==1 | is.na(svchi)
)
dfpart <- rbind(df0[with(df0, which.max(conc)), ], dfsub[dfsub$fxcateg==50, ], df100[with(df100, which.min(conc)), ])
sv <- fitlinear(dfpart, gamfit)
svchi <- assessfit(sv, dfpart, gamfit)
params <- sv
DEdata <- dfpart
fit <- gamfit
simple <- TRUE
# calculate chi squared value from given line
expected <- invprobit(params[1] + params[2]*log10(DEdata$dose))
### B1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | DEdata$fxcateg==50
n <- sum(sel)
n
sel
expected
params
sv
svchi
dfpart
df
head(subhb)
# total up the results for each test (ID)
# c <- with(subhb, tapply(conc_use, ID, mean, na.rm=TRUE))
# n <- with(subhb, tapply(Number_Tested, ID, max, na.rm=TRUE))
# d <- with(subhb, tapply(Test_Dead, ID, sum, na.rm=TRUE))
# h <- with(subhb, tapply(Hours, ID, max, na.rm=TRUE))
# p <- with(subhb, tapply(pH_use, ID, mean, na.rm=TRUE))
# y <- with(subhb, tapply(Year, ID, mean, na.rm=TRUE))
# total up the results for each group (fg)
c <- with(subhb, tapply(conc_use, fg, mean, na.rm=TRUE))
n <- with(subhb, tapply(Number_Tested, fg, max, na.rm=TRUE))
d <- with(subhb, tapply(Test_Dead, fg, sum, na.rm=TRUE))
h <- with(subhb, tapply(Hours, fg, max, na.rm=TRUE))
p <- with(subhb, tapply(pH_use, fg, mean, na.rm=TRUE))
y <- with(subhb, tapply(Year, fg, mean, na.rm=TRUE))
e <- with(subhb, tapply(Number_Tested, fg, sd, na.rm=TRUE))
mytable(e)
sel <- is.na(e) | e > 0
e[sel]
mainhb[mainhb$fg %in% names(e[sel]), ]
subhb[subhb$fg %in% names(e[sel]), ]
subhb[subhb$fg %in% names(e[sel]), c("fg", "Number_Tested")]
dat24 <- data.frame(ndead=d, ntest=n, hours=h, conc=c, ph=p, year=y)
# there are some cases where the ID has a max check time less than 18 hours, even tho the group had max check time of > 18
# for now, just get rid of these IDs
dat24 <- dat24[subdex(dat24, conc>0 & ntest>0 & round(hours)>18 & e==0), ]
dat24$fg <- mainhb$fg[match(dimnames(dat24)[[1]], mainhb$ID)]
rm(c, n, d, h, p, y, e, sel)
dim(dat24)
dat24
# total up the results for each test (ID)
c <- with(subhb, tapply(conc_use, ID, mean, na.rm=TRUE))
n <- with(subhb, tapply(Number_Tested, ID, max, na.rm=TRUE))
d <- with(subhb, tapply(Test_Dead, ID, sum, na.rm=TRUE))
h <- with(subhb, tapply(Hours, ID, max, na.rm=TRUE))
p <- with(subhb, tapply(pH_use, ID, mean, na.rm=TRUE))
y <- with(subhb, tapply(Year, ID, mean, na.rm=TRUE))
# total up the results for each group (fg)
# c <- with(subhb, tapply(conc_use, fg, mean, na.rm=TRUE))
# n <- with(subhb, tapply(Number_Tested, fg, max, na.rm=TRUE))
# d <- with(subhb, tapply(Test_Dead, fg, sum, na.rm=TRUE))
# h <- with(subhb, tapply(Hours, fg, max, na.rm=TRUE))
# p <- with(subhb, tapply(pH_use, fg, mean, na.rm=TRUE))
# y <- with(subhb, tapply(Year, fg, mean, na.rm=TRUE))
e <- with(subhb, tapply(Number_Tested, ID, sd, na.rm=TRUE))
mytable(e)
sel <- is.na(e) | e > 0
e[sel]
mainhb[mainhb$ID %in% names(e[sel]), ]
subhb[subhb$ID %in% names(e[sel]), ]
dat24 <- data.frame(ndead=d, ntest=n, hours=h, conc=c, ph=p, year=y)
dim(dat24)
head(dat24)
mytable(rownames(dat24))
dat24 <- data.frame(ndead=d, ntest=n, hours=h, conc=c, ph=p, year=y)
# there are some cases where the ID has a max check time less than 18 hours, even tho the group had max check time of > 18
# for now, just get rid of these IDs
dat24 <- dat24[subdex(dat24, conc>0 & ntest>0 & round(hours)>18 & e==0), ]
dat24$fg <- mainhb$fg[match(dimnames(dat24)[[1]], mainhb$ID)]
head(dat24)
dat24b <- aggregate(dat24[, c("ndead", "ntest")], dat24[, c("hours", "conc", "year", "fg")], sum)
head(dat24b)
hist(dat24b$hours)
########################################################################################################################################
datl <- split(dat24b, dat24$fg)
cleanup()
# C:\JVA\Lamprey\ChemControl\Resistance\MS\HBQA1990s.r
if(FALSE) {
source("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/ReadRawData v2.r")
source("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/AnalyzeRaw v3.r")
graphics.off()
cleanup()
y
}
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawStaticData.RData")
mainhb <- with(main, main[Folder=="Slaght" & Water_Name=="Lake Huron", ])
subhb <- with(sub, sub[ID %in% mainhb$ID & Species==2, ])
mainhb <- mainhb[mainhb$ID %in% subhb$ID, ]
mytable(mainhb$Year)
mytable(round(mainhb$Duration))
length(unique(mainhb$group))
mytable(round(mainhb$Duration))
mytable(round(subhb$Hours))
# total up the results for each test (ID)
c <- with(subhb, tapply(conc_use, ID, mean, na.rm=TRUE))
n <- with(subhb, tapply(Number_Tested, ID, max, na.rm=TRUE))
d <- with(subhb, tapply(Test_Dead, ID, sum, na.rm=TRUE))
h <- with(subhb, tapply(Hours, ID, max, na.rm=TRUE))
p <- with(subhb, tapply(pH_use, ID, mean, na.rm=TRUE))
y <- with(subhb, tapply(Year, ID, mean, na.rm=TRUE))
# total up the results for each group (fg)
# c <- with(subhb, tapply(conc_use, fg, mean, na.rm=TRUE))
# n <- with(subhb, tapply(Number_Tested, fg, max, na.rm=TRUE))
# d <- with(subhb, tapply(Test_Dead, fg, sum, na.rm=TRUE))
# h <- with(subhb, tapply(Hours, fg, max, na.rm=TRUE))
# p <- with(subhb, tapply(pH_use, fg, mean, na.rm=TRUE))
# y <- with(subhb, tapply(Year, fg, mean, na.rm=TRUE))
e <- with(subhb, tapply(Number_Tested, ID, sd, na.rm=TRUE))
mytable(e)
sel <- is.na(e) | e > 0
e[sel]
mainhb[mainhb$ID %in% names(e[sel]), ]
subhb[subhb$ID %in% names(e[sel]), ]
dat24 <- data.frame(ndead=d, ntest=n, hours=h, conc=c, ph=p, year=y)
# there are some cases where the ID has a max check time less than 18 hours, even tho the group had max check time of > 18
# for now, just get rid of these IDs
dat24 <- dat24[subdex(dat24, conc>0 & ntest>0 & round(hours)>18 & e==0), ]
dat24$fg <- mainhb$fg[match(dimnames(dat24)[[1]], mainhb$ID)]
rm(c, n, d, h, p, y, e, sel)
# aggregate resutls from multiple tests at the same exact conditions
dat24b <- aggregate(dat24[, c("ndead", "ntest")], dat24[, c("hours", "conc", "year", "fg")], sum)
########################################################################################################################################
datl <- split(dat24b, dat24b$fg)
fLW <- vector("list", length(datl))
pctalive <- 50
lc50 <- vector("list", length(datl))
yr <- numeric(length(datl))
nkeep <- numeric(length(datl))
options(warn=1)
#pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
for(i in seq(datl)) {
#for(i in 2) {
print(i)
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
#graphics.off()
options(warn=0)
graphics.off()
options(warn=1)
#pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
for(i in seq(datl)) {
#for(i in 2) {
windows()
print(i)
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
#graphics.off()
options(warn=0)
graphics.off()
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
for(i in seq(datl)) {
print(i)
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
ests <- data.frame(do.call(rbind, lc50))
rownames(ests) <- names(datl)
ests <- cbind(ests, yr, nkeep)
head(ests)
rm(lc50, yr, nkeep, i, df, mydat)
ls()
cleanup()
# C:\JVA\Lamprey\ChemControl\Resistance\MS\HBQA1990s.r
if(FALSE) {
source("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/ReadRawData v2.r")
source("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/AnalyzeRaw v3.r")
graphics.off()
cleanup()
y
}
load("C:/JVA/Lamprey/ChemControl/Resistance/Analysis/RawStaticData.RData")
mainhb <- with(main, main[Folder=="Slaght" & Water_Name=="Lake Huron", ])
subhb <- with(sub, sub[ID %in% mainhb$ID & Species==2, ])
mainhb <- mainhb[mainhb$ID %in% subhb$ID, ]
mytable(mainhb$Year)
mytable(round(mainhb$Duration))
length(unique(mainhb$group))
mytable(round(mainhb$Duration))
mytable(round(subhb$Hours))
# total up the results for each test (ID)
c <- with(subhb, tapply(conc_use, ID, mean, na.rm=TRUE))
n <- with(subhb, tapply(Number_Tested, ID, max, na.rm=TRUE))
d <- with(subhb, tapply(Test_Dead, ID, sum, na.rm=TRUE))
h <- with(subhb, tapply(Hours, ID, max, na.rm=TRUE))
p <- with(subhb, tapply(pH_use, ID, mean, na.rm=TRUE))
y <- with(subhb, tapply(Year, ID, mean, na.rm=TRUE))
# total up the results for each group (fg)
# c <- with(subhb, tapply(conc_use, fg, mean, na.rm=TRUE))
# n <- with(subhb, tapply(Number_Tested, fg, max, na.rm=TRUE))
# d <- with(subhb, tapply(Test_Dead, fg, sum, na.rm=TRUE))
# h <- with(subhb, tapply(Hours, fg, max, na.rm=TRUE))
# p <- with(subhb, tapply(pH_use, fg, mean, na.rm=TRUE))
# y <- with(subhb, tapply(Year, fg, mean, na.rm=TRUE))
e <- with(subhb, tapply(Number_Tested, ID, sd, na.rm=TRUE))
mytable(e)
sel <- is.na(e) | e > 0
e[sel]
mainhb[mainhb$ID %in% names(e[sel]), ]
subhb[subhb$ID %in% names(e[sel]), ]
dat24 <- data.frame(ndead=d, ntest=n, hours=h, conc=c, ph=p, year=y)
# there are some cases where the ID has a max check time less than 18 hours, even tho the group had max check time of > 18
# for now, just get rid of these IDs
dat24 <- dat24[subdex(dat24, conc>0 & ntest>0 & round(hours)>18 & e==0), ]
dat24$fg <- mainhb$fg[match(dimnames(dat24)[[1]], mainhb$ID)]
rm(c, n, d, h, p, y, e, sel)
# aggregate resutls from multiple tests at the same exact conditions
dat24b <- aggregate(dat24[, c("ndead", "ntest")], dat24[, c("hours", "conc", "year", "fg")], sum)
########################################################################################################################################
datl <- split(dat24b, dat24b$fg)
fLW <- vector("list", length(datl))
pctalive <- 50
lc50 <- vector("list", length(datl))
yr <- numeric(length(datl))
nkeep <- numeric(length(datl))
pdf(file="C:/JVA/Lamprey/ChemControl/Resistance/MS/PlotsHBQA1990s.pdf", paper="letter")
for(i in seq(datl)) {
df <- datl[[i]]
mydat <- with(df, dataprep(dose=conc, ntot=ntest, nfx=ndead))
mydat <- cbind(mydat, df[mydat$rec, ])
yr[i] <- mean(mydat$year, na.rm=TRUE)
nkeep[i] <- sum(mydat$LWkeep)
fLW[[i]] <- fitLW(mydat)
lc50[[i]] <- predlinear(pctalive, fLW[[i]])
if(!is.na(lc50[[i]][, "lower"])) {
par(mar=c(4, 4, 2, 1))
plotDE(mydat, xlab="TFM concentration", ylab="Sea lamprey mortality  (%)", main=mydat$fg[1])
if(!is.na(lc50[[i]][, "ED"])) abline(fLW[[i]]$params)
}
}
graphics.off()
ests <- data.frame(do.call(rbind, lc50))
rownames(ests) <- names(datl)
ests <- cbind(ests, yr, nkeep)
head(ests)
rm(lc50, yr, nkeep, i, df, mydat)
dim(ests)
ests
mytable(ests$yr)
?cheat
cleanup()
search()
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/LC99.9 historical 1988-1998.xlsx")
sl <- readWorksheet(wb, sheet="sea lamprey", startRow=1)
rbt <- readWorksheet(wb, sheet="rainbow trout", startRow=1)
sl
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/LC99.9 historical 1988-1998.xlsx")
sl <- readWorksheet(wb, sheet="sea lamprey", startRow=2)
rbt <- readWorksheet(wb, sheet="rainbow trout", startRow=2)
sl
rbt
dput(names(rbt))
dput(names(sl))
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/LC99.9 historical 1988-1998.xlsx")
sl <- readWorksheet(wb, sheet="sea lamprey", startRow=2)
rbt <- readWorksheet(wb, sheet="rainbow trout", startRow=2)
names(sl) <- c("date", "lot", "lc999", "lc84", "lc50", "lc16", "tempc", "hrs", "alk", "ph")
names(rbt) <- c("date", "lot", "lc16", "lc25", "lc50", "lc84", "tempc", "hrs", "alk", "ph")
dat <- rbind.fill(sl, rbt)
dat
summary(dat)
char2num <- function(x, justindex=FALSE, varname=NULL) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
possiblemissings <- c("na", "NA", ".", "", " ", "  ", "-")
sel <- is.na(asn) & !is.na(x) & !x%in%possiblemissings
if(justindex) {
return(sel)
} else {
if(is.null(varname)) varname <- deparse(substitute(x))
note <- rep("", length(x))
note[sel] <- paste0(varname, ":", x[sel])
return(list(asn, note))
}
}
a <- c("1.5", "3", "NA", "*error", ".", "12")
char2num(a)
data.frame(char2num(a))
q()
tweethead()
q()
# C:\JVA\ASA\CSP SC\RegistrationCountGraph.r
Date2 <- as.Date(paste0(c(rep("2014-", 2), rep("2015-", 3)), 
c("12-04", "12-29", "01-12", "01-26", "02-05")))
Reg15 <- c(154, 221, 327, 365, 401)
Date <- as.Date(paste0(c(rep("2014-", 5), rep("2015-", 6)), 
c("11-01", "11-26", "12-12", "12-19", "12-27", "01-06", "01-13", "01-22", "01-27", "02-03", "02-06")))
Reg14 <- c(36, 92, 124, 157, 209, 287, 303, 339, 345, 365, 389)
Reg13 <- c(NA, NA, 89, 125, 165, 218, 236, 266, 279, 301, 330)
L <- length(Date)
pd <- pretty(Date, 4)
windows(h=5, w=5)
par(mar=c(4, 4, 2, 2.5), yaxs="i", las=1)
plot(Date, Reg14, type="n", axes=FALSE, las=1, ylim=c(0, 1.1*max(Reg15, Reg14, Reg13, na.rm=TRUE)), 
ylab="Total Count",main="CSP Registration")
axis(1, at=pd, labels=c("Nov 1", "Dec 1", "Jan 1", "Feb 1"))
axis(2)
box()
lines(Date, Reg13, lwd=1, pch=16, type="o", col="gray")
mtext(" CSP\n 2013", side=4, at=Reg13[L], col="lightgray", adj=0)
lines(Date, Reg14, lwd=2, pch=16, type="o", col="gray")
mtext(" CSP\n 2014", side=4, at=Reg14[L], col="darkgray", adj=0)
lines(Date2, Reg15, lwd=3, pch=16, type="o")
mtext(" CSP\n 2015", side=4, at=Reg15[length(Date2)], font=2, adj=0, line=-8)
?plot
char2num <- function(x, justindex=FALSE, varname=NULL, pmissing=c("NA", ".", "", " ", "-")) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
sel <- is.na(asn) & !is.na(x) & !x%in%pmissing
if(justindex) {
return(sel)
} else {
note <- rep("", length(x))
if(varname==FALSE) {
note[sel] <- x[sel]
} else {
if(is.null(varname)) varname <- deparse(substitute(x))
note[sel] <- paste0(varname, ":", x[sel])
}
return(list(asn, note))
}
}
a <- c("1.5", "3", "NA", "*error", ".", "12")
char2num(a)
varname
x
is.null(x)
is.null(x) <- TRUE
x <- NULL
x
x==FALSE
(!is.null(x) & x==FALSE)
char2num <- function(x, justindex=FALSE, varname=NULL, pmissing=c("NA", ".", "", " ", "-")) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
sel <- is.na(asn) & !is.na(x) & !x%in%pmissing
if(justindex) {
return(sel)
} else {
note <- rep("", length(x))
if(is.null(varname)) varname <- deparse(substitute(x))
if(varname==FALSE) {
note[sel] <- x[sel]
} else {
note[sel] <- paste0(varname, ":", x[sel])
}
return(list(asn, note))
}
}
char2num(a)
char2num(a, FALSE)
char2num(a, justindex=TRUE)
q()
char2num(a, varname=FALSE)
char2num(a, varname="pH")
a <- c(">1.5", "3", "NA", "missing", ".", "12")
char2num <- function(x, varname=NULL, pmissing=c("NA", ".", "", " ", "-"), justindex=FALSE) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
sel <- is.na(asn) & !is.na(x) & !x%in%pmissing
if(justindex) {
return(sel)
} else {
note <- rep("", length(x))
if(is.null(varname)) varname <- deparse(substitute(x))
if(varname==FALSE) {
note[sel] <- x[sel]
} else {
note[sel] <- paste0(varname, ":", x[sel])
}
return(list(asn, note))
}
}
char2num(a)
char2num(a, FALSE)
char2num(a, "pH")
char2num(a, pmissing=c("NA", "missing", "."))
char2num(a, justindex=TRUE)
b <- c("22", "", "33", "44", "55", "*error")
q()
df <- data.frame(a, b)
df
sapply(df, char2num)
lapply(df, char2num)
dfnum <- sapply(df, char2num)
dfnum
length(dfnum)
dim(dfnum)
dfnum[, 1]
dfnum[1, ]
apply(dfnum, 1, data.frame)
apply(dfnum, 1, cbind)
apply(dfnum, 1, data.frame)
lapply(df, function(x) data.frame(x, char2num(x)))
char2num <- function(x, varname=NULL, pmissing=c("NA", ".", "", " ", "-"), justindex=FALSE) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
sel <- is.na(asn) & !is.na(x) & !x%in%pmissing
if(justindex) {
return(sel)
} else {
note <- rep("", length(x))
if(is.null(varname)) varname <- deparse(substitute(x))
if(varname==FALSE) {
note[sel] <- x[sel]
} else {
note[sel] <- paste0(varname, ":", x[sel])
}
return(list(asn=asn, note=note))
}
}
lapply(df, function(x) data.frame(x, char2num(x)))
sapply(df, function(x) data.frame(x, char2num(x)))
char2num <- function(x, varname=NULL, pmissing=c("NA", ".", "", " ", "-"), justindex=FALSE) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
sel <- is.na(asn) & !is.na(x) & !x%in%pmissing
if(justindex) {
return(sel)
} else {
note <- rep("", length(x))
if(is.null(varname)) varname <- deparse(substitute(x))
if(varname==FALSE) {
note[sel] <- x[sel]
} else {
note[sel] <- paste0(varname, ":", x[sel])
}
return(data.frame(asn=asn, note=note))
}
}
lapply(df, char2num)
char2num <- function(x, varname=NULL, pmissing=c("NA", ".", "", " ", "-"), justindex=FALSE) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
sel <- is.na(asn) & !is.na(x) & !x%in%pmissing
if(justindex) {
return(sel)
} else {
note <- rep("", length(x))
if(is.null(varname)) varname <- deparse(substitute(x))
if(varname==FALSE) {
note[sel] <- x[sel]
} else {
note[sel] <- paste0(varname, ":", x[sel])
}
return(list(asn=asn, note=note))
}
}
char2num(a)
char2num(a, FALSE)
char2num(a, "pH")
char2num <- function(x, varname=NULL, pmissing=c("NA", ".", "", " ", "-"), justindex=FALSE) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
sel <- is.na(asn) & !is.na(x) & !x%in%pmissing
if(justindex) {
return(sel)
} else {
note <- rep("", length(x))
if(is.null(varname)) varname <- deparse(substitute(x))
if(varname==FALSE) {
note[sel] <- x[sel]
} else {
note[sel] <- paste0(varname, ":", x[sel])
}
return(list(asn, note))
}
}
char2num(a, "pH")
char2num(a, pmissing=c("NA", "missing", "."))
char2num(a, justindex=TRUE)
# C:\JVA\Lamprey\ChemControl\Resistance\MS\HBQA2000s.r
library(plyr)
wb <- loadWorkbook("C:/JVA/Lamprey/ChemControl/Resistance/Slaght/historic LC25 and LC99.9 (3).xls")
gs <- getSheets(wb)
length(gs)
# there are 8 tabs
# all the tabs have the same columns of data, except for #4
startrowz <- c(4, 2, 4, NA, 3, 3, 3, 3)
datlist <- vector("list", length(gs))
firstline <- datlist
for(i in 1:8) {
firstline[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=1, endRow=1, header=FALSE)
firstline[[i]]$tab <- gs[i]
if(i != 4) {
datlist[[i]] <- readWorksheet(wb, sheet=gs[i], startRow=startrowz[i])
datlist[[i]]$tab <- gs[i]
}
}
# add in the fourth tab to position 4 and position 9
datlist[[4]] <- readWorksheet(wb, sheet=gs[4], startRow=3, endRow=26)
datlist[[4]]$tab <- gs[4]
datlist[[9]] <- readWorksheet(wb, sheet=gs[4], startRow=27)
datlist[[9]]$tab <- gs[4]
# assign new names and combine data
newnames <- list(
c("lot", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "junk", "sp2", "lc9992", "lc502", "ph2", "alk2", "junk", "sp1", "lc251", "lc501", "ph1", "alk1", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "junk", "sp1", "so1", "lc251", "lc501", "ph1", "alk1", "junk", "sp2", "so2", "lc9992", "lc502", "ph2", "alk2", "tab"),
c("lot", "lc9992", "junk", "ph2", "alk2", "junk2", "junk3", "lc251", "tab"),
c("lot", "lc9992", "ph2", "alk2", "junk", "junk2", "lc251", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc50", "lc25", "lc999", "tab"),
c("lot", "ph", "alk", "sp", "so", "lc25", "lc50", "lc999", "tab"))
for(i in 1:9) {
names(datlist[[i]]) <- newnames[[i]]
}
# combine data frames within each list, then combine the two lists
dat <- do.call(rbind.fill, datlist)
dat$row <- 1:dim(dat)[1]
fir <- do.call(rbind.fill, firstline)
names(fir) <- c("lot", "tab")
fir$row <- 0
datb <- rbind.fill(dat, fir)
rm(wb, gs, startrowz, firstline, datlist, newnames, i, dat, fir)
# remove rows and columns with all missing data
tabcol <- match(c("tab", "row"), names(datb))
dat2 <- datb[!apply(is.na(datb[, -tabcol]), 1, all), !apply(is.na(datb), 2, all)]
# tease out the years from the header rows
keywords <- c("Clar", "H&S 2", "H&S d", "Kin", "Wey", "Iof")
keysel <- apply(sapply(keywords, grepl, dat2$lot), 1, any)
dat2$header <- ""
dat2$header[keysel] <- dat2$lot[keysel]
dat2$year <- NA
dat2$year[keysel] <- as.numeric(gsub("[[:alpha:]]|[[:punct:]]|[[:space:]]", "", dat2$lot[keysel]))
dat2 <- with(dat2, dat2[order(tab, row), ])
dat2$header <- fill(dat2$header)
dat2$year <- fill(dat2$year)
# remove rows with headers
dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21]
tail(dat2[apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), 2:21], 11)
# ask Karen about KI with missing LC
dat3 <- dat2[!apply(is.na(dat2[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")]), 1, all), ]
# remove rows with "lc" or "h" in the LC columns
lclook <- apply(dat3[, c("lc25", "lc251", "lc50", "lc501", "lc502", "lc999", "lc9992")], 1, paste, collapse="*")
dat4 <- dat3[!(grepl("lc", lclook, ignore.case=TRUE) | grepl("h", lclook, ignore.case=TRUE)), ]
rm(datb, tabcol, dat2, keywords, keysel, dat3, lclook)
# grab sea lamprey data ... all the "2"s and sp="SL"
mytable(dat4$sp1)
mytable(dat4$sp2)
mytable(dat4$sp)
the2s <- dat4[, c("tab", "header", "row", "year", "lot", "sp2", "so2", "ph2", "alk2", "lc502", "lc9992")]
thespsls <- dat4[subdex(dat4, sp=="SL"), c("tab", "header", "row", "year", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the2s) <- names(thespsls)[-10]
sldat <- rbind.fill(the2s, thespsls)
sldat$sp <- "SL"
# grab rainbow trout data ... all the "1"s and sp="RBT"
the1s <- dat4[, c("tab", "header", "row", "year", "lot", "sp1", "so1", "ph1", "alk1", "lc251", "lc501")]
thesprbts <- dat4[subdex(dat4, sp=="RBT"), c("tab", "header", "row", "year", "lot", "sp", "so", "ph", "alk", "lc25", "lc50", "lc999")]
names(the1s) <- names(thesprbts)[-12]
rbtdat <- rbind.fill(the1s, thesprbts)
rbtdat$sp <- "RBT"
# combine the works
both <- rbind.fill(rbtdat, sldat)
both <- with(both, both[order(tab, lot), ])
# remove rows with all missing data
both2 <- both[!apply(is.na(both[, c("so", "ph", "alk", "lc25", "lc50", "lc999")]), 1, all), ]
with(both2, both2[order(sp, year, ph), ])
rm(dat4, the2s, thespsls, sldat, the1s, thesprbts, rbtdat, both)
# these columns should be numeric (ph  alk lc25 lc50 lc999) ... check to see if it's okay to convert
colz <- c("ph", "alk", "lc25", "lc50", "lc999")
tonum <- lapply(colz, function(v) char2num(both2[, v], varname=v))
tonum
both3 <- both2
both3[, colz] <- data.frame(sapply(tonum, "[", 1))
both3$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
sel <- both3$comment!=""
both3[sel, ]
both3[sel, ]
both2[sel, ]
both2[sel, c(8, 9, 10, 12)]
both2[1:5, c(8, 9, 10, 12)]
both2[1:5, c(8, 9, 10, 12)], both2[sel, c(8, 9, 10, 12)]
rbind(both2[1:5, c(8, 9, 10, 12)], both2[sel, c(8, 9, 10, 12)])
dput(rbind(both2[1:5, c(8, 9, 10, 12)], both2[sel, c(8, 9, 10, 12)]))
a <- rbind(both2[1:5, c(8, 9, 10, 12)], both2[sel, c(8, 9, 10, 12)])
dim(a)
a <- rbind(both2[1:3, c(8, 9, 10, 12)], both2[sel, c(8, 9, 10, 12)])
dim(a)
a[sample(7), ]
cbind(1:7, a[sample(7), ])
cbind(row=1:7, a[sample(7), ])
dput(cbind(row=1:7, a[sample(7), ]))
df <- (id = 1:7, x1 = c(NA, "8.2", "8.2", "8.2", "<6", NA, "8.2"), 
x2 = c(NA, "83", "79", "83", "79-80", NA, "83"), 
    x3 = c("?", NA, NA, "9.4", NA, NA, "6.6"), 
x4 = c(NA, "2.63", "1.9-2.7", NA, "2.7", "*", NA))
df <- data.frame(id = 1:7, 
x1 = c(NA, "8.2", "8.2", "8.2", "<6", NA, "8.2"), 
x2 = c(NA, "83", "79", "83", "79-80", NA, "83"), 
    x3 = c("?", NA, NA, "9.4", NA, NA, "6.6"), 
x4 = c(NA, "2.63", "1.9-2.7", NA, "2.7", "*", NA))
df
df <- data.frame(id = 1:7, 
x1 = c(NA, "8.2", "8.2", "8.2", "<6", NA, "8.2"), 
x2 = c(NA, "83", "79", "83", "79-80", "NA", "83"), 
    x3 = c("?", NA, NA, "9.4", NA, NA, "6.6"), 
x4 = c("NA", "2.63", "1.9-2.7", NA, "2.7", "*", NA))
df
df <- data.frame(id = 1:7, 
x1 = c(NA, "8.2", "8.2", "8.2", "<6", NA, "8.2"), 
x2 = c(NA, "83", "79", "83", "79-80", "NA", "83"), 
    x3 = c("?", NA, NA, "9.4", NA, NA, "6.6"), 
x4 = c("NA", "2.63", "1.9-2.7", NA, "2.7", "*", NA))
tonum <- lapply(df, char2num)
df2 <- data.frame(sapply(tonum, "[", 1))
df$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
df <- data.frame(id = 1:7, 
x1 = c(NA, "8.2", "8.2", "8.2", "<6", NA, "8.2"), 
x2 = c(NA, "83", "79", "83", "79-80", "NA", "83"), 
    x3 = c("?", NA, NA, "9.4", NA, NA, "6.6"), 
x4 = c("NA", "2.63", "1.9-2.7", NA, "2.7", "*", NA))
tonum <- lapply(df, char2num)
df2 <- data.frame(sapply(tonum, "[", 1))
df2$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
df
df2
df <- data.frame(
x1 = c(NA, 8.2, 8.2, 8.2, 8.6, 8.1, 8.2), 
x2 = c(NA, "83", "*", "83", "79-80", "NA", "83"), 
    x3 = c("?", NA, NA, "9.4", NA, ">10", "6.6"))
vars <- c("x2", "x3")
tonum <- lapply(vars, function(v) char2num(df[, v], varname=v))
df2 <- data.frame(sapply(tonum, "[", 1))
df2$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
df
df2
char2num <- function(x, varname=NULL, pmissing=c("NA", ".", "", " ", "-"), justindex=FALSE) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
sel <- is.na(asn) & !is.na(x) & !x%in%pmissing
if(justindex) {
return(sel)
} else {
note <- rep("", length(x))
if(is.null(varname)) varname <- deparse(substitute(x))
if(varname==FALSE) {
note[sel] <- x[sel]
return(list(asn, note))
} else {
note[sel] <- paste0(varname, ":", x[sel])
return(list(varname=asn, note=note))
}
}
}
df <- data.frame(
x1 = c(NA, 8.2, 8.2, 8.2, 8.6, 8.1, 8.2), 
x2 = c(NA, "83", "*", "83", "79-80", "NA", "83"), 
    x3 = c("?", NA, NA, "9.4", NA, ">10", "6.6"))
vars <- c("x2", "x3")
tonum <- lapply(vars, function(v) char2num(df[, v], varname=v))
df2 <- data.frame(sapply(tonum, "[", 1))
df2$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
df
df2
?list
char2num <- function(x, varname=NULL, pmissing=c("NA", ".", "", " ", "-"), justindex=FALSE) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
sel <- is.na(asn) & !is.na(x) & !x%in%pmissing
if(justindex) {
return(sel)
} else {
note <- rep("", length(x))
if(is.null(varname)) varname <- deparse(substitute(x))
if(varname==FALSE) {
note[sel] <- x[sel]
out <- list(asn, note)
} else {
note[sel] <- paste0(varname, ":", x[sel])
out <- list(asn, note)
names(out) <- c(varname, "note")
}
return(out)
}
}
df <- data.frame(
x1 = c(NA, 8.2, 8.2, 8.2, 8.6, 8.1, 8.2), 
x2 = c(NA, "83", "*", "83", "79-80", "NA", "83"), 
    x3 = c("?", NA, NA, "9.4", NA, ">10", "6.6"))
vars <- c("x2", "x3")
tonum <- lapply(vars, function(v) char2num(df[, v], varname=v))
df2 <- data.frame(sapply(tonum, "[", 1))
df2$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
df
df2
df <- data.frame(
x1 = c(NA, 8.2, 8.2, 8.2, 8.6, 8.1, 8.2), 
x2 = c(NA, "83", "*", "83", "79-80", "NA", "83"), 
    x3 = c(NA, NA, NA, "9.4", "?", ">10", "6.6"))
vars <- c("x2", "x3")
tonum <- lapply(vars, function(v) char2num(df[, v], varname=v))
df2 <- data.frame(sapply(tonum, "[", 1))
df2$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
df
df2
?paste
df <- data.frame(
x1 = c(NA, 8.2, 8.2, 8.2, 8.6, 8.1, 8.2), 
x2 = c(NA, "83", "*", "83", "79-80", "NA", "83"), 
    x3 = c(NA, NA, NA, "9.4", "?", ">10", "6.6"))
vars <- c("x2", "x3")
tonum <- lapply(vars, function(v) char2num(df[, v], varname=v))
df2 <- df
df2[, vars] <- data.frame(sapply(tonum, "[", 1))
df2$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
df
df2
#' Convert Character to Numeric
#'
#' Convert a character vector to a numeric vector, save any non-numeric values to a separate vector of comments.
#' @param x A character vector to be convert to numeric.
#' @param varnameA character vector to be used in the generated comment vector.  If NULL (default), the name of x will be used.  If FALSE, no varname will be used in the comment.
#' @param pmissingA character vector to be used in the generated comment vector.
#' @param justindexA logical scalar indicating if the output should just be the index of non-numeric values, default FALSE.
#' @return By default, a list of length two with the converted numeric vector and the comment vector.
#'If justindex = TRUE, a character vector the same length as x, indicating the elements with non-numeric values.
#' @details
#' @export
#' @examples 
#' a <- c(">1.5", "3", "NA", "missing", ".", "12")
#' char2num(a)
#' char2num(a, FALSE)
#' char2num(a, "pH")
#' char2num(a, pmissing=c("NA", "missing", "."))
#' char2num(a, justindex=TRUE)
#' df <- data.frame(
#' x1 = c(NA, 8.2, 8.2, 8.2, 8.6, 8.1, 8.2), 
#' x2 = c(NA, "83", "*", "83", "79-80", "NA", "83"), 
#'     x3 = c(NA, NA, NA, "9.4", "?", ">10", "6.6"))
#' vars <- c("x2", "x3")
#' tonum <- lapply(vars, function(v) char2num(df[, v], varname=v))
#' df2 <- df
#' df2[, vars] <- data.frame(sapply(tonum, "[", 1))
#' df2$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
char2num <- function(x, varname=NULL, pmissing=c("NA", ".", "", " ", "-"), justindex=FALSE) {
origopt <- options("warn")
options(warn=-1)
asn <- as.numeric(x)
options(warn=origopt$warn)
sel <- is.na(asn) & !is.na(x) & !x%in%pmissing
if(justindex) {
return(sel)
} else {
note <- rep("", length(x))
if(is.null(varname)) varname <- deparse(substitute(x))
if(varname==FALSE) {
note[sel] <- x[sel]
out <- list(asn, note)
} else {
note[sel] <- paste0(varname, ":", x[sel])
out <- list(asn, note)
names(out) <- c(varname, "note")
}
return(out)
}
}
# these columns should be numeric (ph  alk lc25 lc50 lc999) ... check to see if it's okay to convert
colz <- c("ph", "alk", "lc25", "lc50", "lc999")
tonum <- lapply(colz, function(v) char2num(both2[, v], varname=v))
both3 <- both2
both3[, colz] <- data.frame(sapply(tonum, "[", 1))
both3$comment <- apply(do.call(cbind, sapply(tonum, "[", 2)), 1, paste, collapse="")
sel <- both3$comment!=""
both3[sel, ]
?cheat
pkgup("jvamisc")
pkgup("jvamisc")
q()
