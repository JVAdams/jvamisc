sul <- unique(ls[sel])
for(i in seq(sul)) {
sel2 <- sel & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i)
}
windows()
par(mar=c(4, 4, 1, 1))
plot(year[sel], combPE[sel], type="n", las=1, log="", xlab="Year", ylab="Adults")
sul <- unique(ls[sel])
for(i in seq(sul)) {
sel2 <- sel & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i)
}
plotit <- function(sell, llog) {
windows()
par(mar=c(4, 4, 1, 1))
plot(year[sell], combPE[sell], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
sul <- unique(ls[sell])
for(i in seq(sul)) {
sel2 <- sell & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i)
}
}
mylake <- 1
yrcut <- 2004.5
# plot all non-model time series for past 10 years
sel1 <- ls %in% rownames(look2[look2[, "TRUE"]==0, ]) & lake==mylake & year > yrcut
# plot all model time series for past 10 years
sel2 <- ls %in% rownames(look2[look2[, "FALSE"]==0, ]) & lake==mylake & year > yrcut
# plot mixed time series for past 10 years
sel3 <- ls %in% rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ]) & lake==mylake & year > yrcut
plotit(sel1, "y")
plotit(sel2, "y")
plotit(sel3, "y")
plotit <- function(mylake, sell, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
sul <- unique(ls[selall])
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(sul)) {
sel2 <- sell & lake==mylake & year > yrcut & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i)
}
}
# plot all non-model time series for past 10 years
selbest <- ls %in% rownames(look2[look2[, "TRUE"]==0, ]) & lake==mylake & year > yrcut
# plot all model time series for past 10 years
selmodel <- ls %in% rownames(look2[look2[, "FALSE"]==0, ]) & lake==mylake & year > yrcut
# plot mixed time series for past 10 years
selmixed <- ls %in% rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ]) & lake==mylake & year > yrcut
plotit(1, selbest)
plotit(1, selmodel)
plotit(1, selmixed)
plotit <- function(mylake, sell, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
sul <- unique(ls[selall])
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(sul)) {
sel2 <- sell & lake==mylake & year > yrcut & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i, type="o", pch=ifelse(est.source=="model", 16, 1))
}
}
# plot all non-model time series for past 10 years
selbest <- ls %in% rownames(look2[look2[, "TRUE"]==0, ]) & lake==mylake & year > yrcut
# plot all model time series for past 10 years
selmodel <- ls %in% rownames(look2[look2[, "FALSE"]==0, ]) & lake==mylake & year > yrcut
# plot mixed time series for past 10 years
selmixed <- ls %in% rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ]) & lake==mylake & year > yrcut
plotit(1, selbest)
plotit(1, selmodel)
plotit(1, selmixed)
plotit <- function(mylake, sell, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
sul <- unique(ls[selall])
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(sul)) {
sel2 <- sell & lake==mylake & year > yrcut & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i, type="o", pch=ifelse(est.source[sel2]=="model", 1, 16))
}
}
# plot all non-model time series for past 10 years
selbest <- ls %in% rownames(look2[look2[, "TRUE"]==0, ]) & lake==mylake & year > yrcut
# plot all model time series for past 10 years
selmodel <- ls %in% rownames(look2[look2[, "FALSE"]==0, ]) & lake==mylake & year > yrcut
# plot mixed time series for past 10 years
selmixed <- ls %in% rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ]) & lake==mylake & year > yrcut
plotit(1, selbest)
plotit(1, selmodel)
plotit(1, selmixed)
plotit(3, selbest)
plotit(3, selmodel)
plotit(3, selmixed)
graphics.off()
plotit <- function(mylake, sell, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
sul <- unique(ls[selall])
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(sul)) {
sel2 <- sell & lake==mylake & year > yrcut & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i, type="o", pch=ifelse(est.source[sel2]=="model", 1, 16))
}
}
# all non-model time series
selbest <- ls %in% rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
selmodel <- ls %in% rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
selmixed <- ls %in% rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, selbest)
plotit(3, selmodel)
plotit(3, selmixed)
plotit(5, selbest)
plotit(5, selmodel)
plotit(5, selmixed)
graphics.off()
plotit(3, selbest)
plotit(3, selmodel)
plotit(3, selmixed)
plotit(3, selbest, "")
plotit(3, selmodel, "")
plotit(3, selmixed, "")
plotit(1, selbest, "")
plotit(1, selmodel, "")
plotit(1, selmixed, "")
plotit(5, selbest, "")
plotit(5, selmodel, "")
plotit(5, selmixed, "")
graphics.off()
plotit(3, selbest)
plotit(3, selmodel)
plotit(3, selmixed)
plotit <- function(mylake, sell, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
sul <- unique(ls[selall])
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(sul)) {
sel2 <- sell & lake==mylake & year > yrcut & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i, lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], combPE[sel2], col=i, type="o", pch=ifelse(est.source[sel2]=="model", 1, 16))
lines(year[sel2], y[sel2], col=i, type="o", pch=16, cex=1.5)
}
}
# all non-model time series
selbest <- ls %in% rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
selmodel <- ls %in% rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
selmixed <- ls %in% rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, selbest)
plotit(3, selmodel)
plotit(3, selmixed)
plotit <- function(mylake, sell, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
sul <- unique(ls[selall])
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(sul)) {
sel2 <- sell & lake==mylake & year > yrcut & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i, lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y[sel2], col=i, type="o", pch=16, cex=1.5)
}
}
# all non-model time series
selbest <- ls %in% rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
selmodel <- ls %in% rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
selmixed <- ls %in% rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, selbest)
plotit(3, selmodel)
plotit(3, selmixed)
plotit <- function(mylake, sell, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
sul <- unique(ls[selall])
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(sul)) {
sel2 <- sell & lake==mylake & year > yrcut & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i, lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y, col=i, type="o", pch=16, cex=1.5)
}
}
# all non-model time series
selbest <- ls %in% rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
selmodel <- ls %in% rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
selmixed <- ls %in% rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, selbest)
plotit(3, selmodel)
plotit(3, selmixed)
graphics.off()
plotit <- function(mylake, sell, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
sul <- unique(ls[selall])
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(sul)) {
sel2 <- sell & lake==mylake & year > yrcut & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i, lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y, col=i, type="o", pch=16, cex=1.2)
}
}
# all non-model time series
selbest <- ls %in% rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
selmodel <- ls %in% rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
selmixed <- ls %in% rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, selbest)
plotit(3, selmodel)
plotit(3, selmixed)
showmarks()
plotit <- function(mylake, sell, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
sul <- unique(ls[selall])
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(sul)) {
sel2 <- sell & lake==mylake & year > yrcut & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i, lty=3)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y, col=i, type="o", pch=16, cex=1.2, lwd=2)
}
}
# all non-model time series
selbest <- ls %in% rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
selmodel <- ls %in% rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
selmixed <- ls %in% rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, selbest)
plotit(3, selmodel)
plotit(3, selmixed)
plotit <- function(mylake, sell, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
sul <- unique(ls[selall])
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(sul)) {
sel2 <- sell & lake==mylake & year > yrcut & ls==sul[i]
lines(year[sel2], combPE[sel2], col=i, lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y, col=i, type="o", pch=16, cex=1.2, lwd=2)
}
}
# all non-model time series
selbest <- ls %in% rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
selmodel <- ls %in% rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
selmixed <- ls %in% rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, selbest)
plotit(3, selmodel)
plotit(3, selmixed)
graphics.off()
lss
lls
?brewer
display.brewer.all()
colz <- rep(brewer.pal(12, "Set3"), 5)
plotit <- function(mylake, lss, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(lss)) {
sel2 <- sell & lake==mylake & year > yrcut & ls==lss[i]
lines(year[sel2], combPE[sel2], col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, selbest)
plotit(3, selmodel)
plotit(3, selmixed)
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
colz <- rep(brewer.pal(12, "Set3"), 5)
plotit <- function(mylake, lss, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(lss)) {
sel2 <- lake==mylake & year > yrcut & ls==lss[i]
lines(year[sel2], combPE[sel2], col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
lsmodel
plotit(3, lsmodel)
mylake=3
lss=lsmodel
llog="y"
yrcut=2004.5
selall <- lake==mylake & year > yrcut
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
seq(lss)
length(colz)
181/12
colz <- rep(brewer.pal(12, "Set3"), 25)
plotit <- function(mylake, lss, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(lss)) {
sel2 <- lake==mylake & year > yrcut & ls==lss[i]
lines(year[sel2], combPE[sel2], col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
colz <- rep(brewer.pal(12, "Set1"), 50)
plotit <- function(mylake, lss, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(lss)) {
sel2 <- lake==mylake & year > yrcut & ls==lss[i]
lines(year[sel2], combPE[sel2], col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
mylake=3
lss=lsmodel
llog="y"
yrcut=2004.5
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
colz <- rep(brewer.pal(12, "Dark2"), 50)
plotit <- function(mylake, lss, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
windows()
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(lss)) {
sel2 <- lake==mylake & year > yrcut & ls==lss[i]
lines(year[sel2], combPE[sel2], col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
mylake=3
lss=lsmodel
llog="y"
yrcut=2004.5
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
length(map5)
dim(map5)
map5
windows(h=5, w=9)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
head(dat)
sel <- est.source=="model"
points(long[sel], lat[sel], col=colz[1], cex=2)
sel <- est.source=="model"
windows(h=5, w=9)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[sel], lat[sel], col=colz[1], cex=2)
windows(h=5, w=9)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[!sel], lat[!sel], col=colz[2], cex=3, lwd=2)
sel <- est.source=="model"
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[sel], lat[sel], col=colz[1], cex=2)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[!sel], lat[!sel], col=colz[2], cex=3, lwd=2)
selm <- year==2014 & est.source=="model"
selo <- year==2014 & est.source!="model"
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selm], lat[selm], col=colz[1], cex=2)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
legend("topright", cex=c(1, 3), lwd=c(1, 2), col=coz[1:2], pch=1)
legend("topright", c("Untrapped", "Trapped"), cex=c(1, 3), lwd=c(1, 2), col=coz[1:2], pch=1)
legend("topright", c("Untrapped", "Trapped"), cex=c(1, 3), lwd=c(1, 2), col=colz[1:2], pch=1)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
legend("topright", c("Untrapped", "Trapped"), pt.cex=c(1, 3), lwd=c(1, 2), col=colz[1:2], pch=1)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
legend("right", c("Untrapped", "Trapped"), pt.cex=c(1, 3), lwd=c(1, 2), col=colz[1:2], pch=1, byt="n")
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
legend("right", c("Untrapped", "Trapped"), pt.cex=c(1, 3), lwd=c(1, 2), col=colz[1:2], pch=1, bty="n")
?legend
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
legend("right", c("Untrapped", "Trapped"), pt.cex=c(2, 3), pt.lwd=c(1, 2), col=colz[1:2], pch=1, bty="n")
plotit <- function(mylake, lss, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
windows(h=6, w=3)
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(lss)) {
sel2 <- lake==mylake & year > yrcut & ls==lss[i]
lines(year[sel2], combPE[sel2], col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit <- function(mylake, lss, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
windows(h=5.5, w=3.3)
par(mar=c(4, 4, 1, 1))
plot(year[selall], combPE[selall], type="n", las=1, log=llog, xlab="Year", ylab="Adults")
for(i in seq(lss)) {
sel2 <- lake==mylake & year > yrcut & ls==lss[i]
lines(year[sel2], combPE[sel2], col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
graphics.off()
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
plotit <- function(mylake, lss, llog="y", yrcut=2004.5) {
selall <- lake==mylake & year > yrcut
windows(h=5.5, w=3.3)
par(mar=c(4, 4, 1, 1))
if(llog=="y") {
fac <- 1
ylabb <- "Adults"
} else {
fac <- 1000
ylabb <- "Adults  (thousands)"
}
plot(year[selall], combPE[selall]/fac, type="n", las=1, log=llog, xlab="Year", ylab=ylabb)
for(i in seq(lss)) {
sel2 <- lake==mylake & year > yrcut & ls==lss[i]
lines(year[sel2], combPE[sel2]/fac, col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y/fac, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
plotit(3, lsmodel, "")
plotit(3, lsmodel)
locator()
dat[lake==3 & year==2008 & combPE > 6000, 1:10]
dat[lake==3 & year==2008 & combPE > 6000,]
locator()
dat[lake==3 & year==2008 & combPE > 6000,]
locator()
dat[lake==3 & year>2004.5 & strname=="Garden", ]
graphics.off()
plotit(1, lsbest)
plotit(1, lsmodel)
plotit(1, lsmixed)
plotit(1, lsbest, "")
plotit(1, lsmodel, "")
plotit(1, lsmixed, "")
graphics.off()
q()
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selm], lat[selm], col=colz[1], cex=2, lwd=2)
# C:\JVA\GLFC\CLC\CLCAdultIndex.r
{ # functions
# the following seven plot.table related functions are from the Systematic Investor Toolbox
# load Systematic Investor Toolbox
# require(RCurl)
# sit = getURLContent("https://github.com/systematicinvestor/SIT/raw/master/sit.gz", binary=TRUE, followlocation=TRUE, ssl.verifypeer=FALSE)
# con = gzcon(rawConnection(sit, "rb"))
# source(con)
# close(con)
draw.cell <- function(title, r, c, text.cex = 1, bg.col = 'white', frame.cell = T) {
if(!frame.cell) bcol = bg.col else bcol = 'black'
rect((2*(c - 1) + .5), -(r - .5), (2*c + .5), -(r + .5), col = bg.col, border = bcol)
if( c == 1) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else if( r == 1 ) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else {
text((2*c + .5), -r, title, adj = 1, cex = text.cex)
}
}
plot.table.helper.auto.adjust.cex <- function(temp.table, keep.all.same.cex = FALSE) {
nr = nrow(temp.table)
nc = ncol(temp.table)
all.xrange = diff(par()$usr[1:2]) / nc
xrange = matrix( strwidth(paste('  ', temp.table), units = 'user', cex = 1), nc = nc)
all.yrange = diff(par()$usr[3:4]) / nr
yrange = matrix( 5/3 * strheight(temp.table, units = 'user', cex = 1), nc = nc)
plot.matrix.cex = pmin( round(all.yrange / yrange, 2) , round(all.xrange / xrange, 2) )
header.col.cex = min(plot.matrix.cex[1,-1])
header.row.cex = min(plot.matrix.cex[-1,1])
title.cex = plot.matrix.cex[1, 1]
data.cex = min(plot.matrix.cex[-1, -1])
if ( keep.all.same.cex ) {
plot.matrix.cex[] = min(plot.matrix.cex)
} else {
plot.matrix.cex[1,-1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,-1]= min(c(header.col.cex, header.row.cex, data.cex))
plot.matrix.cex[1,1]= min(c(header.col.cex, header.row.cex, data.cex, title.cex))
plot.matrix.cex[1,-1] = min(c(header.col.cex))
plot.matrix.cex[-1,1] = min(c(header.row.cex))
plot.matrix.cex[-1,-1]= min(c(data.cex))
plot.matrix.cex[1,1]= min(c(title.cex))
}
return(plot.matrix.cex)
}
make.table <- function(nr, nc) {
savepar = par(mar = rep(1, 4))
plot(c(0.5, nc*2 + 0.5), c(-0.5, -(nr + 0.5)), xaxs = 'i', yaxs = 'i',
type = 'n', xlab = '', ylab = '', axes = FALSE)
savepar
}
trim <- function(s) {
s = sub(pattern = '^ +', replacement = '', x = s)
s = sub(pattern = ' +$', replacement = '', x = s)
return(s)
}
plot.table.param <- function(plot.matrix, smain = '', plot.matrix.cex, plot.matrix_bg.col, frame.cell = T, keep.all.same.cex = FALSE) {
n = nrow(plot.matrix)
pages = unique(c(seq(0, n, by = 120), n))
for(p in 1:(length(pages)-1)) {
rindex = (pages[p]+1) : pages[p+1]
temp.table = matrix('', nr = length(rindex)+1, nc = ncol(plot.matrix)+1)
temp.table[-1, -1] = plot.matrix[rindex,]
temp.table[1, -1] = colnames(plot.matrix)
temp.table[-1, 1] = rownames(plot.matrix)[rindex]
temp.table[1, 1] = smain
nr = nrow(temp.table)
nc = ncol(temp.table)
par(mar = c(0, 0, 0, 0), cex = 0.5)
oldpar = make.table(nr, nc)
text.cex = plot.matrix.cex[c(1, 1 + rindex), ]
text.cex = plot.table.helper.auto.adjust.cex(temp.table, keep.all.same.cex)
bg.col = plot.matrix_bg.col[c(1, 1 + rindex), ]
for(r in 1:nr) {
for(c in 1:nc) {
draw.cell( paste('', temp.table[r,c], '', sep=' '), r, c,
text.cex = text.cex[r,c], bg.col = bg.col[r,c], frame.cell = frame.cell)
}}
}
}
plot.table <- function(plot.matrix, smain="", text.cex=1, frame.cell=TRUE, highlight=FALSE, colorbar=FALSE, keep_all.same.cex=FALSE) {
if( is.null(rownames(plot.matrix)) & is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
if( ncol(temp.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[-1, -1, drop = FALSE]
colnames(plot.matrix) = temp.matrix[1, -1]
rownames(plot.matrix) = temp.matrix[-1, 1]
smain = temp.matrix[1, 1]
} else if( is.null(rownames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( ncol(plot.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[, -1, drop = FALSE]
colnames(plot.matrix) = colnames(temp.matrix)[-1]
rownames(plot.matrix) = temp.matrix[,1]
smain = colnames(temp.matrix)[1]
} else if( is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
plot.matrix = temp.matrix[-1, , drop = FALSE]
rownames(plot.matrix) = rownames(temp.matrix)[-1]
colnames(plot.matrix) = temp.matrix[1, ]
smain = rownames(temp.matrix)[1]
}
plot.matrix[which(trim(plot.matrix) == "NA")] = ""
plot.matrix[which(trim(plot.matrix) == "NA%")] = ""
plot.matrix[which(is.na(plot.matrix))] = ""
nr = nrow(plot.matrix) + 1
nc = ncol(plot.matrix) + 1
is_highlight = TRUE
if(is.logical(highlight)) {
is_highlight = highlight
if(highlight) highlight = plot.table.helper.color(plot.matrix)
}
if(!is_highlight) {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[seq(1, nr, 2), ] = "yellow"
plot.matrix_bg.col[1,] = "gray";
plot.table.param( plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
} else {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[1,] = "gray"
plot.matrix_bg.col[2:nr,2:nc] = highlight
plot.table.param(plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
}
}
plot.table.helper.color <- function (temp) {
temp = matrix(as.double(gsub("[%,$]", "", temp)), nrow(temp), ncol(temp))
highlight = as.vector(temp)
cols = rep(NA, length(highlight))
ncols = length(highlight[!is.na(highlight)])
cols[1:ncols] = rev(rainbow(ncols, start=0.5/6, end=3.5/6))
o = sort.list(highlight, na.last = TRUE, decreasing = FALSE)
o1 = sort.list(o, na.last = TRUE, decreasing = FALSE)
highlight = matrix(cols[o1], nrow = nrow(temp))
highlight[is.na(temp)] = NA
return(highlight)
}
ModelEst <- function(fit, df) {
# derive regression estimates from log(y) fit
mse <- rev(as.matrix(summary(fit)[[1]])[, "Mean Sq"])[1]
plpe <- predict(fit, newdata=df, se.fit=T)
m <- plpe$fit
v <- plpe$se.fit^2 + mse
exp(m + v/2)
}
myrange <- function(x) {
if(all(is.na(x))) r <- c(NA, NA) else r <- range(x, na.rm=TRUE)
return(r)
}
jackindex <- function(m) {
# m is a matrix of numbers (stream PEs) with observations (years) as rows and individuals (streams) as columns
if(any(is.na(m))) stop("The input matrix may not have any missing values.")
# calculate the index as the sum of the columns for each row
rowsum <- apply(m, 1, sum)
# calculate the mean of the index
avgind <- mean(rowsum)
# recalculate the index, leaving out one individual at a time
loo <- apply(m, 2, function(column) (rowsum - column))
# rescale the loo index, relative to mean
looscaled <- apply(loo, 2, function(x) x/mean(x))
# convert to original scale
looscaled2 <- looscaled * avgind
# calculate range
ranges <- t(apply(looscaled2, 1, range))
cbind(index=rowsum, lo=ranges[, 1], hi=ranges[, 2])
}
# selstreams <- index.streams[[1]] 
# allstreamdf <- dat
# alllakedf <- lk 
# min.nmr=2 
# show=FALSE
index.est <- function(selstreams, allstreamdf, alllakedf, min.nmr=2, show=FALSE) {
# INDEX OF ADULT SEA LAMPREY ABUNDANCE
### INPUTS
# selstreams = vector of stream ids, e.g., 1.064 (lake + strcode/1000)
# allstreamdf = data frame of mark-recap estimates for all streams, with vars:  year lake ls Emr CVmr
# alllakedf = data frame of lake-wide PEs from Mullett et al. (2003) spawner model with vars:  lake year PE
# min.nmr = minimum number of mark-recapture estimates needed in a year to generate an index, default 2
# show = print out a brief summary of the results, default FALSE
### OUTPUTS
# indfit = simple model used to predict missing mark-recap estimates
# streamdf = original allstreamdf, subsetted by selstreams, with estimates for missing mark-recaps
# indxdf = original alllakedf, subsetted by lake, with annual index, including raw (indxraw), kept based on min.nmr (indxkeep, indxkeep.lo, indxkeep.hi)
# scaleup = conversion factor used to scale up annual index to spawner model PE
streamdf <- allstreamdf[allstreamdf$ls %in% selstreams, ]
# error checks
check1 <- var(streamdf$lake)
if(is.na(check1) | is.null(check1)) stop("Either no streams selected or critical data missing.") else if(check1 > 0) stop("Selected streams should be only from ONE lake.")
if(any(is.na(match(c("year", "lake", "ls", "Emr", "CVmr"), names(allstreamdf))))) stop("allstreamdf must include these variables: year lake ls Emr CVmr.")
if(any(is.na(match(c("year", "lake", "PE"), names(alllakedf))))) stop("alllakedf must include these variables: lake year PE.")
# fill in missing mark-recap data
indfit <- aov(log(Emr) ~ as.factor(ls) + as.factor(year), data=streamdf, weights=1/CVmr^2)
# figure out estimable years (those with at least 1 m-r estimate)
n.mr <- tapply(!is.na(streamdf$Emr), streamdf$year, sum)
eyrs <- as.numeric(names(n.mr)[n.mr > 0.5])
estimable <- streamdf$year %in% eyrs
streamdf$Pmr <- NA
streamdf$Pmr[estimable] <- ModelEst(fit=indfit, df=streamdf[estimable, ])
streamdf$COMBmr <- ifelse(is.na(streamdf$Emr), streamdf$Pmr, streamdf$Emr)
# annual index (sum across streams)
indxdf <- aggregate(COMBmr ~ year + lake, streamdf, sum, na.rm=TRUE, na.action=na.pass)
names(indxdf)[names(indxdf)=="COMBmr"] <- "indxraw"
indxdf$indxraw[indxdf$indxraw==0] <- NA
# only keep lake-wide index for years with at least min.nmr mark-recap estimates
indxdf$n.mr <- n.mr
indxdf$indxkeep <- ifelse(indxdf$n.mr > (min.nmr - 0.5), indxdf$indxraw, NA)
indxdf$indxkeep.lo <- NA
indxdf$indxkeep.hi <- NA
# matrix of stream estimates (rows = years, columns = index streams)
streamests <- with(streamdf, tapply(COMBmr, list(year, ls), mean))
# selection of only those streams with a keepable index
selkeep <- !is.na(indxdf$indxkeep)
jack <- jackindex(streamests[selkeep, ])
indxdf$indxkeep.lo[selkeep] <- jack[, "lo"]
indxdf$indxkeep.hi[selkeep] <- jack[, "hi"]
# scale up the index to the spawner model PE
lk1 <- lk[lk$lake == streamdf$lake[1], ]
indxdf2 <- merge(lk1, indxdf, all=TRUE)
scaleup <- median(indxdf2$PE / indxdf2$indxkeep, na.rm=TRUE)
if(show) {
cat("\nindfit\n")
print(summary(indfit))
cat("\nstreamdf\n")
print(tail(streamdf[, c("lake", "year", "ls", "Emr", "CVmr", "Pmr", "COMBmr")]))
cat("\nscaleup\n")
print(scaleup)
cat("\nindxdf\n")
print(tail(indxdf[, c("lake", "year", "n.mr", "indxraw", "indxkeep", "indxkeep.lo", "indxkeep.hi")]))
}
list(indfit=indfit, streamdf=streamdf, scaleup=scaleup, indxdf=indxdf)
}
calctarg <- function(lakenum, adults, year, targyears, adjust=c(1, 1, 0.25, 1, 1)) {
# lakenum = vector of lake numbers (1-5)
# adults = vector of lakewide adult sea lamprey estimates
# year = vector of years
# targyears = list (length 5) of selected years from which to calculate targets
# lake huron target is 25% of
targets <- data.frame(lake=1:5, target=rep(NA, 5), lo=rep(NA, 5), hi=rep(NA, 5))
for(i in 1:5) {
pick5 <- adults[lakenum==i & is.element(year, targyears[[i]]) & !is.na(adults)]
if(length(pick5) > 0) {
targets$target[i] <- mean(pick5)
n <- length(pick5)
ci <- qnorm(1 - 0.05/2) * sqrt(var(pick5)) / sqrt(n)
targets[i, c("lo", "hi")] <- mean(pick5) + c(-1, 1)*ci# using z dist (known variance)
targets[i, c("target", "lo", "hi")] <- adjust[i]*targets[i, c("target", "lo", "hi")]
} else {
targets[i, c("target", "lo", "hi")] <- c(NA, NA, NA)
}
}
targets
}
}
# bring in lake-wide spawner data
lk <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/LakePEdynamic.csv", as.is=T)
# bring in stream-specific data
dat <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/StreamPEdynamicALLCOLS.csv", as.is=T)
dat$ls <- dat$lscode
attach(dat)
colz <- rep(brewer.pal(12, "Dark2"), 50)
selm <- year==2014 & est.source=="model"
selo <- year==2014 & est.source!="model"
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selm], lat[selm], col=colz[1], cex=2, lwd=2)
# C:\JVA\GLFC\CLC\CLCAdultIndex.r
{ # functions
# the following seven plot.table related functions are from the Systematic Investor Toolbox
# load Systematic Investor Toolbox
# require(RCurl)
# sit = getURLContent("https://github.com/systematicinvestor/SIT/raw/master/sit.gz", binary=TRUE, followlocation=TRUE, ssl.verifypeer=FALSE)
# con = gzcon(rawConnection(sit, "rb"))
# source(con)
# close(con)
draw.cell <- function(title, r, c, text.cex = 1, bg.col = 'white', frame.cell = T) {
if(!frame.cell) bcol = bg.col else bcol = 'black'
rect((2*(c - 1) + .5), -(r - .5), (2*c + .5), -(r + .5), col = bg.col, border = bcol)
if( c == 1) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else if( r == 1 ) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else {
text((2*c + .5), -r, title, adj = 1, cex = text.cex)
}
}
plot.table.helper.auto.adjust.cex <- function(temp.table, keep.all.same.cex = FALSE) {
nr = nrow(temp.table)
nc = ncol(temp.table)
all.xrange = diff(par()$usr[1:2]) / nc
xrange = matrix( strwidth(paste('  ', temp.table), units = 'user', cex = 1), nc = nc)
all.yrange = diff(par()$usr[3:4]) / nr
yrange = matrix( 5/3 * strheight(temp.table, units = 'user', cex = 1), nc = nc)
plot.matrix.cex = pmin( round(all.yrange / yrange, 2) , round(all.xrange / xrange, 2) )
header.col.cex = min(plot.matrix.cex[1,-1])
header.row.cex = min(plot.matrix.cex[-1,1])
title.cex = plot.matrix.cex[1, 1]
data.cex = min(plot.matrix.cex[-1, -1])
if ( keep.all.same.cex ) {
plot.matrix.cex[] = min(plot.matrix.cex)
} else {
plot.matrix.cex[1,-1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,-1]= min(c(header.col.cex, header.row.cex, data.cex))
plot.matrix.cex[1,1]= min(c(header.col.cex, header.row.cex, data.cex, title.cex))
plot.matrix.cex[1,-1] = min(c(header.col.cex))
plot.matrix.cex[-1,1] = min(c(header.row.cex))
plot.matrix.cex[-1,-1]= min(c(data.cex))
plot.matrix.cex[1,1]= min(c(title.cex))
}
return(plot.matrix.cex)
}
make.table <- function(nr, nc) {
savepar = par(mar = rep(1, 4))
plot(c(0.5, nc*2 + 0.5), c(-0.5, -(nr + 0.5)), xaxs = 'i', yaxs = 'i',
type = 'n', xlab = '', ylab = '', axes = FALSE)
savepar
}
trim <- function(s) {
s = sub(pattern = '^ +', replacement = '', x = s)
s = sub(pattern = ' +$', replacement = '', x = s)
return(s)
}
plot.table.param <- function(plot.matrix, smain = '', plot.matrix.cex, plot.matrix_bg.col, frame.cell = T, keep.all.same.cex = FALSE) {
n = nrow(plot.matrix)
pages = unique(c(seq(0, n, by = 120), n))
for(p in 1:(length(pages)-1)) {
rindex = (pages[p]+1) : pages[p+1]
temp.table = matrix('', nr = length(rindex)+1, nc = ncol(plot.matrix)+1)
temp.table[-1, -1] = plot.matrix[rindex,]
temp.table[1, -1] = colnames(plot.matrix)
temp.table[-1, 1] = rownames(plot.matrix)[rindex]
temp.table[1, 1] = smain
nr = nrow(temp.table)
nc = ncol(temp.table)
par(mar = c(0, 0, 0, 0), cex = 0.5)
oldpar = make.table(nr, nc)
text.cex = plot.matrix.cex[c(1, 1 + rindex), ]
text.cex = plot.table.helper.auto.adjust.cex(temp.table, keep.all.same.cex)
bg.col = plot.matrix_bg.col[c(1, 1 + rindex), ]
for(r in 1:nr) {
for(c in 1:nc) {
draw.cell( paste('', temp.table[r,c], '', sep=' '), r, c,
text.cex = text.cex[r,c], bg.col = bg.col[r,c], frame.cell = frame.cell)
}}
}
}
plot.table <- function(plot.matrix, smain="", text.cex=1, frame.cell=TRUE, highlight=FALSE, colorbar=FALSE, keep_all.same.cex=FALSE) {
if( is.null(rownames(plot.matrix)) & is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
if( ncol(temp.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[-1, -1, drop = FALSE]
colnames(plot.matrix) = temp.matrix[1, -1]
rownames(plot.matrix) = temp.matrix[-1, 1]
smain = temp.matrix[1, 1]
} else if( is.null(rownames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( ncol(plot.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[, -1, drop = FALSE]
colnames(plot.matrix) = colnames(temp.matrix)[-1]
rownames(plot.matrix) = temp.matrix[,1]
smain = colnames(temp.matrix)[1]
} else if( is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
plot.matrix = temp.matrix[-1, , drop = FALSE]
rownames(plot.matrix) = rownames(temp.matrix)[-1]
colnames(plot.matrix) = temp.matrix[1, ]
smain = rownames(temp.matrix)[1]
}
plot.matrix[which(trim(plot.matrix) == "NA")] = ""
plot.matrix[which(trim(plot.matrix) == "NA%")] = ""
plot.matrix[which(is.na(plot.matrix))] = ""
nr = nrow(plot.matrix) + 1
nc = ncol(plot.matrix) + 1
is_highlight = TRUE
if(is.logical(highlight)) {
is_highlight = highlight
if(highlight) highlight = plot.table.helper.color(plot.matrix)
}
if(!is_highlight) {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[seq(1, nr, 2), ] = "yellow"
plot.matrix_bg.col[1,] = "gray";
plot.table.param( plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
} else {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[1,] = "gray"
plot.matrix_bg.col[2:nr,2:nc] = highlight
plot.table.param(plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
}
}
plot.table.helper.color <- function (temp) {
temp = matrix(as.double(gsub("[%,$]", "", temp)), nrow(temp), ncol(temp))
highlight = as.vector(temp)
cols = rep(NA, length(highlight))
ncols = length(highlight[!is.na(highlight)])
cols[1:ncols] = rev(rainbow(ncols, start=0.5/6, end=3.5/6))
o = sort.list(highlight, na.last = TRUE, decreasing = FALSE)
o1 = sort.list(o, na.last = TRUE, decreasing = FALSE)
highlight = matrix(cols[o1], nrow = nrow(temp))
highlight[is.na(temp)] = NA
return(highlight)
}
ModelEst <- function(fit, df) {
# derive regression estimates from log(y) fit
mse <- rev(as.matrix(summary(fit)[[1]])[, "Mean Sq"])[1]
plpe <- predict(fit, newdata=df, se.fit=T)
m <- plpe$fit
v <- plpe$se.fit^2 + mse
exp(m + v/2)
}
myrange <- function(x) {
if(all(is.na(x))) r <- c(NA, NA) else r <- range(x, na.rm=TRUE)
return(r)
}
jackindex <- function(m) {
# m is a matrix of numbers (stream PEs) with observations (years) as rows and individuals (streams) as columns
if(any(is.na(m))) stop("The input matrix may not have any missing values.")
# calculate the index as the sum of the columns for each row
rowsum <- apply(m, 1, sum)
# calculate the mean of the index
avgind <- mean(rowsum)
# recalculate the index, leaving out one individual at a time
loo <- apply(m, 2, function(column) (rowsum - column))
# rescale the loo index, relative to mean
looscaled <- apply(loo, 2, function(x) x/mean(x))
# convert to original scale
looscaled2 <- looscaled * avgind
# calculate range
ranges <- t(apply(looscaled2, 1, range))
cbind(index=rowsum, lo=ranges[, 1], hi=ranges[, 2])
}
# selstreams <- index.streams[[1]] 
# allstreamdf <- dat
# alllakedf <- lk 
# min.nmr=2 
# show=FALSE
index.est <- function(selstreams, allstreamdf, alllakedf, min.nmr=2, show=FALSE) {
# INDEX OF ADULT SEA LAMPREY ABUNDANCE
### INPUTS
# selstreams = vector of stream ids, e.g., 1.064 (lake + strcode/1000)
# allstreamdf = data frame of mark-recap estimates for all streams, with vars:  year lake ls Emr CVmr
# alllakedf = data frame of lake-wide PEs from Mullett et al. (2003) spawner model with vars:  lake year PE
# min.nmr = minimum number of mark-recapture estimates needed in a year to generate an index, default 2
# show = print out a brief summary of the results, default FALSE
### OUTPUTS
# indfit = simple model used to predict missing mark-recap estimates
# streamdf = original allstreamdf, subsetted by selstreams, with estimates for missing mark-recaps
# indxdf = original alllakedf, subsetted by lake, with annual index, including raw (indxraw), kept based on min.nmr (indxkeep, indxkeep.lo, indxkeep.hi)
# scaleup = conversion factor used to scale up annual index to spawner model PE
streamdf <- allstreamdf[allstreamdf$ls %in% selstreams, ]
# error checks
check1 <- var(streamdf$lake)
if(is.na(check1) | is.null(check1)) stop("Either no streams selected or critical data missing.") else if(check1 > 0) stop("Selected streams should be only from ONE lake.")
if(any(is.na(match(c("year", "lake", "ls", "Emr", "CVmr"), names(allstreamdf))))) stop("allstreamdf must include these variables: year lake ls Emr CVmr.")
if(any(is.na(match(c("year", "lake", "PE"), names(alllakedf))))) stop("alllakedf must include these variables: lake year PE.")
# fill in missing mark-recap data
indfit <- aov(log(Emr) ~ as.factor(ls) + as.factor(year), data=streamdf, weights=1/CVmr^2)
# figure out estimable years (those with at least 1 m-r estimate)
n.mr <- tapply(!is.na(streamdf$Emr), streamdf$year, sum)
eyrs <- as.numeric(names(n.mr)[n.mr > 0.5])
estimable <- streamdf$year %in% eyrs
streamdf$Pmr <- NA
streamdf$Pmr[estimable] <- ModelEst(fit=indfit, df=streamdf[estimable, ])
streamdf$COMBmr <- ifelse(is.na(streamdf$Emr), streamdf$Pmr, streamdf$Emr)
# annual index (sum across streams)
indxdf <- aggregate(COMBmr ~ year + lake, streamdf, sum, na.rm=TRUE, na.action=na.pass)
names(indxdf)[names(indxdf)=="COMBmr"] <- "indxraw"
indxdf$indxraw[indxdf$indxraw==0] <- NA
# only keep lake-wide index for years with at least min.nmr mark-recap estimates
indxdf$n.mr <- n.mr
indxdf$indxkeep <- ifelse(indxdf$n.mr > (min.nmr - 0.5), indxdf$indxraw, NA)
indxdf$indxkeep.lo <- NA
indxdf$indxkeep.hi <- NA
# matrix of stream estimates (rows = years, columns = index streams)
streamests <- with(streamdf, tapply(COMBmr, list(year, ls), mean))
# selection of only those streams with a keepable index
selkeep <- !is.na(indxdf$indxkeep)
jack <- jackindex(streamests[selkeep, ])
indxdf$indxkeep.lo[selkeep] <- jack[, "lo"]
indxdf$indxkeep.hi[selkeep] <- jack[, "hi"]
# scale up the index to the spawner model PE
lk1 <- lk[lk$lake == streamdf$lake[1], ]
indxdf2 <- merge(lk1, indxdf, all=TRUE)
scaleup <- median(indxdf2$PE / indxdf2$indxkeep, na.rm=TRUE)
if(show) {
cat("\nindfit\n")
print(summary(indfit))
cat("\nstreamdf\n")
print(tail(streamdf[, c("lake", "year", "ls", "Emr", "CVmr", "Pmr", "COMBmr")]))
cat("\nscaleup\n")
print(scaleup)
cat("\nindxdf\n")
print(tail(indxdf[, c("lake", "year", "n.mr", "indxraw", "indxkeep", "indxkeep.lo", "indxkeep.hi")]))
}
list(indfit=indfit, streamdf=streamdf, scaleup=scaleup, indxdf=indxdf)
}
calctarg <- function(lakenum, adults, year, targyears, adjust=c(1, 1, 0.25, 1, 1)) {
# lakenum = vector of lake numbers (1-5)
# adults = vector of lakewide adult sea lamprey estimates
# year = vector of years
# targyears = list (length 5) of selected years from which to calculate targets
# lake huron target is 25% of
targets <- data.frame(lake=1:5, target=rep(NA, 5), lo=rep(NA, 5), hi=rep(NA, 5))
for(i in 1:5) {
pick5 <- adults[lakenum==i & is.element(year, targyears[[i]]) & !is.na(adults)]
if(length(pick5) > 0) {
targets$target[i] <- mean(pick5)
n <- length(pick5)
ci <- qnorm(1 - 0.05/2) * sqrt(var(pick5)) / sqrt(n)
targets[i, c("lo", "hi")] <- mean(pick5) + c(-1, 1)*ci# using z dist (known variance)
targets[i, c("target", "lo", "hi")] <- adjust[i]*targets[i, c("target", "lo", "hi")]
} else {
targets[i, c("target", "lo", "hi")] <- c(NA, NA, NA)
}
}
targets
}
}
# bring in lake-wide spawner data
lk <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/LakePEdynamic.csv", as.is=T)
# bring in stream-specific data
dat <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/StreamPEdynamicALLCOLS.csv", as.is=T)
dat$ls <- dat$lscode
attach(dat)
colz <- rep(brewer.pal(8, "Dark2"), 100)
selm <- year==2014 & est.source=="model"
selo <- year==2014 & est.source!="model"
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selm], lat[selm], col=colz[1], cex=2, lwd=2)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
legend("right", c("Untrapped", "Trapped"), pt.cex=c(2, 3), pt.lwd=c(1, 2), col=colz[1:2], pch=1, bty="n")
search()
detach()
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selm], lat[selm], col=colz[1], cex=2, lwd=2)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
legend("right", c("Untrapped", "Trapped"), pt.cex=c(2, 3), pt.lwd=2, col=colz[1:2], pch=1, bty="n")
selm <- year==2014 & est.source=="model"
selo <- year==2014 & est.source!="model"
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selm], lat[selm], col=colz[1], cex=2, lwd=2)
legend("right", c("Untrapped", "Trapped"), pt.cex=c(2, 3), pt.lwd=2, col=colz[1:2], pch=1, bty="n")
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selm], lat[selm], col=colz[1], cex=2, lwd=2)
legend("right", c("Trapped", "Untrapped"), pt.cex=c(3, 2), pt.lwd=2, col=colz[2:1], pch=1, bty="n")
graphics.off()
### plots of time series
look <- table(ls, year, est.source=="model")
# just last 10 years
look2 <- apply(look[, 29:38, ], c(1, 3), sum)
look3 <- look2[look2[, 1]>0 & look2[, 2]>0, ]
look3[order(look3[, 1] - look3[, 2]), ]
dat[match(rownames(look3), ls), 1:10]
#dat[match(unlist(index.streams), ls), 1:10]
plotit <- function(mylake, lss, llog="y", yrcut=2004.5, ...) {
selall <- lake==mylake & year > yrcut
windows(h=5.5, w=3.3)
par(mar=c(4, 4, 1, 1))
if(llog=="y") {
fac <- 1
ylabb <- "Adults"
} else {
fac <- 1000
ylabb <- "Adults  (thousands)"
}
plot(year[selall], combPE[selall]/fac, type="n", las=1, log=llog, xlab="Year", ylab=ylabb, ...)
for(i in seq(lss)) {
sel2 <- lake==mylake & year > yrcut & ls==lss[i]
lines(year[sel2], combPE[sel2]/fac, col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y/fac, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
plotit(3, lsbest, "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lss]))
plotit(3, lsbest, "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lss])/fac)
plotit(3, lsbest, "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lss])/1000)
range(combPE[lake==mylake & year > yrcut & ls %in% lss])
range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])
plotit(3, lsbest, "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
### index streams
# 2014-04-09 Jess and Gale agreed that the East Au Gres (38) should be replaced with the Au Sable (36) in Lake Huron
# 2014-04-10 Jess thinks that we should just stick with the East Au Gres (38)
index.streams <- list(
Sup = c(1, 2, 9, 29, 31, 32, 62),
Mic = c(5, 6, 15, 24, 26, 35),
Hur = c(10, 16, 27, 32, 999, 38),
Eri = c(1, 2, 3, 7, 9),
Ont = c(5, 9, 22, 23, 36)
)
index.streams <- lapply(1:5, function(i) i + index.streams[[i]]/1000)
index.streams
index.streams[[3]]
plotit(3, index.streams[[3]], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
lsbest
lsbest[lsbest %in% index.streams[[3]]
]
plotit(3, lsbest[!(lsbest %in% index.streams[[3]])], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
plotit(3, lsbest[lsbest %in% index.streams[[3]]], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
search()
ls(6)
length(mapL)
mapit <- function(mylake, lss) {
sel <- lake==mylake & year=2014 & ls %in% lss
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[sel], lat[sel], col=colz, pch=16)
}
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])])
mapit <- function(mylake, lss) {
sel <- lake==mylake & year==2014 & ls %in% lss
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[sel], lat[sel], col=colz, pch=16)
}
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])])
mapit <- function(mylake, lss) {
sel <- lake==mylake & year==2014 & ls %in% lss
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
points(long[sel], lat[sel], col=colz, pch=16)
}
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])])
mapit <- function(mylake, lss, ...) {
sel <- lake==mylake & year==2014 & ls %in% lss
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
points(long[sel], lat[sel], col=colz, pch=16, cex=2)
text(long[sel], lat[sel], strname[sel], col=colz, pos=2, cex=2, ...)
}
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])])
mapit <- function(mylake, lss, ...) {
sel <- lake==mylake & year==2014 & ls %in% lss
windows(h=6, w=10)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
points(long[sel], lat[sel], col=colz, pch=16, cex=2)
text(long[sel], lat[sel], strname[sel], col=colz, pos=2, cex=1.5, ...)
}
graphics.off()
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])])
mapit(3, lsbest[lsbest %in% index.streams[[3]]], font=2)
?par
mapit <- function(mylake, lss, ...) {
sel <- lake==mylake & year==2014 & ls %in% lss
windows(h=6, w=10)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
points(long[sel], lat[sel], col=colz, pch=16, cex=2)
text(long[sel], lat[sel], strname[sel], col=colz, cex=1.5, ...)
}
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2)
mapit <- function(mylake, lss, ...) {
sel <- lake==mylake & year==2014 & ls %in% lss
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
points(long[sel], lat[sel], col=colz, pch=16, cex=2)
text(long[sel], lat[sel], strname[sel], col=colz, cex=1.5, ...)
}
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2)
mapit <- function(mylake, lss, ...) {
sel <- lake==mylake & year==2014 & ls %in% lss
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
points(long[sel], lat[sel], col=colz, pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colz, ...)
}
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2, font=1, cex=1.2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2, cex=1.5)
mapit <- function(mylake, lss, ...) {
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
for(i in seq(lss)) {
sel <- lake==mylake & year==2014 & ls==lss[i]
points(long[sel], lat[sel], col=colz, pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colz, ...)
}
}
graphics.off()
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2, font=1, cex=1.2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2, cex=1.5)
mapit <- function(mylake, lss, ...) {
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
for(i in seq(lss)) {
sel <- lake==mylake & year==2014 & ls==lss[i]
points(long[sel], lat[sel], col=colz[i], pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colz[i], ...)
}
}
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2, font=1, cex=1.2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2, cex=1.5)
mylake <- 3
lss <- lsbest[!(lsbest %in% index.streams[[3]])]
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
 seq(lss)
lsbest
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
lsbest
plotit <- function(mylake, lss, llog="y", yrcut=2004.5, ...) {
selall <- lake==mylake & year > yrcut
lss2 <- ls[lake==mylake & year==2014]
windows(h=5.5, w=3.3)
par(mar=c(4, 4, 1, 1))
if(llog=="y") {
fac <- 1
ylabb <- "Adults"
} else {
fac <- 1000
ylabb <- "Adults  (thousands)"
}
plot(year[selall], combPE[selall]/fac, type="n", las=1, log=llog, xlab="Year", ylab=ylabb, ...)
for(i in seq(lss2)) {
sel2 <- lake==mylake & year > yrcut & ls==lss2[i]
lines(year[sel2], combPE[sel2]/fac, col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y/fac, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
mapit <- function(mylake, lss, ...) {
lss2 <- ls[lake==mylake & year==2014]
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
for(i in seq(lss2)) {
sel <- lake==mylake & year==2014 & ls==lss2[i]
points(long[sel], lat[sel], col=colz[i], pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colz[i], ...)
}
}
graphics.of()
graphic.off()
graphics.off()
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
graphics.off()
plotit <- function(mylake, lss, llog="y", yrcut=2004.5, ...) {
selall <- lake==mylake & year > yrcut
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5.5, w=3.3)
par(mar=c(4, 4, 1, 1))
if(llog=="y") {
fac <- 1
ylabb <- "Adults"
} else {
fac <- 1000
ylabb <- "Adults  (thousands)"
}
plot(year[selall], combPE[selall]/fac, type="n", las=1, log=llog, xlab="Year", ylab=ylabb, ...)
for(i in seq(lss2)) {
sel2 <- lake==mylake & year > yrcut & ls==lss2[i]
lines(year[sel2], combPE[sel2]/fac, col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y/fac, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
mapit <- function(mylake, lss, ...) {
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
for(i in seq(lss2)) {
sel <- lake==mylake & year==2014 & ls==lss2[i]
points(long[sel], lat[sel], col=colz[i], pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colz[i], ...)
}
}
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
plotit(3, lsbest[!(lsbest %in% index.streams[[3]])], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
plotit(3, lsbest[lsbest %in% index.streams[[3]]], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2, font=1, cex=1.2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2, cex=1.5)
brewer.pal()
?brewer
display.brewer.all()
graphics.off()
colz <- rep(c(brewer.pal(8, "Dark2"), brewer.pal(8, "Set2")), 100)
### map of trapped and untrapped streams
selm <- year==2014 & est.source=="model"
selo <- year==2014 & est.source!="model"
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selm], lat[selm], col=colz[1], cex=2, lwd=2)
legend("right", c("Trapped", "Untrapped"), pt.cex=c(3, 2), pt.lwd=2, col=colz[2:1], pch=1, bty="n")
### index streams
# 2014-04-09 Jess and Gale agreed that the East Au Gres (38) should be replaced with the Au Sable (36) in Lake Huron
# 2014-04-10 Jess thinks that we should just stick with the East Au Gres (38)
index.streams <- list(
Sup = c(1, 2, 9, 29, 31, 32, 62),
Mic = c(5, 6, 15, 24, 26, 35),
Hur = c(10, 16, 27, 32, 999, 38),
Eri = c(1, 2, 3, 7, 9),
Ont = c(5, 9, 22, 23, 36)
)
index.streams <- lapply(1:5, function(i) i + index.streams[[i]]/1000)
### plots of time series
look <- table(ls, year, est.source=="model")
# just last 10 years
look2 <- apply(look[, 29:38, ], c(1, 3), sum)
look3 <- look2[look2[, 1]>0 & look2[, 2]>0, ]
look3[order(look3[, 1] - look3[, 2]), ]
dat[match(rownames(look3), ls), 1:10]
#dat[match(unlist(index.streams), ls), 1:10]
plotit <- function(mylake, lss, llog="y", yrcut=2004.5, ...) {
selall <- lake==mylake & year > yrcut
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5.5, w=3.3)
par(mar=c(4, 4, 1, 1))
if(llog=="y") {
fac <- 1
ylabb <- "Adults"
} else {
fac <- 1000
ylabb <- "Adults  (thousands)"
}
plot(year[selall], combPE[selall]/fac, type="n", las=1, log=llog, xlab="Year", ylab=ylabb, ...)
for(i in seq(lss2)) {
sel2 <- lake==mylake & year > yrcut & ls==lss2[i]
lines(year[sel2], combPE[sel2]/fac, col=colz[i], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y/fac, col=colz[i], type="o", pch=16, cex=1.2, lwd=2)
}
}
mapit <- function(mylake, lss, ...) {
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
for(i in seq(lss2)) {
sel <- lake==mylake & year==2014 & ls==lss2[i]
points(long[sel], lat[sel], col=colz[i], pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colz[i], ...)
}
}
# all non-model time series
lsbest <- rownames(look2[look2[, "TRUE"]==0, ])
# all model time series
lsmodel <- rownames(look2[look2[, "FALSE"]==0, ])
# mixed time series
lsmixed <- rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ])
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
dat[lake==3 & year==2008 & combPE > 6000, ]
dat[lake==3 & year>2004.5 & strname=="Garden", ]
plotit(3, lsbest[!(lsbest %in% index.streams[[3]])], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
plotit(3, lsbest[lsbest %in% index.streams[[3]]], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2, font=1, cex=1.2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2, cex=1.5)
head(dat)
sub <- dat[, c("year", "ls", "combPE")]
sub <- dat[year > yrcut, c("year", "ls", "combPE")]
tapply(sub$combPE, sub$ls, median)
# all non-model time series
lsbest <- as.numeric(rownames(look2[look2[, "TRUE"]==0, ]))
# all model time series
lsmodel <- as.numeric(rownames(look2[look2[, "FALSE"]==0, ]))
# mixed time series
lsmixed <- as.numeric(rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ]))
sub <- dat[year > yrcut, c("year", "ls", "combPE")]
medPE <- tapply(sub$combPE, sub$ls, median)
df1 <- cbind(medPE, ls=as.numeric(names(medPE)))
df2 <- cbind(ls=c(lsbest, lsmodel, lsmixed), group=rep(c("1best", "2model", "3mixed"), c(length(lsbest), length(lsmodel), length(lsmixed))))
merge(df1, df2)
df <- merge(df1, df2)
df$lake <- floor(df$sub)
sub <- dat[year > yrcut, c("year", "ls", "combPE")]
medPE <- tapply(sub$combPE, sub$ls, median)
df1 <- cbind(medPE, ls=as.numeric(names(medPE)))
df2 <- cbind(ls=c(lsbest, lsmodel, lsmixed), group=rep(c("1best", "2model", "3mixed"), c(length(lsbest), length(lsmodel), length(lsmixed))))
df <- merge(df1, df2)
df$lake <- floor(df$ls)
head(df)
df <- df[order(df$lake, df$group, -df$medPE), ]
head(df)
df$lg <- paste(df$lake, df$group)
head(df)
tapply(-df$medPE, df$lg, rank)
?rank
tapply(-df$medPE, df$lg, rank, ties.method="random")
sub <- dat[year > yrcut, c("year", "ls", "combPE")]
medPE <- tapply(sub$combPE, sub$ls, median)
df1 <- cbind(medPE, ls=as.numeric(names(medPE)))
df2 <- cbind(ls=c(lsbest, lsmodel, lsmixed), group=rep(c("1best", "2model", "3mixed"), c(length(lsbest), length(lsmodel), length(lsmixed))))
df <- merge(df1, df2)
df$lake <- floor(df$ls)
df <- df[order(df$lake, df$group, -df$medPE), ]
df$lg <- paste(df$lake, df$group)
df$coli <- unlist(tapply(-df$medPE, df$lg, rank, ties.method="random"))
df$colx <- colz[df$coli]
head(df)
df
summary(df)
51/16
colz <- rep(c(brewer.pal(8, "Dark2"), brewer.pal(8, "Set2")), 4)
plotit <- function(mylake, lss, llog="y", yrcut=2004.5, ...) {
selall <- lake==mylake & year > yrcut
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5.5, w=3.3)
par(mar=c(4, 4, 1, 1))
if(llog=="y") {
fac <- 1
ylabb <- "Adults"
} else {
fac <- 1000
ylabb <- "Adults  (thousands)"
}
plot(year[selall], combPE[selall]/fac, type="n", las=1, log=llog, xlab="Year", ylab=ylabb, ...)
for(i in seq(lss2)) {
sel2 <- lake==mylake & year > yrcut & ls==lss2[i]
lines(year[sel2], combPE[sel2]/fac, col=colkey$colx[colkey$ls==lss2[i]], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y/fac, col=colkey$colx[colkey$ls==lss2[i]], type="o", pch=16, cex=1.2, lwd=2)
}
}
mapit <- function(mylake, lss, ...) {
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
for(i in seq(lss2)) {
sel <- lake==mylake & year==2014 & ls==lss2[i]
points(long[sel], lat[sel], col=colkey$colx[colkey$ls==lss2[i]], pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colkey$colx[colkey$ls==lss2[i]], ...)
}
}
# all non-model time series
lsbest <- as.numeric(rownames(look2[look2[, "TRUE"]==0, ]))
# all model time series
lsmodel <- as.numeric(rownames(look2[look2[, "FALSE"]==0, ]))
# mixed time series
lsmixed <- as.numeric(rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ]))
# create a color key
sub <- dat[year > yrcut, c("year", "ls", "combPE")]
medPE <- tapply(sub$combPE, sub$ls, median)
df1 <- cbind(medPE, ls=as.numeric(names(medPE)))
df2 <- cbind(ls=c(lsbest, lsmodel, lsmixed), group=rep(c("1best", "2model", "3mixed"), c(length(lsbest), length(lsmodel), length(lsmixed))))
colkey <- merge(df1, df2)
colkey$lake <- floor(colkey$ls)
colkey <- colkey[order(colkey$lake, colkey$group, -colkey$medPE), ]
colkey$lg <- paste(colkey$lake, colkey$group)
colkey$coli <- unlist(tapply(-colkey$medPE, colkey$lg, rank, ties.method="random"))
colkey$colx <- colz[colkey$coli]
head(colkey)
graphics.off()
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
dat[lake==3 & year==2008 & combPE > 6000, ]
dat[lake==3 & year>2004.5 & strname=="Garden", ]
plotit(3, lsbest[!(lsbest %in% index.streams[[3]])], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
plotit(3, lsbest[lsbest %in% index.streams[[3]]], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2, font=1, cex=1.2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2, cex=1.5)
# estimate adult index of abundance for each lake using index streams
indices <- lapply(index.streams, index.est, dat, lk)
# combine index data for all lakes in one dataframe
indxall <- do.call(rbind, lapply(indices, "[[", "indxdf"))
# calculate targets 
sptargyrz <- list(1994:1998, 1988:1992, 1989:1993, 1991:1995, 1999:2003)
targyrz <- apply(sapply(sptargyrz, range), 2, paste, collapse="-")
# spawner model
targets.sm <- calctarg(lakenum=lk$lake, adults=lk$PE, year=lk$year, targyears=sptargyrz)
# adult index
targets.ai <- calctarg(lakenum=indxall$lake, adults=indxall$indxkeep, year=indxall$year, targyears=sptargyrz)
# spawner model targets scaled down to adult index
targets.sm.su <- cbind(lake=targets.sm[, 1], (1/sapply(indices, "[[", "scaleup")) * targets.sm[, -1])
# adult index adjusted
targets.ai.adj <- targets.ai
targets.ai.adj[is.na(targets.ai$target), ] <- targets.sm.su[is.na(targets.ai$target), ]
YEAR1 <- 1984
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
col7 <- c("#8dd3c7", "#ffffb3", "#bebada", "#fb8072", "#80b1d3", "#fdb462", "#b3de69")
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 1), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
a <- barplot(t(p)/1000, las=1, col=col7, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Adult abundance  (thousands)", main=Lakenames[mylake], border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
box()
legend("topleft", rev(colnames(p)), fill=rev(col7[1:dim(p)[2]]), cex=0.5, bty="n", border=NA)
}
fig(3)
mylake <- 3
windows()
par(mar=c(4, 4, 1, 1), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
p
colnames(p)
match(dat$ls, colnames(p))
match(colnames(p), dat$strname)
match(colnames(p), susbstring(dat$strname, 1, 10))
match(colnames(p), substring(dat$strname, 1, 10))
dat$ls[match(colnames(p), substring(dat$strname, 1, 10))]
dat$ls[match(colnames(p), substring(dat$strname, 1, 10))]
match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)
match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)
colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 1), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Adult abundance  (thousands)", main=Lakenames[mylake], border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.5, bty="n", border=NA)
}
fig(3)
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 3), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Adult abundance  (thousands)", main=Lakenames[mylake], border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.7, bty="n", border=NA)
}
fig(3)
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 3), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
print(myscaleup)
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Adult abundance  (thousands)", main=Lakenames[mylake], border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.7, bty="n", border=NA)
}
fig(3)
p
apply(p, 1, sum)
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 3), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
print(myscaleup)
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Adult abundance  (thousands)", main=Lakenames[mylake], border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
axis(4, at=pretty(myscaleup*anntotals)/anntotals, labels=pretty(myscaleup*anntotals))
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.7, bty="n", border=NA)
}
fig(3)
pretty(myscaleup*anntotals)
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 3), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
print(myscaleup)
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Adult abundance  (thousands)", main=Lakenames[mylake], border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*anntotals)
axis(4, at=prt/anntotals, labels=prt)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.7, bty="n", border=NA)
}
fig(3)
mylake <- 3
windows()
par(mar=c(4, 4, 1, 3), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
print(myscaleup)
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Adult abundance  (thousands)", main=Lakenames[mylake], border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*anntotals)
prt
axis(4, at=prt/myscaleup, labels=prt)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.7, bty="n", border=NA)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*anntotals)/1000
axis(4, at=prt/myscaleup, labels=prt)
box()
prt <- pretty(myscaleup*c(0, anntotals)/1000
prt <- pretty(myscaleup*c(0, anntotals))/1000
prt
axis(4, at=prt/myscaleup, labels=prt)
par(mar=c(4, 4, 1, 3), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
print(myscaleup)
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Adult abundance  (thousands)", main=Lakenames[mylake], border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.7, bty="n", border=NA)
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
print(myscaleup)
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", main=Lakenames[mylake], border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.7, bty="n", border=NA)
}
fig(3)
?title
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.7, bty="n", border=NA)
}
fig(3)
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.8, bty="n", border=NA)
}
fig(3)
?legend
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA, inset=.3)
}
fig(3)
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA, inset=c(0.3, 0))
}
fig(3)
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA, inset=c(0.4, 0))
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA, inset=c(4, 0))
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA, inset=c(1000, 0))
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA, inset=c(0, 0))
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA, inset=c(2, 2))
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA, inset=2)
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA, inset=.3)
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA, inset=.4)
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA, inset=.1)
outcex <- 1.2
YEARb <- 1995
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA)
}
fig(3)
outcex <- 1.2
YEARb <- 2005
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows()
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("top", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA)
}
fig(3)
outcex <- 1.2
YEARb <- 2005
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows(h=5.5, w=6.6)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.9, bty="n", border=NA)
}
fig(3)
outcex <- 1.2
YEARb <- 2005
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows(h=5.5, w=6.6)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.85, bty="n", border=NA)
}
fig(3)
outcex <- 1.2
YEARb <- 2005
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows(h=5.5, w=6.6)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.8, bty="n", border=NA)
}
fig(3)
outcex <- 1.2
YEARb <- 2005
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows(h=5.5, w=6.3)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.8, bty="n", border=NA)
}
fig(3)
outcex <- 1.2
YEARb <- 2005
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mymap <- mapL[[mylake]]
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
myscaleup <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(myscaleup*c(0, anntotals))/1000
axis(4, at=prt/myscaleup, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.8, bty="n", border=NA)
}
fig(3)
graphics.off()
### spawner model and adult index time series overlaid
fig <- function(mylake) {
par(mar=c(4, 4, 1, 4), cex=1.2, yaxs="i")
mylk <- lk[lk$lake==i, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, y1, y2[x2>=YEAR1], na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
legend("center", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18))
}
fig(3)
### spawner model and adult index time series overlaid
fig <- function(mylake) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, y1[x1>=YEARb], y2[x2>=YEARb], na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
legend("center", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18))
}
fig(3)
### spawner model and adult index time series overlaid
fig <- function(mylake) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, y1[x1>=YEARb], y2[x2>=YEARb], na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
legend("center", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18))
}
fig(3)
### spawner model and adult index time series overlaid
fig <- function(mylake) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, y1[x1>=YEARb], y2[x2>=YEARb], na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
legend("botom", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18))
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
}
fig(3)
### spawner model and adult index time series overlaid
fig <- function(mylake) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, y1[x1>=YEARb], y2[x2>=YEARb], na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
legend("bottom", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18))
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
}
fig(3)
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, y1[x1>=YEARb], y2[x2>=YEARb], na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
names(indices[[mylake]])
head(myindxdf)
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, y2[x2>=YEARb], na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
legend("bottom", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18))
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
head(mylk)
blindcolz[3]
blindcolz[7]
arrows(x2, mylk$lo/1000, x1, mylk$hi/1000, length=1, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, mylk$hi[x2>=YEARb]/1000, na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
arrows(x2, mylk$lo/1000, x1, mylk$hi/1000, length=0.1, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
legend("bottom", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18))
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, mylk$hi[x2>=YEARb]/convfac/1000, na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
arrows(x2, mylk$lo/convfac/1000, x1, mylk$hi/convfac/1000, length=0.1, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
legend("bottom", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18))
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, mylk$hi[x2>=YEARb]/convfac/1000, na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
arrows(x2, mylk$lo/convfac/1000, x1, mylk$hi/convfac/1000, length=0.05, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
legend("bottom", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18))
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
sp <- TRUE
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, mylk$hi[x2>=YEARb]/convfac/1000, na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
if(sp) {
arrows(x2, mylk$lo/convfac/1000, x1, mylk$hi/convfac/1000, length=0.05, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
legend("bottom", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18), bty="n")
}
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
if(sp) lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
sp <- FALSE
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, mylk$hi[x2>=YEARb]/convfac/1000, na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, col=blindcolz[7], col.axis=blindcolz[7], las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), col=blindcolz[3], col.axis=blindcolz[3], las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
if(sp) {
arrows(x2, mylk$lo/convfac/1000, x1, mylk$hi/convfac/1000, length=0.05, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
legend("bottom", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18), bty="n")
}
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
if(sp) lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
### spawner model and adult index time series overlaid
fig <- function(mylake, sp=TRUE) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, mylk$hi[x2>=YEARb]/convfac/1000, na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
if(sp) {
arrows(x2, mylk$lo/convfac/1000, x1, mylk$hi/convfac/1000, length=0.05, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
legend("bottom", c("Adult index", "Spawner model"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18), bty="n")
}
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
if(sp) lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
}
fig(3, FALSE)
fig(3)
cleanup()
q()
# C:\JVA\GLFC\CLC\CLCAdultIndex.r
{ # functions
# the following seven plot.table related functions are from the Systematic Investor Toolbox
# load Systematic Investor Toolbox
# require(RCurl)
# sit = getURLContent("https://github.com/systematicinvestor/SIT/raw/master/sit.gz", binary=TRUE, followlocation=TRUE, ssl.verifypeer=FALSE)
# con = gzcon(rawConnection(sit, "rb"))
# source(con)
# close(con)
draw.cell <- function(title, r, c, text.cex = 1, bg.col = 'white', frame.cell = T) {
if(!frame.cell) bcol = bg.col else bcol = 'black'
rect((2*(c - 1) + .5), -(r - .5), (2*c + .5), -(r + .5), col = bg.col, border = bcol)
if( c == 1) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else if( r == 1 ) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else {
text((2*c + .5), -r, title, adj = 1, cex = text.cex)
}
}
plot.table.helper.auto.adjust.cex <- function(temp.table, keep.all.same.cex = FALSE) {
nr = nrow(temp.table)
nc = ncol(temp.table)
all.xrange = diff(par()$usr[1:2]) / nc
xrange = matrix( strwidth(paste('  ', temp.table), units = 'user', cex = 1), nc = nc)
all.yrange = diff(par()$usr[3:4]) / nr
yrange = matrix( 5/3 * strheight(temp.table, units = 'user', cex = 1), nc = nc)
plot.matrix.cex = pmin( round(all.yrange / yrange, 2) , round(all.xrange / xrange, 2) )
header.col.cex = min(plot.matrix.cex[1,-1])
header.row.cex = min(plot.matrix.cex[-1,1])
title.cex = plot.matrix.cex[1, 1]
data.cex = min(plot.matrix.cex[-1, -1])
if ( keep.all.same.cex ) {
plot.matrix.cex[] = min(plot.matrix.cex)
} else {
plot.matrix.cex[1,-1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,-1]= min(c(header.col.cex, header.row.cex, data.cex))
plot.matrix.cex[1,1]= min(c(header.col.cex, header.row.cex, data.cex, title.cex))
plot.matrix.cex[1,-1] = min(c(header.col.cex))
plot.matrix.cex[-1,1] = min(c(header.row.cex))
plot.matrix.cex[-1,-1]= min(c(data.cex))
plot.matrix.cex[1,1]= min(c(title.cex))
}
return(plot.matrix.cex)
}
make.table <- function(nr, nc) {
savepar = par(mar = rep(1, 4))
plot(c(0.5, nc*2 + 0.5), c(-0.5, -(nr + 0.5)), xaxs = 'i', yaxs = 'i',
type = 'n', xlab = '', ylab = '', axes = FALSE)
savepar
}
trim <- function(s) {
s = sub(pattern = '^ +', replacement = '', x = s)
s = sub(pattern = ' +$', replacement = '', x = s)
return(s)
}
plot.table.param <- function(plot.matrix, smain = '', plot.matrix.cex, plot.matrix_bg.col, frame.cell = T, keep.all.same.cex = FALSE) {
n = nrow(plot.matrix)
pages = unique(c(seq(0, n, by = 120), n))
for(p in 1:(length(pages)-1)) {
rindex = (pages[p]+1) : pages[p+1]
temp.table = matrix('', nr = length(rindex)+1, nc = ncol(plot.matrix)+1)
temp.table[-1, -1] = plot.matrix[rindex,]
temp.table[1, -1] = colnames(plot.matrix)
temp.table[-1, 1] = rownames(plot.matrix)[rindex]
temp.table[1, 1] = smain
nr = nrow(temp.table)
nc = ncol(temp.table)
par(mar = c(0, 0, 0, 0), cex = 0.5)
oldpar = make.table(nr, nc)
text.cex = plot.matrix.cex[c(1, 1 + rindex), ]
text.cex = plot.table.helper.auto.adjust.cex(temp.table, keep.all.same.cex)
bg.col = plot.matrix_bg.col[c(1, 1 + rindex), ]
for(r in 1:nr) {
for(c in 1:nc) {
draw.cell( paste('', temp.table[r,c], '', sep=' '), r, c,
text.cex = text.cex[r,c], bg.col = bg.col[r,c], frame.cell = frame.cell)
}}
}
}
plot.table <- function(plot.matrix, smain="", text.cex=1, frame.cell=TRUE, highlight=FALSE, colorbar=FALSE, keep_all.same.cex=FALSE) {
if( is.null(rownames(plot.matrix)) & is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
if( ncol(temp.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[-1, -1, drop = FALSE]
colnames(plot.matrix) = temp.matrix[1, -1]
rownames(plot.matrix) = temp.matrix[-1, 1]
smain = temp.matrix[1, 1]
} else if( is.null(rownames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( ncol(plot.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[, -1, drop = FALSE]
colnames(plot.matrix) = colnames(temp.matrix)[-1]
rownames(plot.matrix) = temp.matrix[,1]
smain = colnames(temp.matrix)[1]
} else if( is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
plot.matrix = temp.matrix[-1, , drop = FALSE]
rownames(plot.matrix) = rownames(temp.matrix)[-1]
colnames(plot.matrix) = temp.matrix[1, ]
smain = rownames(temp.matrix)[1]
}
plot.matrix[which(trim(plot.matrix) == "NA")] = ""
plot.matrix[which(trim(plot.matrix) == "NA%")] = ""
plot.matrix[which(is.na(plot.matrix))] = ""
nr = nrow(plot.matrix) + 1
nc = ncol(plot.matrix) + 1
is_highlight = TRUE
if(is.logical(highlight)) {
is_highlight = highlight
if(highlight) highlight = plot.table.helper.color(plot.matrix)
}
if(!is_highlight) {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[seq(1, nr, 2), ] = "yellow"
plot.matrix_bg.col[1,] = "gray";
plot.table.param( plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
} else {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[1,] = "gray"
plot.matrix_bg.col[2:nr,2:nc] = highlight
plot.table.param(plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
}
}
plot.table.helper.color <- function (temp) {
temp = matrix(as.double(gsub("[%,$]", "", temp)), nrow(temp), ncol(temp))
highlight = as.vector(temp)
cols = rep(NA, length(highlight))
ncols = length(highlight[!is.na(highlight)])
cols[1:ncols] = rev(rainbow(ncols, start=0.5/6, end=3.5/6))
o = sort.list(highlight, na.last = TRUE, decreasing = FALSE)
o1 = sort.list(o, na.last = TRUE, decreasing = FALSE)
highlight = matrix(cols[o1], nrow = nrow(temp))
highlight[is.na(temp)] = NA
return(highlight)
}
ModelEst <- function(fit, df) {
# derive regression estimates from log(y) fit
mse <- rev(as.matrix(summary(fit)[[1]])[, "Mean Sq"])[1]
plpe <- predict(fit, newdata=df, se.fit=T)
m <- plpe$fit
v <- plpe$se.fit^2 + mse
exp(m + v/2)
}
myrange <- function(x) {
if(all(is.na(x))) r <- c(NA, NA) else r <- range(x, na.rm=TRUE)
return(r)
}
jackindex <- function(m) {
# m is a matrix of numbers (stream PEs) with observations (years) as rows and individuals (streams) as columns
if(any(is.na(m))) stop("The input matrix may not have any missing values.")
# calculate the index as the sum of the columns for each row
rowsum <- apply(m, 1, sum)
# calculate the mean of the index
avgind <- mean(rowsum)
# recalculate the index, leaving out one individual at a time
loo <- apply(m, 2, function(column) (rowsum - column))
# rescale the loo index, relative to mean
looscaled <- apply(loo, 2, function(x) x/mean(x))
# convert to original scale
looscaled2 <- looscaled * avgind
# calculate range
ranges <- t(apply(looscaled2, 1, range))
cbind(index=rowsum, lo=ranges[, 1], hi=ranges[, 2])
}
# selstreams <- index.streams[[1]] 
# allstreamdf <- dat
# alllakedf <- lk 
# min.nmr=2 
# show=FALSE
index.est <- function(selstreams, allstreamdf, alllakedf, min.nmr=2, show=FALSE) {
# INDEX OF ADULT SEA LAMPREY ABUNDANCE
### INPUTS
# selstreams = vector of stream ids, e.g., 1.064 (lake + strcode/1000)
# allstreamdf = data frame of mark-recap estimates for all streams, with vars:  year lake ls Emr CVmr
# alllakedf = data frame of lake-wide PEs from Mullett et al. (2003) spawner model with vars:  lake year PE
# min.nmr = minimum number of mark-recapture estimates needed in a year to generate an index, default 2
# show = print out a brief summary of the results, default FALSE
### OUTPUTS
# indfit = simple model used to predict missing mark-recap estimates
# streamdf = original allstreamdf, subsetted by selstreams, with estimates for missing mark-recaps
# indxdf = original alllakedf, subsetted by lake, with annual index, including raw (indxraw), kept based on min.nmr (indxkeep, indxkeep.lo, indxkeep.hi)
# scaleup = conversion factor used to scale up annual index to spawner model PE
streamdf <- allstreamdf[allstreamdf$ls %in% selstreams, ]
# error checks
check1 <- var(streamdf$lake)
if(is.na(check1) | is.null(check1)) stop("Either no streams selected or critical data missing.") else if(check1 > 0) stop("Selected streams should be only from ONE lake.")
if(any(is.na(match(c("year", "lake", "ls", "Emr", "CVmr"), names(allstreamdf))))) stop("allstreamdf must include these variables: year lake ls Emr CVmr.")
if(any(is.na(match(c("year", "lake", "PE"), names(alllakedf))))) stop("alllakedf must include these variables: lake year PE.")
# fill in missing mark-recap data
indfit <- aov(log(Emr) ~ as.factor(ls) + as.factor(year), data=streamdf, weights=1/CVmr^2)
# figure out estimable years (those with at least 1 m-r estimate)
n.mr <- tapply(!is.na(streamdf$Emr), streamdf$year, sum)
eyrs <- as.numeric(names(n.mr)[n.mr > 0.5])
estimable <- streamdf$year %in% eyrs
streamdf$Pmr <- NA
streamdf$Pmr[estimable] <- ModelEst(fit=indfit, df=streamdf[estimable, ])
streamdf$COMBmr <- ifelse(is.na(streamdf$Emr), streamdf$Pmr, streamdf$Emr)
# annual index (sum across streams)
indxdf <- aggregate(COMBmr ~ year + lake, streamdf, sum, na.rm=TRUE, na.action=na.pass)
names(indxdf)[names(indxdf)=="COMBmr"] <- "indxraw"
indxdf$indxraw[indxdf$indxraw==0] <- NA
# only keep lake-wide index for years with at least min.nmr mark-recap estimates
indxdf$n.mr <- n.mr
indxdf$indxkeep <- ifelse(indxdf$n.mr > (min.nmr - 0.5), indxdf$indxraw, NA)
indxdf$indxkeep.lo <- NA
indxdf$indxkeep.hi <- NA
# matrix of stream estimates (rows = years, columns = index streams)
streamests <- with(streamdf, tapply(COMBmr, list(year, ls), mean))
# selection of only those streams with a keepable index
selkeep <- !is.na(indxdf$indxkeep)
jack <- jackindex(streamests[selkeep, ])
indxdf$indxkeep.lo[selkeep] <- jack[, "lo"]
indxdf$indxkeep.hi[selkeep] <- jack[, "hi"]
# scale up the index to the spawner model PE
lk1 <- lk[lk$lake == streamdf$lake[1], ]
indxdf2 <- merge(lk1, indxdf, all=TRUE)
scaleup <- median(indxdf2$PE / indxdf2$indxkeep, na.rm=TRUE)
if(show) {
cat("\nindfit\n")
print(summary(indfit))
cat("\nstreamdf\n")
print(tail(streamdf[, c("lake", "year", "ls", "Emr", "CVmr", "Pmr", "COMBmr")]))
cat("\nscaleup\n")
print(scaleup)
cat("\nindxdf\n")
print(tail(indxdf[, c("lake", "year", "n.mr", "indxraw", "indxkeep", "indxkeep.lo", "indxkeep.hi")]))
}
list(indfit=indfit, streamdf=streamdf, scaleup=scaleup, indxdf=indxdf)
}
calctarg <- function(lakenum, adults, year, targyears, adjust=c(1, 1, 0.25, 1, 1)) {
# lakenum = vector of lake numbers (1-5)
# adults = vector of lakewide adult sea lamprey estimates
# year = vector of years
# targyears = list (length 5) of selected years from which to calculate targets
# lake huron target is 25% of
targets <- data.frame(lake=1:5, target=rep(NA, 5), lo=rep(NA, 5), hi=rep(NA, 5))
for(i in 1:5) {
pick5 <- adults[lakenum==i & is.element(year, targyears[[i]]) & !is.na(adults)]
if(length(pick5) > 0) {
targets$target[i] <- mean(pick5)
n <- length(pick5)
ci <- qnorm(1 - 0.05/2) * sqrt(var(pick5)) / sqrt(n)
targets[i, c("lo", "hi")] <- mean(pick5) + c(-1, 1)*ci# using z dist (known variance)
targets[i, c("target", "lo", "hi")] <- adjust[i]*targets[i, c("target", "lo", "hi")]
} else {
targets[i, c("target", "lo", "hi")] <- c(NA, NA, NA)
}
}
targets
}
}
# bring in lake-wide spawner data
lk <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/LakePEdynamic.csv", as.is=T)
# bring in stream-specific data
dat <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/StreamPEdynamicALLCOLS.csv", as.is=T)
dat$ls <- dat$lscode
attach(dat)
colz <- rep(c(brewer.pal(8, "Dark2"), brewer.pal(8, "Set2")), 4)
### map of trapped and untrapped streams
selm <- year==2014 & est.source=="model"
selo <- year==2014 & est.source!="model"
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selm], lat[selm], col=colz[1], cex=2, lwd=2)
legend("right", c("Trapped", "Untrapped"), pt.cex=c(3, 2), pt.lwd=2, col=colz[2:1], pch=1, bty="n")
### index streams
# 2014-04-09 Jess and Gale agreed that the East Au Gres (38) should be replaced with the Au Sable (36) in Lake Huron
# 2014-04-10 Jess thinks that we should just stick with the East Au Gres (38)
index.streams <- list(
Sup = c(1, 2, 9, 29, 31, 32, 62),
Mic = c(5, 6, 15, 24, 26, 35),
Hur = c(10, 16, 27, 32, 999, 38),
Eri = c(1, 2, 3, 7, 9),
Ont = c(5, 9, 22, 23, 36)
)
index.streams <- lapply(1:5, function(i) i + index.streams[[i]]/1000)
### plots of time series
look <- table(ls, year, est.source=="model")
# just last 10 years
look2 <- apply(look[, 29:38, ], c(1, 3), sum)
look3 <- look2[look2[, 1]>0 & look2[, 2]>0, ]
look3[order(look3[, 1] - look3[, 2]), ]
dat[match(rownames(look3), ls), 1:10]
#dat[match(unlist(index.streams), ls), 1:10]
plotit <- function(mylake, lss, llog="y", yrcut=2004.5, ...) {
selall <- lake==mylake & year > yrcut
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5.5, w=3.3)
par(mar=c(4, 4, 1, 1))
if(llog=="y") {
fac <- 1
ylabb <- "Adults"
} else {
fac <- 1000
ylabb <- "Adults  (thousands)"
}
plot(year[selall], combPE[selall]/fac, type="n", las=1, log=llog, xlab="Year", ylab=ylabb, ...)
for(i in seq(lss2)) {
sel2 <- lake==mylake & year > yrcut & ls==lss2[i]
lines(year[sel2], combPE[sel2]/fac, col=colkey$colx[colkey$ls==lss2[i]], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y/fac, col=colkey$colx[colkey$ls==lss2[i]], type="o", pch=16, cex=1.2, lwd=2)
}
}
mapit <- function(mylake, lss, ...) {
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
for(i in seq(lss2)) {
sel <- lake==mylake & year==2014 & ls==lss2[i]
points(long[sel], lat[sel], col=colkey$colx[colkey$ls==lss2[i]], pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colkey$colx[colkey$ls==lss2[i]], ...)
}
}
# all non-model time series
lsbest <- as.numeric(rownames(look2[look2[, "TRUE"]==0, ]))
# all model time series
lsmodel <- as.numeric(rownames(look2[look2[, "FALSE"]==0, ]))
# mixed time series
lsmixed <- as.numeric(rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ]))
# create a color key
sub <- dat[year > yrcut, c("year", "ls", "combPE")]
medPE <- tapply(sub$combPE, sub$ls, median)
df1 <- cbind(medPE, ls=as.numeric(names(medPE)))
df2 <- cbind(ls=c(lsbest, lsmodel, lsmixed), group=rep(c("1best", "2model", "3mixed"), c(length(lsbest), length(lsmodel), length(lsmixed))))
colkey <- merge(df1, df2)
colkey$lake <- floor(colkey$ls)
colkey <- colkey[order(colkey$lake, colkey$group, -colkey$medPE), ]
colkey$lg <- paste(colkey$lake, colkey$group)
colkey$coli <- unlist(tapply(-colkey$medPE, colkey$lg, rank, ties.method="random"))
colkey$colx <- colz[colkey$coli]
head(colkey)
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
dat[lake==3 & year==2008 & combPE > 6000, ]
dat[lake==3 & year>2004.5 & strname=="Garden", ]
plotit(3, lsbest[!(lsbest %in% index.streams[[3]])], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
plotit(3, lsbest[lsbest %in% index.streams[[3]]], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2, font=1, cex=1.2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2, cex=1.5)
# estimate adult index of abundance for each lake using index streams
indices <- lapply(index.streams, index.est, dat, lk)
# combine index data for all lakes in one dataframe
indxall <- do.call(rbind, lapply(indices, "[[", "indxdf"))
# calculate targets 
sptargyrz <- list(1994:1998, 1988:1992, 1989:1993, 1991:1995, 1999:2003)
targyrz <- apply(sapply(sptargyrz, range), 2, paste, collapse="-")
# spawner model
targets.sm <- calctarg(lakenum=lk$lake, adults=lk$PE, year=lk$year, targyears=sptargyrz)
# adult index
targets.ai <- calctarg(lakenum=indxall$lake, adults=indxall$indxkeep, year=indxall$year, targyears=sptargyrz)
# spawner model targets scaled down to adult index
targets.sm.su <- cbind(lake=targets.sm[, 1], (1/sapply(indices, "[[", "scaleup")) * targets.sm[, -1])
# adult index adjusted
targets.ai.adj <- targets.ai
targets.ai.adj[is.na(targets.ai$target), ] <- targets.sm.su[is.na(targets.ai$target), ]
YEAR1 <- 1984
outcex <- 1.2
YEARb <- 2005
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
convfac <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(convfac*c(0, anntotals))/1000
axis(4, at=prt/convfac, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.8, bty="n", border=NA)
}
fig(3)
### spawner model and adult index time series overlaid
fig <- function(mylake, sp=TRUE) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, mylk$hi[x2>=YEARb]/convfac/1000, na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
if(sp) {
arrows(x2, mylk$lo/convfac/1000, x1, mylk$hi/convfac/1000, length=0.05, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
legend("bottom", c("Adult index", "Current method"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18), bty="n")
}
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
if(sp) lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
}
fig(3, FALSE)
fig(3)
cleanup()
search()
detach()
graphics.off()
# C:\JVA\GLFC\CLC\CLCAdultIndex.r
{ # functions
# the following seven plot.table related functions are from the Systematic Investor Toolbox
# load Systematic Investor Toolbox
# require(RCurl)
# sit = getURLContent("https://github.com/systematicinvestor/SIT/raw/master/sit.gz", binary=TRUE, followlocation=TRUE, ssl.verifypeer=FALSE)
# con = gzcon(rawConnection(sit, "rb"))
# source(con)
# close(con)
draw.cell <- function(title, r, c, text.cex = 1, bg.col = 'white', frame.cell = T) {
if(!frame.cell) bcol = bg.col else bcol = 'black'
rect((2*(c - 1) + .5), -(r - .5), (2*c + .5), -(r + .5), col = bg.col, border = bcol)
if( c == 1) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else if( r == 1 ) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else {
text((2*c + .5), -r, title, adj = 1, cex = text.cex)
}
}
plot.table.helper.auto.adjust.cex <- function(temp.table, keep.all.same.cex = FALSE) {
nr = nrow(temp.table)
nc = ncol(temp.table)
all.xrange = diff(par()$usr[1:2]) / nc
xrange = matrix( strwidth(paste('  ', temp.table), units = 'user', cex = 1), nc = nc)
all.yrange = diff(par()$usr[3:4]) / nr
yrange = matrix( 5/3 * strheight(temp.table, units = 'user', cex = 1), nc = nc)
plot.matrix.cex = pmin( round(all.yrange / yrange, 2) , round(all.xrange / xrange, 2) )
header.col.cex = min(plot.matrix.cex[1,-1])
header.row.cex = min(plot.matrix.cex[-1,1])
title.cex = plot.matrix.cex[1, 1]
data.cex = min(plot.matrix.cex[-1, -1])
if ( keep.all.same.cex ) {
plot.matrix.cex[] = min(plot.matrix.cex)
} else {
plot.matrix.cex[1,-1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,-1]= min(c(header.col.cex, header.row.cex, data.cex))
plot.matrix.cex[1,1]= min(c(header.col.cex, header.row.cex, data.cex, title.cex))
plot.matrix.cex[1,-1] = min(c(header.col.cex))
plot.matrix.cex[-1,1] = min(c(header.row.cex))
plot.matrix.cex[-1,-1]= min(c(data.cex))
plot.matrix.cex[1,1]= min(c(title.cex))
}
return(plot.matrix.cex)
}
make.table <- function(nr, nc) {
savepar = par(mar = rep(1, 4))
plot(c(0.5, nc*2 + 0.5), c(-0.5, -(nr + 0.5)), xaxs = 'i', yaxs = 'i',
type = 'n', xlab = '', ylab = '', axes = FALSE)
savepar
}
trim <- function(s) {
s = sub(pattern = '^ +', replacement = '', x = s)
s = sub(pattern = ' +$', replacement = '', x = s)
return(s)
}
plot.table.param <- function(plot.matrix, smain = '', plot.matrix.cex, plot.matrix_bg.col, frame.cell = T, keep.all.same.cex = FALSE) {
n = nrow(plot.matrix)
pages = unique(c(seq(0, n, by = 120), n))
for(p in 1:(length(pages)-1)) {
rindex = (pages[p]+1) : pages[p+1]
temp.table = matrix('', nr = length(rindex)+1, nc = ncol(plot.matrix)+1)
temp.table[-1, -1] = plot.matrix[rindex,]
temp.table[1, -1] = colnames(plot.matrix)
temp.table[-1, 1] = rownames(plot.matrix)[rindex]
temp.table[1, 1] = smain
nr = nrow(temp.table)
nc = ncol(temp.table)
par(mar = c(0, 0, 0, 0), cex = 0.5)
oldpar = make.table(nr, nc)
text.cex = plot.matrix.cex[c(1, 1 + rindex), ]
text.cex = plot.table.helper.auto.adjust.cex(temp.table, keep.all.same.cex)
bg.col = plot.matrix_bg.col[c(1, 1 + rindex), ]
for(r in 1:nr) {
for(c in 1:nc) {
draw.cell( paste('', temp.table[r,c], '', sep=' '), r, c,
text.cex = text.cex[r,c], bg.col = bg.col[r,c], frame.cell = frame.cell)
}}
}
}
plot.table <- function(plot.matrix, smain="", text.cex=1, frame.cell=TRUE, highlight=FALSE, colorbar=FALSE, keep_all.same.cex=FALSE) {
if( is.null(rownames(plot.matrix)) & is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
if( ncol(temp.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[-1, -1, drop = FALSE]
colnames(plot.matrix) = temp.matrix[1, -1]
rownames(plot.matrix) = temp.matrix[-1, 1]
smain = temp.matrix[1, 1]
} else if( is.null(rownames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( ncol(plot.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[, -1, drop = FALSE]
colnames(plot.matrix) = colnames(temp.matrix)[-1]
rownames(plot.matrix) = temp.matrix[,1]
smain = colnames(temp.matrix)[1]
} else if( is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
plot.matrix = temp.matrix[-1, , drop = FALSE]
rownames(plot.matrix) = rownames(temp.matrix)[-1]
colnames(plot.matrix) = temp.matrix[1, ]
smain = rownames(temp.matrix)[1]
}
plot.matrix[which(trim(plot.matrix) == "NA")] = ""
plot.matrix[which(trim(plot.matrix) == "NA%")] = ""
plot.matrix[which(is.na(plot.matrix))] = ""
nr = nrow(plot.matrix) + 1
nc = ncol(plot.matrix) + 1
is_highlight = TRUE
if(is.logical(highlight)) {
is_highlight = highlight
if(highlight) highlight = plot.table.helper.color(plot.matrix)
}
if(!is_highlight) {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[seq(1, nr, 2), ] = "yellow"
plot.matrix_bg.col[1,] = "gray";
plot.table.param( plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
} else {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[1,] = "gray"
plot.matrix_bg.col[2:nr,2:nc] = highlight
plot.table.param(plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
}
}
plot.table.helper.color <- function (temp) {
temp = matrix(as.double(gsub("[%,$]", "", temp)), nrow(temp), ncol(temp))
highlight = as.vector(temp)
cols = rep(NA, length(highlight))
ncols = length(highlight[!is.na(highlight)])
cols[1:ncols] = rev(rainbow(ncols, start=0.5/6, end=3.5/6))
o = sort.list(highlight, na.last = TRUE, decreasing = FALSE)
o1 = sort.list(o, na.last = TRUE, decreasing = FALSE)
highlight = matrix(cols[o1], nrow = nrow(temp))
highlight[is.na(temp)] = NA
return(highlight)
}
ModelEst <- function(fit, df) {
# derive regression estimates from log(y) fit
mse <- rev(as.matrix(summary(fit)[[1]])[, "Mean Sq"])[1]
plpe <- predict(fit, newdata=df, se.fit=T)
m <- plpe$fit
v <- plpe$se.fit^2 + mse
exp(m + v/2)
}
myrange <- function(x) {
if(all(is.na(x))) r <- c(NA, NA) else r <- range(x, na.rm=TRUE)
return(r)
}
jackindex <- function(m) {
# m is a matrix of numbers (stream PEs) with observations (years) as rows and individuals (streams) as columns
if(any(is.na(m))) stop("The input matrix may not have any missing values.")
# calculate the index as the sum of the columns for each row
rowsum <- apply(m, 1, sum)
# calculate the mean of the index
avgind <- mean(rowsum)
# recalculate the index, leaving out one individual at a time
loo <- apply(m, 2, function(column) (rowsum - column))
# rescale the loo index, relative to mean
looscaled <- apply(loo, 2, function(x) x/mean(x))
# convert to original scale
looscaled2 <- looscaled * avgind
# calculate range
ranges <- t(apply(looscaled2, 1, range))
cbind(index=rowsum, lo=ranges[, 1], hi=ranges[, 2])
}
# selstreams <- index.streams[[1]] 
# allstreamdf <- dat
# alllakedf <- lk 
# min.nmr=2 
# show=FALSE
index.est <- function(selstreams, allstreamdf, alllakedf, min.nmr=2, show=FALSE) {
# INDEX OF ADULT SEA LAMPREY ABUNDANCE
### INPUTS
# selstreams = vector of stream ids, e.g., 1.064 (lake + strcode/1000)
# allstreamdf = data frame of mark-recap estimates for all streams, with vars:  year lake ls Emr CVmr
# alllakedf = data frame of lake-wide PEs from Mullett et al. (2003) spawner model with vars:  lake year PE
# min.nmr = minimum number of mark-recapture estimates needed in a year to generate an index, default 2
# show = print out a brief summary of the results, default FALSE
### OUTPUTS
# indfit = simple model used to predict missing mark-recap estimates
# streamdf = original allstreamdf, subsetted by selstreams, with estimates for missing mark-recaps
# indxdf = original alllakedf, subsetted by lake, with annual index, including raw (indxraw), kept based on min.nmr (indxkeep, indxkeep.lo, indxkeep.hi)
# scaleup = conversion factor used to scale up annual index to spawner model PE
streamdf <- allstreamdf[allstreamdf$ls %in% selstreams, ]
# error checks
check1 <- var(streamdf$lake)
if(is.na(check1) | is.null(check1)) stop("Either no streams selected or critical data missing.") else if(check1 > 0) stop("Selected streams should be only from ONE lake.")
if(any(is.na(match(c("year", "lake", "ls", "Emr", "CVmr"), names(allstreamdf))))) stop("allstreamdf must include these variables: year lake ls Emr CVmr.")
if(any(is.na(match(c("year", "lake", "PE"), names(alllakedf))))) stop("alllakedf must include these variables: lake year PE.")
# fill in missing mark-recap data
indfit <- aov(log(Emr) ~ as.factor(ls) + as.factor(year), data=streamdf, weights=1/CVmr^2)
# figure out estimable years (those with at least 1 m-r estimate)
n.mr <- tapply(!is.na(streamdf$Emr), streamdf$year, sum)
eyrs <- as.numeric(names(n.mr)[n.mr > 0.5])
estimable <- streamdf$year %in% eyrs
streamdf$Pmr <- NA
streamdf$Pmr[estimable] <- ModelEst(fit=indfit, df=streamdf[estimable, ])
streamdf$COMBmr <- ifelse(is.na(streamdf$Emr), streamdf$Pmr, streamdf$Emr)
# annual index (sum across streams)
indxdf <- aggregate(COMBmr ~ year + lake, streamdf, sum, na.rm=TRUE, na.action=na.pass)
names(indxdf)[names(indxdf)=="COMBmr"] <- "indxraw"
indxdf$indxraw[indxdf$indxraw==0] <- NA
# only keep lake-wide index for years with at least min.nmr mark-recap estimates
indxdf$n.mr <- n.mr
indxdf$indxkeep <- ifelse(indxdf$n.mr > (min.nmr - 0.5), indxdf$indxraw, NA)
indxdf$indxkeep.lo <- NA
indxdf$indxkeep.hi <- NA
# matrix of stream estimates (rows = years, columns = index streams)
streamests <- with(streamdf, tapply(COMBmr, list(year, ls), mean))
# selection of only those streams with a keepable index
selkeep <- !is.na(indxdf$indxkeep)
jack <- jackindex(streamests[selkeep, ])
indxdf$indxkeep.lo[selkeep] <- jack[, "lo"]
indxdf$indxkeep.hi[selkeep] <- jack[, "hi"]
# scale up the index to the spawner model PE
lk1 <- lk[lk$lake == streamdf$lake[1], ]
indxdf2 <- merge(lk1, indxdf, all=TRUE)
scaleup <- median(indxdf2$PE / indxdf2$indxkeep, na.rm=TRUE)
if(show) {
cat("\nindfit\n")
print(summary(indfit))
cat("\nstreamdf\n")
print(tail(streamdf[, c("lake", "year", "ls", "Emr", "CVmr", "Pmr", "COMBmr")]))
cat("\nscaleup\n")
print(scaleup)
cat("\nindxdf\n")
print(tail(indxdf[, c("lake", "year", "n.mr", "indxraw", "indxkeep", "indxkeep.lo", "indxkeep.hi")]))
}
list(indfit=indfit, streamdf=streamdf, scaleup=scaleup, indxdf=indxdf)
}
calctarg <- function(lakenum, adults, year, targyears, adjust=c(1, 1, 0.25, 1, 1)) {
# lakenum = vector of lake numbers (1-5)
# adults = vector of lakewide adult sea lamprey estimates
# year = vector of years
# targyears = list (length 5) of selected years from which to calculate targets
# lake huron target is 25% of
targets <- data.frame(lake=1:5, target=rep(NA, 5), lo=rep(NA, 5), hi=rep(NA, 5))
for(i in 1:5) {
pick5 <- adults[lakenum==i & is.element(year, targyears[[i]]) & !is.na(adults)]
if(length(pick5) > 0) {
targets$target[i] <- mean(pick5)
n <- length(pick5)
ci <- qnorm(1 - 0.05/2) * sqrt(var(pick5)) / sqrt(n)
targets[i, c("lo", "hi")] <- mean(pick5) + c(-1, 1)*ci# using z dist (known variance)
targets[i, c("target", "lo", "hi")] <- adjust[i]*targets[i, c("target", "lo", "hi")]
} else {
targets[i, c("target", "lo", "hi")] <- c(NA, NA, NA)
}
}
targets
}
}
# bring in lake-wide spawner data
lk <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/LakePEdynamic.csv", as.is=T)
# bring in stream-specific data
dat <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/StreamPEdynamicALLCOLS.csv", as.is=T)
dat$ls <- dat$lscode
attach(dat)
colz <- rep(c(brewer.pal(8, "Dark2"), brewer.pal(8, "Set2")), 4)
### map of trapped and untrapped streams
selm <- year==2014 & est.source=="model"
selo <- year==2014 & est.source!="model"
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selm], lat[selm], col=colz[1], cex=2, lwd=2)
legend("right", c("Trapped", "Untrapped"), pt.cex=c(3, 2), pt.lwd=2, col=colz[2:1], pch=1, bty="n")
### index streams
# 2014-04-09 Jess and Gale agreed that the East Au Gres (38) should be replaced with the Au Sable (36) in Lake Huron
# 2014-04-10 Jess thinks that we should just stick with the East Au Gres (38)
index.streams <- list(
Sup = c(1, 2, 9, 29, 31, 32, 62),
Mic = c(5, 6, 15, 24, 26, 35),
Hur = c(10, 16, 27, 32, 999, 38),
Eri = c(1, 2, 3, 7, 9),
Ont = c(5, 9, 22, 23, 36)
)
index.streams <- lapply(1:5, function(i) i + index.streams[[i]]/1000)
### plots of time series
look <- table(ls, year, est.source=="model")
# just last 10 years
look2 <- apply(look[, 29:38, ], c(1, 3), sum)
look3 <- look2[look2[, 1]>0 & look2[, 2]>0, ]
look3[order(look3[, 1] - look3[, 2]), ]
dat[match(rownames(look3), ls), 1:10]
#dat[match(unlist(index.streams), ls), 1:10]
plotit <- function(mylake, lss, llog="y", yrcut=2004.5, ...) {
selall <- lake==mylake & year > yrcut
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5.5, w=3.3)
par(mar=c(4, 4, 1, 1))
if(llog=="y") {
fac <- 1
ylabb <- "Adults"
} else {
fac <- 1000
ylabb <- "Adults  (thousands)"
}
plot(year[selall], combPE[selall]/fac, type="n", las=1, log=llog, xlab="Year", ylab=ylabb, ...)
for(i in seq(lss2)) {
sel2 <- lake==mylake & year > yrcut & ls==lss2[i]
lines(year[sel2], combPE[sel2]/fac, col=colkey$colx[colkey$ls==lss2[i]], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y/fac, col=colkey$colx[colkey$ls==lss2[i]], type="o", pch=16, cex=1.2, lwd=2)
}
}
mapit <- function(mylake, lss, ...) {
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
for(i in seq(lss2)) {
sel <- lake==mylake & year==2014 & ls==lss2[i]
points(long[sel], lat[sel], col=colkey$colx[colkey$ls==lss2[i]], pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colkey$colx[colkey$ls==lss2[i]], ...)
}
}
# all non-model time series
lsbest <- as.numeric(rownames(look2[look2[, "TRUE"]==0, ]))
# all model time series
lsmodel <- as.numeric(rownames(look2[look2[, "FALSE"]==0, ]))
# mixed time series
lsmixed <- as.numeric(rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ]))
# create a color key
yrcut <- 2004.5
sub <- dat[year > yrcut, c("year", "ls", "combPE")]
medPE <- tapply(sub$combPE, sub$ls, median)
df1 <- cbind(medPE, ls=as.numeric(names(medPE)))
df2 <- cbind(ls=c(lsbest, lsmodel, lsmixed), group=rep(c("1best", "2model", "3mixed"), c(length(lsbest), length(lsmodel), length(lsmixed))))
colkey <- merge(df1, df2)
colkey$lake <- floor(colkey$ls)
colkey <- colkey[order(colkey$lake, colkey$group, -colkey$medPE), ]
colkey$lg <- paste(colkey$lake, colkey$group)
colkey$coli <- unlist(tapply(-colkey$medPE, colkey$lg, rank, ties.method="random"))
colkey$colx <- colz[colkey$coli]
head(colkey)
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
dat[lake==3 & year==2008 & combPE > 6000, ]
dat[lake==3 & year>2004.5 & strname=="Garden", ]
plotit(3, lsbest[!(lsbest %in% index.streams[[3]])], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
plotit(3, lsbest[lsbest %in% index.streams[[3]]], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2, font=1, cex=1.2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2, cex=1.5)
# estimate adult index of abundance for each lake using index streams
indices <- lapply(index.streams, index.est, dat, lk)
# combine index data for all lakes in one dataframe
indxall <- do.call(rbind, lapply(indices, "[[", "indxdf"))
# calculate targets 
sptargyrz <- list(1994:1998, 1988:1992, 1989:1993, 1991:1995, 1999:2003)
targyrz <- apply(sapply(sptargyrz, range), 2, paste, collapse="-")
# spawner model
targets.sm <- calctarg(lakenum=lk$lake, adults=lk$PE, year=lk$year, targyears=sptargyrz)
# adult index
targets.ai <- calctarg(lakenum=indxall$lake, adults=indxall$indxkeep, year=indxall$year, targyears=sptargyrz)
# spawner model targets scaled down to adult index
targets.sm.su <- cbind(lake=targets.sm[, 1], (1/sapply(indices, "[[", "scaleup")) * targets.sm[, -1])
# adult index adjusted
targets.ai.adj <- targets.ai
targets.ai.adj[is.na(targets.ai$target), ] <- targets.sm.su[is.na(targets.ai$target), ]
YEAR1 <- 1984
outcex <- 1.2
YEARb <- 2005
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
convfac <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(convfac*c(0, anntotals))/1000
axis(4, at=prt/convfac, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.8, bty="n", border=NA)
}
fig(3)
### spawner model and adult index time series overlaid
fig <- function(mylake, sp=TRUE) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, mylk$hi[x2>=YEARb]/convfac/1000, na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
if(sp) {
arrows(x2, mylk$lo/convfac/1000, x1, mylk$hi/convfac/1000, length=0.05, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
legend("bottom", c("Adult index", "Current method"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18), bty="n")
}
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
if(sp) lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
}
fig(3, FALSE)
fig(3)
graphics.off()
search()
detach()
cleanup()
# C:\JVA\GLFC\CLC\CLCAdultIndex.r
{ # functions
# the following seven plot.table related functions are from the Systematic Investor Toolbox
# load Systematic Investor Toolbox
# require(RCurl)
# sit = getURLContent("https://github.com/systematicinvestor/SIT/raw/master/sit.gz", binary=TRUE, followlocation=TRUE, ssl.verifypeer=FALSE)
# con = gzcon(rawConnection(sit, "rb"))
# source(con)
# close(con)
draw.cell <- function(title, r, c, text.cex = 1, bg.col = 'white', frame.cell = T) {
if(!frame.cell) bcol = bg.col else bcol = 'black'
rect((2*(c - 1) + .5), -(r - .5), (2*c + .5), -(r + .5), col = bg.col, border = bcol)
if( c == 1) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else if( r == 1 ) {
text((2*(c - 1) + .5), -r, title, adj = 0, cex = text.cex)
} else {
text((2*c + .5), -r, title, adj = 1, cex = text.cex)
}
}
plot.table.helper.auto.adjust.cex <- function(temp.table, keep.all.same.cex = FALSE) {
nr = nrow(temp.table)
nc = ncol(temp.table)
all.xrange = diff(par()$usr[1:2]) / nc
xrange = matrix( strwidth(paste('  ', temp.table), units = 'user', cex = 1), nc = nc)
all.yrange = diff(par()$usr[3:4]) / nr
yrange = matrix( 5/3 * strheight(temp.table, units = 'user', cex = 1), nc = nc)
plot.matrix.cex = pmin( round(all.yrange / yrange, 2) , round(all.xrange / xrange, 2) )
header.col.cex = min(plot.matrix.cex[1,-1])
header.row.cex = min(plot.matrix.cex[-1,1])
title.cex = plot.matrix.cex[1, 1]
data.cex = min(plot.matrix.cex[-1, -1])
if ( keep.all.same.cex ) {
plot.matrix.cex[] = min(plot.matrix.cex)
} else {
plot.matrix.cex[1,-1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,1] = min(c(header.col.cex, header.row.cex))
plot.matrix.cex[-1,-1]= min(c(header.col.cex, header.row.cex, data.cex))
plot.matrix.cex[1,1]= min(c(header.col.cex, header.row.cex, data.cex, title.cex))
plot.matrix.cex[1,-1] = min(c(header.col.cex))
plot.matrix.cex[-1,1] = min(c(header.row.cex))
plot.matrix.cex[-1,-1]= min(c(data.cex))
plot.matrix.cex[1,1]= min(c(title.cex))
}
return(plot.matrix.cex)
}
make.table <- function(nr, nc) {
savepar = par(mar = rep(1, 4))
plot(c(0.5, nc*2 + 0.5), c(-0.5, -(nr + 0.5)), xaxs = 'i', yaxs = 'i',
type = 'n', xlab = '', ylab = '', axes = FALSE)
savepar
}
trim <- function(s) {
s = sub(pattern = '^ +', replacement = '', x = s)
s = sub(pattern = ' +$', replacement = '', x = s)
return(s)
}
plot.table.param <- function(plot.matrix, smain = '', plot.matrix.cex, plot.matrix_bg.col, frame.cell = T, keep.all.same.cex = FALSE) {
n = nrow(plot.matrix)
pages = unique(c(seq(0, n, by = 120), n))
for(p in 1:(length(pages)-1)) {
rindex = (pages[p]+1) : pages[p+1]
temp.table = matrix('', nr = length(rindex)+1, nc = ncol(plot.matrix)+1)
temp.table[-1, -1] = plot.matrix[rindex,]
temp.table[1, -1] = colnames(plot.matrix)
temp.table[-1, 1] = rownames(plot.matrix)[rindex]
temp.table[1, 1] = smain
nr = nrow(temp.table)
nc = ncol(temp.table)
par(mar = c(0, 0, 0, 0), cex = 0.5)
oldpar = make.table(nr, nc)
text.cex = plot.matrix.cex[c(1, 1 + rindex), ]
text.cex = plot.table.helper.auto.adjust.cex(temp.table, keep.all.same.cex)
bg.col = plot.matrix_bg.col[c(1, 1 + rindex), ]
for(r in 1:nr) {
for(c in 1:nc) {
draw.cell( paste('', temp.table[r,c], '', sep=' '), r, c,
text.cex = text.cex[r,c], bg.col = bg.col[r,c], frame.cell = frame.cell)
}}
}
}
plot.table <- function(plot.matrix, smain="", text.cex=1, frame.cell=TRUE, highlight=FALSE, colorbar=FALSE, keep_all.same.cex=FALSE) {
if( is.null(rownames(plot.matrix)) & is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
if( ncol(temp.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[-1, -1, drop = FALSE]
colnames(plot.matrix) = temp.matrix[1, -1]
rownames(plot.matrix) = temp.matrix[-1, 1]
smain = temp.matrix[1, 1]
} else if( is.null(rownames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( ncol(plot.matrix) == 1 ) temp.matrix = cbind("", temp.matrix)
plot.matrix = temp.matrix[, -1, drop = FALSE]
colnames(plot.matrix) = colnames(temp.matrix)[-1]
rownames(plot.matrix) = temp.matrix[,1]
smain = colnames(temp.matrix)[1]
} else if( is.null(colnames(plot.matrix)) ) {
temp.matrix = plot.matrix
if( nrow(temp.matrix) == 1 ) temp.matrix = rbind("", temp.matrix)
plot.matrix = temp.matrix[-1, , drop = FALSE]
rownames(plot.matrix) = rownames(temp.matrix)[-1]
colnames(plot.matrix) = temp.matrix[1, ]
smain = rownames(temp.matrix)[1]
}
plot.matrix[which(trim(plot.matrix) == "NA")] = ""
plot.matrix[which(trim(plot.matrix) == "NA%")] = ""
plot.matrix[which(is.na(plot.matrix))] = ""
nr = nrow(plot.matrix) + 1
nc = ncol(plot.matrix) + 1
is_highlight = TRUE
if(is.logical(highlight)) {
is_highlight = highlight
if(highlight) highlight = plot.table.helper.color(plot.matrix)
}
if(!is_highlight) {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[seq(1, nr, 2), ] = "yellow"
plot.matrix_bg.col[1,] = "gray";
plot.table.param( plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
} else {
plot.matrix.cex = matrix(1, nr = nr, nc = nc )
plot.matrix_bg.col = matrix("white", nr = nr, nc = nc )
plot.matrix_bg.col[1,] = "gray"
plot.matrix_bg.col[2:nr,2:nc] = highlight
plot.table.param(plot.matrix, smain, plot.matrix.cex, plot.matrix_bg.col,
frame.cell, keep_all.same.cex)
}
}
plot.table.helper.color <- function (temp) {
temp = matrix(as.double(gsub("[%,$]", "", temp)), nrow(temp), ncol(temp))
highlight = as.vector(temp)
cols = rep(NA, length(highlight))
ncols = length(highlight[!is.na(highlight)])
cols[1:ncols] = rev(rainbow(ncols, start=0.5/6, end=3.5/6))
o = sort.list(highlight, na.last = TRUE, decreasing = FALSE)
o1 = sort.list(o, na.last = TRUE, decreasing = FALSE)
highlight = matrix(cols[o1], nrow = nrow(temp))
highlight[is.na(temp)] = NA
return(highlight)
}
ModelEst <- function(fit, df) {
# derive regression estimates from log(y) fit
mse <- rev(as.matrix(summary(fit)[[1]])[, "Mean Sq"])[1]
plpe <- predict(fit, newdata=df, se.fit=T)
m <- plpe$fit
v <- plpe$se.fit^2 + mse
exp(m + v/2)
}
myrange <- function(x) {
if(all(is.na(x))) r <- c(NA, NA) else r <- range(x, na.rm=TRUE)
return(r)
}
jackindex <- function(m) {
# m is a matrix of numbers (stream PEs) with observations (years) as rows and individuals (streams) as columns
if(any(is.na(m))) stop("The input matrix may not have any missing values.")
# calculate the index as the sum of the columns for each row
rowsum <- apply(m, 1, sum)
# calculate the mean of the index
avgind <- mean(rowsum)
# recalculate the index, leaving out one individual at a time
loo <- apply(m, 2, function(column) (rowsum - column))
# rescale the loo index, relative to mean
looscaled <- apply(loo, 2, function(x) x/mean(x))
# convert to original scale
looscaled2 <- looscaled * avgind
# calculate range
ranges <- t(apply(looscaled2, 1, range))
cbind(index=rowsum, lo=ranges[, 1], hi=ranges[, 2])
}
# selstreams <- index.streams[[1]] 
# allstreamdf <- dat
# alllakedf <- lk 
# min.nmr=2 
# show=FALSE
index.est <- function(selstreams, allstreamdf, alllakedf, min.nmr=2, show=FALSE) {
# INDEX OF ADULT SEA LAMPREY ABUNDANCE
### INPUTS
# selstreams = vector of stream ids, e.g., 1.064 (lake + strcode/1000)
# allstreamdf = data frame of mark-recap estimates for all streams, with vars:  year lake ls Emr CVmr
# alllakedf = data frame of lake-wide PEs from Mullett et al. (2003) spawner model with vars:  lake year PE
# min.nmr = minimum number of mark-recapture estimates needed in a year to generate an index, default 2
# show = print out a brief summary of the results, default FALSE
### OUTPUTS
# indfit = simple model used to predict missing mark-recap estimates
# streamdf = original allstreamdf, subsetted by selstreams, with estimates for missing mark-recaps
# indxdf = original alllakedf, subsetted by lake, with annual index, including raw (indxraw), kept based on min.nmr (indxkeep, indxkeep.lo, indxkeep.hi)
# scaleup = conversion factor used to scale up annual index to spawner model PE
streamdf <- allstreamdf[allstreamdf$ls %in% selstreams, ]
# error checks
check1 <- var(streamdf$lake)
if(is.na(check1) | is.null(check1)) stop("Either no streams selected or critical data missing.") else if(check1 > 0) stop("Selected streams should be only from ONE lake.")
if(any(is.na(match(c("year", "lake", "ls", "Emr", "CVmr"), names(allstreamdf))))) stop("allstreamdf must include these variables: year lake ls Emr CVmr.")
if(any(is.na(match(c("year", "lake", "PE"), names(alllakedf))))) stop("alllakedf must include these variables: lake year PE.")
# fill in missing mark-recap data
indfit <- aov(log(Emr) ~ as.factor(ls) + as.factor(year), data=streamdf, weights=1/CVmr^2)
# figure out estimable years (those with at least 1 m-r estimate)
n.mr <- tapply(!is.na(streamdf$Emr), streamdf$year, sum)
eyrs <- as.numeric(names(n.mr)[n.mr > 0.5])
estimable <- streamdf$year %in% eyrs
streamdf$Pmr <- NA
streamdf$Pmr[estimable] <- ModelEst(fit=indfit, df=streamdf[estimable, ])
streamdf$COMBmr <- ifelse(is.na(streamdf$Emr), streamdf$Pmr, streamdf$Emr)
# annual index (sum across streams)
indxdf <- aggregate(COMBmr ~ year + lake, streamdf, sum, na.rm=TRUE, na.action=na.pass)
names(indxdf)[names(indxdf)=="COMBmr"] <- "indxraw"
indxdf$indxraw[indxdf$indxraw==0] <- NA
# only keep lake-wide index for years with at least min.nmr mark-recap estimates
indxdf$n.mr <- n.mr
indxdf$indxkeep <- ifelse(indxdf$n.mr > (min.nmr - 0.5), indxdf$indxraw, NA)
indxdf$indxkeep.lo <- NA
indxdf$indxkeep.hi <- NA
# matrix of stream estimates (rows = years, columns = index streams)
streamests <- with(streamdf, tapply(COMBmr, list(year, ls), mean))
# selection of only those streams with a keepable index
selkeep <- !is.na(indxdf$indxkeep)
jack <- jackindex(streamests[selkeep, ])
indxdf$indxkeep.lo[selkeep] <- jack[, "lo"]
indxdf$indxkeep.hi[selkeep] <- jack[, "hi"]
# scale up the index to the spawner model PE
lk1 <- lk[lk$lake == streamdf$lake[1], ]
indxdf2 <- merge(lk1, indxdf, all=TRUE)
scaleup <- median(indxdf2$PE / indxdf2$indxkeep, na.rm=TRUE)
if(show) {
cat("\nindfit\n")
print(summary(indfit))
cat("\nstreamdf\n")
print(tail(streamdf[, c("lake", "year", "ls", "Emr", "CVmr", "Pmr", "COMBmr")]))
cat("\nscaleup\n")
print(scaleup)
cat("\nindxdf\n")
print(tail(indxdf[, c("lake", "year", "n.mr", "indxraw", "indxkeep", "indxkeep.lo", "indxkeep.hi")]))
}
list(indfit=indfit, streamdf=streamdf, scaleup=scaleup, indxdf=indxdf)
}
calctarg <- function(lakenum, adults, year, targyears, adjust=c(1, 1, 0.25, 1, 1)) {
# lakenum = vector of lake numbers (1-5)
# adults = vector of lakewide adult sea lamprey estimates
# year = vector of years
# targyears = list (length 5) of selected years from which to calculate targets
# lake huron target is 25% of
targets <- data.frame(lake=1:5, target=rep(NA, 5), lo=rep(NA, 5), hi=rep(NA, 5))
for(i in 1:5) {
pick5 <- adults[lakenum==i & is.element(year, targyears[[i]]) & !is.na(adults)]
if(length(pick5) > 0) {
targets$target[i] <- mean(pick5)
n <- length(pick5)
ci <- qnorm(1 - 0.05/2) * sqrt(var(pick5)) / sqrt(n)
targets[i, c("lo", "hi")] <- mean(pick5) + c(-1, 1)*ci# using z dist (known variance)
targets[i, c("target", "lo", "hi")] <- adjust[i]*targets[i, c("target", "lo", "hi")]
} else {
targets[i, c("target", "lo", "hi")] <- c(NA, NA, NA)
}
}
targets
}
}
# bring in lake-wide spawner data
lk <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/LakePEdynamic.csv", as.is=T)
# bring in stream-specific data
dat <- read.csv("C:/JVA/Lamprey/Adults/SpawnDisModel/2014/StreamPEdynamicALLCOLS.csv", as.is=T)
dat$ls <- dat$lscode
attach(dat)
colz <- rep(c(brewer.pal(8, "Dark2"), brewer.pal(8, "Set2")), 4)
### map of trapped and untrapped streams
selm <- year==2014 & est.source=="model"
selo <- year==2014 & est.source!="model"
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
lines(map5$x, map5$y, col="darkgray", lwd=0.5)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selo], lat[selo], col=colz[2], cex=3, lwd=2)
windows(h=6, w=10)
par(mar=rep(0, 4))
map(xlim=range(map5$x, na.rm=T), ylim=range(map5$y, na.rm=T), col=NA, mar=rep(0, 4))
points(long[selm], lat[selm], col=colz[1], cex=2, lwd=2)
legend("right", c("Trapped", "Untrapped"), pt.cex=c(3, 2), pt.lwd=2, col=colz[2:1], pch=1, bty="n")
### index streams
# 2014-04-09 Jess and Gale agreed that the East Au Gres (38) should be replaced with the Au Sable (36) in Lake Huron
# 2014-04-10 Jess thinks that we should just stick with the East Au Gres (38)
index.streams <- list(
Sup = c(1, 2, 9, 29, 31, 32, 62),
Mic = c(5, 6, 15, 24, 26, 35),
Hur = c(10, 16, 27, 32, 999, 38),
Eri = c(1, 2, 3, 7, 9),
Ont = c(5, 9, 22, 23, 36)
)
index.streams <- lapply(1:5, function(i) i + index.streams[[i]]/1000)
### plots of time series
look <- table(ls, year, est.source=="model")
# just last 10 years
look2 <- apply(look[, 29:38, ], c(1, 3), sum)
look3 <- look2[look2[, 1]>0 & look2[, 2]>0, ]
look3[order(look3[, 1] - look3[, 2]), ]
dat[match(rownames(look3), ls), 1:10]
#dat[match(unlist(index.streams), ls), 1:10]
plotit <- function(mylake, lss, llog="y", yrcut=2004.5, ...) {
selall <- lake==mylake & year > yrcut
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5.5, w=3.3)
par(mar=c(4, 4, 1, 1))
if(llog=="y") {
fac <- 1
ylabb <- "Adults"
} else {
fac <- 1000
ylabb <- "Adults  (thousands)"
}
plot(year[selall], combPE[selall]/fac, type="n", las=1, log=llog, xlab="Year", ylab=ylabb, ...)
for(i in seq(lss2)) {
sel2 <- lake==mylake & year > yrcut & ls==lss2[i]
lines(year[sel2], combPE[sel2]/fac, col=colkey$colx[colkey$ls==lss2[i]], lty=2)
y <- ifelse(est.source[sel2]=="model", NA, combPE[sel2])
lines(year[sel2], y/fac, col=colkey$colx[colkey$ls==lss2[i]], type="o", pch=16, cex=1.2, lwd=2)
}
}
mapit <- function(mylake, lss, ...) {
lss2 <- ls[lake==mylake & year==2014 & ls %in% lss]
windows(h=5, w=8)
par(mar=c(0, 6, 0, 6))
map(xlim=range(mapL[[mylake]]$x, na.rm=T), ylim=range(mapL[[mylake]]$y, na.rm=T), col=NA, mar=c(0, 6, 0, 6))
lines(mapL[[mylake]]$x, mapL[[mylake]]$y, col="darkgray", lwd=0.5)
par(xpd=NA)
for(i in seq(lss2)) {
sel <- lake==mylake & year==2014 & ls==lss2[i]
points(long[sel], lat[sel], col=colkey$colx[colkey$ls==lss2[i]], pch=16, cex=1.5)
text(long[sel], lat[sel], strname[sel], col=colkey$colx[colkey$ls==lss2[i]], ...)
}
}
# all non-model time series
lsbest <- as.numeric(rownames(look2[look2[, "TRUE"]==0, ]))
# all model time series
lsmodel <- as.numeric(rownames(look2[look2[, "FALSE"]==0, ]))
# mixed time series
lsmixed <- as.numeric(rownames(look2[look2[, "TRUE"]!=0 & look2[, "FALSE"]!=0, ]))
# create a color key
yrcut <- 2004.5
sub <- dat[year > yrcut, c("year", "ls", "combPE")]
medPE <- tapply(sub$combPE, sub$ls, median)
df1 <- cbind(medPE, ls=as.numeric(names(medPE)))
df2 <- cbind(ls=c(lsbest, lsmodel, lsmixed), group=rep(c("1best", "2model", "3mixed"), c(length(lsbest), length(lsmodel), length(lsmixed))))
colkey <- merge(df1, df2)
colkey$lake <- floor(colkey$ls)
colkey <- colkey[order(colkey$lake, colkey$group, -colkey$medPE), ]
colkey$lg <- paste(colkey$lake, colkey$group)
colkey$coli <- unlist(tapply(-colkey$medPE, colkey$lg, rank, ties.method="random"))
colkey$colx <- colz[colkey$coli]
head(colkey)
plotit(3, lsbest)
plotit(3, lsmodel)
plotit(3, lsmixed)
plotit(3, lsbest, "")
plotit(3, lsmodel, "")
plotit(3, lsmixed, "")
dat[lake==3 & year==2008 & combPE > 6000, ]
dat[lake==3 & year>2004.5 & strname=="Garden", ]
mylake <- 3
plotit(3, lsbest[!(lsbest %in% index.streams[[3]])], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
plotit(3, lsbest[lsbest %in% index.streams[[3]]], "", ylim=range(combPE[lake==mylake & year > yrcut & ls %in% lsbest])/1000)
mapit(3, lsbest[!(lsbest %in% index.streams[[3]])], pos=2, font=1, cex=1.2)
mapit(3, lsbest[lsbest %in% index.streams[[3]]], pos=4, font=2, cex=1.5)
# estimate adult index of abundance for each lake using index streams
indices <- lapply(index.streams, index.est, dat, lk)
# combine index data for all lakes in one dataframe
indxall <- do.call(rbind, lapply(indices, "[[", "indxdf"))
# calculate targets 
sptargyrz <- list(1994:1998, 1988:1992, 1989:1993, 1991:1995, 1999:2003)
targyrz <- apply(sapply(sptargyrz, range), 2, paste, collapse="-")
# spawner model
targets.sm <- calctarg(lakenum=lk$lake, adults=lk$PE, year=lk$year, targyears=sptargyrz)
# adult index
targets.ai <- calctarg(lakenum=indxall$lake, adults=indxall$indxkeep, year=indxall$year, targyears=sptargyrz)
# spawner model targets scaled down to adult index
targets.sm.su <- cbind(lake=targets.sm[, 1], (1/sapply(indices, "[[", "scaleup")) * targets.sm[, -1])
# adult index adjusted
targets.ai.adj <- targets.ai
targets.ai.adj[is.na(targets.ai$target), ] <- targets.sm.su[is.na(targets.ai$target), ]
YEAR1 <- 1984
outcex <- 1.2
YEARb <- 2005
### bar plot of individual index stream PEs
fig <- function(mylake) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mystreamdf <- indices[[mylake]]$streamdf
myindxdf <- indices[[mylake]]$indxdf
convfac <- indices[[mylake]]$scaleup
mystreamdf <- mystreamdf[mystreamdf$year >= YEARb, ]
myindxdf <- myindxdf[myindxdf$year >= YEARb, ]
p <- with(mystreamdf, tapply(COMBmr, list(year, substring(strname, 1, 10)), mean))
p[is.na(myindxdf$indxkeep), ] <- NA
p <- p[, rev(order(apply(p, 2, median, na.rm=TRUE)))]
yrz <- as.numeric(dimnames(p)[[1]])
pyrz <- pretty(yrz)
mycol <- colkey$colx[match(dat$ls[match(colnames(p), substring(dat$strname, 1, 10))], colkey$ls)]
a <- barplot(t(p)/1000, las=1, col=mycol, axes=FALSE, names.arg=rep("", dim(p)[1]), ylim=1.03*c(0, max(apply(p, 1, sum, na.rm=TRUE)))/1000, 
xlab="Year", ylab="Index Adults  (thousands)", border=NA)
axis(1, at=a[match(pyrz, yrz)], pyrz)
axis(2, las=1)
anntotals <- apply(p, 1, sum)
prt <- pretty(convfac*c(0, anntotals))/1000
axis(4, at=prt/convfac, labels=prt, las=1)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
box()
legend("topleft", rev(colnames(p)), fill=rev(mycol[1:dim(p)[2]]), cex=0.8, bty="n", border=NA)
}
fig(3)
### spawner model and adult index time series overlaid
fig <- function(mylake, sp=TRUE) {
windows(h=5.5, w=5.5)
par(mar=c(4, 4, 1, 4), yaxs="i", cex=1.2)
mylk <- lk[lk$lake==mylake, ]# lake year PE lo hi
myindxdf <- indices[[mylake]]$indxdf# year lake indxraw n.mr indxkeep indxkeep.lo indxkeep.hi
convfac <- indices[[mylake]]$scaleup
x1 <- myindxdf$year
y1 <- myindxdf$indxkeep/1000
x2 <- mylk$year
y2 <- mylk$PE/convfac/1000
yr <- 1.05*range(0, myindxdf$indxkeep.hi[x1>=YEARb]/1000, mylk$hi[x2>=YEARb]/convfac/1000, na.rm=TRUE)
plot(1, 1, type="n", xlim=range(lk$year[lk$year>=YEARb]), ylim=yr, xlab="Year", ylab="Index Adults  (thousands)", axes=FALSE)
axis(1)
axis(2, las=1)
par(mgp=c(3, 2.2, 0))
axis(4, at=pretty(convfac*yr)/convfac, labels=pretty(convfac*yr), las=1, hadj=1)
par(mgp=c(3, 1, 0))
box()
arrows(x1, myindxdf$indxkeep.lo/1000, x1, myindxdf$indxkeep.hi/1000, length=0, angle=90, code=3, lwd=10, lend="square", col="#ffddc1")
if(sp) {
arrows(x2, mylk$lo/convfac/1000, x1, mylk$hi/convfac/1000, length=0.05, angle=90, code=3, lwd=1, lend="square", col=blindcolz[3])
abline(h=targets.sm$target[mylake]/convfac/1000, col=blindcolz[3], lty=2)
legend("bottom", c("Adult index", "Current method"), col=blindcolz[c(7, 3)], lwd=2, pch=c(17, 18), bty="n")
}
abline(h=targets.ai.adj$target[mylake]/1000, col=blindcolz[7], lty=2)
if(sp) lines(x2, y2, col=blindcolz[3], type="o", pch=18, lwd=2)
lines(x1, y1, col=blindcolz[7], type="o", pch=17, lwd=2)
mtext("Lake-wide Adults  (thousands)", side=4, line=3, cex=1.2)
}
fig(3, FALSE)
fig(3)
cleanup()
q()
cm <- 0:20
dB <- 20*log10(cm) - 67.6
plot(dB, cm)
abline(v=-48)
plot(cm, dB)
plot(cm, dB, las=1)
par("usr")
cm <- 0:20
dB <- 20*log10(cm) - 67.6
dB66 <- 20*log10(6.6) - 67.6
cm48 <- 10^((-48 + 67.6)/20)
windows(h=3, w=4)
par(mar=c(4, 4, 1, 1), xaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, col="blue")
lines(c(cm48, cm48, 0), c(pusr[3], -48, -48), lty=2, col="blue")
points(6.6, db66, col="red")
lines(c(6.6, 6.6, 0), c(pusr[3], db66, db66), lty=2, col="red")
> 
points(6.6, dB66, col="red")
lines(c(6.6, 6.6, 0), c(pusr[3], dB66, dB66), lty=2, col="red")
par(mar=c(4, 4, 1, 1), xaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, col="blue")
lines(c(cm48, cm48, 0), c(pusr[4], -48, -48), lty=2, col="blue")
points(6.6, dB66, col="red")
lines(c(6.6, 6.6, 0), c(pusr[4], dB66, dB66), lty=2, col="red")
> pusr
pusr
par(mar=c(4, 4, 1, 1), xaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, col="blue")
lines(c(cm48, cm48, 0), c(pusr[3], -48, -48), lty=2, col="blue")
points(6.6, dB66, col="red")
lines(c(6.6, 6.6, 0), c(pusr[3], dB66, dB66), lty=2, col="red")
par(mar=c(4, 4, 1, 1), xaxs="i", yaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, col="blue")
lines(c(cm48, cm48, 0), c(pusr[3], -48, -48), lty=2, col="blue")
points(6.6, dB66, col="red")
lines(c(6.6, 6.6, 0), c(pusr[3], dB66, dB66), lty=2, col="red")
par(mar=c(4, 4, 1, 1), xaxs="i", yaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, pch=16, col="blue")
text(cm48, -48, paste0("(", round(cm48, 1), "-48)"), col="blue", pos=4)
lines(c(cm48, cm48, 0), c(pusr[3], -48, -48), lty=2, col="blue")
points(6.6, dB66, pch=16, col="red")
text(6.6, dB66, paste0("(6.6, ", round(dB66, 1), ")"), col="red", pos=4)
lines(c(6.6, 6.6, 0), c(pusr[3], dB66, dB66), lty=2, col="red")
par(mar=c(4, 4, 1, 1), xaxs="i", yaxs="i")
pusr <- par("usr")
plot(cm, dB, las=1, type="l", xlab="Total length  (cm)", ylab="Target strength  (dB)")
points(cm48, -48, pch=16, col="blue")
text(cm48, -48, paste0("(", round(cm48, 1), ", -48.0)"), col="blue", pos=4)
lines(c(cm48, cm48, 0), c(pusr[3], -48, -48), lty=2, col="blue")
points(6.6, dB66, pch=16, col="red")
text(6.6, dB66, paste0("(6.6, ", round(dB66, 1), ")"), col="red", pos=4)
lines(c(6.6, 6.6, 0), c(pusr[3], dB66, dB66), lty=2, col="red")
cleanup()
q()
library(devtools)
?find_rtools
find_rtools()
find_rtools(TRUE)
?capwords
q()
# C:\JVA\Admin\Duties\TallyTally.r
# by default, the data will be summarized for the current fiscal year
FY <- as.numeric(rev(strsplit(date(), " ")[[1]])[1])
start <- paste0(FY-1, "-10-01")
end <- paste0(FY, "-09-30")
#start <- paste0(2014, "-07-01")
#end <- paste0(2014, "-09-30")
wb <- loadWorkbook("C:/JVA/Admin/Duties/NewTally.xlsx")
dat <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=3)
dat$Hours <- as.numeric(dat$Hours)
sub <- dat[substring(dat$Date, 1, 10) >= start & substring(dat$Date, 1, 10) <= end, ]
look <- aggregate(Hours ~ Agency + PersonTask, data=sub, sum)
look2 <- look[order(look$Agency, look$Hours, decreasing=TRUE), c(1, 3, 2)]
look2
write.csv(look2, "C:/JVA/Admin/Duties/latest.csv", row.names=FALSE)
cleanup()
q()
df1<-data.frame(area=c(1,2),group1=c(2,3),group2=c(1,5),group3=c(4,0))
df1
df2<-data.frame(person_id=seq(1:15),area=c(rep(1,7),rep(2,8)),group_num=c(1,1,2,3,3,3,3,1,1,1,2,2,2,2,2))
df2
q()
?cheat
# C:\JVA\Consult\Deines\ExploreChla.r
library(lubridate)
library(rtf)
# read in the data
dat <- read.csv("C:/JVA/Consult/Deines/master_harvest_chl_metadata.csv")
?save
FishSpecies <- dat
save(FishSpecies)
save(FishSpecies, FishSpecies.RData)
save(FishSpecies, "FishSpecies.RData")
save(FishSpecies, file="FishSpecies.RData")
?cheat
q()
install.packages("Deducer",,"http://rforge.net/")
library(Deducer)
q()
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("jvamisc")
setwd("C:/JVA/R/Working Directory")
library(jvamisc)
chi
?chi
## From Agresti(2007) p.39
M <- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))
dimnames(M) <- list(gender = c("M", "F"), party = c("Democrat", "Independent", "Republican"))
chi(M)
ls()
cleanup()
ls()
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 100
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
hist(df$sr2, breaks=brks, col="skyblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="orange", lwd=2)
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 100
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2)
hist(df$sr2, breaks=brks, col="skyblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="orange", lwd=2)
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 100
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="skyblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="orange", lwd=2)
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
graphics.off()
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 1000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="skyblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="orange", lwd=2)
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 1000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="brown", lwd=2)
legend("topleft", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
?hist
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 10000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, "Randomization")
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 10000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization," format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
paste("Randomization," format(nsim, big.mark=","), "simulations")
paste("Randomization,", format(nsim, big.mark=","), "simulations")
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 10000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(4, 3, 2, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="Trap catch", ylab="", main="")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="Fish wheel catch", ylab="", main="")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization:", format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 1000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(3, 3, 3, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="", ylab="", main="Trap catch")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="", ylab="", main="Fish wheel catch")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization:", format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 1000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(3, 3, 3, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="", ylab="", main="Trap catch")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="", ylab="", main="Fish wheel catch")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE, font=2, cex=1.2)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization:", format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 1000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(3, 3, 3, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="", ylab="", main="Trap catch")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="", ylab="", main="Fish wheel catch")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE, font=2, cex=1.3)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization:", format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
# C:\JVA\GLFC\People\Miehls\game.r
# Game with 29/294 vs. 0/66 to help get a sense of how different they really are ... Bayesian approach?  
# Assume some percentages and ask what the probability is of seeing this result?
c1 <- 294
r1 <- 29
c2 <- 66
r2 <- 0
m <- matrix(c(c1-r1, r1, c2-r2, r2), nrow=2)
chi(m)
ctot <- c1 + c2
rtot <- r1 + r2
ptot <- rtot/ctot
nsim <- 10000
plotit <- function(df, title) {
windows(h=8, w=6.5)
par(mfrow=c(2, 1), mar=c(3, 3, 3, 1), oma=c(0, 1, 2, 0), las=1, yaxs="i")
hist(df$sr1, breaks=brks, col="skyblue", xlab="", ylab="", main="Trap catch")
abline(v=r1, col="orange", lwd=2)
legend("topleft", "Observed catch", col="orange", lwd=2, bty="n")
hist(df$sr2, breaks=brks, col="lightblue", xlab="", ylab="", main="Fish wheel catch")
abline(v=r2, col="brown", lwd=2)
legend("topright", "Observed catch", col="brown", lwd=2, bty="n")
mtext("Frequency", side=2, outer=TRUE, las=0)
mtext(title, side=3, outer=TRUE, font=2, cex=1.3)
}
# Randomization / Permutation Test
catch <- rep(c("Trap", "Wheel"), c(c1, c2))
rp <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
recap <- sample(rep(0:1, c(c1+c2-r1-r2, r1+r2)))
rp$sr1[i] <- sum(recap[catch=="Trap"])
rp$sr2[i] <- sum(recap[catch=="Wheel"])
}
rp$extreme <- rp$sr1 >= r1 & rp$sr2 <= r2
table(rp$extreme)
brks <- seq(-0.5, max(rp$sr1)+0.5, 1)
plotit(rp, paste("Randomization:", format(nsim, big.mark=","), "simulations"))
if(FALSE) {
# Monte Carlo simulation
mc <- data.frame(sr1=rep(NA, nsim), sr2=rep(NA, nsim))
for(i in 1:nsim) {
mc$sr1[i] <- sum(sample(0:1, size=c1, replace=TRUE, prob=c(1-ptot, ptot)))
mc$sr2[i] <- sum(sample(0:1, size=c2, replace=TRUE, prob=c(1-ptot, ptot)))
}
mc$extreme <- mc$sr1 >= r1 & mc$sr2 <= r2
table(mc$extreme)
brks <- seq(-0.5, max(mc$sr1)+0.5, 1)
plotit(mc, "Monte Carlo Simulation")
}
ctot
ls()
rtot
c1
c2
360-29
22/10000
head(rp)
apply(rp, 2, mean)
cleanup()
q()
?cheat
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
catch <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
temp <- readWorksheet(wb, sheet=getSheets(wb)[3], startRow=1)
warnings()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
catch <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
temp <- readWorksheet(wb, sheet=getSheets(wb)[3], startRow=1)
q()
# install from local folder
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("jvamisc")
setwd("C:/JVA/R/Working Directory")
library(jvamisc)
?capwords
capwords(c("using AIC for model selection"))
capwords(c("using AIC", "for MODEL selection"), strict=FALSE)
attach(cat)
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(capwords(barrier.name[match(sub[j], slbarid)]), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
}
ls()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
cat$week <- marday%/%7 + 1
# ack!  Need zero catches as well !!
table(cat$catch > 0.5)
attach(cat)
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(capwords(barrier.name[match(sub[j], slbarid)]), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
}
cleanup()
search()
detach()
graphics.off()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
cat$week <- marday%/%7 + 1
# ack!  Need zero catches as well !!
table(cat$catch > 0.5)
attach(cat)
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(capwords(barrier.name[match(sub[j], slbarid)]), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
}
cleanup()
search()
q()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
cat$week <- marday%/%7 + 1
# ack!  Need zero catches as well !!
table(cat$catch > 0.5)
cat$week <- cat$marday%/%7 + 1
# ack!  Need zero catches as well !!
table(cat$catch > 0.5)
attach(cat)
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(capwords(barrier.name[match(sub[j], slbarid)]), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
}
capwords(barrier.name[match(sub, slbarid)])
sort(capwords(barrier.name[match(sub, slbarid)]))
length(unique(sort(capwords(barrier.name[match(sub, slbarid)]))))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)]), 1, 10)))
)
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 10)))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 8)))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 6)))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 4)))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 5)))
length(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 6)))
(unique(substring(sort(capwords(barrier.name[match(sub, slbarid)])), 1, 6)))
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
}
wklymyr <- apply(wklycat, 1:2, sum, na.rm=TRUE)
wklymyr
wklymyr <- apply(wklycat, 1:2, sum, na.rm=TRUE)
wklytot <- apply(wklymyr, 2, sum, na.rm=TRUE)
wklymyrp <- sweep(wklymyr, 2, wklytot, "/")
wklymyrp
apply(wklymyrp, 2, sum)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], col="grey", lwd=3)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
cleanup()
q()
ls()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
cat$week <- cat$marday%/%7 + 1
# ack!  Need zero catches as well !!
table(cat$catch > 0.5)
attach(cat)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
tapply(marday, 
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
wklymyr <- apply(wklycat, 1:2, sum, na.rm=TRUE)
wklytot <- apply(wklymyr, 2, sum, na.rm=TRUE)
wklymyrp <- sweep(wklymyr, 2, wklytot, "/")
wklymyrp
wklycat <- tapply(catch, list(week, slbarid, year), sum, na.rm=TRUE)
yrlycat <- apply(wklycat, 2:3, sum, na.rm=TRUE)
wklyp <- sweep(wklycat, 2:3, yrlycat, "/")
# check to see that the proportions sum to 1
apply(wklyp, 2:3, sum, na.rm=TRUE)
wklymyr <- apply(wklycat, 1:2, sum, na.rm=TRUE)
wklytot <- apply(wklymyr, 2, sum, na.rm=TRUE)
wklymyrp <- sweep(wklymyr, 2, wklytot, "/")
wklymyrp
wklymyrp
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in seq(sub)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
dim(wklymyrp)
suw
rows(wklymyrp)
row(wklymyrp)
apply(row(wklymyrp)*wklymyrp, 2, sum)
apply(row(wklymyrp)*wklymyrp, 2, sum)/wklytot
mid <- apply(row(wklymyrp)*wklymyrp, 2, sum)
mid
mid <- apply(row(wklymyrp)*wklymyrp, 2, sum)
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
abline(v=mid[j], lwd=2)
}
suw
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=1:21, lwd=2, col="lightgray")
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col="lightgray")
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col="lightgray")
abline(h=seq(0, 1, 0.2), lwd=2, col="lightgray")
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.2))
abline(h=seq(0, 1, 0.25), lwd=2, col="lightgray")
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.8))
abline(h=seq(0, 1, 0.25), lwd=2, col="lightgray")
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1)
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
box()
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1, xaxs="i", yaxs="i")
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(1, 0, 0, 0), oma=c(2, 2, 1, 1), las=1, xaxs="i", yaxs="i")
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), las=1, xaxs="i", yaxs="i")
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
windows(h=6.5, w=8)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, -4), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, -2), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, line=0.5, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
?par
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i", xpd=FALSE)
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
windows()
par("xpd")
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
par(xpd=FALSE)
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
windows(h=5.5, w=9)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
par(xpd=FALSE)
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
par(xpd=FALSE)
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), at=mid[j], side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), at=mid[j], side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
par(xpd=FALSE)
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), at=mid[j], side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
abline(v=mid[j], lwd=2)
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
par(xpd=FALSE)
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
par(mfrow=n2mfrow(length(sub)), mar=c(2, 1, 0, 0), oma=c(2, 2, 1, 1), xaxs="i", yaxs="i")
for(j in order(mid)) {
#plot(1, 1, xlim=range(week), ylim=c(0, 1), type="n", axes=FALSE, xlab="", ylab="")
plot(1, 1, xlim=range(week) + c(4, 0), ylim=c(0, 0.75), type="n", axes=FALSE, xlab="", ylab="")
mtext(substring(capwords(barrier.name[match(sub[j], slbarid)]), 1, 10), at=mid[j], side=1, line=0.2, cex=0.8)
abline(v=seq(1, 101, 4), lwd=2, col=gray(0.9))
abline(h=seq(0, 1, 0.5), lwd=2, col=gray(0.9))
par(xpd=TRUE)
for(k in seq(suy)) {
lines(suw, wklyp[, j, k], col=k)
}
par(xpd=FALSE)
abline(v=mid[j], lwd=2)
lines(suw, wklymyrp[, j], lwd=2)
}
mtext("Date", side=1, outer=TRUE)
mtext("Proportion of catch", side=2, outer=TRUE)
q()
3pg <- 10
cleanup()
??gaussian
zq
qz
?rnorm
qnorm(0.95, 0, 1)
qnorm(0.975, 0, 1)
qnorm(0.975, 4, 1)
alpha <- 0.05
qnorm(1-alpha/2, 0, 1)
gaus3p <- function(x, y, ...) {
# fit a 3 parameter Gaussian curve
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y), b=sqrt(var(x)), c=x[y==max(y)][1], r=0), ...)
}
gaus3p(marday, catch, data=cat2)
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
cat$week <- cat$marday%/%7 + 1
# Don't need any zero catch data for this approach
cat2 <- cat[cat$catch > 0.5, ]
gaus3p <- function(x, y, ...) {
# fit a 3 parameter Gaussian curve
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y), b=sqrt(var(x)), c=x[y==max(y)][1], r=0), ...)
}
gaus3p(marday, catch, data=cat2)
head(cat2)
head(cat2)
?nls
gaus3p(cat2$marday, cat2$catch)
gaus3p <- function(x, y, ...) {
# fit a 3 parameter Gaussian curve
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1], r=0), ...)
}
gaus3p(cat2$marday, cat2$catch)
list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1])
x <- cat2$marday
y <- cat2$catch
list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1])
attach(cat2)
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
x <- cat2$marday[cat2$slbarid==sub[1]]
y <- cat2$catch[cat2$slbarid==sub[1]]
list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1])
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...)
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]))
fit <- nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]))
coef(fit)
co <- coef(fit)
alpha=0.1
co <- coef(fit)
z <- qnorm(1-alpha/2)
co["b"] + c(-1, 1) * z * co["c"]
co["b"] + z * co["c"]
co["b"] - z * co["c"]
fit <- gaus3p(cat2$marday[cat2$slbarid==sub[1]], cat2$catch[cat2$slbarid==sub[1]])
timez(fit)
gaus3p <- function(x, y, ...) {
# fit a 3 parameter Gaussian curve
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...)
}
timez <- function(fit, alpha=0.1) {
# calculate start and end days for 1-alpha * 100% of distribution
co <- coef(fit)
z <- qnorm(1-alpha/2)
co["b"] + c(-1, 1) * z * co["c"]
}
fit <- gaus3p(cat2$marday[cat2$slbarid==sub[1]], cat2$catch[cat2$slbarid==sub[1]])
timez(fit)
head(cat2)
aggregate(catch ~ slbarid + year, sum)
aggregate(catch, lls(slbarid, year), sum)
?aggregate
aggregate(catch, list(slbarid, year), sum)
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
head(smry)
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
head(smry)
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
head(smry)
cat2[slbarid==128410003 & year==1993, ]
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$start <- NA
smry$end <- NA
for(i in sub) {
for(j in suy) {
sel <- slbarid==sub[i] & year==suy[j]
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
summary(smry)
plot(sort(smry$numdays))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$start <- NA
smry$end <- NA
for(i in sub) {
for(j in suy) {
sel <- slbarid==sub[i] & year==suy[j]
if(sum(sel) > 7) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
for(i in sub) {
for(j in suy) {
sel <- slbarid==sub[i] & year==suy[j]
if(!is.na(sel & sum(sel) > 7) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
for(i in sub) {
for(j in suy) {
sel <- slbarid==sub[i] & year==suy[j]
if(!is.na(sel) & sum(sel) > 7) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
warnings()
for(i in sub) {
for(j in suy) {
sel <- slbarid==sub[i] & year==suy[j]
print(i)
print(j)
if(!is.na(sel) & sum(sel) > 7) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
print(i)
print(j)
if(!is.na(sel) & sum(sel) > 7) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
sel
sum(sel)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
print(i)
print(j)
if(!is.na(sel) & sum(sel) >= 21) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
warnings()
sel
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
print(i)
print(j)
if(sum(sel[!is.na(sel)]) >= 21) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
sel
sum(sel)
cat2[sel, ]
?weighted.mean
?mean
?weighted.var
alpha <- 0.1
z <- qnorm(1-alpha/2)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
print(i)
print(j)
if(sum(sel[!is.na(sel)]) >= 7) {
x <- rep(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- mean(x) + c(-1, 1) * z * sd(x)
}
}}
head(smry)
??truncate
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$start <- NA
smry$end <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
mn <- mean(
print(i)
print(j)
if(sum(sel[!is.na(sel)]) >= 21) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
print(i)
print(j)
if(sum(sel[!is.na(sel)]) >= 21) {
fit <- gaus3p(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}}
sel
cat2[sel, ]
plot(marday[sel], catch[sel])
fit <- gaus3p(marday[sel], catch[sel])
?nls
fit <- gaus3p(marday[sel], catch[sel], maxiter=500)
fit <- gaus3p(marday[sel], catch[sel], nls.control(maxiter=500))
fit <- gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500))
?try
try(log("a"))
print(try(log("a"), TRUE))
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
fit
class(fit)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
print(i)
print(j)
if(sum(sel[!is.na(sel)]) >= 21) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
}}
search()
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$start <- NA
smry$end <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 21) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
}}
summary(smry)
dim(smry)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 7) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
}}
summary(smry)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 4) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
}}
summary(smry)
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 1) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("start", "end")] <- timez(fit)
}
}
}}
summary(smry)
smry2 <- smry[!is.na(smry$start), ]
dim(smry2)
head(smry2)
timez <- function(fit, alpha=0.1) {
# calculate start and end days for 1-alpha * 100% of distribution
co <- coef(fit)
z <- qnorm(1-alpha/2)
c(co["a"], co["b"], co["c"], co["b"] + c(-1, 1) * z * co["c"])
}
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$a
smry$b
smry$c
smry$start <- NA
smry$end <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 4) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("a", "b", "c", "start", "end")] <- timez(fit)
}
}
}}
smry2 <- smry[!is.na(smry$start), ]
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$a <- NA
smry$b <- NA
smry$c <- NA
smry$start <- NA
smry$end <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 4) {
fit <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
if(class(fit)!="try-error") {
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("a", "b", "c", "start", "end")] <- timez(fit)
}
}
}}
smry2 <- smry[!is.na(smry$start), ]
head(smry2)
plotdf(smry2)
graphics.off()
sel <- slbarid==111510001 & year==1993
sel <- slbarid==111510001 & year==1993
plot(marday[sel], catch[sel])
head(smry2)
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus2p <- function(x, y, ...) {
# fit a 2 parameter Gaussian curve, assume that peak is known
a <- max(y, na.rm=TRUE)
nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...)
}
gaus3p(marday[sel], catch[sel])
gaus2p(marday[sel], catch[sel])
fit$a
coef(fit)
gaus2p <- function(x, y, ...) {
# fit a 2 parameter Gaussian curve, assume that peak is known
a <- max(y, na.rm=TRUE)
c("a"=a, coef(nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...))
}
gaus3p <- function(x, y, ...) {
# fit a 3 parameter Gaussian curve
coef(nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(a=max(y, na.rm=TRUE), b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...))
}
gaus2p <- function(x, y, ...) {
# fit a 2 parameter Gaussian curve, assume that peak is known
a <- max(y, na.rm=TRUE)
c("a"=a, coef(nls(y ~ a*exp(-0.5*((x-c)/b)^2), start=list(b=sqrt(var(x, na.rm=TRUE)), c=x[y==max(y, na.rm=TRUE)][1]), ...)))
}
timez <- function(co, alpha=0.1) {
# calculate start and end days for 1-alpha * 100% of distribution
z <- qnorm(1-alpha/2)
c(co["a"], co["b"], co["c"], co["b"] + c(-1, 1) * z * co["c"])
}
coe <- gaus2p(marday[sel], catch[sel])
coe
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
?par
?rnorm
pnorm((newday-mn)/s, mn, s)
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pnorm((newday-mn)/s, mn, s)
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
par(new=TRUE, xaxs="d")
lines(newday, pnorm((newday-mn)/s, mn, s), col="green")
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
par(new=TRUE, xaxs="d")
plot(newday, pnorm((newday-mn)/s, mn, s), type="l", col="green")
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
par(new=TRUE, xaxs="d")
plot(newday, pnorm((newday-mn)/s, mn, s), type="l", col="green")
pusr <- par("usr")
pusr
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
par(xaxs="i")
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pusr <- par("usr")
par(new=TRUE, xaxs="d")
plot(newday, pnorm((newday-mn)/s, mn, s), xlim=pusr[1:2], type="l", col="green")
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
par(xaxs="i")
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pusr <- par("usr")
par(new=TRUE)
plot(newday, pnorm((newday-mn)/s, mn, s), xlim=pusr[1:2], type="l", col="green")
(newday-mn)/s
pnorm((newday-mn)/s, mn, s)
?pnrom
?pnorm
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
par(xaxs="i")
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pusr <- par("usr")
par(new=TRUE)
plot(newday, dnorm((newday-mn)/s, mn, s), xlim=pusr[1:2], type="l", col="green")
dnorm((newday-mn)/s, mn, s)
require(graphics)
dnorm(0) == 1/sqrt(2*pi)
dnorm(1) == exp(-1/2)/sqrt(2*pi)
dnorm(1) == 1/sqrt(2*pi*exp(1))
## Using "log = TRUE" for an extended range :
par(mfrow = c(2,1))
plot(function(x) dnorm(x, log = TRUE), -60, 50,
     main = "log { Normal density }")
curve(log(dnorm(x)), add = TRUE, col = "red", lwd = 2)
mtext("dnorm(x, log=TRUE)", adj = 0)
mtext("log(dnorm(x))", col = "red", adj = 1)
x <- -60:50
dnorm(x)
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
par(xaxs="i")
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pusr <- par("usr")
par(new=TRUE)
plot(newday, dnorm((newday-mn)/s), xlim=pusr[1:2], type="l", col="green")
dnorm((newday-mn)/s)
dnorm(newday, mn, s)
y1 <- dnorm((newday-mn)/s)
y2 <- dnorm(newday, mn, s)
windows()
y1/y2
sel <- slbarid==111510001 & year==1993
sel2 <- smry2$slbarid==111510001 & smry2$year==1993
newday <- min(marday[sel]):max(marday[sel])
newcat <- smry2$a[sel2]*exp(-0.5*((newday-smry2$c[sel2])/smry2$b[sel2])^2)
windows()
par(xaxs="i")
plot(marday[sel], catch[sel])
lines(newday, newcat)
gaus3p(marday[sel], catch[sel])
coe <- gaus2p(marday[sel], catch[sel])
newcat2 <- coe["a"]*exp(-0.5*((newday-coe["c"])/coe["b"])^2)
lines(newday, newcat2, col="red")
x <- rep(marday[sel], catch[sel])
mn <- mean(x)
s <- sd(x)
pusr <- par("usr")
par(new=TRUE)
plot(newday, dnorm(newday, mn, s), xlim=pusr[1:2], type="l", col="green")
suw <- sort(unique(week))
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$dmean <- NA
smry$dsd <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 2) {
x <- rep(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("dmean", "dsd")] <- c(mean(x), sd(x))
}
# if(sum(sel[!is.na(sel)]) >= 4) {
# coe <- try(gaus3p(marday[sel], catch[sel], control=nls.control(maxiter=500)), TRUE)
# if(class(coe)!="try-error") {
# smry[smry$slbarid==sub[i] & smry$year==suy[j], c("a", "b", "c", "start", "end")] <- timez(coe)
# }
# }
}}
smry2 <- smry[!is.na(smry$dmean), ]
dim(smry)
dim(smry2)
head(smry2)
smry2 <- smry[!is.na(smry$dmean), ]
alpha <- 0.01
z <- qnorm(1-alpha/2)
smry2$start <- smry2$dmean - z * smry2$dsd
smry2$end <- smry2$dmean + z * smry2$dsd
plotdf(smry2)
head(smry2)
head(barrier)
dim(barrier)
length(unique(barrier$slbarid))
match(smry2$slbarid, barrier$slbarid)
m <- match(smry2$slbarid, barrier$slbarid)
smry2[is.na(m), ]
smry2$slbarid[is.na(m)]
unique(smry2$slbarid[is.na(m)])
smry[smry$slbarid %in% unique(smry2$slbarid[is.na(m)]), ]
cat[cat$slbarid %in% unique(smry2$slbarid[is.na(m)]), ]
cat[match(unique(smry2$slbarid[is.na(m)]), cat$slbarid), ]
head(barrier)
sort(barrier$barrier.name)
barrier
barrier[c(9, 13), ]
cat[match(unique(smry2$slbarid[is.na(m)]), cat$slbarid), ]
match(unique(cat$slbarid), barrier$slbarid)
temp <- readWorksheet(wb, sheet=getSheets(wb)[3], startRow=1)
temp <- fixnames(temp)
temp$mint <- as.numeric(temp$mintemp..c.)
temp$maxt <- as.numeric(temp$maxtemp..c.)
temp$avgt <- as.numeric(temp$avgtemp..c.)
head(temp)
match(unique(temp$slbarid), barrier$slbarid)
m <- match(unique(temp$slbarid), barrier$slbarid)
m[is.na(m)]
unique(temp$slbarid)[is.na(m)]
unique(temp$slbarid)
temp[is.na(slbarid), ]
summary(temp)
temp[is.na(temp$slbarid), ]
dim(temp)
head(barrier)
barrier
temp[is.na(temp$slbarid), ]
temp$strcode[is.na(temp$slbarid), ]
temp$str.code[is.na(temp$slbarid)]
unique(temp$str.code[is.na(temp$slbarid)])
length(temp$str.code[is.na(temp$slbarid)])
table(temp$str.code)
head(temp)
head(temp)
temp$year <- year(cat$date)
temp$month <- month(cat$date)
temp$day <- day(cat$date)
temp$year <- year(temp$date)
temp$month <- month(temp$date)
temp$day <- day(temp$date)
temp$marday <- as.numeric(as.Date(paste(temp$year, temp$month, temp$day, sep="-")) - as.Date(paste0(temp$year, "-03-01")) + 1)
temp$slbarid[sel] <- 501910046
temp$barrier.name[sel] <- "DEXTER DAM"
temp$mint <- as.numeric(temp$mintemp..c.)
temp$maxt <- as.numeric(temp$maxtemp..c.)
temp$avgt <- as.numeric(temp$avgtemp..c.)
temp$year <- year(temp$date)
temp$month <- month(temp$date)
temp$day <- day(temp$date)
temp$marday <- as.numeric(as.Date(paste(temp$year, temp$month, temp$day, sep="-")) - as.Date(paste0(temp$year, "-03-01")) + 1)
head(temp)
first
?lab
lag
?lag
temp2 <- temp[order(temp$slbarid, temp$marday), ]
f <- first(temp$slbarid)
temp2[1:20, ]
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp$slbarid)
temp2[1:20, ]
lag(temp2$marday)[1:20]
lag(temp2$marday[1:20])
(temp2$marday[1:20])
lag(temp2$marday[1:20], 1)
lag(temp2$marday[1:20], 2)
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp$slbarid)
temp2dago <- c(NA, NA, temp$avgt)[1:length(temp$avgt)]
temp2dago[1:20]
f
cumsum(f)
f <- first(temp$slbarid)
f2 <- first(f)
f
f2
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp$slbarid)
f2 <- first(f)
temp2dago <- c(NA, NA, temp$avgt)[1:length(temp$avgt)]
temp2dago[f2==1] <- NA
temp2[1:500, ]
temp2dago
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp$slbarid)
f2 <- first(f)
temp$temp2dago <- c(NA, NA, temp$avgt)[1:length(temp$avgt)]
temp$temp2dago[f2==1] <- NA
f==1
seq(f)[f==1]
f
table(f)
length(f)
is.na(f)
sum(is.na(f))
cleanup()
q()
# C:\JVA\Lamprey\Adults\Barriers\Operating Times\barriertime.r
library(lubridate)
fixnames <- function(df) {
names(df) <- make.names(casefold(names(df)), unique=TRUE, allow_=FALSE)
df
}
# bring in the data, fix the names
wb <- loadWorkbook("C:/JVA/Lamprey/Adults/Barriers/Operating Times/Operating Time Analysis data JVA.xlsx")
barrier <- readWorksheet(wb, sheet=getSheets(wb)[1], startRow=1)
barrier <- fixnames(barrier)
cat <- readWorksheet(wb, sheet=getSheets(wb)[2], startRow=1)
cat <- fixnames(cat)
temp <- readWorksheet(wb, sheet=getSheets(wb)[3], startRow=1)
temp <- fixnames(temp)
### estimate start and end times for barrier operation based on observed (truncated) distribution of catch days
# two barrier codes have typos in them
cat$slbarid[cat$slbarid==221310048] <- 221610048
cat$slbarid[cat$slbarid==27391001] <- 273910001
cat$year <- year(cat$date)
cat$month <- month(cat$date)
cat$day <- day(cat$date)
cat$marday <- as.numeric(as.Date(paste(cat$year, cat$month, cat$day, sep="-")) - as.Date(paste0(cat$year, "-03-01")) + 1)
# Don't need any zero catch data for this approach
cat2 <- cat[cat$catch > 0.5, ]
attach(cat2)
sub <- sort(unique(slbarid))
suy <- sort(unique(year))
smry <- aggregate(catch, list(slbarid=slbarid, year=year), sum)
names(smry)[names(smry)=="x"] <- "totcatch"
smry$numdays <- aggregate(!is.na(catch), list(slbarid=slbarid, year=year), sum)$x
smry$dmean <- NA
smry$dsd <- NA
for(i in seq(sub)) {
for(j in seq(suy)) {
sel <- slbarid==sub[i] & year==suy[j]
x <- rep(marday[sel], catch[sel])
if(sum(sel[!is.na(sel)]) >= 2) {
x <- rep(marday[sel], catch[sel])
smry[smry$slbarid==sub[i] & smry$year==suy[j], c("dmean", "dsd")] <- c(mean(x), sd(x))
}
}}
smry2 <- smry[!is.na(smry$dmean), ]
alpha <- 0.01
z <- qnorm(1-alpha/2)
smry2$start <- smry2$dmean - z * smry2$dsd
smry2$end <- smry2$dmean + z * smry2$dsd
detach(cat2)
### calculate two-day change in temperature for each marday
# one barrier is missing its code and name
sel <- temp$str.code==19
temp$slbarid[sel] <- 501910046
temp$barrier.name[sel] <- "DEXTER DAM"
temp$mint <- as.numeric(temp$mintemp..c.)
temp$maxt <- as.numeric(temp$maxtemp..c.)
temp$avgt <- as.numeric(temp$avgtemp..c.)
temp$year <- year(temp$date)
temp$month <- month(temp$date)
temp$day <- day(temp$date)
temp$marday <- as.numeric(as.Date(paste(temp$year, temp$month, temp$day, sep="-")) - as.Date(paste0(temp$year, "-03-01")) + 1)
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp$slbarid)
f2 <- first(f)
temp$temp2dago <- c(NA, NA, temp$avgt)[1:length(temp$avgt)]
temp$temp2dago[f2==1] <- NA
seq(f)[f==1]
look <- seq(f)[f==1]
look
look-5
look[-1]-5
paste(look[-1]-5, look[-length(look)]+5, sep=":")
paste(look[-1]-5, look[-length(look)]+5, sep=":", collapse=", ")
temp[c(1506:6, 2837:1516, 3240:2847, 4309:3250, 5663:4319, 6788:5673, 8258:6798, 9116:8268, 9452:9126, 10812:9462, 12173:10822, 12892:12183, 13828:12902, 
15503:13838, 16753:15513, 17732:16763, 18772:17742, 20220:18782, 21363:20230, 22867:21373, 22943:22877, 24506:22953, 24982:24516, 26073:24992, 26641:26083, 
28490:26651, 30028:28500, 31808:30038, 32133:31818, 32738:32143, 34338:32748, 35436:34348, 36875:35446, 38474:36885), ]
28490:26651, 30028:28500, 31808:30038, 32133:31818, 32738:32143, 34338:32748, 35436:34348, 36875:35446, 38474:36885), ]
temp[c(1506:6, 2837:1516, 3240:2847, 4309:3250, 5663:4319, 6788:5673, 8258:6798, 9116:8268, 9452:9126, 10812:9462, 12173:10822, 12892:12183, 13828:12902, 
15503:13838, 16753:15513, 17732:16763, 18772:17742, 20220:18782, 21363:20230, 22867:21373, 22943:22877, 24506:22953, 24982:24516, 26073:24992, 26641:26083, 
28490:26651, 30028:28500, 31808:30038, 32133:31818, 32738:32143, 34338:32748, 35436:34348, 36875:35446, 38474:36885), ]
paste(look-3, look+3, sep=":", collapse=", ")
temp[c(1508:1514, 2839:2845, 3242:3248, 4311:4317, 5665:5671, 6790:6796, 8260:8266, 9118:9124, 9454:9460, 10814:10820, 12175:12181, 12894:12900, 13830:13836, 
15505:15511, 16755:16761, 17734:17740, 18774:18780, 20222:20228, 21365:21371, 22869:22875, 22945:22951, 24508:24514, 24984:24990, 26075:26081, 26643:26649, 
28492:28498, 30030:30036, 31810:31816, 32135:32141, 32740:32746, 34340:34346, 35438:35444, 36877:36883, 38476:38482), ]
temp$tempdelta2 <- temp$avgt - temp$temp2dago
head(barrier)
head(cat2)
barrier2 <- merge(barrier, cat2)
head(barrier2)
barrier2 <- merge(barrier, smry2)
head(barrier2)
barrier2 <- merge(barrier, smry2, all=TRUE)
dim(barrier)
dim(smry2)
dim(barrier2)
summary(barrier2)
barrier2[is.na(barrier2$start), ]
sort(unique(cat$barrier.name))
dim(smry2)
dim(barrier2)
head(barrier2)
head(barrier2)
head(temp)
dput(names(temp))
dput(names(barrier))
head(barrier)
names(barrier) <- c("lake.code", "str.code", "slbarid", "barrier.name", "lat", "long", "miles2mouth", "feet2mouth", "gradient", "elevsiteft", "elevmouthft")
head(barrier)
# merge catch data with barrier data
barrier2 <- merge(barrier, smry2, all=TRUE)
dim(smry2)
dim(barrier2)
# no catch data for ORWELL BROOK or STERLING VALLEY
barrier2[is.na(barrier2$start), ]
head(smry2)
head(barrier2)
# merge temperature and barrier/catch data
barrier2$start <- round(barrier2$start)
barrier2$end <- round(barrier2$end)
head(barrier2)
intersect
intersect(names(barrier2), names(temp))
keep <- c("lake.code", "str.code", "str.code.1", "slbarid", "barrier.name", "samples", "avgt", "year", "marday", "tempdelta2")
incomm <- c("lake.code", "slbarid", "barrier.name", "str.code", "year")
barrier3 <- merge(barrier2, temp[, keep], by.x=c(incomm, "start"), by.y=c(incomm, "marday"))
head(barrier3)
barrier3 <- merge(barrier2, temp[, keep], by.x=c(incomm, "end"), by.y=c(incomm, "marday"), all.x=TRUE)
barrier4 <- merge(barrier3, temp[, keep], by.x=c(incomm, "start"), by.y=c(incomm, "marday"), all.x=TRUE)
head(barrier4)
barrier4[1:20, ]
keep <- c("lake.code", "str.code", "str.code.1", "slbarid", "barrier.name", "samples", "avgt", "year", "month", "day", "marday", "tempdelta2")
incomm <- c("lake.code", "slbarid", "barrier.name", "str.code", "year")
barrier3 <- merge(barrier2, temp[, keep], by.x=c(incomm, "end"), by.y=c(incomm, "marday"), all.x=TRUE)
barrier4 <- merge(barrier3, temp[, keep], by.x=c(incomm, "start"), by.y=c(incomm, "marday"), all.x=TRUE)
head(barrier4)
summary(barrier4)
dim(barrier4)
whatdate <- function(marday, year) {
marday + as.Date(paste0(year, "-03-01")) - 1
}
whatdate(1, 2013)
whatdate(1, 2014)
whatdate(-1, 2014)
whatdate(-1, 2013)
whatdate(-1, 2012)
summary(smry)
summary(smry2)
whatdate(5, 2013)
whatdate(152, 2013)
head(temp)
tapply(temp$marday, list(temp$slbarid, temp$year), range)
tapply(temp$marday, list(temp$slbarid, temp$year), min)
tapply(temp$marday, list(temp$slbarid, temp$year), min, na.rm=TRUE)
tapply(temp$marday, list(temp$slbarid, temp$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep="-"))
tapply(temp$marday, list(temp$slbarid, temp$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
temp$mint <- as.numeric(temp$mintemp..c.)
temp$maxt <- as.numeric(temp$maxtemp..c.)
temp$avgt <- as.numeric(temp$avgtemp..c.)
temp$year <- year(temp$date)
temp$month <- month(temp$date)
temp$day <- day(temp$date)
temp$marday <- as.numeric(as.Date(paste(temp$year, temp$month, temp$day, sep="-")) - as.Date(paste0(temp$year, "-03-01")) + 1)
temp2 <- temp[order(temp$slbarid, temp$year, temp$marday), ]
f <- first(temp2$slbarid)
f2 <- first(f)
temp2$temp2dago <- c(NA, NA, temp2$avgt)[1:length(temp2$avgt)]
temp2$temp2dago[f2==1] <- NA
temp2$tempdelta2 <- temp2$avgt - temp2$temp2dago
tapply(temp2$marday, list(temp2$slbarid, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
head(barrier2)
tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
options("max.print")
options(max.print=1000)
tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
cav
# temperature data available
tav <- tapply(temp2$marday, list(temp2$slbarid, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
dim(tav)
dim(cav)
match(dimnames(tav)[[1]], dimnames(cav)[[1]])
match(dimnames(tav)[[2]], dimnames(cav)[[2]])
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(temp2$slbarid, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(temp2$slbarid, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])]
dim(cav)
dim(tav)
dim(tav2)
tav2
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$slbarid, barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(temp2$slbarid, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])]
dimnames(tav2) <- dimnames(cav)
look <- !is.na(cav) & is.na(tav)
!is.na(cav)
is.na(tav)
look <- !is.na(cav) & is.na(tav2)
look
margtot(look)
addmargins(look)
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
addmargins(dont)
dont/(have+dont)
dim(dont)
addmargins(dont)
dim(addmargins(dont))
addmargins(dont)[38, ] / (addmargins(have)[38, ] + addmargins(dont)[38, ])
sort(addmargins(dont)[38, ] / (addmargins(have)[38, ] + addmargins(dont)[38, ]))
dim(dont)
sort(addmargins(dont)[22, ] / (addmargins(have)[22, ] + addmargins(dont)[22, ]))
sort(addmargins(dont)[, 22] / (addmargins(have)[, 22] + addmargins(dont)[, 22]))
head(temp2)
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(barrier2$barrier.name, barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(temp2$barrier.name, temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])]
dimnames(tav2) <- dimnames(cav)
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
addmargins(dont)
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(substring(barrier2$barrier.name, 1, 10), barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(substring(barrier2$barrier.name, 1, 10), temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])]
dimnames(tav2) <- dimnames(cav)
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
addmargins(dont)
dim(dont)
# catch data
cav <- tapply(paste(barrier2$start, barrier2$end, sep=":"), list(substring(barrier2$barrier.name, 1, 15), barrier2$year), unique)
# temperature data available
tav <- tapply(temp2$marday, list(substring(barrier2$barrier.name, 1, 15), temp2$year), function(x) paste(min(x, na.rm=TRUE), max(x, na.rm=TRUE), sep=":"))
tav2 <- tav[match(dimnames(cav)[[1]], dimnames(tav)[[1]]), match(dimnames(cav)[[2]], dimnames(tav)[[2]])]
dimnames(tav2) <- dimnames(cav)
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
addmargins(dont)
show <- addmargins(dont)
ifelse(show==0, "", "need")
ifelse(show==0, 0, XXX)
ifelse(show==0, 0, 999)
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
show <- addmargins(dont)
show[show==1] <- 99
show
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
show <- addmargins(dont)
show[show==1] <- -99
show
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
show <- addmargins(dont)
show[show==1] <- -909
show
have <- !is.na(cav) & !is.na(tav2)
addmargins(have)
dont <- !is.na(cav) & is.na(tav2)
show <- addmargins(dont)
show[show==1] <- -999
show
summary(barrier4)
keep <- c("lake.code", "str.code", "str.code.1", "slbarid", "barrier.name", "samples", "avgt", "year", "marday", "tempdelta2")
incomm <- c("lake.code", "slbarid", "barrier.name", "str.code", "year")
barrier3 <- merge(barrier2, temp2[, keep], by.x=c(incomm, "end"), by.y=c(incomm, "marday"), all.x=TRUE)
barrier4 <- merge(barrier3, temp2[, keep], by.x=c(incomm, "start"), by.y=c(incomm, "marday"), all.x=TRUE)
barrier5 <- barrier4[!is.na(barrier4$start) & !is.na(barrier4$avgt.x) & !is.na(barrier4$avgt.y), ]
dim(barrier5)
barrier5
table(barrier5$barrier.name, barrier$year)
table(barrier5$barrier.name, barrier5$year)
addmargins(table(barrier5$barrier.name, barrier5$year))
dput(names(barrier5)
)
head(barrier)
barrier5 <- barrier4[!is.na(barrier4$start) & !is.na(barrier4$avgt.x) & !is.na(barrier4$avgt.y), 
c("lake.code", "slbarid", "barrier.name", "str.code", "str.code.1.x", "lat", "long", "gradient", 
"year", "numdays", "dmean", "dsd", "start", "end", "avgt.x", "tempdelta2.x", "avgt.y", "tempdelta2.y")]
head(barrier5)
barrier5
dim(barrier5)
addmargins(table(barrier5$barrier.name, barrier5$year))
?game
?gam
?lm
fit <- gam(start ~ s(lat) + s(long) + s(gradient) + s(avgt.x) + s(tempdelta2.x), weight=numdays, data=barrier5)
graphics.off(0
graphics.off()
plot(fit)
plot(fit)
summary(fit)
fit <- gam(start ~ s(lat, k=3) + s(long, k=3) + s(gradient, k=3) + s(avgt.x, k=3) + s(tempdelta2.x, k=3), weight=numdays, data=barrier5)
summary(fit)
plot(fit)
fit <- gam(start ~ s(lat, k=4) + s(long, k=4) + s(gradient, k=4) + s(avgt.x, k=4) + s(tempdelta2.x, k=4), weight=numdays, data=barrier5)
summary(fit)
plot(fit)
fit <- gam(start ~ s(lat, k=4) + s(long, k=4) + s(log(gradient), k=4) + s(avgt.x, k=4) + s(tempdelta2.x, k=4), weight=numdays, data=barrier5)
summary(barrier5)
plot(sort(barrier5$gradient))
(sort(barrier5$gradient))
fit <- gam(start ~ s(lat, k=4) + s(long, k=4) + s(log(gradient + 0.01), k=4) + s(avgt.x, k=4) + s(tempdelta2.x, k=4), weight=numdays, data=barrier5)
summary(fit)
plot(fit)
summary(barrier5)
hist(barrier5$avgt.x)
plot(sort(barrier5$avgt.x))
?map
rescale
sclae
search()
ls(6)
colr
?colr
library(plotrix)
rescale
colr
windows()
map(xlim=range(long), ylim=range(lat), type="n")
lines(map5)
points(long, lat, cex=rescale(start, c(0.1, 0.3)), col=colr(start, "blue", "yellow"), lwd=2)
attach(barrier5)
windows()
map(xlim=range(long), ylim=range(lat), type="n")
lines(map5)
points(long, lat, cex=rescale(start, c(0.1, 0.3)), col=colr(start, "blue", "yellow"), lwd=2)
rescale(start, c(0.1, 0.3))
points(long, lat, cex=rescale(start, c(1, 3)), col=colr(start, "blue", "yellow"), lwd=2)
map(xlim=range(long), ylim=range(lat), type="n")
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(1, 3)), col=colr(start, "blue", "yellow"), lwd=2)
map(xlim=range(long), ylim=range(lat), type="n")
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "yellow"), lwd=2)
windows(w=9, h=6.5)
map(xlim=range(long), ylim=range(lat), type="n", par=rep(0, 4))
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "yellow"), lwd=2)
map(xlim=range(long), ylim=range(lat), type="n", mar=rep(0, 4))
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "yellow"), lwd=2)
head(map5)
map(xlim=range(map5$x, na.rm=TRUE), ylim=range(map5$y, na.rm=TRUE), type="n", mar=rep(0, 4))
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "yellow"), lwd=2)
map(xlim=range(map5$x, na.rm=TRUE), ylim=range(map5$y, na.rm=TRUE), type="n", mar=rep(0, 4))
lines(map5, col="lightgray")
points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "cyan"), lwd=2)
fit <- gam(start ~ s(lat) + s(long), weight=numdays, data=barrier5)
summary(fit)
windows(w=9, h=6.5)
map(xlim=range(map5$x, na.rm=TRUE), ylim=range(map5$y, na.rm=TRUE), type="n", mar=rep(0, 4))
lines(map5, col="lightgray")
#points(long, lat, cex=rescale(start, c(0.5, 6)), col=colr(start, "blue", "cyan"), lwd=2)
points(long, lat, cex=rescale(fit$fitted, c(0.5, 6)), col=colr(fit$fitted, "blue", "cyan"), lwd=2)
show
show
cleanup()
q()
as.Date(paste(1995:2005, "04-27", sep="-")
)
as.Date(paste(1995:2005, "04-27", sep="-"))
library(lubridate)
day(as.Date(paste(1995:2005, "04-27", sep="-")))
?lubridate
wday(as.Date(paste(1995:2005, "04-27", sep="-")))
wday(as.Date(paste(1995:2005, "04-27", sep="-")), TRUE)
d <- as.Date(paste(1995:2005, "04-27", sep="-"))
cbind(d, wday(d, TRUE))
d
data.frame(d, wday(d, TRUE))
q()
Samsmall <- data.frame(Rain=sample(20))
Samsmall$Water_Balance <- NA
Samsmall$Evaporation<-5
# initialization
Samsmall$Water_Balance[1]=0
# loop for calculating water balance for a given dataset
ndays <- nrow(Samsmall)
for (iday in 2:ndays) {
  Samsmall$Water_Balance[iday] <- Samsmall$Water_Balance[iday-1] +
Samsmall$Rain[iday] - Samsmall$Evaporation[iday]
  if (Samsmall$Water_Balance[iday]<0){
    Samsmall$Water_Balance[iday]=0
  }else if(Samsmall$Water_Balance[iday]>100){
    Samsmall$Water_Balance[iday]=100
  }
}
Samsmall
cumsum(Samsmall$Rain) - 5
cumsum(Samsmall$Rain - Samsmall$Evaporation)
# example data
Samsmall <- data.frame(Rain=sample(20), Year=1930, Day=sample(20), Month=rep(1:2, 10))
Samsmall$Evaporation <- 5
# you can vectorize your for loop as follows
Samsmall$Water_Balance <- cumsum(Samsmall$Rain - Samsmall$Evaporation)
Samsmall$Water_Balance[Samsmall$Water_Balance < 0] <- 0
Samsmall$Water_Balance[Samsmall$Water_Balance > 100] <- 100
Samsmall
# example data
Samsmall <- data.frame(Year=1930, Month=rep(1:2, 10), Day=sample(20), Rain=sample(20))
Samsmall$Evaporation <- 5
# you can vectorize your for loop as follows
Samsmall$Water_Balance <- cumsum(Samsmall$Rain - Samsmall$Evaporation)
Samsmall$Water_Balance[Samsmall$Water_Balance < 0] <- 0
Samsmall$Water_Balance[Samsmall$Water_Balance > 100] <- 100
## Table of water balance for a specific year.
require(reshape2)
samsmall30<-subset(Samsmall,Year==1930)
attach(samsmall30)
#produce table with data
sam30<-dcast(samsmall30,Day~Month,value.var="Water_Balance")
#add column names as months
colnames(sam30)[2:13]<-month.abb[1:12]
sam30
?dcast
month.abbr
monthabbr
??month
month.abb
factor(Samsmall$Month, month.abb)
Samsmall
?factor
factor(Samsmall$Month, 1:12, month.abb)
tapply(Samsmall$Water_Balance, list(Samsmall$Day, Samsmall$Mon, Samsmall$Year))
tapply(Samsmall$Water_Balance, list(Samsmall$Day, Samsmall$Mon, Samsmall$Year), mean)
Samsmall$Mon <- factor(Samsmall$Month, 1:12, month.abb)
Samsmall
tapply(Samsmall$Water_Balance, list(Samsmall$Day, Samsmall$Mon, Samsmall$Year), mean)
# Fake data
Samsmall <- data.frame(Year=sample(1930:1033, 20, TRUE), Month=rep(1:2, 10), Day=sample(20), Rain=sample(20))
Samsmall$Evaporation <- 5
Samsmall$Water_Balance <- cumsum(Samsmall$Rain - Samsmall$Evaporation)
Samsmall$Water_Balance[Samsmall$Water_Balance < 0] <- 0
Samsmall$Water_Balance[Samsmall$Water_Balance > 100] <- 100
Samsmall$Mon <- factor(Samsmall$Month, 1:12, month.abb)
tapply(Samsmall$Water_Balance, list(Samsmall$Day, Samsmall$Mon, Samsmall$Year), mean)
# Fake data
Samsmall <- data.frame(Year=sample(1930:1933, 20, TRUE), Month=rep(1:2, 10), Day=sample(20), Rain=sample(20))
Samsmall$Evaporation <- 5
Samsmall$Water_Balance <- cumsum(Samsmall$Rain - Samsmall$Evaporation)
Samsmall$Water_Balance[Samsmall$Water_Balance < 0] <- 0
Samsmall$Water_Balance[Samsmall$Water_Balance > 100] <- 100
Samsmall$Mon <- factor(Samsmall$Month, 1:12, month.abb)
tapply(Samsmall$Water_Balance, list(Samsmall$Day, Samsmall$Mon, Samsmall$Year), mean)
library(dplyr)
i.data2 <- data.frame(sample(1:6, size=484, replace=T)) # simulate data to create a data frame
colnames(i.data2) <- "years.before.initiated" # add a column name
m.data2 <- mutate(i.data2,  years.before.initiated.cat =
                    cut(years.before.initiated, breaks=c(0,1,2,3,4,5,6),include.lowest=TRUE))
                        # create a new variable
g.data2 <- group_by(m.data2, years.before.initiated.cat) # group by years.before.initiated.cat
s.data2 <- summarise(g.data2, anl.count =n() ) # summarize to get the count
rb.data <- rbind(s.data2, c("Total", colSums(s.data2[,2, drop=FALSE]))) # row bind with the column total
rb.data
s.data2
class(s.data2)
dim(s.data2)
addmargins(s.data2)
addmargins
?addmargins
addmargins(s.data2)
addmargins(s.data2, 1)
addmargins(s.data2, 2)
c("Total", colSums(s.data2[,2, drop=FALSE]))
colSums(s.data2[,2, drop=FALSE])
margtot
cleanup()
q()
# C:\JVA\Consult\Stapanian\Amphib\Model selection with AIC.r
# which environmental variables best predict this index of amphibian biotic integrity
# relevant emails:
# 15 May 2013 - https://mail.google.com/mail/u/0/?shva=1#search/amphibian/13ea801401e50a84
#  8 Aug 2013 - https://mail.google.com/mail/u/1/?shva=1#inbox/1405defbc5969b40
# 27 Aug 2013 - https://mail.google.com/mail/u/1/?shva=1#inbox/140c042c5ba851fc
wb <- loadWorkbook("C:/JVA/Consult/Stapanian/Amphib/amphibians_Jean Apr18.xlsx")
dat <- readWorksheet(wb, sheet="Jean")
names(dat) <- make.names(casefold(names(dat)), unique=T, allow_=F)
dimnames(dat)[[1]] <- dat$site.code
rm(wb)
# Analysis 1 should include the following (17) as potential predictors: 
varz1 <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", "water", "forest", "wtld.forest", "wtld.emerg", 
"pasture", "row.crop", "suburban", "transitional", "rock", "urban")
varz1 <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", "water", "forest", "wtld.forest", "wtld.emerg", 
"pasture", "row.crop", "suburban", "transitional", "rock", "urban")
### data exploration ###
attach(dat)
# several variables need to be log transformed
logk <- function(x) {
mx <- min(x, na.rm=TRUE)
if(mx<0) {
x <- x + abs(mx)
mx <- 0
}
k <- min(x[x>0], na.rm=TRUE)/2
print(k)
log(x + min(x[x>0], na.rm=TRUE)/2)
}
tranvar <- logk(as.vector(dat[, c("water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")]))
names(tranvar) <- paste0("log", names(tranvar))
head(tranvar)
dat2 <- cbind(dat, tranvar)
rm(logk, tranvar)
detach(dat)
# Analysis 1 should include the following (17) as potential predictors: 
varz1 <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", "logwater", "logforest", "logwtld.forest", "logwtld.emerg", 
"logpasture", "logrow.crop", "logsuburban", "logtransitional", "logrock", "logurban")
v1namz <- c("ORAM~metric~1", "ORAM~metric~2", "ORAM~metric~3", "ORAM~metric~4", "ORAM~metric~5", "ORAM~metric~6", "OVIBI", 
"LDI[water]", "LDI[forest]", "LDI[wetland~forest]", "LDI[wetland~emergent]", "LDI[pasture]", "LDI[crop]", "LDI[suburban]", "LDI[transitional]", 
"LDI[rock]", "LDI[urban]")
# AbbreviationDescription                                                                             
# LDIwaterProp. standing water                                                              
# LDIforestProp. upland (non-hydric soils) forest                                   
# LDIwetland forestProp. wetland (hydric soils) forest                                         
# LDIwetland emergentProp. wetland dominated by emergent vegetation                
# LDIpastureProp. pasture
# LDIcropProp. agricultural row-crop land
# LDIsuburbanProp. suburban residential
# LDIrockProp. exposed rock substrate
# LDItransitionalProp. land being transitioned to an undefined use
# LDIurbanProp. urban area         
# ORAM metric 1Area (6)                                                                                                            
# ORAM metric 2Upland buffers and surrounding land use (14)
# ORAM metric 3Hydrology (30)          
# ORAM metric 4Habitat Alteration and Development (20)
# ORAM metric 5Special wetlands (10)
# ORAM metric 6Plant communities, interspersion, and microtopography (20)            
# OVIBI10 metrics describing wetland vegetation quality (100)
# get rid of four variables with few unique values
# metric5 (with 3 unique values), logtransitional (with 4), and metric1 and logrock (each with 6).
rid <- c(5, 15, 1, 16)
varz1 <- varz1[-rid]
v1namz <- v1namz[-rid]
attach(dat2)
ct <- t(
sapply(varz1, function(x) {
ct <- cor.test(dat2[, x], amphibi)
ctp <- ct$p.value
ctr <- as.vector(ct$estimate)
c(p=ctp, r=ctr)
})
)
title <- ifelse(ct[, "p"] < 0.05/length(varz1), paste0("bold('*'~", v1namz, ")"), v1namz)
windows(h=8, w=5.5)
#par(mfcol=c(6, 3), mar=c(2.5, 2, 1.5, 1), oma=c(0, 2.5, 0, 0), las=1, cex=0.7)
par(mfcol=c(5, 3), mar=c(2.5, 2, 1.5, 1), oma=c(0, 2.5, 0, 0), las=1, cex=0.7)
for(i in rev(order(ct[, "r"]))) plot(dat2[, varz1[i]], amphibi, xlab="", ylab="", main=as.expression(parse(text=title[i])))
mtext("AmphIBI", side=2, outer=TRUE, las=0, line=1)
suv <- sort(unique(veg.class))
windows(h=6.5, w=6.5)
map("state", mar=c(1, 1, 1, 1), region= "ohio", col="darkgray", lwd=2)
for(i in seq(suv)) {
sel <- veg.class==suv[i]
points(lon.dd[sel], lat.dd[sel], cex=2, lwd=2, pch=c(2, 1)[i], col=c("black", "gray")[i])
}
legend("bottomright", capwords(suv), pch=c(2, 1), col=c("black", "gray"), pt.lwd=2, pt.cex=2, cex=1.15, title="Veg. Class")
par(usr=c(-126, 94, 21, 193), xpd=NA)
polygon(c(-128, -128, -64, -64, -128), c(22, 52, 52, 22, 22), col="white", lwd=2)
map("state", add=T, mar=c(0, 0, 0, 0)) 
map("state", region="ohio", fill=T, add=T) 
detach(dat2)
rm(suv, i, sel, title)
round(ct[rev(order(ct[, "r"])), ], 4)
0.05/length(varz1)
# C:\JVA\Consult\Stapanian\AmphibSens\Explore v3.r
# relevant emails:
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/1439c3834064343b
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/143baffe32131385
# 13 Mar 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/144bb971f5eca226
# objectives
# Find the best predictive model of the following responses
# using as independent variables the 6 ORAM metrics, OVIBI score, and the 10 LDI metrics.
# 1. number of salamander species (x.ssp) 
# 2. % sensitive species (x.sen)
# 3. % tolerant species (x.ol)
# 4. Amphibian Quality Assessment Index (aqai)
# 5. presence/absence of [wood frogs or spotted salamanders] (spot.wdscore, binary)
plotimp <- function(rpartfit, ordered=TRUE, plot=TRUE, horiz=TRUE, col=colz[ord], xlab="", las=1, ...) {
# calculate importance of variables
# http://cran.at.r-project.org/web/packages/rpart/vignettes/longintro.pdf
# importance = An overall measure of variable importance is the sum of the goodness of split
# measures for each split for which it was the primary variable, plus goodness * (adjusted
# agreement) for all splits in which it was a surrogate.
# I scaled them to sum to 100
imp <- rpartfit$variable.importance
xvars <- attr(fit$terms, "term.labels")
implong <- imp[match(xvars, names(imp))]
names(implong) <- xvars
implong[is.na(implong)] <- 0
implong <- 100*implong/sum(implong)
if(ordered) {
ord <- order(implong)
} else {
ord <- rev(seq(implong))
}
if(plot) {
colz <- colr(seq(implong), "yellow", "blue")
barplot(implong[ord], horiz=horiz, col=col, xlab=xlab, las=las, ...)
}
implong
}
library(plotrix)
library(rpart)
wb <- loadWorkbook("C:/JVA/Consult/Stapanian/AmphibSens/amphibians_13FEB2014.xlsx")
dat <- readWorksheet(wb, sheet="Jean2")
names(dat) <- make.names(casefold(names(dat)), unique=T, allow_=F)
dat$spotwdn <- dat$spot.wdscore/10
dat$spotwdf <- as.factor(dat$spot.wdscore)
responsesn <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdn")
responses <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdf")
respnames <- c("Salamanders (# species)", "Sensitive  (% species)", "Tolerant  (% species)", "Amphibian Quality Assessment Index", 
"Presence of Wood F. or Spotted S.")
indeps <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", 
"water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")
indnames <- c("Oram 1", "Oram 2", "Oram 3", "Oram 4", "Oram 5", "Oram 6", "OVIBI", 
"LDI water", "LDI forest", "LDI wet. forest", "LDI wet. emergent", 
"LDI pasture", "LDI crop", "LDI suburban", "LDI transitional", "LDI rock", 
"LDI urban")
# other varz ... c("site.code", "ldi..1km.", "x.tolscore", "x.senscore")
# just for grins, develop one Y variable that encompasses all of the responses
pca <- princomp(dat[, responsesn], cor=TRUE)
Y <- pca$scores[, 1]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i])
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
saveimp[rev(order(apply(saveimp, 1, mean))), ]
x <- dat[, indeps]
y <- dat[, responsesn]
candidates <- list(c("metric4", "vibi.score"), 
c("metric4", "vibi.score"), 
c("metric4", "metric2"),
c("metric4", "metric3"),
c("metric4", "row.crop"))
# fit linear regression to the candidates variables
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
}
print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
chosen <- list(c("metric4", "vibi.score"), 
c("metric4"), 
c("metric4"),
c("metric4"),
c("metric4"))
# visualize the chosen variables
colz <- c("blue", "orange")
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 0, 0, 0))
for(i in (seq(responsesn))) {
if(i==1) {
plot(dat$metric4, y[, i], type="n", xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
for(j in 1:2) {
sel <- (dat$vibi.score < 60) == c(TRUE, FALSE)[j]
mycol <- colz[j]
points(dat$metric4[sel], jitter(y[sel, i]), cex=1.5, col=mycol)
lines(loess.smooth(dat$metric4[sel], y[sel, i], span=1, degree=2), col=mycol, lwd=2)
}
legend("topleft", paste("OVIBI", c("<", "\U2265"), "60"), col=colz, lwd=2)
} else {
if(i == 5) {
yy <- as.numeric(y[, i])-1
plot(dat$metric4, jitter(yy, factor=0.2), xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, yy, span=1, degree=2), lwd=2)
} else {
plot(dat$metric4, y[, i], xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, y[, i], span=1, degree=2), lwd=2)
}
}
}
mtext("ORAM 4", side=1, outer=TRUE, line=0.5)
dat[order(dat$metric4, Y), c("site.code", "metric4", "vibi.score", responses)]
fit
fit$terms
attr(fit$terms, "term.labels")
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray")
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
saveimp[rev(order(apply(saveimp, 1, mean))), ]
?barplot
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=indnames)
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
responsesn <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdn")
responses <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdf")
respnames <- c("Salamanders (# species)", "Sensitive  (% species)", "Tolerant  (% species)", "Amphibian Quality Assessment Index", 
"Presence of Wood F. or Spotted S.")
indeps <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", 
"water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")
indnames <- c("Oram 1", "Oram 2", "Oram 3", "Oram 4", "Oram 5", "Oram 6", "OVIBI", 
"LDI water", "LDI forest", "LDI wet. forest", "LDI wet. emergent", 
"LDI pasture", "LDI crop", "LDI suburban", "LDI transitional", "LDI rock", 
"LDI urban")
notthese <- c(1, 5, 15, 16)
indeps <- indeps[-notthese]
indnames <- indnames[-notthese]
# other varz ... c("site.code", "ldi..1km.", "x.tolscore", "x.senscore")
# just for grins, develop one Y variable that encompasses all of the responses
pca <- princomp(dat[, responsesn], cor=TRUE)
Y <- pca$scores[, 1]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=indnames)
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
saveimp[rev(order(apply(saveimp, 1, mean))), ]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=rev(indnames))
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
# C:\JVA\Consult\Stapanian\AmphibSens\Explore v3.r
# relevant emails:
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/1439c3834064343b
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/143baffe32131385
# 13 Mar 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/144bb971f5eca226
# objectives
# Find the best predictive model of the following responses
# using as independent variables the 6 ORAM metrics, OVIBI score, and the 10 LDI metrics.
# 1. number of salamander species (x.ssp) 
# 2. % sensitive species (x.sen)
# 3. % tolerant species (x.ol)
# 4. Amphibian Quality Assessment Index (aqai)
# 5. presence/absence of [wood frogs or spotted salamanders] (spot.wdscore, binary)
plotimp <- function(rpartfit, ordered=TRUE, plot=TRUE, horiz=TRUE, col=colz[ord], xlab="", las=1, ...) {
# calculate importance of variables
# http://cran.at.r-project.org/web/packages/rpart/vignettes/longintro.pdf
# importance = An overall measure of variable importance is the sum of the goodness of split
# measures for each split for which it was the primary variable, plus goodness * (adjusted
# agreement) for all splits in which it was a surrogate.
# I scaled them to sum to 100
imp <- rpartfit$variable.importance
xvars <- attr(fit$terms, "term.labels")
implong <- imp[match(xvars, names(imp))]
names(implong) <- xvars
implong[is.na(implong)] <- 0
implong <- 100*implong/sum(implong)
if(ordered) {
ord <- order(implong)
} else {
ord <- rev(seq(implong))
}
if(plot) {
colz <- colr(seq(implong), "yellow", "blue")
barplot(implong[ord], horiz=horiz, col=col, xlab=xlab, las=las, ...)
}
implong
}
library(plotrix)
library(rpart)
wb <- loadWorkbook("C:/JVA/Consult/Stapanian/AmphibSens/amphibians_13FEB2014.xlsx")
dat <- readWorksheet(wb, sheet="Jean2")
names(dat) <- make.names(casefold(names(dat)), unique=T, allow_=F)
dat$spotwdn <- dat$spot.wdscore/10
dat$spotwdf <- as.factor(dat$spot.wdscore)
responsesn <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdn")
responses <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdf")
respnames <- c("Salamanders (# species)", "Sensitive  (% species)", "Tolerant  (% species)", "Amphibian Quality Assessment Index", 
"Presence of Wood F. or Spotted S.")
indeps <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", 
"water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")
indnames <- c("ORAM 1", "ORAM 2", "ORAM 3", "ORAM 4", "ORAM 5", "ORAM 6", "OVIBI", 
"LDI water", "LDI forest", "LDI wet. forest", "LDI wet. emergent", 
"LDI pasture", "LDI crop", "LDI suburban", "LDI transitional", "LDI rock", 
"LDI urban")
notthese <- c(1, 5, 15, 16)
indeps <- indeps[-notthese]
indnames <- indnames[-notthese]
# other varz ... c("site.code", "ldi..1km.", "x.tolscore", "x.senscore")
# just for grins, develop one Y variable that encompasses all of the responses
pca <- princomp(dat[, responsesn], cor=TRUE)
Y <- pca$scores[, 1]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
### FIGURE 2 ###
windows(h=8, w=6.5)
par(mar=c(3, 5, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=rev(indnames))
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
par(mar=c(3, 8, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=rev(indnames))
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
responsesn <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdn")
responses <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdf")
respnames <- c("Salamanders (# species)", "Sensitive  (% species)", "Tolerant  (% species)", "Amphibian Quality Assessment Index", 
"Presence of Wood F. or Spotted S.")
respnames <- c("Pond-Breeding", "% Sensitive", "% Tolerant", "Amphibian QAI", "Presence of SS/WF")
indeps <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", 
"water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")
indnames <- c("ORAM 1", "ORAM 2", "ORAM 3", "ORAM 4", "ORAM 5", "ORAM 6", "OVIBI", 
"LDI water", "LDI forest", "LDI wet. forest", "LDI wet. emergent", 
"LDI pasture", "LDI crop", "LDI suburban", "LDI transitional", "LDI rock", 
"LDI urban")
notthese <- c(1, 5, 15, 16)
indeps <- indeps[-notthese]
indnames <- indnames[-notthese]
# other varz ... c("site.code", "ldi..1km.", "x.tolscore", "x.senscore")
# just for grins, develop one Y variable that encompasses all of the responses
pca <- princomp(dat[, responsesn], cor=TRUE)
Y <- pca$scores[, 1]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
### FIGURE 2 ###
windows(h=8, w=6.5)
par(mar=c(3, 8, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=rev(indnames))
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
saveimp[rev(order(apply(saveimp, 1, mean))), ]
x <- dat[, indeps]
y <- dat[, responsesn]
candidates <- list(c("metric4", "vibi.score"), 
c("metric4", "vibi.score"), 
c("metric4", "metric2"),
c("metric4", "metric3"),
c("metric4", "row.crop"))
# fit linear regression to the candidates variables
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
}
print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
chosen <- list(c("metric4", "vibi.score"), 
c("metric4"), 
c("metric4"),
c("metric4"),
c("metric4"))
# visualize the chosen variables
colz <- c("blue", "orange")
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 0, 0, 0))
for(i in (seq(responsesn))) {
if(i==1) {
plot(dat$metric4, y[, i], type="n", xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
for(j in 1:2) {
sel <- (dat$vibi.score < 60) == c(TRUE, FALSE)[j]
mycol <- colz[j]
points(dat$metric4[sel], jitter(y[sel, i]), cex=1.5, col=mycol)
lines(loess.smooth(dat$metric4[sel], y[sel, i], span=1, degree=2), col=mycol, lwd=2)
}
legend("topleft", paste("OVIBI", c("<", "\U2265"), "60"), col=colz, lwd=2)
} else {
if(i == 5) {
yy <- as.numeric(y[, i])-1
plot(dat$metric4, jitter(yy, factor=0.2), xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, yy, span=1, degree=2), lwd=2)
} else {
plot(dat$metric4, y[, i], xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, y[, i], span=1, degree=2), lwd=2)
}
}
}
mtext("ORAM 4", side=1, outer=TRUE, line=0.5)
# visualize the chosen variables
colz <- c("blue", "orange")
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 0, 0, 0))
for(i in (seq(responsesn))) {
if(i==1) {
plot(dat$metric4, y[, i], type="n", xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
for(j in 1:2) {
sel <- (dat$vibi.score < 60) == c(TRUE, FALSE)[j]
mycol <- colz[j]
points(dat$metric4[sel], jitter(y[sel, i]), cex=1.5, col=mycol, pch=j)
lines(loess.smooth(dat$metric4[sel], y[sel, i], span=1, degree=2), col=mycol, lwd=2)
}
legend("topleft", paste("OVIBI", c("<", "\U2265"), "60"), col=colz, lwd=2)
} else {
if(i == 5) {
yy <- as.numeric(y[, i])-1
plot(dat$metric4, jitter(yy, factor=0.2), xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, yy, span=1, degree=2), lwd=2)
} else {
plot(dat$metric4, y[, i], xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, y[, i], span=1, degree=2), lwd=2)
}
}
}
mtext("ORAM 4", side=1, outer=TRUE, line=0.5)
dat[order(dat$metric4, Y), c("site.code", "metric4", "vibi.score", responses)]
graphics.off()
head(dat)
head(dat)
dat[order(dat$metric4, Y), c("site.code", "metric4", "vibi.score", responses)]
?cor
?cor.test
?corr.test
utils:::menuInstallPkgs()
library(psych)
?corr.test
corr.test(dat[, c("metric3", "metric4")], dat[, c("x.ssp", "x.sen")], adjust="non")
corr.test(dat[, c("metric3", "metric4")], dat[, c("x.ssp", "x.sen")], adjust="none")
corr.test(dat[, c("metric3", "metric4")], dat[, c("x.ssp", "x.sen")], adjust="bonferroni")
corm <- corr.test(dat[, c("metric3", "metric4")], dat[, c("x.ssp", "x.sen")], adjust="none")
corm
print(corm)
print(corm, short=FALSE)
names(corm)
names(print(corm, short=FALSE))
corm$r
corm$p
cbind(corm$r, corm$p)
corm <- corr.test(dat[, c("metric3", "metric4")], dat[, c("x.ssp", "x.sen")], adjust="none")
ncolz <- dim(corm$r)[[2]]
cbind(corm$r, corm$p)[, rep(1:ncolz, rep(2, ncolz))]
corm <- corr.test(dat[, indeps], dat[, responses[-5]], adjust="none")
ncolz <- dim(corm$r)[[2]]
cbind(corm$r, corm$p)[, rep(1:ncolz, rep(2, ncolz))]
round(cbind(corm$r, corm$p)[, rep(1:ncolz, rep(2, ncolz))])
round(cbind(corm$r, corm$p)[, rep(1:ncolz, rep(2, ncolz))], 2)
rep(1:ncolz, rep(2, ncolz))
c(1:ncolz, ncolz+(1:ncolz))
dim(corm)
corm
dim(corm$r)
ncolz
1:2*ncolz
1:(2*ncolz)
matrix(1:(2*ncolz), nrow=2)
unlist(matrix(1:(2*ncolz), nrow=2))
as.vector(matrix(1:(2*ncolz), nrow=2))
as.vector(matrix(1:(2*ncolz), nrow=2, byrow=TRUE))
corm <- corr.test(dat[, indeps], dat[, responses[-5]], adjust="none")
ncolz <- dim(corm$r)[[2]]
cbind(corm$r, corm$p)[, as.vector(matrix(1:(2*ncolz), nrow=2, byrow=TRUE))]
round(cbind(corm$r, corm$p)[, as.vector(matrix(1:(2*ncolz), nrow=2, byrow=TRUE))], 2)
cleanup()
q()
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("jvamisc")
setwd("C:/JVA/R/Working Directory")
library(jvamisc)
?plotcor
?capwords
# example using a symmetric matrix
sr <- cor(swiss)
sord <- plotcor(sr)
sr[sord[[1]], sord[[2]]]
# example using an asymmetric matrix
lr <- cor(longley)[1:3, 4:7]
lord <- plotcor(lr)
lr[lord[[1]], lord[[2]]]
sord <- plotcor(sr)
capwords(c("using AIC for model selection"))
capwords(c("using AIC", "for MODEL selection"), strict=FALSE)
cleanup()
# C:\JVA\Consult\Stapanian\AmphibSens\Explore v3.r
# relevant emails:
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/1439c3834064343b
# 22 Jan 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/143baffe32131385
# 13 Mar 2014 - https://mail.google.com/mail/u/0/?shva=1#inbox/144bb971f5eca226
# objectives
# Find the best predictive model of the following responses
# using as independent variables the 6 ORAM metrics, OVIBI score, and the 10 LDI metrics.
# 1. number of salamander species (x.ssp) 
# 2. % sensitive species (x.sen)
# 3. % tolerant species (x.ol)
# 4. Amphibian Quality Assessment Index (aqai)
# 5. presence/absence of [wood frogs or spotted salamanders] (spot.wdscore, binary)
plotimp <- function(rpartfit, ordered=TRUE, plot=TRUE, horiz=TRUE, col=colz[ord], xlab="", las=1, ...) {
# calculate importance of variables
# http://cran.at.r-project.org/web/packages/rpart/vignettes/longintro.pdf
# importance = An overall measure of variable importance is the sum of the goodness of split
# measures for each split for which it was the primary variable, plus goodness * (adjusted
# agreement) for all splits in which it was a surrogate.
# I scaled them to sum to 100
imp <- rpartfit$variable.importance
xvars <- attr(fit$terms, "term.labels")
implong <- imp[match(xvars, names(imp))]
names(implong) <- xvars
implong[is.na(implong)] <- 0
implong <- 100*implong/sum(implong)
if(ordered) {
ord <- order(implong)
} else {
ord <- rev(seq(implong))
}
if(plot) {
colz <- colr(seq(implong), "yellow", "blue")
barplot(implong[ord], horiz=horiz, col=col, xlab=xlab, las=las, ...)
}
implong
}
library(plotrix)
library(rpart)
wb <- loadWorkbook("C:/JVA/Consult/Stapanian/AmphibSens/amphibians_13FEB2014.xlsx")
dat <- readWorksheet(wb, sheet="Jean2")
names(dat) <- make.names(casefold(names(dat)), unique=T, allow_=F)
dat$spotwdn <- dat$spot.wdscore/10
dat$spotwdf <- as.factor(dat$spot.wdscore)
responsesn <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdn")
responses <- c("x.ssp", "x.sen", "x.tol", "aqai", "spotwdf")
respnames <- c("Salamanders (# species)", "Sensitive  (% species)", "Tolerant  (% species)", "Amphibian Quality Assessment Index", 
"Presence of Wood F. or Spotted S.")
respnames <- c("Pond-Breeding", "% Sensitive", "% Tolerant", "Amphibian QAI", "Presence of SS/WF")
indeps <- c("metric1", "metric2", "metric3", "metric4", "metric5", "metric6", "vibi.score", 
"water", "forest", "wtld.forest", "wtld.emerg", "pasture", "row.crop", "suburban", "transitional", "rock", "urban")
indnames <- c("ORAM 1", "ORAM 2", "ORAM 3", "ORAM 4", "ORAM 5", "ORAM 6", "OVIBI", 
"LDI water", "LDI forest", "LDI wet. forest", "LDI wet. emergent", 
"LDI pasture", "LDI crop", "LDI suburban", "LDI transitional", "LDI rock", 
"LDI urban")
notthese <- c(1, 5, 15, 16)
indeps <- indeps[-notthese]
indnames <- indnames[-notthese]
# other varz ... c("site.code", "ldi..1km.", "x.tolscore", "x.senscore")
# just for grins, develop one Y variable that encompasses all of the responses
pca <- princomp(dat[, responsesn], cor=TRUE)
Y <- pca$scores[, 1]
# apply trees to find the important variables
set.seed(367)
saveimp <- matrix(NA, nrow=length(indeps), ncol=length(responses), dimnames=list(indeps, responses))
### FIGURE 2 ###
windows(h=8, w=6.5)
par(mar=c(3, 8, 1.5, 1), mfrow=c(3, 2), oma=c(2, 3, 0, 0))
for(i in seq(responses)) {
xy <- cbind(y=dat[, responses[i]], dat[, indeps])
fit <- rpart(y ~ ., data=xy)
saveimp[, i] <- plotimp(fit, ordered=FALSE, xlim=c(0, 31), main=respnames[i], col="gray", names.arg=rev(indnames))
}
mtext("Importance", side=1, outer=TRUE, line=0.5)
mtext("Candidate predictors", side=2, outer=TRUE, line=1)
saveimp[rev(order(apply(saveimp, 1, mean))), ]
x <- dat[, indeps]
y <- dat[, responsesn]
candidates <- list(c("metric4", "vibi.score"), 
c("metric4", "vibi.score"), 
c("metric4", "metric2"),
c("metric4", "metric3"),
c("metric4", "row.crop"))
# fit linear regression to the candidates variables
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 2, 0, 0))
for(i in seq(responsesn)) {
if(i==5) {
fit <- glm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), family=binomial, data=dat)
} else {
fit <- lm(paste0("y[, i] ~ ", paste0(candidates[[i]], collapse=" + ")), data=dat)
}
print(summary(fit))
plot(fit$fitted, fit$resid, xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
abline(h=0, lty=2)
}
mtext("Predicted values", side=1, outer=TRUE, line=0.5)
mtext("Residuals", side=2, outer=TRUE, line=0.5)
chosen <- list(c("metric4", "vibi.score"), 
c("metric4"), 
c("metric4"),
c("metric4"),
c("metric4"))
# visualize the chosen variables
colz <- c("blue", "orange")
### FIGURE 3 ###
windows(h=8, w=6.5)
par(mar=c(3, 3, 1.5, 1), mfrow=c(3, 2), oma=c(2, 0, 0, 0))
for(i in (seq(responsesn))) {
if(i==1) {
plot(dat$metric4, y[, i], type="n", xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
for(j in 1:2) {
sel <- (dat$vibi.score < 60) == c(TRUE, FALSE)[j]
mycol <- colz[j]
points(dat$metric4[sel], jitter(y[sel, i]), cex=1.5, col=mycol, pch=j)
lines(loess.smooth(dat$metric4[sel], y[sel, i], span=1, degree=2), col=mycol, lwd=2)
}
legend("topleft", paste("OVIBI", c("<", "\U2265"), "60"), col=colz, lwd=2)
} else {
if(i == 5) {
yy <- as.numeric(y[, i])-1
plot(dat$metric4, jitter(yy, factor=0.2), xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, yy, span=1, degree=2), lwd=2)
} else {
plot(dat$metric4, y[, i], xlab="", ylab="", cex=1.5, las=1, main=respnames[i])
lines(loess.smooth(dat$metric4, y[, i], span=1, degree=2), lwd=2)
}
}
}
mtext("ORAM 4", side=1, outer=TRUE, line=0.5)
dat[order(dat$metric4, Y), c("site.code", "metric4", "vibi.score", responses)]
library(psych)
corm <- corr.test(dat[, indeps], dat[, responses[-5]], adjust="none")
ncolz <- dim(corm$r)[[2]]
cbind(corm$r, corm$p)[, as.vector(matrix(1:(2*ncolz), nrow=2, byrow=TRUE))]
windows(h=9, w=4.3)
ordz <- plotcor(corm$r, mar=c(0.1, 6, 4, 0.1))
corm$r[ordz[[1]], ordz[[2]]]
ordz <- plotcor(corm$r, mar=c(0.1, 6, 4, 0.1), atcex=0.5)
ordz <- plotcor(corm$r, mar=c(0.1, 6, 4, 0.1), atcex=1)
ordz <- plotcor(corm$r, mar=c(0.1, 6, 4, 0.1), atcex=.9)
r <- corm$r
dimnames(r) <- list(indnames, respnames[-5])
windows(h=9, w=4.3)
ordz <- plotcor(r, mar=c(0.1, 6, 4, 0.1), atcex=.9)
r[ordz[[1]], ordz[[2]]]
r <- corm$r
dimnames(r) <- list(indnames, respnames[-5])
windows(h=9, w=4.3)
ordz <- plotcor(r, mar=c(0.1, 8, 8, 0.1), atcex=.9)
r[ordz[[1]], ordz[[2]]]
cite(rpart)
cite("rpart")
citation("rpart")
3520-37-800
?plotcor
plotcor(cor(mtcars))
plotcor(cor(mtcars))
plotcor(cor(mtcars), mar=c(0.1, 3, 3, 0.1))
plotcor(cor(mtcars), mar=c(0.1, 4, 4, 0.1))
plotcorr
plotcor
cleanup()
search()
detach(5)
search()
url("https://github.com/JVAdams/jvamisc/blob/master/R/plotcor.r") 
ls()
a <- url("https://github.com/JVAdams/jvamisc/blob/master/R/plotcor.r") 
a
?url
?source
source("https://github.com/JVAdams/jvamisc/blob/master/R/plotcor.r") 
library(devtools)
source_url("https://github.com/JVAdams/jvamisc/blob/master/R/plotcor.r")
?source_url
ls()
source_url("https://gist.github.com/hadley/6872663/raw/hi.r")
cleanup()
library(jvamisc)
cleanup()
q()
walker <- 581
burke <- 497
n <- walker+burke
nsim <- 100
res <- rep(NA, nsim)
for(i in 1:nsim) {
res[i] <- sum(sample(0:1, n, TRUE))
}
res
hist(res)
hist(res)
abline(v=c(walker, burke), col="red")
hist(res/n)
abline(v=c(walker, burke)/n, col="red")
nsim <- 10000
res <- rep(NA, nsim)
for(i in 1:nsim) {
res[i] <- sum(sample(0:1, n, TRUE))
}
hist(res/n, nclass=25)
abline(v=c(walker, burke)/n, col="red")
table(res<burke)
mean(table(res<burke))
mean(res<burke)
nsim <- 100
res <- rep(NA, nsim)
for(i in 1:nsim) {
res[i] <- sum(sample(0:1, n, TRUE, prob=c(burke, walker)/n))
}
hist(res/n, nclass=25)
hist(res/n, nclass=25)
abline(v=0.5, col="red")
mean(res < 0.5)
nsim <- 10000
res <- rep(NA, nsim)
for(i in 1:nsim) {
res[i] <- sum(sample(0:1, n, TRUE, prob=c(burke, walker)/n))
}
hist(res/n, nclass=25)
abline(v=0.5, col="red")
mean(res < 0.5)
res < 0.5
sum(res < 0.5)
mean(res < 0.5*n)
q()
orderedx <- c(1, 1, 1, 1, 2, 6, 9, 100, 100, 100)
extremes=c(0, 100)
nconsec=2
his <- orderedx==extremes[2]
his
cumsum(his)
cumsum(his) > nconsec
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- cumsum(lo) <= nconsec
selnoh
selnohi
selnolo
lo
orderedx==extremes[1]
orderedx
orderedx <- c(0, 0, 0, 0, 2, 6, 9, 100, 100, 100)
extremes=c(0, 100)
nconsec=2
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- cumsum(lo) <= nconsec
lo
selnolo
keeponly <- function(orderedx, extremes=c(0, 100), nconsec=2) {
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- rev(cumsum(lo) <= nconsec)
selnolo & selnohi
}
keeponly(c(0, 0, 0, 0, 2, 6, 9, 100, 100, 100))
keeponly(c(0, 0, 2, 6, 9, 100, 100, 100))
cleanup()
# C:\JVA\Lamprey\ChemControl\Toxicity\LWCode.r - estimation of LC99.9 using automated Litchfield Wilcoxon (1959)
library(mgcv)
library(MASS)
library(tcltk)
###  functions  ###################################################################################################
probit <- function(prob) qnorm(prob)
inv.probit <- function(quan) pnorm(quan)
keeponly <- function(orderedx, extremes=c(0, 100), nconsec=2) {
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- rev(cumsum(lo) <= nconsec)
selnolo & selnohi
}
# corrected values from Litchfield and Wilcoxon Table 1
expected <- 1:49
corrected <- c(0.3, 0.7, 1.0, 1.3, 1.6, 2.0, 2.3, 2.6, 2.9, 3.2, 3.5, 3.8, 4.1, 4.4, 4.7, 4.9, 5.2, 5.5, 5.7, 6.0, 
6.2, 6.5, 6.7, 7.0, 7.2, 7.4, 7.6, 7.8, 8.1, 8.3, 8.4, 8.6, 8.8, 9.0, 9.2, 9.3, 9.5, 9.6, 9.8, 9.9, 10.0, 10.1, 
10.2, 10.3, 10.3, 10.4, 10.4, 10.4, 10.5)
expected.dif.5 <- abs(0.50 - expected/100)
correction <- corrected/100
fit.table1 <- gam(correction ~ s(expected.dif.5))
fill <- function (x) 
{
    y <- x
    last <- x[1]
    if (is.character(x)) {
        for (i in 2:length(x)) if (x[i] == "" | is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    else {
        for (i in 2:length(x)) if (is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    y
}
correct.val <- function(val) {
# given a value between 0 and 1, calculate a corrected value from Litchfield and Wilcoxon Table 1
correction <- predict(fit.table1, data.frame(expected.dif.5 = abs(0.5 - val)))
result1 <- ifelse(val < 0.5, correction, 1-correction)
result2 <- ifelse(val >= 0.01 & val <= 0.99, result1, val)
result2
}
rm(expected, corrected, expected.dif.5, correction)
chi.prop <- function(obs.prop, exp.prop, n) {
# chi squared value from observed and expected proportions and n
sum(n * (obs.prop - exp.prop)^2 / (exp.prop * (1 - exp.prop)))
}
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
y
}
startvals <- function(data) {
# define log10(lc50) and log10(lc999) starting values
fit <- lm(y ~ x, data=data)
lc50.1 <- -fit$coef[1]/fit$coef[2]
lc999.1 <- (probit(0.999) - fit$coef[1])/fit$coef[2]
sv <- c(lc50.1, lc999.1)
p <- pchi.from.LC(x=sv, data=data, list=F)
list(sv=sv, p=p)
}
LC <- function(pct, b0=int, b1=slope) {
as.numeric(10^( (probit(pct/100) - b0) / b1 ))
}
rawdat <- read.csv(C:/JVA/Lamprey/ChemControl/Toxicity/RawToxTestData424and501.csv, as.is=TRUE)
rawdat2 <- data.frame(lapply(rawdat, fill))
sut <- sort(unique(rawdat2$Test.ID))
i <- 1
sel <- rawdat2$Test.ID==sut[i]
dose=rawdat2$TFM.Conc...mg.L.[sel]
ndead=rawdat2$No..Dead[sel]
ntot=rawdat2$No..Tested[sel]
description=with(rawdat2[sel, ], paste(Test.ID, Source, Batch, Species))[1]
rawdat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/RawToxTestData424and501.csv", as.is=TRUE)
rawdat2 <- data.frame(lapply(rawdat, fill))
sut <- sort(unique(rawdat2$Test.ID))
i <- 1
sel <- rawdat2$Test.ID==sut[i]
dose=rawdat2$TFM.Conc...mg.L.[sel]
ndead=rawdat2$No..Dead[sel]
ntot=rawdat2$No..Tested[sel]
description=with(rawdat2[sel, ], paste(Test.ID, Source, Batch, Species))[1]
### A. The data and graph.
# A 1. Don't list > 2 consecutive 100% effects at the upper end or > 2 consecutive 0% effects at the lower end.
df <- data.frame(dose=dose, ndead=ndead, ntot=ntot)
df$nalive <- df$ntot - df$ndead
df$pdead <- df$ndead/df$ntot
df <- df[order(df$dose, df$pdead), ]
# get rid of any zero dosages (controls)
df <- df[df$dose > 0, ]
# get rid of consecutives ...
df2 <- df[keeponly(df$pdead), ]
# define three mortality categories, 0 for no dead, 100 for all dead, and 50 from any proportional mortality
df2$mcat <- rep(50, length(df2$pdead))
df2$mcat[df2$ntot==df2$nalive] <- 0
df2$mcat[df2$ntot==df2$ndead] <- 100
(var(df2$mcat) < 0.00000001 & df2$mcat[1] != 50) | dim(df2)[1] < 3)
(var(df2$mcat) < 0.00000001 & df2$mcat[1] != 50) | dim(df2)[1] < 3
# A 2. Plot doses against % effect on logarithmic-probability paper
df2$x <- log10(df2$dose)
df2$y <- probit(df2$pdead)
yr <- probit(c(0.001, 0.999))
df2$y[df2$pdead==0] <- yr[1]
df2$y[df2$pdead==1] <- yr[2]
# calculate starting values
pms <- sum(df2$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
df3 <- df2[df2$mcat==50, ]
svp <- startvals(df3)
}
# fit line to partial mortalities with last 0% and first 100%
if(pms==1 | is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][sum(df2$mcat==0), ], df2[df2$mcat==50, ], df2[df2$mcat==100, ][1, ])
svp <- startvals(df3)
}
# fit line to all the data
if(pms < 1 | is.na(svp$p)) {
svp <- startvals(df2)
}
# fit line to first 0% and last 100% alone
if(is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][1, ], df2[df2$mcat==100, ][sum(df2$mcat==100), ])
svp <- startvals(df3)
}
# B. 1., B. 2., and C. are all inside the function pchi.from.LC()
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
# C. The chi squared test
# find the LC50 and LC999 (on the log10 scale) that give the lowest p value for the chi-square
bestLC <- optim(par=svp$sv, fn=pchi.from.LC, data=df2)
estLCs <- bestLC$par
chi <- pchi.from.LC(estLCs, data=df2, list=T)
if(!is.na(chi$p) & chi$p < 0.05) print("Chi squared test indicates poor fit.")
rm(pms, svp, df3, bestLC)
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
LC25 <- LC(25)
LC50 <- LC(50)
LC50
as.numeric(10^estLCs[1])
N' <- 3
ls()
# L-W
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
# D. 1. Read from the line on the graph the dose for 16, 50, and 84% effects
LC16 <- LC(16)
LC50 <- LC(50) # same as 10^estLCs[1]
LC84 <- LC(84)
# D. 2. Calculate the slope function, S
S <- (LC84/LC50 + LC50/LC16) / 2
# D. 3. Obtain Nprime, the total number of animals tested at those doses with expected effects
LC84
df
df2
df2$dose > LC18 & df2$dose < LC84
df2$dose > LC16 & df2$dose < LC84
df2$ntot[df2$dose > LC16 & df2$dose < LC84]
sum(df2$ntot[df2$dose > LC16 & df2$dose < LC84])
=19/20
19/20
Nprime <- sum(df2$ntot[df2$dose > LC16 & df2$dose < LC84])
# D. 4. Calculate S to the exponent for the LC50
f50 <- S^(2.77/sqrt(Nprime))
# D. 5. Calculate the 95% confidence limits of the LC50 as
upper50 <- LC50 * f50
lower50 <- LC50 / f50
LC50
lower50
upper50
df2
rawdat
cleanup()
rawdat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/RawToxTestData424and501.csv", as.is=TRUE)
rawdat2 <- data.frame(lapply(rawdat, fill))
sut <- sort(unique(rawdat2$Test.ID))
sel <- rawdat2$Test.ID==4
dose=rawdat2$TFM.Conc...mg.L.[sel]
ndead=rawdat2$No..Dead[sel]
ntot=rawdat2$No..Tested[sel]
description=with(rawdat2[sel, ], paste(Test.ID, Source, Batch, Species))[1]
library(mgcv)
library(MASS)
library(tcltk)
###  functions  ###################################################################################################
probit <- function(prob) qnorm(prob)
inv.probit <- function(quan) pnorm(quan)
keeponly <- function(orderedx, extremes=c(0, 100), nconsec=2) {
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- rev(cumsum(lo) <= nconsec)
selnolo & selnohi
}
# corrected values from Litchfield and Wilcoxon Table 1
expected <- 1:49
corrected <- c(0.3, 0.7, 1.0, 1.3, 1.6, 2.0, 2.3, 2.6, 2.9, 3.2, 3.5, 3.8, 4.1, 4.4, 4.7, 4.9, 5.2, 5.5, 5.7, 6.0, 
6.2, 6.5, 6.7, 7.0, 7.2, 7.4, 7.6, 7.8, 8.1, 8.3, 8.4, 8.6, 8.8, 9.0, 9.2, 9.3, 9.5, 9.6, 9.8, 9.9, 10.0, 10.1, 
10.2, 10.3, 10.3, 10.4, 10.4, 10.4, 10.5)
expected.dif.5 <- abs(0.50 - expected/100)
correction <- corrected/100
fit.table1 <- gam(correction ~ s(expected.dif.5))
fill <- function (x) 
{
    y <- x
    last <- x[1]
    if (is.character(x)) {
        for (i in 2:length(x)) if (x[i] == "" | is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    else {
        for (i in 2:length(x)) if (is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    y
}
correct.val <- function(val) {
# given a value between 0 and 1, calculate a corrected value from Litchfield and Wilcoxon Table 1
correction <- predict(fit.table1, data.frame(expected.dif.5 = abs(0.5 - val)))
result1 <- ifelse(val < 0.5, correction, 1-correction)
result2 <- ifelse(val >= 0.01 & val <= 0.99, result1, val)
result2
}
rm(expected, corrected, expected.dif.5, correction)
chi.prop <- function(obs.prop, exp.prop, n) {
# chi squared value from observed and expected proportions and n
sum(n * (obs.prop - exp.prop)^2 / (exp.prop * (1 - exp.prop)))
}
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
y
}
startvals <- function(data) {
# define log10(lc50) and log10(lc999) starting values
fit <- lm(y ~ x, data=data)
lc50.1 <- -fit$coef[1]/fit$coef[2]
lc999.1 <- (probit(0.999) - fit$coef[1])/fit$coef[2]
sv <- c(lc50.1, lc999.1)
p <- pchi.from.LC(x=sv, data=data, list=F)
list(sv=sv, p=p)
}
LC <- function(pct, b0=int, b1=slope) {
as.numeric(10^( (probit(pct/100) - b0) / b1 ))
}
### A. The data and graph.
# A 1. Don't list > 2 consecutive 100% effects at the upper end or > 2 consecutive 0% effects at the lower end.
df <- data.frame(dose=dose, ndead=ndead, ntot=ntot)
df$nalive <- df$ntot - df$ndead
df$pdead <- df$ndead/df$ntot
df <- df[order(df$dose, df$pdead), ]
# get rid of any zero dosages (controls)
df <- df[df$dose > 0, ]
# get rid of consecutives ...
df2 <- df[keeponly(df$pdead), ]
# define three mortality categories, 0 for no dead, 100 for all dead, and 50 from any proportional mortality
df2$mcat <- rep(50, length(df2$pdead))
df2$mcat[df2$ntot==df2$nalive] <- 0
df2$mcat[df2$ntot==df2$ndead] <- 100
df2
(var(df2$mcat) < 0.00000001 & df2$mcat[1] != 50) | dim(df2)[1] < 3
# A 2. Plot doses against % effect on logarithmic-probability paper
df2$x <- log10(df2$dose)
df2$y <- probit(df2$pdead)
yr <- probit(c(0.001, 0.999))
df2$y[df2$pdead==0] <- yr[1]
df2$y[df2$pdead==1] <- yr[2]
# calculate starting values
pms <- sum(df2$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
df3 <- df2[df2$mcat==50, ]
svp <- startvals(df3)
}
# fit line to partial mortalities with last 0% and first 100%
if(pms==1 | is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][sum(df2$mcat==0), ], df2[df2$mcat==50, ], df2[df2$mcat==100, ][1, ])
svp <- startvals(df3)
}
# fit line to all the data
if(pms < 1 | is.na(svp$p)) {
svp <- startvals(df2)
}
# fit line to first 0% and last 100% alone
if(is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][1, ], df2[df2$mcat==100, ][sum(df2$mcat==100), ])
svp <- startvals(df3)
}
bestLC <- optim(par=svp$sv, fn=pchi.from.LC, data=df2)
estLCs <- bestLC$par
chi <- pchi.from.LC(estLCs, data=df2, list=T)
if(!is.na(chi$p) & chi$p < 0.05) print("Chi squared test indicates poor fit.")
rm(pms, svp, df3, bestLC)
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
# D. 1. Read from the line on the graph the dose for 16, 50, and 84% effects
LC16 <- LC(16)
LC50 <- LC(50) # same as 10^estLCs[1]
LC84 <- LC(84)
# D. 2. Calculate the slope function, S
S <- (LC84/LC50 + LC50/LC16) / 2
# D. 3. Obtain Nprime, the total number of animals tested at those doses with expected effects
#between 16 and 84%.
Nprime <- sum(df2$ntot[df2$dose > LC16 & df2$dose < LC84])
# D. 4. Calculate S to the exponent for the LC50
f50 <- S^(2.77/sqrt(Nprime))
# D. 5. Calculate the 95% confidence limits of the LC50 as
upper50 <- LC50 * f50
lower50 <- LC50 / f50
# E. Calculate the confidence limits of S ... 
### I'm skipping this step because it requires a Nomograph (no. 3) to estimate A
# F. Factors for significantly heterogeneous data ...
### I'm skipping this step
# G. Test for parallelism of two lines and estimate of relative potency
### I'm skipping this step
ls()
df2
chi
LC84
LC50
LC16
S
cleanup()
rawdat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/RawToxTestData424and501.csv", as.is=TRUE)
rawdat2 <- data.frame(lapply(rawdat, fill))
sut <- sort(unique(rawdat2$Test.ID))
sel <- rawdat2$Test.ID==4
dose=rawdat2$TFM.Conc...mg.L.[sel]
ndead=rawdat2$No..Dead[sel]
ntot=rawdat2$No..Tested[sel]
description=with(rawdat2[sel, ], paste(Test.ID, Source, Batch, Species))[1]
# C:\JVA\Lamprey\ChemControl\Toxicity\LWCode.r - estimation of LC99.9 using automated Litchfield Wilcoxon (1959)
library(mgcv)
library(MASS)
library(tcltk)
###  functions  ###################################################################################################
probit <- function(prob) qnorm(prob)
inv.probit <- function(quan) pnorm(quan)
keeponly <- function(orderedx, extremes=c(0, 100), nconsec=2) {
hi <- orderedx==extremes[2]
selnohi <- cumsum(hi) <= nconsec
lo <- rev(orderedx==extremes[1])
selnolo <- rev(cumsum(lo) <= nconsec)
selnolo & selnohi
}
# corrected values from Litchfield and Wilcoxon Table 1
expected <- 1:49
corrected <- c(0.3, 0.7, 1.0, 1.3, 1.6, 2.0, 2.3, 2.6, 2.9, 3.2, 3.5, 3.8, 4.1, 4.4, 4.7, 4.9, 5.2, 5.5, 5.7, 6.0, 
6.2, 6.5, 6.7, 7.0, 7.2, 7.4, 7.6, 7.8, 8.1, 8.3, 8.4, 8.6, 8.8, 9.0, 9.2, 9.3, 9.5, 9.6, 9.8, 9.9, 10.0, 10.1, 
10.2, 10.3, 10.3, 10.4, 10.4, 10.4, 10.5)
expected.dif.5 <- abs(0.50 - expected/100)
correction <- corrected/100
fit.table1 <- gam(correction ~ s(expected.dif.5))
fill <- function (x) 
{
    y <- x
    last <- x[1]
    if (is.character(x)) {
        for (i in 2:length(x)) if (x[i] == "" | is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    else {
        for (i in 2:length(x)) if (is.na(x[i])) 
            y[i] <- last
        else last <- x[i]
    }
    y
}
correct.val <- function(val) {
# given a value between 0 and 1, calculate a corrected value from Litchfield and Wilcoxon Table 1
correction <- predict(fit.table1, data.frame(expected.dif.5 = abs(0.5 - val)))
result1 <- ifelse(val < 0.5, correction, 1-correction)
result2 <- ifelse(val >= 0.01 & val <= 0.99, result1, val)
result2
}
rm(expected, corrected, expected.dif.5, correction)
chi.prop <- function(obs.prop, exp.prop, n) {
# chi squared value from observed and expected proportions and n
sum(n * (obs.prop - exp.prop)^2 / (exp.prop * (1 - exp.prop)))
}
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
y
}
startvals <- function(data) {
# define log10(lc50) and log10(lc999) starting values
fit <- lm(y ~ x, data=data)
lc50.1 <- -fit$coef[1]/fit$coef[2]
lc999.1 <- (probit(0.999) - fit$coef[1])/fit$coef[2]
sv <- c(lc50.1, lc999.1)
p <- pchi.from.LC(x=sv, data=data, list=F)
list(sv=sv, p=p)
}
LC <- function(pct, b0=int, b1=slope) {
as.numeric(10^( (probit(pct/100) - b0) / b1 ))
}
### A. The data and graph.
# A 1. Don't list > 2 consecutive 100% effects at the upper end or > 2 consecutive 0% effects at the lower end.
df <- data.frame(dose=dose, ndead=ndead, ntot=ntot)
df$nalive <- df$ntot - df$ndead
df$pdead <- df$ndead/df$ntot
df <- df[order(df$dose, df$pdead), ]
# get rid of any zero dosages (controls)
df <- df[df$dose > 0, ]
# get rid of consecutives ...
df2 <- df[keeponly(df$pdead), ]
# define three mortality categories, 0 for no dead, 100 for all dead, and 50 from any proportional mortality
df2$mcat <- rep(50, length(df2$pdead))
df2$mcat[df2$ntot==df2$nalive] <- 0
df2$mcat[df2$ntot==df2$ndead] <- 100
# if we have < 3 observations or we only have all dead or all survive, we can't estimate LCs
if((var(df2$mcat) < 0.00000001 & df2$mcat[1] != 50) | dim(df2)[1] < 3) {
estLCs <- NA
chi <- NA
} else {
# A 2. Plot doses against % effect on logarithmic-probability paper
df2$x <- log10(df2$dose)
df2$y <- probit(df2$pdead)
yr <- probit(c(0.001, 0.999))
df2$y[df2$pdead==0] <- yr[1]
df2$y[df2$pdead==1] <- yr[2]
# calculate starting values
pms <- sum(df2$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
df3 <- df2[df2$mcat==50, ]
svp <- startvals(df3)
}
# fit line to partial mortalities with last 0% and first 100%
if(pms==1 | is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][sum(df2$mcat==0), ], df2[df2$mcat==50, ], df2[df2$mcat==100, ][1, ])
svp <- startvals(df3)
}
# fit line to all the data
if(pms < 1 | is.na(svp$p)) {
svp <- startvals(df2)
}
# fit line to first 0% and last 100% alone
if(is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][1, ], df2[df2$mcat==100, ][sum(df2$mcat==100), ])
svp <- startvals(df3)
}
# B. 1., B. 2., and C. are all inside the function pchi.from.LC()
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
# C. The chi squared test
# find the LC50 and LC999 (on the log10 scale) that give the lowest p value for the chi-square
bestLC <- optim(par=svp$sv, fn=pchi.from.LC, data=df2)
estLCs <- bestLC$par
chi <- pchi.from.LC(estLCs, data=df2, list=T)
if(!is.na(chi$p) & chi$p < 0.05) print("Chi squared test indicates poor fit.")
rm(pms, svp, df3, bestLC)
}
# L-W
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
# D. 1. Read from the line on the graph the dose for 16, 50, and 84% effects
LC16 <- LC(16)
LC50 <- LC(50) # same as 10^estLCs[1]
LC84 <- LC(84)
# D. 2. Calculate the slope function, S
S <- (LC84/LC50 + LC50/LC16) / 2
# D. 3. Obtain Nprime, the total number of animals tested at those doses with expected effects
#between 16 and 84%.
Nprime <- sum(df2$ntot[df2$dose > LC16 & df2$dose < LC84])
# D. 4. Calculate S to the exponent for the LC50
f50 <- S^(2.77/sqrt(Nprime))
# D. 5. Calculate the 95% confidence limits of the LC50 as
upper50 <- LC50 * f50
lower50 <- LC50 / f50
# E. Calculate the confidence limits of S ... 
### I'm skipping this step because it requires a Nomograph (no. 3) to estimate A
# F. Factors for significantly heterogeneous data ...
### I'm skipping this step
# G. Test for parallelism of two lines and estimate of relative potency
### I'm skipping this step
chi
LC84
LC50
LC16
S
Nprime
lower50
upper50
df2
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
print(data.frame(data, expected, cor.exp)
y
}
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
print(data.frame(data, expected, cor.exp))
y
}
pchi.from.LC(estLCs, data=df2, list=T)
o <- 50 
e <- 67
(o - e) / e^2
0.67*4
chi
search()
ls(7)
jvamisc:::chi
chi.n <- function(obs.n, exp.n) {
# chi squared value from observed and expected numbers
(obs.n - exp.n)^2 / (exp.n)
}
data
df
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
#chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
look <- chi.n(data$pdead*data$ntot)[sel], (cor.exp*data$ntot)[sel])
chi. <- sum(look)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
print(data.frame(data, expected, cor.exp))
y
}
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
#chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
look <- chi.n((data$pdead*data$ntot)[sel], (cor.exp*data$ntot)[sel])
chi. <- sum(look)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
print(data.frame(data, expected, cor.exp))
y
}
### A. The data and graph.
# A 1. Don't list > 2 consecutive 100% effects at the upper end or > 2 consecutive 0% effects at the lower end.
df <- data.frame(dose=dose, ndead=ndead, ntot=ntot)
df$nalive <- df$ntot - df$ndead
df$pdead <- df$ndead/df$ntot
df <- df[order(df$dose, df$pdead), ]
# get rid of any zero dosages (controls)
df <- df[df$dose > 0, ]
# get rid of consecutives ...
df2 <- df[keeponly(df$pdead), ]
# define three mortality categories, 0 for no dead, 100 for all dead, and 50 from any proportional mortality
df2$mcat <- rep(50, length(df2$pdead))
df2$mcat[df2$ntot==df2$nalive] <- 0
df2$mcat[df2$ntot==df2$ndead] <- 100
# if we have < 3 observations or we only have all dead or all survive, we can't estimate LCs
if((var(df2$mcat) < 0.00000001 & df2$mcat[1] != 50) | dim(df2)[1] < 3) {
estLCs <- NA
chi <- NA
} else {
# A 2. Plot doses against % effect on logarithmic-probability paper
df2$x <- log10(df2$dose)
df2$y <- probit(df2$pdead)
yr <- probit(c(0.001, 0.999))
df2$y[df2$pdead==0] <- yr[1]
df2$y[df2$pdead==1] <- yr[2]
# calculate starting values
pms <- sum(df2$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
df3 <- df2[df2$mcat==50, ]
svp <- startvals(df3)
}
# fit line to partial mortalities with last 0% and first 100%
if(pms==1 | is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][sum(df2$mcat==0), ], df2[df2$mcat==50, ], df2[df2$mcat==100, ][1, ])
svp <- startvals(df3)
}
# fit line to all the data
if(pms < 1 | is.na(svp$p)) {
svp <- startvals(df2)
}
# fit line to first 0% and last 100% alone
if(is.na(svp$p)) {
df3 <- rbind(df2[df2$mcat==0, ][1, ], df2[df2$mcat==100, ][sum(df2$mcat==100), ])
svp <- startvals(df3)
}
# B. 1., B. 2., and C. are all inside the function pchi.from.LC()
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
# C. The chi squared test
# find the LC50 and LC999 (on the log10 scale) that give the lowest p value for the chi-square
bestLC <- optim(par=svp$sv, fn=pchi.from.LC, data=df2)
estLCs <- bestLC$par
chi <- pchi.from.LC(estLCs, data=df2, list=T)
if(!is.na(chi$p) & chi$p < 0.05) print("Chi squared test indicates poor fit.")
rm(pms, svp, df3, bestLC)
}
# L-W
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
# D. 1. Read from the line on the graph the dose for 16, 50, and 84% effects
LC16 <- LC(16)
LC50 <- LC(50) # same as 10^estLCs[1]
LC84 <- LC(84)
# D. 2. Calculate the slope function, S
S <- (LC84/LC50 + LC50/LC16) / 2
# D. 3. Obtain Nprime, the total number of animals tested at those doses with expected effects
#between 16 and 84%.
Nprime <- sum(df2$ntot[df2$dose > LC16 & df2$dose < LC84])
# D. 4. Calculate S to the exponent for the LC50
f50 <- S^(2.77/sqrt(Nprime))
# D. 5. Calculate the 95% confidence limits of the LC50 as
upper50 <- LC50 * f50
lower50 <- LC50 / f50
# E. Calculate the confidence limits of S ... 
### I'm skipping this step because it requires a Nomograph (no. 3) to estimate A
# F. Factors for significantly heterogeneous data ...
### I'm skipping this step
# G. Test for parallelism of two lines and estimate of relative potency
### I'm skipping this step
pchi.from.LC <- function(x, data, list=F) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- x[1]
LC999 <- x[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- inv.probit(int + slope*data$x)
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | data$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(data$mcat==50, expected, correct.val(expected))
if(n > 2) {
### C. The chi squared test
#chi. <- chi.prop(data$pdead[sel], cor.exp[sel], n)
look <- chi.n((data$pdead*data$ntot)[sel], (cor.exp*data$ntot)[sel])
chi. <- sum(look)
p. <- 1-pchisq(chi., n-2)
} else {
chi. <- NA
p. <- NA
}
# save the p value as a negative for minimization by optim()
if(list) y <- list(chi2=chi., p=p., df=n-2) else y <- -p.
looky <- data.frame(data, expected, cor.exp)
looky$chicont <- NA
looky$chicont[sel] <- look
print(looky)
y
}
pchi.from.LC(estLCs, data=df2, list=T)
.065*8
cleanup()
q()
??contour
# C:\JVA\Lamprey\ChemControl\Toxicity\nomogram.r
epct <- rep(c(50, 95, 99), rep(3, 3))
omepct <- c(50, 30, 20, 30, 10, 5, 10, 5, 2)
chicontdivn <- c(1, .35, .16, 1.9, .22, .052, 1, .25, .04)
library(lattice)
contourplot(chicontdivn ~ epct + omepct)
# C:\JVA\Lamprey\ChemControl\Toxicity\nomogram.r
epct <- rep(c(50, 95, 99), rep(3, 3))
omepct <- c(50, 30, 20, 30, 10, 5, 10, 5, 2)
chicontdivn <- c(1, .35, .16, 1.9, .22, .052, 1, .25, .04)
n <- 8
e <- n*epct
op <- omepct + epct
o <- n*opct
mycont <- (o - e)^2/e
mycontdivn <- mycont/n
cbind(o, e, mycont, mycontdivn, op, epct, chicontdivn)
ep <- rep(c(50, 95, 99), rep(3, 3))
omepct <- c(50, 30, 20, 30, 10, 5, 10, 5, 2)
chicontdivn <- c(1, .35, .16, 1.9, .22, .052, 1, .25, .04)
n <- 8
e <- n*ep
op <- omepct + ep
o <- n*op
mycont <- (o - e)^2/e
mycontdivn <- mycont/n
cbind(o, e, mycont, mycontdivn, op, ep, chicontdivn)
ep <- rep(c(50, 95, 99), rep(3, 3))
omepct <- c(50, 30, 20, 30, 10, 5, 10, 5, 2)
chicontdivn <- c(1, .35, .16, 1.9, .22, .052, 1, .25, .04)
n <- 8
e <- n*ep/100
op <- omepct + ep
o <- n*op/100
mycont <- (o - e)^2/e
mycontdivn <- mycont/n
cbind(o, e, mycont, mycontdivn, op, ep, chicontdivn)
plot(mycontdivn, chicontdivn)
library(Design)
utils:::menuInstallPkgs()
A <- 1:10
C <- 1:10
B <- A + C
windows()
plot(0:1, 0:1, type="n", xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-5)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-10)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-5)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-10)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(0.1, 4))
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-5)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-10)
?axis
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4))
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A, line=-3)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-8)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-13)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A, line=-3)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-8)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-13)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=seq(0, 1, length=length(A)), labels=A, line=-3)
axis(2, at=seq(0, 1, length=length(B)), labels=B, line=-13)
axis(2, at=seq(0, 1, length=length(C)), labels=C, line=-23)
ep2 <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1 <- rev(100-ep2)
chicont <- 
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005), seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005),  seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.005),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
length(ep2)
length(chicont)
ep1
rescale
library(plotrix)
rescale
# labels
ep2 <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1 <- rev(100-ep2)
opmep <- ep1[-(1:6)]
chicont <- 
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005), seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005),  seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.005),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
length(ep2)
length(chicont)
# scales
A <- log(ep1)
C <- log(chicont)
Br <- range(A) + range(C)
library(plotrix)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=A, labels=ep1, line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=opmep, line=-13)
axis(2, at=C, labels=chicont, line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=ep1, line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=opmep, line=-13)
axis(2, at=rescale(C, 0:1), labels=chicont, line=-23)
ep1
as.character(ep1)
ep2
as.character(ep2)
?fuzzy
??fuzzy
round(ep1, 2)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep1), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-5)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-5, tick=FALSE, adj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-7, tick=FALSE, adj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
?axis
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-7, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-4, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
# labels
ep2 <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1 <- rev(100-ep2)
opmep <- ep1[-(1:6)]
chicont <- 
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
length(ep2)
length(chicont)
# scales
A <- log(ep1)
C <- log(chicont)
Br <- range(A) + range(C)
library(plotrix)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(A, 0:1), labels=round(rev(ep2), 2), line=-3)
axis(2, at=rescale(A, 0:1), labels=round(ep1, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=round(opmep, 3), line=-13)
axis(2, at=rescale(C, 0:1), labels=round(chicont, 4), line=-23)
# ticks
ep2 <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1 <- rev(100-ep2)
opmep <- ep1[-(1:6)]
chicont <- 
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
# labels
ep2l <- c(50, 70, 80, 90, 95, 97, 98, 99, seq(99.5, 99.9, 0.1), 99.95, 99.96, 99.97, 99.98)
ep1l <- rev(100-ep2l)
opmepl <- ep1l[-(1:3)]
chicontl <- c(seq(0.001, 0.005, 0.001), seq(0.01, 0.05, 0.01), seq(0.1, 0.5, 0.1), 1, 2)
# scales
A <- log(ep1)
C <- log(chicont)
Br <- range(A) + range(C)
library(plotrix)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=FALSE, line=-13)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmepl), Br), 0:1), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23, lwd=2)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=FALSE, line=-13)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23, tck=0.01)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmepl), Br), 0:1), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23, lwd.ticks=2)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=FALSE, line=-13)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmepl), Br), 0:1), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23, lwd.ticks=2)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(rescale(log(opmep), Br), 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(rescale(log(opmepl), Br), 0:1), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
range(A)
range(B)
range(C)
range(A) + range(C)
Br
exp(range(A))
exp(Br)
exp(range(B))
exp(range(C))
?rescale
Br
diff(Br)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=(log(opmep)-Br[1])/diff(Br), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log(opmepl)-Br[1])/diff(Br), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
# scales
A <- log(ep1)
C <- log(chicont)
Br <- (range(A) + range(C)) / 2
library(plotrix)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# ticks
axis(2, at=rescale(A, 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=(log(opmep)-Br[1])/diff(Br), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(C, 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log(opmepl)-Br[1])/diff(Br), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
c(0.001, 0.2)
a <- c(0.001, 0.2)
pretty(a)
pretty(log10(a))
10^pretty(log10(a))
?pretty
axisTicks(c(0.001, 0.2), TRUE)
axisTicks(c(0.001, 0.2), FALSE)
axisTicks(log(c(0.001, 0.2)), TRUE)
Br
exp(Br)
cleanup()
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log(opmep), TRUE, nint=15)
chicontl <- axisTicks(log(chicont), TRUE, nint=15)
# scales
A <- log(ep1)
C <- log(chicont)
B <- (A + C) / 2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
rescale(log(ep1l), 0:1)
ep1l
ep2
ep1
ep2l
log(ep2)
axisTicks(log(ep2), TRUE)
ep2
axisTicks(ep2, TRUE)
plot(10*(0:10), log = "y"); (pu <- par("usr"))
aX(2, print(ya <- axisTicks(pu[3:4], log = TRUE)))  # y axis
##--- Demonstrating correspondence between graphics'
##--- axis() and the graphics-engine agnostic  axisTicks() :
require("graphics")
plot(10*(0:10)); (pu <- par("usr"))
aX <- function(side, at, ...)
    axis(side, at = at, labels = FALSE, lwd.ticks = 2, col.ticks = 2,
         tck = 0.05, ...)
aX(1, print(xa <- axisTicks(pu[1:2], log = FALSE)))  # x axis
aX(2, print(ya <- axisTicks(pu[3:4], log = FALSE)))  # y axis
axisTicks(pu[3:4], log = FALSE, n = 10)
plot(10*(0:10), log = "y"); (pu <- par("usr"))
aX(2, print(ya <- axisTicks(pu[3:4], log = TRUE)))  # y axis
pu[3:4]
10*(0:10)
c(10, 100)
axisTicks(c(10, 100), TRUE)
axisTicks(log(c(10, 100)), TRUE)
axisTicks(log10(c(10, 100)), TRUE)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C) / 2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=25)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=25)
chicontl <- axisTicks(log10(chicont), TRUE, nint=25)
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C) / 2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- log10(chicont) / 2
B <- (A + C) / 2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + 2*C) / 2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- 2*log10(chicont)
B <- (A + C)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- 100*c(0.05, 50)
chicont <- 100*c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- axisTicks(log10(ep2), TRUE, nint=15)
ep1l <- rev(100-ep2l)
opmepl <- axisTicks(log10(opmep), TRUE, nint=15)
chicontl <- axisTicks(log10(chicont), TRUE, nint=15)
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C + 2)/2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
A
10^A
10^B
a0^C
10^C
axisTicks(log10(ep2), TRUE, nint=15)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep2l <- sort(unique(c(ep2, axisTicks(log10(ep2), TRUE, nint=15))))
ep1l <- rev(100-ep2l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=15))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C + 2)/2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=15))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C + 2)/2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- c(0.001, 0.2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C + 2)/2
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
axisTicks(log10(ep1), TRUE, nint=25)
axisTicks(log10(ep1), TRUE, nint=55)
axisTicks(log10(ep1), TRUE, nint=105)
axisTicks
A
B
C
10^A
10^B
10^C
0.001^2/0.02
.0447^/.02
.0447^2/.02
2^2/40
31.62^2/50
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- 2*c(0.05, 50)
chicont <- 100*c(0.001, 0.2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- 2*c(0.05, 50)
chicont <- 100*c(0.001, 0.2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- 2*c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmep <- B
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
B
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmep <- 10^B
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmep <- 10^(B/2)
opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmep <- 10^(B)
opmepl <- sort(unique(c(10^(B/2), axisTicks(log10(B/2), TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=(log10(opmepl)-B[1])/diff(B), labels=round(opmepl, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontl, 4), line=-23)
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
chicontladj <- chicontl/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmepl <- sort(unique(c(10^(B), axisTicks(log10(B), TRUE, nint=25))))
opmepladj <- sort(unique(c(10^(B/2), axisTicks(log10(B/2), TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(log10(opmepl), 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
axisTicks(log10(B), TRUE, nint=25)
B
opmepl <- sort(unique(c(10^(B), axisTicks(B, TRUE, nint=25))))
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=25))))
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=25))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=25))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=25))))
chicontladj <- chicontl/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmepl <- sort(unique(c(10^(B), axisTicks(B, TRUE, nint=25))))
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=25))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(log10(opmepl), 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
graphics.off()
cleanup()
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=15))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj <- chicontl/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmepl <- sort(unique(c(10^(B), axisTicks(B, TRUE, nint=15))))
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(log10(opmepl), 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
opmepl
opmepladj
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=15))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj <- chicontl/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl <- 2*log(opmepladj)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(log10(opmepl), 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
opmepladj
B
10^(B/2)
opmepl <- 2*log10(opmepladj)
opmepl
library(plotrix)
# ranges
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
#opmep <- c(0.05, 50)
chicont <- 100*c(0.001, 2)
# ticks/labels
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l <- rev(100-ep1l)
#opmepl <- sort(unique(c(opmep, axisTicks(log10(opmep), TRUE, nint=15))))
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj <- chicontl/100
# scales
A <- log10(ep1)
C <- log10(chicont)
B <- (A + C)
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl <- 2*log10(opmepladj)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
ep1l
opmepl
opmepladj
ep2l
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l <- rev(100-ep1l)
# label B using the observed - expected percentage scale
opmepladj <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl <- 2*log10(opmepladj)
# label C using the contrib/n scale
chicontl <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj <- chicontl/100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl/100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj.)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl/100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj.)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl./100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
chicontl
signif(chicontl, 1)
signif(chicontl, 1) - chicontl
signif(chicontl, 1) - chicontl == 0
mod(chicontl, 2)
chicontl %*% 2
chicontl %/% 2
bigtix <- function(x, fudge=10) {
onedigit <- signif(x, 1) - round(x, fudge) == 0
j1 <- (x %/% 1) == 0
j2 <- (x %/% 2) == 0
j5 <- (x %/% 5) == 0
onedigit & (j1 | j2 | j5)
}
ep2l
ep2l[bigtix(ep2l)]
bigtix(ep2l)
ep1l[bigtix(ep1l)]
bigtix(ep1l)
ep1l
x <- ep1l
fudge=10
onedigit <- signif(x, 1) - round(x, fudge) == 0
j1 <- (x %/% 1) == 0
j2 <- (x %/% 2) == 0
j5 <- (x %/% 5) == 0
onedigit
j1
?"%/%"
signif(x, 1)
scientific(signif(x, 1))
?format
format(signif(x, 1), sci=TRUE)
substring(format(signif(x, 1), sci=TRUE), 1, 1)
bigtix <- function(x, fudge=10, roundingto=c(1, 2, 5)) {
onedigit <- signif(x, 1) - round(x, fudge) == 0
gooddigit <- substring(format(signif(x, 1), sci=TRUE), 1, 1) %in% roundingto
onedigit & gooddigit
}
ep2l. <- ep1l[bigtix(ep1l)]
ep2l
ep2l.
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj.)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl./100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
bigtix <- function(x, fudge=10, roundingto=c(1, 2, 5)) {
onedigit <- signif(x, 1) - round(x, fudge) == 0
gooddigit <- substring(format(signif(x, 1), sci=TRUE), 1, 1) %in% roundingto
onedigit & gooddigit
}
ep1l. <- ep1l[bigtix(ep1l)]
ep2l. <- rev(100 - ep1l.)
opmepladj. <- opmepladj[bigtix(opmepladj)]
opmepl <- 2*log10(opmepladj)
chicontl. <- chicontl[bigtix(chicontl)]
chicontladj <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
ep1l. <- ep1l[bigtix(ep1l)]
ep2l. <- rev(100 - ep1l.)
opmepladj. <- opmepladj[bigtix(opmepladj)]
opmepl. <- 2*log10(opmepladj)
chicontl. <- chicontl[bigtix(chicontl)]
chicontladj. <- chicontl/100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
opmepl
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj.)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl./100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
bigtix <- function(x, fudge=10, roundingto=c(1, 2, 5)) {
onedigit <- signif(x, 1) - round(x, fudge) == 0
gooddigit <- substring(format(signif(x, 1), sci=TRUE), 1, 1) %in% roundingto
onedigit & gooddigit
}
ep1l. <- ep1l[bigtix(ep1l)]
ep2l. <- rev(100 - ep1l.)
opmepladj. <- opmepladj[bigtix(opmepladj)]
opmepl. <- 2*log10(opmepladj.)
chicontl. <- chicontl[bigtix(chicontl)]
chicontladj. <- chicontl./100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
ep1l. <- sort(unique(range(ep1l), ep1l[bigtix(ep1l)]))
ep2l. <- rev(100 - ep1l.)
opmepladj. <- sort(unique(range(opmepladj), opmepladj[bigtix(opmepladj)]))
opmepl. <- 2*log10(opmepladj.)
chicontl. <- sort(unique(range(chicontl), chicontl[bigtix(chicontl)]))
chicontladj. <- chicontl./100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
graphics.off()
cleanup()
# the nomogram consists of three vertical lines/scales: A, B, and C
library(plotrix)
# ranges of the A and C scales
# A is the expected percentage on the log scale, log10(ep)
ep2 <- c(50, 99.98)
ep1 <- rev(100-ep2)
A <- log10(ep1)
# C is 100 times the contribution to the chi-squared divided by n on the log scale, log10(100*contrib/n), where n is the total number
chicont <- 100*c(0.001, 2)
C <- log10(chicont)
# B is difference between the observed and expected percentage on the log scale times 2, 2*log10|op - ep|
B <- (A + C)
# contrib = (o - e)^2 / e
# 100*contrib/n = (op - ep)^2 / ep
# log10(100*contrib/n) = 2log10(op - ep) - log10(ep)
# log10(ep) + log10(100*contrib/n) = 2log10(op - ep)
# A + C = B
### ticks/labels
# use two sets of labels for the expected percentage
ep1l. <- sort(unique(c(ep1, axisTicks(log10(ep1), TRUE, nint=15))))
ep2l. <- rev(100-ep1l.)
# label B using the observed - expected percentage scale
opmepladj. <- sort(unique(c(10^(B/2), axisTicks(B/2, TRUE, nint=15))))
opmepl. <- 2*log10(opmepladj.)
# label C using the contrib/n scale
chicontl. <- sort(unique(c(chicont, axisTicks(log10(chicont), TRUE, nint=15))))
chicontladj. <- chicontl./100
ep2l <- c(
seq(50,     80,    5),    seq(82,    90,   2),    seq(91,    95,    1), 
seq(95.5,   98,    0.5),  seq(98.2,  99,   0.2),  seq(99.1,  99.5,  0.1),
seq(99.55,  99.8,  0.05), seq(99.82, 99.9, 0.02), seq(99.91, 99.95, 0.01), 
seq(99.955, 99.98, 0.005))
ep1l <- rev(100-ep2l)
opmepladj <- sort(unique(c(10^(B/2), 
seq(0.05, 0.1, 0.01), seq(0.12, 0.2, 0.02), seq(0.25, 0.5, 0.05),
seq(0.6, 1, 0.1), seq(1.2, 2, 0.2), seq(2.5, 5, 0.5),
seq(6, 10, 1), seq(12, 20, 2), seq(25, 50, 5),
seq(60, 100, 10))))
opmepl <- 2*log10(opmepladj)
chicontl <- 100*
c(seq(0.001, 0.002, 0.0002), seq(0.0025, 0.005, 0.0005),seq(0.006, 0.01, 0.001), 
seq(0.012, 0.02,  0.002),  seq(0.025,  0.05,  0.005), seq(0.06,  0.1,  0.01), 
seq(0.12,  0.2,   0.02),   seq(0.25,   0.5,   0.05),  seq(0.6,   1,    0.1), 
seq(1.2,   2,     0.2))
chicontladj <- chicontl/100
bigtix <- function(x, fudge=10, roundingto=c(1, 2, 5)) {
onedigit <- signif(x, 1) - round(x, fudge) == 0
gooddigit <- substring(format(signif(x, 1), sci=TRUE), 1, 1) %in% roundingto
onedigit & gooddigit
}
ep1l. <- sort(unique(range(ep1l), ep1l[bigtix(ep1l)]))
ep2l. <- rev(100 - ep1l.)
opmepladj. <- sort(unique(range(opmepladj), opmepladj[bigtix(opmepladj)]))
opmepl. <- 2*log10(opmepladj.)
chicontl. <- sort(unique(range(chicontl), chicontl[bigtix(chicontl)]))
chicontladj. <- chicontl./100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
ep1l. <- sort(unique(c(range(ep1l), ep1l[bigtix(ep1l)])))
ep2l. <- rev(100 - ep1l.)
opmepladj. <- sort(unique(c(range(opmepladj), opmepladj[bigtix(opmepladj)])))
opmepl. <- 2*log10(opmepladj.)
chicontl. <- sort(unique(c(range(chicontl), chicontl[bigtix(chicontl)])))
chicontladj. <- chicontl./100
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=rep(1, 4), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=c(1, 1, 3, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=2, line=-c(3, 13, 23))
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=2, line=-c(3, 13, 23), adj=0.8)
?mtext
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=2, line=-c(3, 13, 23), adj=0.5, padj=0.8)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=2, line=-c(3, 13, 23), adj=0.5, padj=8)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=2, line=-c(3, 13, 23), adj=0.5, padj=-25)
locator()
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(12, 51, 90))
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=c(1, 1, 3, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(12, 51, 90))
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.90))
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.90), line=2)
par(xaxs="i", yaxs="i", mar=c(1, 1, 2, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-13)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-23)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.90), line=1)
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=c(1, 1, 2, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-13, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-23, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-14)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-25)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.90), line=1)
locator()
windows(h=9, w=6.5)
par(xaxs="i", yaxs="i", mar=c(1, 1, 2, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-14, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-25, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-14)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-25)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.95), line=1)
par(xaxs="i", yaxs="i", mar=c(1, 1, 2, 1), las=1)
plot(0:1, 0:1, type="n", axes=FALSE, xlab="", ylab="")
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(rev(ep2l), 2), line=-3)
# axis(2, at=rescale(log10(ep1l), 0:1), labels=round(ep1l, 2), line=-5, tick=FALSE, hadj=0)
# axis(2, at=rescale(opmepl, 0:1), labels=round(opmepladj, 3), line=-13)
# axis(2, at=rescale(log10(chicontl), 0:1), labels=round(chicontladj, 4), line=-23)
# ticks
axis(2, at=rescale(log10(ep1l), 0:1), labels=FALSE, line=-3, tck=-0.01)
axis(2, at=rescale(opmepl, 0:1), labels=FALSE, line=-14, tck=-0.01)
axis(2, at=rescale(log10(chicontl), 0:1), labels=FALSE, line=-25, tck=-0.01)
# labels
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(rev(ep2l.), 2), line=-3)
axis(2, at=rescale(log10(ep1l.), 0:1), labels=round(ep1l., 2), line=-5, tick=FALSE, hadj=0)
axis(2, at=rescale(opmepl., 0:1), labels=round(opmepladj., 3), line=-14)
axis(2, at=rescale(log10(chicontl.), 0:1), labels=round(chicontladj., 4), line=-25)
mtext(c("Expected %", "Obs. - Exp. %", "Contrib. to Chi / n"), side=3, at=c(0.12, 0.51, 0.90), line=1)
x <- 1:100
lx <- log10(x)
llx <- log10(lx)
windows()
plot(x, lx)
plot(x, llx)
ls
lx
ep1l
x <- ep1l
lx <- log10(x)
lx
diff(lx)
llx <- log10(lx)
sx <- sqrt(x)
lsx <- log10(sx)
x
sx
lsx
plot(lsx, lsx, axes=FALSE)
axis(2, at=lsx, labels=x)
axis(2, at=lsx, labels=x, las=1)
plot(lsx, lsx, axes=FALSE)
axis(2, at=lsx, labels=x, las=1)
windows(h=9, w=6.5)
par(mar=c(1, 10, 1, 10))
plot(lsx, lsx, axes=FALSE)
axis(2, at=lsx, labels=x, las=1)
plot(lsx, lsx, axes=FALSE)
axis(2, at=lsx, labels=round(x, 4), las=1)
q()
# quit and restart R
# install from local folder
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("LW1949")
setwd("C:/JVA/R/Working Directory")
library(LW1949)
rawdat <- read.csv("C:/JVA/Lamprey/ChemControl/Toxicity/RawToxTestData424and501.csv", as.is=TRUE)
rawdat2 <- data.frame(lapply(rawdat, fill))
sut <- sort(unique(rawdat2$Test.ID))
sel <- rawdat2$Test.ID==4
dose=rawdat2$TFM.Conc...mg.L.[sel]
ndead=rawdat2$No..Dead[sel]
ntot=rawdat2$No..Tested[sel]
description=with(rawdat2[sel, ], paste(Test.ID, Source, Batch, Species))[1]
### A. The data and graph.
# A 1. Don't list > 2 consecutive 100% effects at the upper end or > 2 consecutive 0% effects at the lower end.
df <- data.frame(dose=dose, ndead=ndead, ntot=ntot)
df$nalive <- df$ntot - df$ndead
df$pdead <- df$ndead/df$ntot
df <- df[order(df$dose, df$pdead), ]
# get rid of any zero dosages (controls)
df <- df[df$dose > 0, ]
# get rid of consecutives ...
dfsub <- df[keeponly(df$pdead), ]
# define three mortality categories, 0 for no dead, 100 for all dead, and 50 from any proportional mortality
dfsub$mcat <- mcat(dfsub)
# A 2. Plot doses against % effect on logarithmic-probability paper
dfsub$x <- log10(dfsub$dose)
dfsub$y <- probit(dfsub$pdead)
yr <- probit(c(0.001, 0.999))
dfsub$y[dfsub$pdead==0] <- yr[1]
dfsub$y[dfsub$pdead==1] <- yr[2]
gamfit <- gamtable1()
# calculate starting values
pms <- sum(dfsub$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
dfpart <- dfsub[dfsub$mcat==50, ]
svp <- startvals(dfpart, gamfit)
}
#' Determine Starting Values for LC50\% and LC99.9\%
#'
#' Determine starting values for the LC50\% and LC99.9\% (both on the log10 scale).
#' @param dat A data frame of raw toxicity data, including these two variables:
#'ldose = dose (the concentration of the applied chemical on the log10 scale), 
#'and pbpdead, the proportion of dead individuals (on the probit scale, with 0s converted to 0.1\% and 1s converted to 99.9\%).
#' @param fitA model object that can be used to predict the corrected values (as proportions) from \code{distexpprop5}, 
#'the distance from the expected values (as proportions) and 0.5.  Typically the output from \code{\link{gamtable1}()}.
#' @return A list with two elements: sv, a numeric vector of length two giving the starting values for the LC50\% and LC99.9\%,
#'and p, a numeric scalar giving the P value of the associated chi-squared statistic.
#' @export
#' @examples 
#' test <- data.frame(
#' dose=c(0.0625, 0.125, 0.25, 0.5), 
#' ntot=rep(8, 4), 
#' pdead = c(0.125, 0.5, 0.5, 0.875))
#' test$ldose <- log10(test$dose)
#' test$pbpdead <- probit(test$pdead)
#' gamfit <- gamtable1()
#' startvals(test, gamfit)
startvals <- function(dat, fit) {
# define log10(lc50) and log10(lc999) starting values
fit <- lm(pbpdead ~ ldose, data=dat)
lc50.1 <- -fit$coef[1]/fit$coef[2]
lc999.1 <- (probit(0.999) - fit$coef[1])/fit$coef[2]
sv <- c(lc50.1, lc999.1)
p <- pchiLC(LCs=sv, dat=dat, fit, outlist=FALSE)
list(sv=sv, p=p)
}
# A 2. Plot doses against % effect on logarithmic-probability paper
dfsub$ldose <- log10(dfsub$dose)
dfsub$pbpdead <- probit(dfsub$pdead)
yr <- probit(c(0.001, 0.999))
dfsub$pbpdead[dfsub$pdead==0] <- yr[1]
dfsub$pbpdead[dfsub$pdead==1] <- yr[2]
gamfit <- gamtable1()
# calculate starting values
pms <- sum(dfsub$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
dfpart <- dfsub[dfsub$mcat==50, ]
svp <- startvals(dfpart, gamfit)
}
#' P Value of a Chi-Squared Statistic for a Does Response Curve
#'
#' Calculate the P value of the chi-squared statistic for a given dose response curve relating log dose to proportion affected on the 
#'probit scale.
#' @param LCs A numeric vector of estimated lethal concentrations on the log10 scale.  
#'The first element is the LC50\%, the second is the LC99.9\%.These two points define the does response curve.
#' @param dat A data frame of raw toxicity data, including these four variables:
#'dose (the concentration of the applied chemical), ntot (the number of individuals tested), pdead (the proportion of dead individuals), 
#'and mcat (mortality category =0 for none dead, =100 for all dead, and =50 for any partial mortality).
#' @param fitA model object that can be used to predict the corrected values (as proportions) from \code{distexpprop5}, 
#'the distance from the expected values (as proportions) and 0.5.  Typically the output from \code{\link{gamtable1}()}.
#' @param outlistA logical scalar indicating if the output should be a list or a scalar, default FALSE.
#' @return If \code{outlist=TRUE}, a list with three elements: chistat, a numeric scalar, the chi-squared statistic; 
#'pval, a numeric scalar, its associated P value; and df, an integer, the degrees of freedom of \code{chistat}.
#'If \code{outlist=FALSE}, a numeric scalar, the negative P value of the chi-squared statistic (see details).
#' @export
#' @detailsThis function is used as part of a routine that attempts to find the dose response curve that minimizes the 
#'P value from the chi-squared statistic measuring the distance between the observed and expected values.  
#' Following Litchfield and Wilcoxon (1949), records for any 0\% or 100\% dose with expected values < 0.01\% or > 99.99\% are deleted,
#'and expected values are corrected using the \code{\link{correctval}} function.
#' @seealso \code{\link{chi2}} and \code{\link{chisq.test}}.
#' @references J. T. Litchfield, Jr. and F. Wilcoxon.  1949. 
#' \href{http://jpet.aspetjournals.org/content/96/2/99.short}{A simplified method of evaluating dose-effect experiments}.
#' Journal of Pharmacology and Experimental Therapeutics 99(2):99-113.
#' @examples 
#' test <- data.frame(
#' dose=c(0.0625, 0.125, 0.25, 0.5), 
#' ntot=rep(8, 4), 
#' ndead = c(0, 4, 6, 8))
#' test$pdead <- test$ndead/test$ntot
#' test$mcat <- mcat(test)
#' gamfit <- gamtable1()
#' pchiLC(c(0.125, 0.5), test, gamfit)
pchiLC <- function(LCs, dat, fit, outlist=FALSE) {
# calculate chi squared value from given line (defined by log10 transform of the lc50 and lc999)
LC50 <- LCs[1]
LC999 <- LCs[2]
slope <- probit(0.999) / (LC999 - LC50)
int <- -slope*LC50
expected <- invprobit(int + slope*log10(dat$dose))
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
sel <- (expected >= 0.0001 & expected <= 0.9999) | dat$mcat==50
n <- sum(sel)
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
cor.exp <- ifelse(dat$mcat==50, expected, correctval(expected, fit))
if(n > 2) {
### C. The chi squared test
chilist <- chi2((dat$pdead*dat$ntot)[sel], (cor.exp*dat$ntot)[sel])
} else {
chilist <- list(chistat=NA, pval=NA, df=NA)
}
# save the p value as a negative for minimization by optim()
if(outlist) y <- chilist else y <- -chilist$pval
y
}
# A 2. Plot doses against % effect on logarithmic-probability paper
dfsub$ldose <- log10(dfsub$dose)
dfsub$pbpdead <- probit(dfsub$pdead)
yr <- probit(c(0.001, 0.999))
dfsub$pbpdead[dfsub$pdead==0] <- yr[1]
dfsub$pbpdead[dfsub$pdead==1] <- yr[2]
gamfit <- gamtable1()
# calculate starting values
pms <- sum(dfsub$mcat==50)
svp <- list(sv=c(NA, NA), p=NA)
# fit line to partial mortalities alone
if(pms > 1) {
dfpart <- dfsub[dfsub$mcat==50, ]
svp <- startvals(dfpart, gamfit)
}
# fit line to partial mortalities with last 0% and first 100%
if(pms==1 | is.na(svp$p)) {
dfpart <- rbind(dfsub[dfsub$mcat==0, ][sum(dfsub$mcat==0), ], dfsub[dfsub$mcat==50, ], dfsub[dfsub$mcat==100, ][1, ])
svp <- startvals(dfpart, gamfit)
}
# fit line to all the data
if(pms < 1 | is.na(svp$p)) {
svp <- startvals(dfsub, gamfit)
}
# fit line to first 0% and last 100% alone
if(is.na(svp$p)) {
dfpart <- rbind(dfsub[dfsub$mcat==0, ][1, ], dfsub[dfsub$mcat==100, ][sum(dfsub$mcat==100), ])
svp <- startvals(dfpart)
}
# B. 1., B. 2., and C. are all inside the function pchiLC()
# B. 1. If the expected value for any 0% or 100% dose is < 0.01% or > 99.99%, delete record
# B. 2. Using the expected effect, record a corrected value for each 0 and 100% effect
# C. The chi squared test
# find the LC50 and LC999 (on the log10 scale) that give the lowest p value for the chi-square
bestLC <- optim(par=svp$sv, fn=pchiLC, data=dfsub)
estLCs <- bestLC$par
chi <- pchiLC(estLCs, data=dfsub, list=T)
if(!is.na(chi$p) & chi$p < 0.05) warning("Chi squared test indicates poor fit.")
bestLC <- optim(par=svp$sv, fn=pchiLC, dat=dfsub, fit=gamfit)
estLCs <- bestLC$par
chi <- pchiLC(estLCs, data=dfsub, list=T)
if(!is.na(chi$p) & chi$p < 0.05) warning("Chi squared test indicates poor fit.")
bestLC <- optim(par=svp$sv, fn=pchiLC, dat=dfsub, fit=gamfit)
estLCs <- bestLC$par
chi <- pchiLC(estLCs, dat=dfsub, fit=gamfit, outlist=TRUE)
if(!is.na(chi$pval) & chi$pval < 0.05) warning("Chi squared test indicates poor fit.")
bestLC <- optim(par=svp$sv, fn=pchiLC, dat=dfsub, fit=gamfit)
estLCs <- bestLC$par
chi <- pchiLC(estLCs, dat=dfsub, fit=gamfit, outlist=TRUE)
if(!is.na(chi$pval) & chi$pval < 0.05) warning("Chi squared test indicates poor fit.")
rm(pms, svp, dfpart, bestLC)
slope <- as.numeric(probit(0.999) / (estLCs[2] - estLCs[1]))
int <- -slope*estLCs[1]
# D. 1. Read from the line on the graph the dose for 16, 50, and 84% effects
LC16 <- LC(16, b0=int, b1=slope)
LC50 <- LC(50, b0=int, b1=slope) # same as 10^estLCs[1]
LC84 <- LC(84, b0=int, b1=slope)
# D. 2. Calculate the slope function, S
S <- (LC84/LC50 + LC50/LC16) / 2
# D. 3. Obtain Nprime, the total number of animals tested at those doses with expected effects
#between 16 and 84%.
Nprime <- sum(dfsub$ntot[dfsub$dose > LC16 & dfsub$dose < LC84])
# D. 4. Calculate S to the exponent for the LC50
f50 <- S^(2.77/sqrt(Nprime))
# D. 5. Calculate the 95% confidence limits of the LC50 as
upper50 <- LC50 * f50
lower50 <- LC50 / f50
cleanup()
q()
# quit and restart R
# install from local folder
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("artiFISHal")
setwd("C:/JVA/R/Working Directory")
library(artiFISHal)
?artiFISHal
q()
# quit and restart R
# install from local folder
library(devtools)
library(roxygen2)
setwd("C:/JVA/GitHub")
install("LW1949")
setwd("C:/JVA/R/Working Directory")
library(LW1949)
?LW1949
cleanup()
q()
#' Install a Package
#'
#' Install a package from local files, load the library, and save installed package to zip archive.
#' @param package A character scalar, package name.
#' @param wd A character scalar, R working directory, default "C:/JVA/R/Working Directory".
#' @param ld A character scalar, R library directory, default "C:/Users/jvadams/Documents/R/win-library/3.1".
#' @param pd A character scalar, R package directory, default "C:/JVA/GitHub".
#' @importdevtools roxygen2
#' @export
#' @seealso\code{\link{pkgup}}
pkgin <- function(package, wd="C:/JVA/R/Working Directory", ld="C:/Users/jvadams/Documents/R/win-library/3.1", pd="C:/JVA/GitHub") {
# install from local folder
setwd(pd)
install(package)
# load the package
setwd(wd)
library(package, character.only=TRUE)
# save installed package to zip archive
zip(paste0(pd, "/", package, "/", package, ".zip"), paste0(ld, "/", package))
}
pkgin("jvamisc")
library(devtools)
library(roxygen2)
pkgin("jvamisc")
search()
?pkgin
pkg
getwd()
pkg <- "jvamisc"
pkgup(pkg)
q()
